wandb: Currently logged in as: thomas-borsani1. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_155034-83n4je09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-valley-51
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/83n4je09
########## Class: PDNetwork
PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 23
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31.7
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
An error occurred: 'numpy.float64' object cannot be interpreted as an integer

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
An error occurred: [Errno 2] No such file or directory: 'network/CNNetwork23.pth'
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.007 MB of 0.012 MB uploadedwandb: / 0.012 MB of 0.012 MB uploadedwandb: ğŸš€ View run summer-valley-51 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/83n4je09
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_155034-83n4je09/logs
wandb: Currently logged in as: thomas-borsani1. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_155635-p5upjzop
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-silence-52
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/p5upjzop
wandb: - 0.008 MB of 0.014 MB uploaded (0.002 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.002 MB deduped)wandb: | 0.014 MB of 0.014 MB uploaded (0.002 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 11.4%             
wandb: 
wandb: Run history:
wandb:            LR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–
wandb:          Loss â–‚â–‚â–„â–ˆâ–ƒâ–‚â–‚â–…â–…â–‚â–ƒâ–â–â–‚â–ƒâ–â–‚â–‡â–‚â–‚â–‚â–…â–„â–â–â–ˆâ–â–ƒâ–‚â–â–‚
wandb:   Test AUC_PR â–‚â–‡â–„â–ƒâ–‡â–…â–‡â–‚â–â–‡â–‡â–‡â–‡â–‡â–†â–…â–…â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–…â–…â–‡â–†â–†
wandb:  Test AUC_ROC â–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–…â–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–…â–†â–ƒâ–‡â–ƒâ–â–„â–‚â–‚
wandb:    Test Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:  Train AUC_PR â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: Train AUC_ROC â–â–ƒâ–„â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   Train Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:     test_loss â–ƒâ–ƒâ–â–ƒâ–…â–„â–„â–…â–„â–„â–ƒâ–ƒâ–…â–„â–†â–†â–…â–ˆâ–†â–…â–„â–ƒâ–ƒâ–„â–„â–„â–…â–ˆâ–„â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:            LR 0.00125
wandb:          Loss 0.09678
wandb:   Test AUC_PR 0.447
wandb:  Test AUC_ROC 0.65915
wandb:    Test Epoch 31
wandb:  Train AUC_PR 0.93595
wandb: Train AUC_ROC 0.9891
wandb:   Train Epoch 31
wandb:     test_loss 0.48091
wandb: 
wandb: ğŸš€ View run rosy-silence-52 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/p5upjzop
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_155635-p5upjzop/logs
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_155732-yidbusii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-jazz-53
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/yidbusii
wandb: - 0.014 MB of 0.014 MB uploaded (0.002 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 11.1%             
wandb: 
wandb: Run history:
wandb:            LR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          Loss â–‡â–ˆâ–‡â–†â–‚â–„â–†â–…â–‡â–…â–†â–‚â–…â–†â–‚â–‚â–†â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–„â–â–†â–â–‚â–‡â–‚â–ƒâ–‚â–†â–â–ˆâ–„â–„â–
wandb:   Test AUC_PR â–â–ƒâ–†â–†â–ƒâ–†â–†â–ˆâ–†â–‡â–‡â–ˆâ–…â–†â–…â–‡â–ˆâ–†â–†â–…â–†â–…â–‡â–†â–…â–†â–†â–†â–…â–†â–…â–…â–„â–…â–…â–…â–…â–…â–„â–„
wandb:  Test AUC_ROC â–…â–â–†â–…â–ƒâ–†â–ˆâ–†â–ˆâ–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–…â–…â–…â–†â–…â–‡â–†â–†â–†â–†â–†â–…â–†â–„â–…â–…â–…â–†â–…â–…â–…â–…â–„
wandb:    Test Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:  Train AUC_PR â–â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: Train AUC_ROC â–â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   Train Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:     test_loss â–ˆâ–†â–„â–…â–…â–„â–ˆâ–„â–ƒâ–„â–†â–‚â–‚â–â–‚â–‚â–ƒâ–â–‚â–‚â–„â–‚â–…â–‚â–ƒâ–„â–ƒâ–ƒâ–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–‚
wandb: 
wandb: Run summary:
wandb:            LR 0.00063
wandb:          Loss 0.05283
wandb:   Test AUC_PR 0.60906
wandb:  Test AUC_ROC 0.86323
wandb:    Test Epoch 45
wandb:  Train AUC_PR 0.93562
wandb: Train AUC_ROC 0.99011
wandb:   Train Epoch 45
wandb:     test_loss 0.13172
wandb: 
wandb: ğŸš€ View run neat-jazz-53 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/yidbusii
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_155732-yidbusii/logs
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_155848-t2km95tm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-firefly-54
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/t2km95tm
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:            LR â–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          Loss â–ƒâ–„â–ƒâ–ˆâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–„â–…â–‡â–„â–‚â–†â–†â–ƒâ–â–ƒâ–‚â–‚â–†â–‡â–…â–†â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–†
wandb:   Test AUC_PR â–â–„â–ƒâ–…â–…â–†â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:  Test AUC_ROC â–â–ƒâ–„â–…â–…â–†â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    Test Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:  Train AUC_PR â–â–ƒâ–„â–„â–…â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆ
wandb: Train AUC_ROC â–â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   Train Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:     test_loss â–„â–‚â–â–ˆâ–„â–…â–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–â–‚â–„â–ƒâ–‚â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–…â–†â–ƒâ–ƒâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:            LR 1e-05
wandb:          Loss 0.68256
wandb:   Test AUC_PR 0.72723
wandb:  Test AUC_ROC 0.78747
wandb:    Test Epoch 50
wandb:  Train AUC_PR 0.80915
wandb: Train AUC_ROC 0.8633
wandb:   Train Epoch 50
wandb:     test_loss 0.60377
wandb: 
wandb: ğŸš€ View run rich-firefly-54 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/t2km95tm
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_155848-t2km95tm/logs
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_160010-wxw6djpc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-meadow-55
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/wxw6djpc
wandb: - 0.004 MB of 0.009 MB uploadedwandb: \ 0.004 MB of 0.009 MB uploadedwandb: | 0.009 MB of 0.009 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:            LR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          Loss â–…â–†â–„â–ƒâ–…â–‚â–‚â–…â–ˆâ–ƒâ–„â–ƒâ–„â–‚â–‚â–ƒâ–†â–„â–„â–ƒâ–â–…â–†â–‡â–ƒâ–‚â–â–â–â–‚â–„â–ƒâ–‚â–â–‚â–ˆâ–ƒâ–ƒâ–â–‚
wandb:   Test AUC_PR â–â–…â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:  Test AUC_ROC â–â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    Test Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:  Train AUC_PR â–â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: Train AUC_ROC â–â–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   Train Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:     test_loss â–ˆâ–ˆâ–†â–…â–†â–„â–„â–„â–…â–‚â–‚â–â–ƒâ–â–„â–ƒâ–ƒâ–ˆâ–„â–„â–‚â–â–ƒâ–…â–„â–„â–…â–…â–„â–…â–…â–…â–„â–„â–…â–ƒâ–†â–…â–†â–†
wandb: 
wandb: Run summary:
wandb:            LR 0.00063
wandb:          Loss 0.13289
wandb:   Test AUC_PR 0.86615
wandb:  Test AUC_ROC 0.90451
wandb:    Test Epoch 44
wandb:  Train AUC_PR 0.95537
wandb: Train AUC_ROC 0.96927
wandb:   Train Epoch 44
wandb:     test_loss 0.30441
wandb: 
wandb: ğŸš€ View run vital-meadow-55 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/wxw6djpc
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_160010-wxw6djpc/logs
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_160125-x116fqiz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-snowflake-56
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/x116fqiz
wandb: - 0.004 MB of 0.009 MB uploadedwandb: \ 0.004 MB of 0.009 MB uploadedwandb: | 0.009 MB of 0.009 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:            LR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb:          Loss â–…â–†â–†â–ƒâ–†â–ƒâ–„â–ƒâ–ˆâ–†â–…â–…â–„â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–â–ƒâ–†â–‚â–â–ƒâ–â–ƒâ–â–ƒâ–â–â–
wandb:   Test AUC_PR â–„â–„â–ˆâ–…â–†â–‡â–â–ˆâ–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆ
wandb:  Test AUC_ROC â–ƒâ–ƒâ–‡â–ƒâ–†â–‡â–â–ˆâ–†â–†â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:    Test Epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:  Train AUC_PR â–â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: Train AUC_ROC â–â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   Train Epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:     test_loss â–†â–‡â–ƒâ–†â–„â–„â–ˆâ–â–„â–ƒâ–â–…â–ƒâ–„â–‚â–â–â–ƒâ–ƒâ–ƒâ–‚â–…â–†â–„â–†â–†â–‡â–„â–…â–†â–†â–†â–†â–‡â–…
wandb: 
wandb: Run summary:
wandb:            LR 0.00125
wandb:          Loss 0.05559
wandb:   Test AUC_PR 0.87904
wandb:  Test AUC_ROC 0.8892
wandb:    Test Epoch 35
wandb:  Train AUC_PR 0.98071
wandb: Train AUC_ROC 0.98675
wandb:   Train Epoch 35
wandb:     test_loss 0.46179
wandb: 
wandb: ğŸš€ View run serene-snowflake-56 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/x116fqiz
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_160125-x116fqiz/logs
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_160224-c06x6wbw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-water-57
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/c06x6wbw
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.009 MB uploadedwandb: | 0.004 MB of 0.009 MB uploadedwandb: / 0.009 MB of 0.009 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:            LR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          Loss â–†â–ˆâ–†â–„â–…â–‚â–ƒâ–…â–ˆâ–…â–…â–‡â–‚â–„â–„â–ƒâ–„â–„â–…â–‚â–†â–ƒâ–†â–ˆâ–‚â–ƒâ–‚â–„â–ˆâ–‚â–‡â–„â–…â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–
wandb:   Test AUC_PR â–â–ƒâ–†â–„â–†â–‡â–ˆâ–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  Test AUC_ROC â–â–„â–†â–…â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:    Test Epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:  Train AUC_PR â–â–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: Train AUC_ROC â–â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   Train Epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:     test_loss â–‡â–ˆâ–†â–‡â–‡â–†â–…â–‚â–†â–„â–„â–…â–†â–†â–†â–†â–†â–‡â–ƒâ–â–†â–…â–…â–†â–‡â–…â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–†â–†
wandb: 
wandb: Run summary:
wandb:            LR 0.00063
wandb:          Loss 0.05494
wandb:   Test AUC_PR 0.8781
wandb:  Test AUC_ROC 0.88237
wandb:    Test Epoch 42
wandb:  Train AUC_PR 0.9531
wandb: Train AUC_ROC 0.96087
wandb:   Train Epoch 42
wandb:     test_loss 0.40579
wandb: 
wandb: ğŸš€ View run clean-water-57 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/c06x6wbw
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_160224-c06x6wbw/logs
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_160336-q3umwpz8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-fire-58
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/q3umwpz8
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.010 MB uploadedwandb: / 0.004 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:            LR â–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          Loss â–ˆâ–‚â–…â–†â–„â–â–â–„â–â–ƒâ–‚â–â–…â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–â–‚â–â–‡â–â–ƒâ–„â–ƒâ–‚â–„â–â–â–ƒâ–‚â–ƒâ–â–â–‡â–‚â–
wandb:   Test AUC_PR â–â–„â–„â–…â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  Test AUC_ROC â–â–„â–„â–‡â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    Test Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:  Train AUC_PR â–â–‚â–ƒâ–„â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡
wandb: Train AUC_ROC â–â–ƒâ–„â–†â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:   Train Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:     test_loss â–ˆâ–‡â–†â–„â–…â–„â–…â–„â–‚â–â–‚â–â–‚â–ƒâ–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–â–â–‚
wandb: 
wandb: Run summary:
wandb:            LR 1e-05
wandb:          Loss 0.01982
wandb:   Test AUC_PR 0.78572
wandb:  Test AUC_ROC 0.92481
wandb:    Test Epoch 50
wandb:  Train AUC_PR 0.81958
wandb: Train AUC_ROC 0.9689
wandb:   Train Epoch 50
wandb:     test_loss 0.23206
wandb: 
wandb: ğŸš€ View run fluent-fire-58 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/q3umwpz8
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_160336-q3umwpz8/logs
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_160502-6kjv0pbr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-puddle-59
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/6kjv0pbr
########## Class: PDNetwork
PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 23
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.87            Average AUC PR: 0.48
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.83            Average AUC PR: 0.47
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.83            Average AUC PR: 0.48
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.99            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.66            Average AUC PR: 0.44
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 362
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.87            Average AUC PR: 0.46
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.83            Average AUC PR: 0.46
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.71
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.85            Average AUC PR: 0.41
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.75            Average AUC PR: 0.44
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 191
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.89            Average AUC PR: 0.55
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.83            Average AUC PR: 0.45
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.79            Average AUC PR: 0.4
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.44
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 80
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.88            Average AUC PR: 0.51
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.38
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.77            Average AUC PR: 0.47
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.68            Average AUC PR: 0.41
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 769
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.88            Average AUC PR: 0.47
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.77            Average AUC PR: 0.33
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.93            Average AUC PR: 0.75
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.84            Average AUC PR: 0.48
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.67            Average AUC PR: 0.4
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 328
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.89            Average AUC PR: 0.53
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.86            Average AUC PR: 0.49
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.83            Average AUC PR: 0.49
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.88
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.67            Average AUC PR: 0.47
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 204
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.44
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.79            Average AUC PR: 0.39
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.72
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.82            Average AUC PR: 0.4
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.99            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.69            Average AUC PR: 0.47
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 281
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.85            Average AUC PR: 0.48
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.86            Average AUC PR: 0.5
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.76
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.71            Average AUC PR: 0.41
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.91
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.83            Average AUC PR: 0.48
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 841
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.88            Average AUC PR: 0.52
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.83            Average AUC PR: 0.41
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.75
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.84            Average AUC PR: 0.44
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.68            Average AUC PR: 0.41
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: PD
cuda

        ###################################################################################
        #   architecture: PDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.1, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: PD
        #   random state: 31
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: PD
        #   epochs: 31
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.48
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.82            Average AUC PR: 0.45
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.84            Average AUC PR: 0.42
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.91
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.47
########## Class: ADNetwork
ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: AD
cuda

        ###################################################################################
        #   architecture: ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: AD
        #   random state: 23
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: AD
        #   epochs: 45
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.91            Average AUC PR: 0.63
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.65
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.75
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.64
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.63
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.91
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.62
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: AD
cuda

        ###################################################################################
        #   architecture: ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: AD
        #   random state: 362
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: AD
        #   epochs: 45
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.66
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.63
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.65
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.83
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.85            Average AUC PR: 0.56
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.62
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: AD
cuda

        ###################################################################################
        #   architecture: ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: AD
        #   random state: 191
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: AD
        #   epochs: 45
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.91            Average AUC PR: 0.68
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.7
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.65
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.9
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.63
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.99            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.6
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: AD
cuda

        ###################################################################################
        #   architecture: ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: AD
        #   random state: 80
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: AD
        #   epochs: 45
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.7
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.68
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.66
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.65
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.99            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.75            Average AUC PR: 0.55
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: AD
cuda

        ###################################################################################
        #   architecture: ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: AD
        #   random state: 769
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: AD
        #   epochs: 45
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.91            Average AUC PR: 0.66
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.85            Average AUC PR: 0.57
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.63
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.64
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.91
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.63
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: AD
cuda

        ###################################################################################
        #   architecture: ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: AD
        #   random state: 328
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: AD
        #   epochs: 45
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.68
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.62
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.74
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.85            Average AUC PR: 0.56
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.65
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.9
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.63
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: AD
cuda

        ###################################################################################
        #   architecture: ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: AD
        #   random state: 204
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: AD
        #   epochs: 45
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.91            Average AUC PR: 0.64
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.68
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.72
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.63
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.64
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.62
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: AD
cuda

        ###################################################################################
        #   architecture: ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: AD
        #   random state: 281
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: AD
        #   epochs: 45
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.7
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.71
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.93            Average AUC PR: 0.75
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.59
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.62
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.99            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.86            Average AUC PR: 0.6
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: AD
cuda

        ###################################################################################
        #   architecture: ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: AD
        #   random state: 841
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: AD
        #   epochs: 45
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.91            Average AUC PR: 0.65
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.63
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.78
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.66
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.6
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.58
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: AD
cuda

        ###################################################################################
        #   architecture: ADNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: AD
        #   random state: 31
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: AD
        #   epochs: 45
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.91            Average AUC PR: 0.66
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.66
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.93            Average AUC PR: 0.75
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.65
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.63
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.91
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.62
########## Class: CNNetwork
CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: CN
cuda

        ###################################################################################
        #   architecture: CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: CN
        #   random state: 23
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: CN
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.84            Average AUC PR: 0.78
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.72
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.72
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.71
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.72
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.79            Average AUC PR: 0.73
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: CN
cuda

        ###################################################################################
        #   architecture: CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: CN
        #   random state: 362
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: CN
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.82            Average AUC PR: 0.73
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.77            Average AUC PR: 0.68
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.85            Average AUC PR: 0.78
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.77            Average AUC PR: 0.67
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.77            Average AUC PR: 0.68
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.77            Average AUC PR: 0.68
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.77            Average AUC PR: 0.68
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: CN
cuda

        ###################################################################################
        #   architecture: CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: CN
        #   random state: 191
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: CN
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.79            Average AUC PR: 0.68
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.75            Average AUC PR: 0.64
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.81            Average AUC PR: 0.7
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.76            Average AUC PR: 0.65
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.82            Average AUC PR: 0.71
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.76            Average AUC PR: 0.66
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.82            Average AUC PR: 0.71
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.76            Average AUC PR: 0.65
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.82            Average AUC PR: 0.71
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.76            Average AUC PR: 0.66
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: CN
cuda

        ###################################################################################
        #   architecture: CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: CN
        #   random state: 80
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: CN
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.82            Average AUC PR: 0.75
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.79            Average AUC PR: 0.71
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.8            Average AUC PR: 0.73
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.8            Average AUC PR: 0.74
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.8            Average AUC PR: 0.73
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.8            Average AUC PR: 0.74
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: CN
cuda

        ###################################################################################
        #   architecture: CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: CN
        #   random state: 769
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: CN
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.83            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.82            Average AUC PR: 0.8
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.82            Average AUC PR: 0.8
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.85            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.8
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.87            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.82            Average AUC PR: 0.8
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.8
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: CN
cuda

        ###################################################################################
        #   architecture: CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: CN
        #   random state: 328
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: CN
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.84            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.8            Average AUC PR: 0.71
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.87            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.69
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.87            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.79            Average AUC PR: 0.7
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.88            Average AUC PR: 0.82
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.79            Average AUC PR: 0.7
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.88            Average AUC PR: 0.82
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.79            Average AUC PR: 0.71
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: CN
cuda

        ###################################################################################
        #   architecture: CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: CN
        #   random state: 204
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: CN
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.8            Average AUC PR: 0.72
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.8            Average AUC PR: 0.77
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.84            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.78
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.84            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.78
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.84            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.78
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.84            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.78
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: CN
cuda

        ###################################################################################
        #   architecture: CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: CN
        #   random state: 281
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: CN
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.82            Average AUC PR: 0.74
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.77            Average AUC PR: 0.69
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.84            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.7
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.85            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.71
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.85            Average AUC PR: 0.78
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.7
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.85            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.7
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: CN
cuda

        ###################################################################################
        #   architecture: CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: CN
        #   random state: 841
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: CN
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.82            Average AUC PR: 0.76
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.79
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.85            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.82            Average AUC PR: 0.8
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.85            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.81            Average AUC PR: 0.8
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.82            Average AUC PR: 0.8
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.85            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.82            Average AUC PR: 0.8
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: CN
cuda

        ###################################################################################
        #   architecture: CNNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: CN
        #   random state: 31
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: CN
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.83            Average AUC PR: 0.75
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.77            Average AUC PR: 0.67
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.69
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.87            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.79            Average AUC PR: 0.7
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.87            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.69
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.86            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.78            Average AUC PR: 0.7
########## Class: LMCINetwork
LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: LMCI
cuda

        ###################################################################################
        #   architecture: LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: LMCI
        #   random state: 23
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: LMCI
        #   epochs: 44
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.93            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.86
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.88
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.87
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: LMCI
cuda

        ###################################################################################
        #   architecture: LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: LMCI
        #   random state: 362
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: LMCI
        #   epochs: 44
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.93            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.76
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.84
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.85
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.85
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: LMCI
cuda

        ###################################################################################
        #   architecture: LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: LMCI
        #   random state: 191
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: LMCI
        #   epochs: 44
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.88
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.86
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.86
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.86
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.86
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: LMCI
cuda

        ###################################################################################
        #   architecture: LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: LMCI
        #   random state: 80
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: LMCI
        #   epochs: 44
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.88
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: LMCI
cuda

        ###################################################################################
        #   architecture: LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: LMCI
        #   random state: 769
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: LMCI
        #   epochs: 44
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.91
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: LMCI
cuda

        ###################################################################################
        #   architecture: LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: LMCI
        #   random state: 328
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: LMCI
        #   epochs: 44
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.93            Average AUC PR: 0.88
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.88
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.86
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.96
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.86
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: LMCI
cuda

        ###################################################################################
        #   architecture: LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: LMCI
        #   random state: 204
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: LMCI
        #   epochs: 44
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.93            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.75
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.85
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.88
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.88
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: LMCI
cuda

        ###################################################################################
        #   architecture: LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: LMCI
        #   random state: 281
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: LMCI
        #   epochs: 44
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.91            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.88
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.88
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.89
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.89
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: LMCI
cuda

        ###################################################################################
        #   architecture: LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: LMCI
        #   random state: 841
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: LMCI
        #   epochs: 44
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.88
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: LMCI
cuda

        ###################################################################################
        #   architecture: LMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: LMCI
        #   random state: 31
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: LMCI
        #   epochs: 44
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.88
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.96
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.87
########## Class: MCINetwork
MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: MCI
cuda

        ###################################################################################
        #   architecture: MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: MCI
        #   random state: 23
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: MCI
        #   epochs: 35
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.9            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.98
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: MCI
cuda

        ###################################################################################
        #   architecture: MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: MCI
        #   random state: 362
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: MCI
        #   epochs: 35
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.89            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.85            Average AUC PR: 0.82
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.97
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.84
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: MCI
cuda

        ###################################################################################
        #   architecture: MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: MCI
        #   random state: 191
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: MCI
        #   epochs: 35
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.89            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.84
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.98
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.87
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: MCI
cuda

        ###################################################################################
        #   architecture: MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: MCI
        #   random state: 80
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: MCI
        #   epochs: 35
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.88            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.84            Average AUC PR: 0.83
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.98
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: MCI
cuda

        ###################################################################################
        #   architecture: MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: MCI
        #   random state: 769
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: MCI
        #   epochs: 35
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.89            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.85
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.98
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.84
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: MCI
cuda

        ###################################################################################
        #   architecture: MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: MCI
        #   random state: 328
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: MCI
        #   epochs: 35
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.89            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.84
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.97
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.85
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: MCI
cuda

        ###################################################################################
        #   architecture: MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: MCI
        #   random state: 204
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: MCI
        #   epochs: 35
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.89            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.86
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.83            Average AUC PR: 0.8
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.98
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: MCI
cuda

        ###################################################################################
        #   architecture: MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: MCI
        #   random state: 281
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: MCI
        #   epochs: 35
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.8            Average AUC PR: 0.78
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.83            Average AUC PR: 0.82
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.84            Average AUC PR: 0.83
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.82            Average AUC PR: 0.79
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.87            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.82            Average AUC PR: 0.8
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: MCI
cuda

        ###################################################################################
        #   architecture: MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: MCI
        #   random state: 841
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: MCI
        #   epochs: 35
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.88            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.85
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.88
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.99            Average AUC PR: 0.98
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.85
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: MCI
cuda

        ###################################################################################
        #   architecture: MCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: MCI
        #   random state: 31
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: MCI
        #   epochs: 35
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.88            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.88
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.98
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.83
########## Class: EMCINetwork
EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: EMCI
cuda

        ###################################################################################
        #   architecture: EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: EMCI
        #   random state: 23
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: EMCI
        #   epochs: 42
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.9            Average AUC PR: 0.88
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.88
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.88
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.88
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: EMCI
cuda

        ###################################################################################
        #   architecture: EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: EMCI
        #   random state: 362
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: EMCI
        #   epochs: 42
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.9            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.96
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.85
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: EMCI
cuda

        ###################################################################################
        #   architecture: EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: EMCI
        #   random state: 191
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: EMCI
        #   epochs: 42
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.88            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.86
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.91
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.86
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: EMCI
cuda

        ###################################################################################
        #   architecture: EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: EMCI
        #   random state: 80
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: EMCI
        #   epochs: 42
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.89            Average AUC PR: 0.88
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.85
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.96
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.85
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: EMCI
cuda

        ###################################################################################
        #   architecture: EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: EMCI
        #   random state: 769
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: EMCI
        #   epochs: 42
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.91            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.85
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.96
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.87            Average AUC PR: 0.85
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: EMCI
cuda

        ###################################################################################
        #   architecture: EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: EMCI
        #   random state: 328
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: EMCI
        #   epochs: 42
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.91            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.87
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.96
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: EMCI
cuda

        ###################################################################################
        #   architecture: EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: EMCI
        #   random state: 204
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: EMCI
        #   epochs: 42
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.9            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: EMCI
cuda

        ###################################################################################
        #   architecture: EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: EMCI
        #   random state: 281
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: EMCI
        #   epochs: 42
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.88            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.93            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.86
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.93
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: EMCI
cuda

        ###################################################################################
        #   architecture: EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: EMCI
        #   random state: 841
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: EMCI
        #   epochs: 42
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.89            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.86
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.95
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.88            Average AUC PR: 0.87
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: EMCI
cuda

        ###################################################################################
        #   architecture: EMCINetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: EMCI
        #   random state: 31
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: EMCI
        #   epochs: 42
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:10
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.91            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.94
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.96
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.96
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.87
########## Class: FTDNetwork
FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: FTD
cuda

        ###################################################################################
        #   architecture: FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: FTD
        #   random state: 23
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: FTD
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.72
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.92            Average AUC PR: 0.78
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.92            Average AUC PR: 0.78
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.92            Average AUC PR: 0.79
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.83
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.92            Average AUC PR: 0.79
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.82
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.92            Average AUC PR: 0.79
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: FTD
cuda

        ###################################################################################
        #   architecture: FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: FTD
        #   random state: 362
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: FTD
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.77
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.93            Average AUC PR: 0.69
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.92            Average AUC PR: 0.78
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.93            Average AUC PR: 0.79
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.93            Average AUC PR: 0.79
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.93            Average AUC PR: 0.79
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: FTD
cuda

        ###################################################################################
        #   architecture: FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: FTD
        #   random state: 191
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: FTD
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.72
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.75
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.72
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.72
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.72
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.72
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: FTD
cuda

        ###################################################################################
        #   architecture: FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: FTD
        #   random state: 80
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: FTD
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.8
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.92            Average AUC PR: 0.81
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.92            Average AUC PR: 0.81
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.92            Average AUC PR: 0.81
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.92            Average AUC PR: 0.81
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: FTD
cuda

        ###################################################################################
        #   architecture: FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: FTD
        #   random state: 769
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: FTD
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.8
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.76
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.81
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.9
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.81
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.8
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.8
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: FTD
cuda

        ###################################################################################
        #   architecture: FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: FTD
        #   random state: 328
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: FTD
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.77
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.9
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.73
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.91
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.73
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.73
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.9
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.73
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: FTD
cuda

        ###################################################################################
        #   architecture: FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: FTD
        #   random state: 204
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: FTD
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.92            Average AUC PR: 0.78
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.81
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.81
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.88
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.81
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.99            Average AUC PR: 0.92
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.82
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.82
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: FTD
cuda

        ###################################################################################
        #   architecture: FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: FTD
        #   random state: 281
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: FTD
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.9            Average AUC PR: 0.71
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.68
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.75
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.75
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.81
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.74
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.88
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.74
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.74
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: FTD
cuda

        ###################################################################################
        #   architecture: FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: FTD
        #   random state: 841
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: FTD
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.96            Average AUC PR: 0.79
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.89            Average AUC PR: 0.79
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.84
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.82
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.82
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.82
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.86
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.82
Train the model on 3083 observation with 403 features and test it on 343
-------------------- diagnosis: FTD
cuda

        ###################################################################################
        #   architecture: FTDNetwork(
  (net): Sequential(
    (0): Linear(in_features=403, out_features=300, bias=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.5, inplace=False)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.5, inplace=False)
    (12): Linear(in_features=100, out_features=50, bias=True)
    (13): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU6()
    (15): Dropout(p=0.5, inplace=False)
    (16): Linear(in_features=50, out_features=25, bias=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU6()
    (19): Dropout(p=0.1, inplace=False)
    (20): Linear(in_features=25, out_features=12, bias=True)
    (21): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU6()
    (23): Linear(in_features=12, out_features=1, bias=True)
    (24): Sigmoid()
  )
)
        #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
        #   target: FTD
        #   random state: 31
        #   selected_gender: ['M', 'F']
        #   selected_diagnosis: FTD
        #   epochs: 50
        #   learning_rate: 0.01
        #   optimizer : Adagrad
        #   batch size: 64
        #   scheduler: StepLR
        #   weight_decay : 0.00025
        #   step_size:5
        #   gamma : 0.5
        ###################################################################################
            
################################################## 10 ##################################################
Training set: Average AUC ROC: 0.94            Average AUC PR: 0.76
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.69
################################################## 20 ##################################################
Training set: Average AUC ROC: 0.95            Average AUC PR: 0.83
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.74
################################################## 30 ##################################################
Training set: Average AUC ROC: 0.97            Average AUC PR: 0.87
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.91            Average AUC PR: 0.75
################################################## 40 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.85
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.75
################################################## 50 ##################################################
Training set: Average AUC ROC: 0.98            Average AUC PR: 0.89
--------------------------------------------------------------------------------------------------------
Test set:     Average AUC ROC: 0.9            Average AUC PR: 0.75

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 23
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
An error occurred: 'numpy.float64' object cannot be interpreted as an integer
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.008 MB of 0.011 MB uploaded (0.002 MB deduped)wandb: / 0.011 MB of 0.011 MB uploaded (0.002 MB deduped)wandb: ğŸš€ View run olive-puddle-59 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/6kjv0pbr
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_160502-6kjv0pbr/logs
wandb: Currently logged in as: thomas-borsani1. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_160815-mgku14yo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-violet-60
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/mgku14yo

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 23
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
An error occurred: 'numpy.float64' object cannot be interpreted as an integer
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.007 MB uploadedwandb: | 0.007 MB of 0.007 MB uploadedwandb: ğŸš€ View run revived-violet-60 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/mgku14yo
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_160815-mgku14yo/logs
wandb: Currently logged in as: thomas-borsani1. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/students/tborsani/alzheimernet/MTLDeploy/wandb/run-20240529_160922-xtbdo4fk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sound-61
wandb: â­ï¸ View project at https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: ğŸš€ View run at https://wandb.ai/thomas-borsani1/MTL_experiment/runs/xtbdo4fk

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 23
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=0, validation loss=0]  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=4.02, validation loss=3.35]  0%|          | 1/500 [00:00<06:38,  1.25it/s, Train Loss=4.02, validation loss=3.35]  0%|          | 1/500 [00:01<06:38,  1.25it/s, Train Loss=2.47, validation loss=3.14]  0%|          | 2/500 [00:01<05:49,  1.42it/s, Train Loss=2.47, validation loss=3.14]  0%|          | 2/500 [00:02<05:49,  1.42it/s, Train Loss=3.58, validation loss=2.91]  1%|          | 3/500 [00:02<05:32,  1.50it/s, Train Loss=3.58, validation loss=2.91]  1%|          | 3/500 [00:02<05:32,  1.50it/s, Train Loss=2.76, validation loss=2.86]  1%|          | 4/500 [00:02<05:25,  1.52it/s, Train Loss=2.76, validation loss=2.86]  1%|          | 4/500 [00:03<05:25,  1.52it/s, Train Loss=3.43, validation loss=2.85]  1%|          | 5/500 [00:03<05:19,  1.55it/s, Train Loss=3.43, validation loss=2.85]  1%|          | 5/500 [00:03<05:19,  1.55it/s, Train Loss=2.78, validation loss=2.79]  1%|          | 6/500 [00:03<05:17,  1.56it/s, Train Loss=2.78, validation loss=2.79]  1%|          | 6/500 [00:04<05:17,  1.56it/s, Train Loss=4.45, validation loss=2.78]  1%|â–         | 7/500 [00:04<05:27,  1.50it/s, Train Loss=4.45, validation loss=2.78]  1%|â–         | 7/500 [00:05<05:27,  1.50it/s, Train Loss=1.95, validation loss=2.79]  2%|â–         | 8/500 [00:05<05:19,  1.54it/s, Train Loss=1.95, validation loss=2.79]  2%|â–         | 8/500 [00:05<05:19,  1.54it/s, Train Loss=2.78, validation loss=2.8]   2%|â–         | 9/500 [00:05<05:16,  1.55it/s, Train Loss=2.78, validation loss=2.8]  2%|â–         | 9/500 [00:06<05:16,  1.55it/s, Train Loss=1.72, validation loss=2.82]  2%|â–         | 10/500 [00:06<05:18,  1.54it/s, Train Loss=1.72, validation loss=2.82]  2%|â–         | 10/500 [00:07<05:18,  1.54it/s, Train Loss=3.33, validation loss=2.81]  2%|â–         | 11/500 [00:07<05:27,  1.49it/s, Train Loss=3.33, validation loss=2.81]  2%|â–         | 11/500 [00:07<05:27,  1.49it/s, Train Loss=2.07, validation loss=2.78]  2%|â–         | 12/500 [00:07<05:22,  1.51it/s, Train Loss=2.07, validation loss=2.78]  2%|â–         | 12/500 [00:08<05:22,  1.51it/s, Train Loss=2.39, validation loss=2.79]  3%|â–         | 13/500 [00:08<05:16,  1.54it/s, Train Loss=2.39, validation loss=2.79]  3%|â–         | 13/500 [00:09<05:16,  1.54it/s, Train Loss=4.19, validation loss=2.76]  3%|â–         | 14/500 [00:09<05:10,  1.57it/s, Train Loss=4.19, validation loss=2.76]  3%|â–         | 14/500 [00:09<05:10,  1.57it/s, Train Loss=3.55, validation loss=2.76]  3%|â–         | 15/500 [00:09<05:04,  1.59it/s, Train Loss=3.55, validation loss=2.76]  3%|â–         | 15/500 [00:10<05:04,  1.59it/s, Train Loss=2.61, validation loss=2.79]  3%|â–         | 16/500 [00:10<05:09,  1.56it/s, Train Loss=2.61, validation loss=2.79]  3%|â–         | 16/500 [00:11<05:09,  1.56it/s, Train Loss=2.49, validation loss=2.76]  3%|â–         | 17/500 [00:11<05:08,  1.57it/s, Train Loss=2.49, validation loss=2.76]  3%|â–         | 17/500 [00:11<05:08,  1.57it/s, Train Loss=2.88, validation loss=2.73]  4%|â–         | 18/500 [00:11<05:08,  1.56it/s, Train Loss=2.88, validation loss=2.73]  4%|â–         | 18/500 [00:12<05:08,  1.56it/s, Train Loss=1.85, validation loss=2.72]  4%|â–         | 19/500 [00:12<05:08,  1.56it/s, Train Loss=1.85, validation loss=2.72]  4%|â–         | 19/500 [00:13<05:08,  1.56it/s, Train Loss=2.72, validation loss=2.77]  4%|â–         | 20/500 [00:13<05:08,  1.55it/s, Train Loss=2.72, validation loss=2.77]  4%|â–         | 20/500 [00:13<05:08,  1.55it/s, Train Loss=3.21, validation loss=2.74]  4%|â–         | 21/500 [00:13<05:08,  1.55it/s, Train Loss=3.21, validation loss=2.74]  4%|â–         | 21/500 [00:14<05:08,  1.55it/s, Train Loss=2.14, validation loss=2.74]  4%|â–         | 22/500 [00:14<05:06,  1.56it/s, Train Loss=2.14, validation loss=2.74]  4%|â–         | 22/500 [00:15<05:06,  1.56it/s, Train Loss=2.75, validation loss=2.7]   5%|â–         | 23/500 [00:15<05:15,  1.51it/s, Train Loss=2.75, validation loss=2.7]  5%|â–         | 23/500 [00:15<05:15,  1.51it/s, Train Loss=2.38, validation loss=2.69]  5%|â–         | 24/500 [00:15<05:09,  1.54it/s, Train Loss=2.38, validation loss=2.69]  5%|â–         | 24/500 [00:16<05:09,  1.54it/s, Train Loss=3.27, validation loss=2.66]  5%|â–Œ         | 25/500 [00:16<05:04,  1.56it/s, Train Loss=3.27, validation loss=2.66]  5%|â–Œ         | 25/500 [00:16<05:04,  1.56it/s, Train Loss=2.52, validation loss=2.71]  5%|â–Œ         | 26/500 [00:16<04:58,  1.59it/s, Train Loss=2.52, validation loss=2.71]  5%|â–Œ         | 26/500 [00:17<04:58,  1.59it/s, Train Loss=3.86, validation loss=2.72]  5%|â–Œ         | 27/500 [00:17<04:57,  1.59it/s, Train Loss=3.86, validation loss=2.72]  5%|â–Œ         | 27/500 [00:18<04:57,  1.59it/s, Train Loss=2.03, validation loss=2.71]  6%|â–Œ         | 28/500 [00:18<04:58,  1.58it/s, Train Loss=2.03, validation loss=2.71]  6%|â–Œ         | 28/500 [00:18<04:58,  1.58it/s, Train Loss=2.51, validation loss=2.69]  6%|â–Œ         | 29/500 [00:18<04:55,  1.59it/s, Train Loss=2.51, validation loss=2.69]  6%|â–Œ         | 29/500 [00:19<04:55,  1.59it/s, Train Loss=2.74, validation loss=2.67]  6%|â–Œ         | 30/500 [00:19<05:07,  1.53it/s, Train Loss=2.74, validation loss=2.67]  6%|â–Œ         | 30/500 [00:20<05:07,  1.53it/s, Train Loss=3.18, validation loss=2.65]  6%|â–Œ         | 31/500 [00:20<05:03,  1.55it/s, Train Loss=3.18, validation loss=2.65]  6%|â–Œ         | 31/500 [00:20<05:03,  1.55it/s, Train Loss=3.24, validation loss=2.7]   6%|â–‹         | 32/500 [00:20<04:58,  1.57it/s, Train Loss=3.24, validation loss=2.7]  6%|â–‹         | 32/500 [00:21<04:58,  1.57it/s, Train Loss=3.37, validation loss=2.67]  7%|â–‹         | 33/500 [00:21<04:58,  1.56it/s, Train Loss=3.37, validation loss=2.67]  7%|â–‹         | 33/500 [00:21<04:58,  1.56it/s, Train Loss=2.42, validation loss=2.63]  7%|â–‹         | 34/500 [00:21<04:54,  1.58it/s, Train Loss=2.42, validation loss=2.63]  7%|â–‹         | 34/500 [00:22<04:54,  1.58it/s, Train Loss=3.05, validation loss=2.66]  7%|â–‹         | 35/500 [00:22<04:56,  1.57it/s, Train Loss=3.05, validation loss=2.66]  7%|â–‹         | 35/500 [00:23<04:56,  1.57it/s, Train Loss=1.89, validation loss=2.68]  7%|â–‹         | 36/500 [00:23<05:01,  1.54it/s, Train Loss=1.89, validation loss=2.68]  7%|â–‹         | 36/500 [00:23<05:01,  1.54it/s, Train Loss=4.32, validation loss=2.64]  7%|â–‹         | 37/500 [00:23<05:01,  1.53it/s, Train Loss=4.32, validation loss=2.64]  7%|â–‹         | 37/500 [00:24<05:01,  1.53it/s, Train Loss=1.75, validation loss=2.61]  8%|â–Š         | 38/500 [00:24<04:56,  1.56it/s, Train Loss=1.75, validation loss=2.61]  8%|â–Š         | 38/500 [00:25<04:56,  1.56it/s, Train Loss=4.13, validation loss=2.61]  8%|â–Š         | 39/500 [00:25<04:55,  1.56it/s, Train Loss=4.13, validation loss=2.61]  8%|â–Š         | 39/500 [00:25<04:55,  1.56it/s, Train Loss=2.14, validation loss=2.64]  8%|â–Š         | 40/500 [00:25<04:53,  1.57it/s, Train Loss=2.14, validation loss=2.64]  8%|â–Š         | 40/500 [00:26<04:53,  1.57it/s, Train Loss=3.92, validation loss=2.64]  8%|â–Š         | 41/500 [00:26<04:51,  1.57it/s, Train Loss=3.92, validation loss=2.64]  8%|â–Š         | 41/500 [00:27<04:51,  1.57it/s, Train Loss=2.25, validation loss=2.63]  8%|â–Š         | 42/500 [00:27<05:22,  1.42it/s, Train Loss=2.25, validation loss=2.63]  8%|â–Š         | 42/500 [00:27<05:22,  1.42it/s, Train Loss=2.3, validation loss=2.63]   9%|â–Š         | 43/500 [00:27<05:14,  1.45it/s, Train Loss=2.3, validation loss=2.63]  9%|â–Š         | 43/500 [00:28<05:14,  1.45it/s, Train Loss=2.77, validation loss=2.64]  9%|â–‰         | 44/500 [00:28<05:15,  1.44it/s, Train Loss=2.77, validation loss=2.64]  9%|â–‰         | 44/500 [00:29<05:15,  1.44it/s, Train Loss=3.77, validation loss=2.59]  9%|â–‰         | 45/500 [00:29<05:05,  1.49it/s, Train Loss=3.77, validation loss=2.59]  9%|â–‰         | 45/500 [00:29<05:05,  1.49it/s, Train Loss=2.84, validation loss=2.58]  9%|â–‰         | 46/500 [00:29<04:57,  1.53it/s, Train Loss=2.84, validation loss=2.58]  9%|â–‰         | 46/500 [00:30<04:57,  1.53it/s, Train Loss=2.11, validation loss=2.62]  9%|â–‰         | 47/500 [00:30<04:48,  1.57it/s, Train Loss=2.11, validation loss=2.62]  9%|â–‰         | 47/500 [00:31<04:48,  1.57it/s, Train Loss=2.9, validation loss=2.58]  10%|â–‰         | 48/500 [00:31<04:43,  1.60it/s, Train Loss=2.9, validation loss=2.58] 10%|â–‰         | 48/500 [00:31<04:43,  1.60it/s, Train Loss=2.86, validation loss=2.59] 10%|â–‰         | 49/500 [00:31<05:00,  1.50it/s, Train Loss=2.86, validation loss=2.59] 10%|â–‰         | 49/500 [00:32<05:00,  1.50it/s, Train Loss=3.84, validation loss=2.6]  10%|â–ˆ         | 50/500 [00:32<04:59,  1.50it/s, Train Loss=3.84, validation loss=2.6] 10%|â–ˆ         | 50/500 [00:33<04:59,  1.50it/s, Train Loss=2.01, validation loss=2.57] 10%|â–ˆ         | 51/500 [00:33<05:01,  1.49it/s, Train Loss=2.01, validation loss=2.57] 10%|â–ˆ         | 51/500 [00:33<05:01,  1.49it/s, Train Loss=2.64, validation loss=2.57] 10%|â–ˆ         | 52/500 [00:33<05:03,  1.48it/s, Train Loss=2.64, validation loss=2.57] 10%|â–ˆ         | 52/500 [00:34<05:03,  1.48it/s, Train Loss=2.39, validation loss=2.58] 11%|â–ˆ         | 53/500 [00:34<05:21,  1.39it/s, Train Loss=2.39, validation loss=2.58] 11%|â–ˆ         | 53/500 [00:35<05:21,  1.39it/s, Train Loss=2.6, validation loss=2.56]  11%|â–ˆ         | 54/500 [00:35<05:23,  1.38it/s, Train Loss=2.6, validation loss=2.56] 11%|â–ˆ         | 54/500 [00:36<05:23,  1.38it/s, Train Loss=3.03, validation loss=2.54] 11%|â–ˆ         | 55/500 [00:36<05:29,  1.35it/s, Train Loss=3.03, validation loss=2.54] 11%|â–ˆ         | 55/500 [00:36<05:29,  1.35it/s, Train Loss=3.09, validation loss=2.6]  11%|â–ˆ         | 56/500 [00:36<05:28,  1.35it/s, Train Loss=3.09, validation loss=2.6] 11%|â–ˆ         | 56/500 [00:37<05:28,  1.35it/s, Train Loss=2.63, validation loss=2.58] 11%|â–ˆâ–        | 57/500 [00:37<05:12,  1.42it/s, Train Loss=2.63, validation loss=2.58] 11%|â–ˆâ–        | 57/500 [00:38<05:12,  1.42it/s, Train Loss=1.62, validation loss=2.56] 12%|â–ˆâ–        | 58/500 [00:38<05:01,  1.47it/s, Train Loss=1.62, validation loss=2.56] 12%|â–ˆâ–        | 58/500 [00:38<05:01,  1.47it/s, Train Loss=1.48, validation loss=2.54] 12%|â–ˆâ–        | 59/500 [00:38<04:51,  1.51it/s, Train Loss=1.48, validation loss=2.54] 12%|â–ˆâ–        | 59/500 [00:39<04:51,  1.51it/s, Train Loss=2.66, validation loss=2.53] 12%|â–ˆâ–        | 60/500 [00:39<04:56,  1.48it/s, Train Loss=2.66, validation loss=2.53] 12%|â–ˆâ–        | 60/500 [00:40<04:56,  1.48it/s, Train Loss=1.99, validation loss=2.55] 12%|â–ˆâ–        | 61/500 [00:40<04:50,  1.51it/s, Train Loss=1.99, validation loss=2.55] 12%|â–ˆâ–        | 61/500 [00:40<04:50,  1.51it/s, Train Loss=1.74, validation loss=2.51] 12%|â–ˆâ–        | 62/500 [00:40<04:47,  1.52it/s, Train Loss=1.74, validation loss=2.51] 12%|â–ˆâ–        | 62/500 [00:41<04:47,  1.52it/s, Train Loss=2.46, validation loss=2.55] 13%|â–ˆâ–        | 63/500 [00:41<04:49,  1.51it/s, Train Loss=2.46, validation loss=2.55] 13%|â–ˆâ–        | 63/500 [00:42<04:49,  1.51it/s, Train Loss=2.44, validation loss=2.53] 13%|â–ˆâ–        | 64/500 [00:42<05:04,  1.43it/s, Train Loss=2.44, validation loss=2.53] 13%|â–ˆâ–        | 64/500 [00:43<05:04,  1.43it/s, Train Loss=4.06, validation loss=2.57] 13%|â–ˆâ–        | 65/500 [00:43<05:15,  1.38it/s, Train Loss=4.06, validation loss=2.57] 13%|â–ˆâ–        | 65/500 [00:43<05:15,  1.38it/s, Train Loss=1.69, validation loss=2.52] 13%|â–ˆâ–        | 66/500 [00:43<05:21,  1.35it/s, Train Loss=1.69, validation loss=2.52] 13%|â–ˆâ–        | 66/500 [00:44<05:21,  1.35it/s, Train Loss=2.41, validation loss=2.54] 13%|â–ˆâ–        | 67/500 [00:44<05:25,  1.33it/s, Train Loss=2.41, validation loss=2.54] 13%|â–ˆâ–        | 67/500 [00:45<05:25,  1.33it/s, Train Loss=2.63, validation loss=2.51] 14%|â–ˆâ–        | 68/500 [00:45<05:29,  1.31it/s, Train Loss=2.63, validation loss=2.51] 14%|â–ˆâ–        | 68/500 [00:46<05:29,  1.31it/s, Train Loss=2.16, validation loss=2.53] 14%|â–ˆâ–        | 69/500 [00:46<05:09,  1.39it/s, Train Loss=2.16, validation loss=2.53] 14%|â–ˆâ–        | 69/500 [00:46<05:09,  1.39it/s, Train Loss=2.4, validation loss=2.57]  14%|â–ˆâ–        | 70/500 [00:46<04:57,  1.45it/s, Train Loss=2.4, validation loss=2.57] 14%|â–ˆâ–        | 70/500 [00:47<04:57,  1.45it/s, Train Loss=4.91, validation loss=2.54] 14%|â–ˆâ–        | 71/500 [00:47<05:01,  1.42it/s, Train Loss=4.91, validation loss=2.54] 14%|â–ˆâ–        | 71/500 [00:48<05:01,  1.42it/s, Train Loss=1.45, validation loss=2.52] 14%|â–ˆâ–        | 72/500 [00:48<04:49,  1.48it/s, Train Loss=1.45, validation loss=2.52] 14%|â–ˆâ–        | 72/500 [00:48<04:49,  1.48it/s, Train Loss=2.98, validation loss=2.53] 15%|â–ˆâ–        | 73/500 [00:48<04:45,  1.50it/s, Train Loss=2.98, validation loss=2.53] 15%|â–ˆâ–        | 73/500 [00:49<04:45,  1.50it/s, Train Loss=2.87, validation loss=2.53] 15%|â–ˆâ–        | 74/500 [00:49<04:43,  1.50it/s, Train Loss=2.87, validation loss=2.53] 15%|â–ˆâ–        | 74/500 [00:50<04:43,  1.50it/s, Train Loss=2.69, validation loss=2.5]  15%|â–ˆâ–Œ        | 75/500 [00:50<04:43,  1.50it/s, Train Loss=2.69, validation loss=2.5] 15%|â–ˆâ–Œ        | 75/500 [00:50<04:43,  1.50it/s, Train Loss=1.95, validation loss=2.51] 15%|â–ˆâ–Œ        | 76/500 [00:50<04:37,  1.53it/s, Train Loss=1.95, validation loss=2.51] 15%|â–ˆâ–Œ        | 76/500 [00:51<04:37,  1.53it/s, Train Loss=2.58, validation loss=2.53] 15%|â–ˆâ–Œ        | 77/500 [00:51<04:32,  1.55it/s, Train Loss=2.58, validation loss=2.53] 15%|â–ˆâ–Œ        | 77/500 [00:51<04:32,  1.55it/s, Train Loss=1.35, validation loss=2.5]  16%|â–ˆâ–Œ        | 78/500 [00:51<04:33,  1.54it/s, Train Loss=1.35, validation loss=2.5] 16%|â–ˆâ–Œ        | 78/500 [00:52<04:33,  1.54it/s, Train Loss=2, validation loss=2.49]   16%|â–ˆâ–Œ        | 79/500 [00:52<04:29,  1.56it/s, Train Loss=2, validation loss=2.49] 16%|â–ˆâ–Œ        | 79/500 [00:53<04:29,  1.56it/s, Train Loss=3.07, validation loss=2.51] 16%|â–ˆâ–Œ        | 80/500 [00:53<04:24,  1.59it/s, Train Loss=3.07, validation loss=2.51] 16%|â–ˆâ–Œ        | 80/500 [00:53<04:24,  1.59it/s, Train Loss=2.67, validation loss=2.52] 16%|â–ˆâ–Œ        | 81/500 [00:53<04:26,  1.57it/s, Train Loss=2.67, validation loss=2.52] 16%|â–ˆâ–Œ        | 81/500 [00:54<04:26,  1.57it/s, Train Loss=2.55, validation loss=2.52] 16%|â–ˆâ–‹        | 82/500 [00:54<04:25,  1.57it/s, Train Loss=2.55, validation loss=2.52] 16%|â–ˆâ–‹        | 82/500 [00:55<04:25,  1.57it/s, Train Loss=2.66, validation loss=2.49] 17%|â–ˆâ–‹        | 83/500 [00:55<04:34,  1.52it/s, Train Loss=2.66, validation loss=2.49] 17%|â–ˆâ–‹        | 83/500 [00:55<04:34,  1.52it/s, Train Loss=2.09, validation loss=2.52] 17%|â–ˆâ–‹        | 84/500 [00:55<04:29,  1.54it/s, Train Loss=2.09, validation loss=2.52] 17%|â–ˆâ–‹        | 84/500 [00:56<04:29,  1.54it/s, Train Loss=2.93, validation loss=2.5]  17%|â–ˆâ–‹        | 85/500 [00:56<04:24,  1.57it/s, Train Loss=2.93, validation loss=2.5] 17%|â–ˆâ–‹        | 85/500 [00:56<04:24,  1.57it/s, Train Loss=2.53, validation loss=2.48] 17%|â–ˆâ–‹        | 86/500 [00:56<04:23,  1.57it/s, Train Loss=2.53, validation loss=2.48] 17%|â–ˆâ–‹        | 86/500 [00:57<04:23,  1.57it/s, Train Loss=1.54, validation loss=2.49] 17%|â–ˆâ–‹        | 87/500 [00:57<04:58,  1.38it/s, Train Loss=1.54, validation loss=2.49] 17%|â–ˆâ–‹        | 87/500 [00:58<04:58,  1.38it/s, Train Loss=1.81, validation loss=2.52] 18%|â–ˆâ–Š        | 88/500 [00:58<04:49,  1.42it/s, Train Loss=1.81, validation loss=2.52] 18%|â–ˆâ–Š        | 88/500 [00:59<04:49,  1.42it/s, Train Loss=3.71, validation loss=2.53] 18%|â–ˆâ–Š        | 89/500 [00:59<04:37,  1.48it/s, Train Loss=3.71, validation loss=2.53] 18%|â–ˆâ–Š        | 89/500 [00:59<04:37,  1.48it/s, Train Loss=3.16, validation loss=2.52] 18%|â–ˆâ–Š        | 90/500 [00:59<04:33,  1.50it/s, Train Loss=3.16, validation loss=2.52] 18%|â–ˆâ–Š        | 90/500 [01:00<04:33,  1.50it/s, Train Loss=1.89, validation loss=2.51] 18%|â–ˆâ–Š        | 91/500 [01:00<04:26,  1.53it/s, Train Loss=1.89, validation loss=2.51] 18%|â–ˆâ–Š        | 91/500 [01:01<04:26,  1.53it/s, Train Loss=2.6, validation loss=2.49]  18%|â–ˆâ–Š        | 92/500 [01:01<04:21,  1.56it/s, Train Loss=2.6, validation loss=2.49] 18%|â–ˆâ–Š        | 92/500 [01:01<04:21,  1.56it/s, Train Loss=1.71, validation loss=2.49] 19%|â–ˆâ–Š        | 93/500 [01:01<04:19,  1.57it/s, Train Loss=1.71, validation loss=2.49] 19%|â–ˆâ–Š        | 93/500 [01:02<04:19,  1.57it/s, Train Loss=2.33, validation loss=2.49] 19%|â–ˆâ–‰        | 94/500 [01:02<04:26,  1.52it/s, Train Loss=2.33, validation loss=2.49] 19%|â–ˆâ–‰        | 94/500 [01:03<04:26,  1.52it/s, Train Loss=2.21, validation loss=2.47] 19%|â–ˆâ–‰        | 95/500 [01:03<04:21,  1.55it/s, Train Loss=2.21, validation loss=2.47] 19%|â–ˆâ–‰        | 95/500 [01:03<04:21,  1.55it/s, Train Loss=2.36, validation loss=2.5]  19%|â–ˆâ–‰        | 96/500 [01:03<04:14,  1.59it/s, Train Loss=2.36, validation loss=2.5] 19%|â–ˆâ–‰        | 96/500 [01:04<04:14,  1.59it/s, Train Loss=2.37, validation loss=2.49] 19%|â–ˆâ–‰        | 97/500 [01:04<04:10,  1.61it/s, Train Loss=2.37, validation loss=2.49] 19%|â–ˆâ–‰        | 97/500 [01:04<04:10,  1.61it/s, Train Loss=1.8, validation loss=2.46]  20%|â–ˆâ–‰        | 98/500 [01:04<04:11,  1.60it/s, Train Loss=1.8, validation loss=2.46] 20%|â–ˆâ–‰        | 98/500 [01:05<04:11,  1.60it/s, Train Loss=2.4, validation loss=2.49] 20%|â–ˆâ–‰        | 99/500 [01:05<04:17,  1.56it/s, Train Loss=2.4, validation loss=2.49] 20%|â–ˆâ–‰        | 99/500 [01:06<04:17,  1.56it/s, Train Loss=1.77, validation loss=2.47] 20%|â–ˆâ–ˆ        | 100/500 [01:06<04:17,  1.55it/s, Train Loss=1.77, validation loss=2.47] 20%|â–ˆâ–ˆ        | 100/500 [01:06<04:17,  1.55it/s, Train Loss=1.55, validation loss=2.47] 20%|â–ˆâ–ˆ        | 101/500 [01:06<04:11,  1.59it/s, Train Loss=1.55, validation loss=2.47] 20%|â–ˆâ–ˆ        | 101/500 [01:07<04:11,  1.59it/s, Train Loss=2.39, validation loss=2.48] 20%|â–ˆâ–ˆ        | 102/500 [01:07<04:10,  1.59it/s, Train Loss=2.39, validation loss=2.48] 20%|â–ˆâ–ˆ        | 102/500 [01:08<04:10,  1.59it/s, Train Loss=2.99, validation loss=2.47] 21%|â–ˆâ–ˆ        | 103/500 [01:08<04:10,  1.58it/s, Train Loss=2.99, validation loss=2.47] 21%|â–ˆâ–ˆ        | 103/500 [01:08<04:10,  1.58it/s, Train Loss=2.32, validation loss=2.48] 21%|â–ˆâ–ˆ        | 104/500 [01:08<04:08,  1.59it/s, Train Loss=2.32, validation loss=2.48] 21%|â–ˆâ–ˆ        | 104/500 [01:09<04:08,  1.59it/s, Train Loss=2.61, validation loss=2.48] 21%|â–ˆâ–ˆ        | 105/500 [01:09<04:04,  1.62it/s, Train Loss=2.61, validation loss=2.48] 21%|â–ˆâ–ˆ        | 105/500 [01:10<04:04,  1.62it/s, Train Loss=2.54, validation loss=2.46] 21%|â–ˆâ–ˆ        | 106/500 [01:10<04:20,  1.51it/s, Train Loss=2.54, validation loss=2.46] 21%|â–ˆâ–ˆ        | 106/500 [01:10<04:20,  1.51it/s, Train Loss=2.68, validation loss=2.48] 21%|â–ˆâ–ˆâ–       | 107/500 [01:10<04:15,  1.54it/s, Train Loss=2.68, validation loss=2.48] 21%|â–ˆâ–ˆâ–       | 107/500 [01:11<04:15,  1.54it/s, Train Loss=2.01, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 108/500 [01:11<04:13,  1.55it/s, Train Loss=2.01, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 108/500 [01:11<04:13,  1.55it/s, Train Loss=2.23, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 109/500 [01:11<04:12,  1.55it/s, Train Loss=2.23, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 109/500 [01:12<04:12,  1.55it/s, Train Loss=2.01, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 110/500 [01:12<04:11,  1.55it/s, Train Loss=2.01, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 110/500 [01:13<04:11,  1.55it/s, Train Loss=1.74, validation loss=2.49] 22%|â–ˆâ–ˆâ–       | 111/500 [01:13<04:05,  1.59it/s, Train Loss=1.74, validation loss=2.49] 22%|â–ˆâ–ˆâ–       | 111/500 [01:13<04:05,  1.59it/s, Train Loss=2.34, validation loss=2.5]  22%|â–ˆâ–ˆâ–       | 112/500 [01:13<04:11,  1.54it/s, Train Loss=2.34, validation loss=2.5] 22%|â–ˆâ–ˆâ–       | 112/500 [01:14<04:11,  1.54it/s, Train Loss=2.43, validation loss=2.44] 23%|â–ˆâ–ˆâ–       | 113/500 [01:14<04:06,  1.57it/s, Train Loss=2.43, validation loss=2.44] 23%|â–ˆâ–ˆâ–       | 113/500 [01:15<04:06,  1.57it/s, Train Loss=1.96, validation loss=2.47] 23%|â–ˆâ–ˆâ–       | 114/500 [01:15<04:07,  1.56it/s, Train Loss=1.96, validation loss=2.47] 23%|â–ˆâ–ˆâ–       | 114/500 [01:15<04:07,  1.56it/s, Train Loss=2.32, validation loss=2.49] 23%|â–ˆâ–ˆâ–       | 115/500 [01:15<04:07,  1.56it/s, Train Loss=2.32, validation loss=2.49] 23%|â–ˆâ–ˆâ–       | 115/500 [01:16<04:07,  1.56it/s, Train Loss=2.31, validation loss=2.48] 23%|â–ˆâ–ˆâ–       | 116/500 [01:16<04:05,  1.56it/s, Train Loss=2.31, validation loss=2.48] 23%|â–ˆâ–ˆâ–       | 116/500 [01:17<04:05,  1.56it/s, Train Loss=2.26, validation loss=2.47] 23%|â–ˆâ–ˆâ–       | 117/500 [01:17<04:04,  1.57it/s, Train Loss=2.26, validation loss=2.47] 23%|â–ˆâ–ˆâ–       | 117/500 [01:17<04:04,  1.57it/s, Train Loss=2.83, validation loss=2.45] 24%|â–ˆâ–ˆâ–       | 118/500 [01:17<04:08,  1.54it/s, Train Loss=2.83, validation loss=2.45] 24%|â–ˆâ–ˆâ–       | 118/500 [01:18<04:08,  1.54it/s, Train Loss=1.49, validation loss=2.5]  24%|â–ˆâ–ˆâ–       | 119/500 [01:18<04:07,  1.54it/s, Train Loss=1.49, validation loss=2.5] 24%|â–ˆâ–ˆâ–       | 119/500 [01:18<04:07,  1.54it/s, Train Loss=2.58, validation loss=2.5] 24%|â–ˆâ–ˆâ–       | 120/500 [01:18<04:02,  1.57it/s, Train Loss=2.58, validation loss=2.5] 24%|â–ˆâ–ˆâ–       | 120/500 [01:19<04:02,  1.57it/s, Train Loss=2.93, validation loss=2.48] 24%|â–ˆâ–ˆâ–       | 121/500 [01:19<04:02,  1.56it/s, Train Loss=2.93, validation loss=2.48] 24%|â–ˆâ–ˆâ–       | 121/500 [01:20<04:02,  1.56it/s, Train Loss=2.13, validation loss=2.47] 24%|â–ˆâ–ˆâ–       | 122/500 [01:20<04:01,  1.56it/s, Train Loss=2.13, validation loss=2.47] 24%|â–ˆâ–ˆâ–       | 122/500 [01:20<04:01,  1.56it/s, Train Loss=3.15, validation loss=2.48] 25%|â–ˆâ–ˆâ–       | 123/500 [01:20<03:55,  1.60it/s, Train Loss=3.15, validation loss=2.48] 25%|â–ˆâ–ˆâ–       | 123/500 [01:21<03:55,  1.60it/s, Train Loss=1.7, validation loss=2.48]  25%|â–ˆâ–ˆâ–       | 124/500 [01:21<04:01,  1.56it/s, Train Loss=1.7, validation loss=2.48] 25%|â–ˆâ–ˆâ–       | 124/500 [01:22<04:01,  1.56it/s, Train Loss=1.29, validation loss=2.45] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:22<04:00,  1.56it/s, Train Loss=1.29, validation loss=2.45] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:22<04:00,  1.56it/s, Train Loss=1.58, validation loss=2.45] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:22<04:00,  1.55it/s, Train Loss=1.58, validation loss=2.45] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:23<04:00,  1.55it/s, Train Loss=2.29, validation loss=2.45] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:23<03:57,  1.57it/s, Train Loss=2.29, validation loss=2.45] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:24<03:57,  1.57it/s, Train Loss=3.07, validation loss=2.47] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:24<03:53,  1.59it/s, Train Loss=3.07, validation loss=2.47] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:24<03:53,  1.59it/s, Train Loss=2.34, validation loss=2.45] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:24<03:50,  1.61it/s, Train Loss=2.34, validation loss=2.45] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:25<03:50,  1.61it/s, Train Loss=1.41, validation loss=2.46] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:25<03:59,  1.55it/s, Train Loss=1.41, validation loss=2.46] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:25<03:59,  1.55it/s, Train Loss=2.16, validation loss=2.48] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:25<03:57,  1.56it/s, Train Loss=2.16, validation loss=2.48] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:26<03:57,  1.56it/s, Train Loss=1.69, validation loss=2.45] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:26<03:55,  1.56it/s, Train Loss=1.69, validation loss=2.45] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:27<03:55,  1.56it/s, Train Loss=1.55, validation loss=2.47] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:27<03:54,  1.56it/s, Train Loss=1.55, validation loss=2.47] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:27<03:54,  1.56it/s, Train Loss=2.54, validation loss=2.47] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:27<03:50,  1.59it/s, Train Loss=2.54, validation loss=2.47] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:28<03:50,  1.59it/s, Train Loss=2.79, validation loss=2.44] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:28<04:03,  1.50it/s, Train Loss=2.79, validation loss=2.44] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:29<04:03,  1.50it/s, Train Loss=2.11, validation loss=2.45] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:29<04:17,  1.41it/s, Train Loss=2.11, validation loss=2.45] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:30<04:17,  1.41it/s, Train Loss=1.82, validation loss=2.46] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:30<04:07,  1.47it/s, Train Loss=1.82, validation loss=2.46] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:30<04:07,  1.47it/s, Train Loss=2.43, validation loss=2.46] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:30<03:59,  1.51it/s, Train Loss=2.43, validation loss=2.46] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:31<03:59,  1.51it/s, Train Loss=3.01, validation loss=2.44] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:31<03:50,  1.56it/s, Train Loss=3.01, validation loss=2.44] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:31<03:50,  1.56it/s, Train Loss=2.92, validation loss=2.44] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:31<03:47,  1.58it/s, Train Loss=2.92, validation loss=2.44] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:32<03:47,  1.58it/s, Train Loss=2.79, validation loss=2.41] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:32<03:52,  1.54it/s, Train Loss=2.79, validation loss=2.41] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:33<03:52,  1.54it/s, Train Loss=1.35, validation loss=2.44] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:33<03:54,  1.53it/s, Train Loss=1.35, validation loss=2.44] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:33<03:54,  1.53it/s, Train Loss=1.39, validation loss=2.42] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:33<03:51,  1.55it/s, Train Loss=1.39, validation loss=2.42] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:34<03:51,  1.55it/s, Train Loss=2, validation loss=2.44]    29%|â–ˆâ–ˆâ–‰       | 144/500 [01:34<03:46,  1.57it/s, Train Loss=2, validation loss=2.44] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:35<03:46,  1.57it/s, Train Loss=2.42, validation loss=2.46] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:35<03:45,  1.58it/s, Train Loss=2.42, validation loss=2.46] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:35<03:45,  1.58it/s, Train Loss=2.19, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:35<03:46,  1.56it/s, Train Loss=2.19, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:36<03:46,  1.56it/s, Train Loss=2.32, validation loss=2.43] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:36<03:43,  1.58it/s, Train Loss=2.32, validation loss=2.43] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:37<03:43,  1.58it/s, Train Loss=2.01, validation loss=2.45] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:37<03:54,  1.50it/s, Train Loss=2.01, validation loss=2.45] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:37<03:54,  1.50it/s, Train Loss=1.73, validation loss=2.42] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:37<03:50,  1.53it/s, Train Loss=1.73, validation loss=2.42] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:38<03:50,  1.53it/s, Train Loss=1.69, validation loss=2.42] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:38<03:44,  1.56it/s, Train Loss=1.69, validation loss=2.42] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:38<03:44,  1.56it/s, Train Loss=1.56, validation loss=2.42] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:38<03:42,  1.57it/s, Train Loss=1.56, validation loss=2.42] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:39<03:42,  1.57it/s, Train Loss=2, validation loss=2.42]    30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:39<03:40,  1.58it/s, Train Loss=2, validation loss=2.42] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:40<03:40,  1.58it/s, Train Loss=2.87, validation loss=2.43] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:40<03:47,  1.53it/s, Train Loss=2.87, validation loss=2.43] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:40<03:47,  1.53it/s, Train Loss=2.49, validation loss=2.44] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:40<03:44,  1.54it/s, Train Loss=2.49, validation loss=2.44] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:41<03:44,  1.54it/s, Train Loss=4.88, validation loss=2.45] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:41<03:43,  1.54it/s, Train Loss=4.88, validation loss=2.45] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:42<03:43,  1.54it/s, Train Loss=1.63, validation loss=2.45] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:42<03:39,  1.57it/s, Train Loss=1.63, validation loss=2.45] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:42<03:39,  1.57it/s, Train Loss=3.18, validation loss=2.45] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:42<03:40,  1.55it/s, Train Loss=3.18, validation loss=2.45] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:43<03:40,  1.55it/s, Train Loss=1.6, validation loss=2.45]  32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:43<03:40,  1.55it/s, Train Loss=1.6, validation loss=2.45] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:44<03:40,  1.55it/s, Train Loss=1.47, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:44<03:37,  1.57it/s, Train Loss=1.47, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:44<03:37,  1.57it/s, Train Loss=2.66, validation loss=2.41] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:44<03:47,  1.49it/s, Train Loss=2.66, validation loss=2.41] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:45<03:47,  1.49it/s, Train Loss=2.52, validation loss=2.45] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:45<03:44,  1.51it/s, Train Loss=2.52, validation loss=2.45] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:46<03:44,  1.51it/s, Train Loss=2.8, validation loss=2.44]  32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:46<03:40,  1.53it/s, Train Loss=2.8, validation loss=2.44] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:46<03:40,  1.53it/s, Train Loss=1.68, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:46<03:35,  1.56it/s, Train Loss=1.68, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:47<03:35,  1.56it/s, Train Loss=2.69, validation loss=2.44] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:47<03:37,  1.55it/s, Train Loss=2.69, validation loss=2.44] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:48<03:37,  1.55it/s, Train Loss=1.95, validation loss=2.41] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:48<03:36,  1.55it/s, Train Loss=1.95, validation loss=2.41] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:48<03:36,  1.55it/s, Train Loss=1.65, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:48<03:35,  1.55it/s, Train Loss=1.65, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:49<03:35,  1.55it/s, Train Loss=1.74, validation loss=2.44] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:49<03:33,  1.56it/s, Train Loss=1.74, validation loss=2.44] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:49<03:33,  1.56it/s, Train Loss=1.58, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:49<03:32,  1.56it/s, Train Loss=1.58, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:50<03:32,  1.56it/s, Train Loss=1.89, validation loss=2.45] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:50<03:27,  1.59it/s, Train Loss=1.89, validation loss=2.45] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:51<03:27,  1.59it/s, Train Loss=2.18, validation loss=2.44] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:51<03:27,  1.59it/s, Train Loss=2.18, validation loss=2.44] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:51<03:27,  1.59it/s, Train Loss=2.04, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:51<03:31,  1.55it/s, Train Loss=2.04, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:52<03:31,  1.55it/s, Train Loss=2.25, validation loss=2.44] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:52<03:31,  1.55it/s, Train Loss=2.25, validation loss=2.44] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:53<03:31,  1.55it/s, Train Loss=1.78, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:53<03:27,  1.58it/s, Train Loss=1.78, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:53<03:27,  1.58it/s, Train Loss=2.35, validation loss=2.42] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:53<03:29,  1.55it/s, Train Loss=2.35, validation loss=2.42] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:54<03:29,  1.55it/s, Train Loss=1.39, validation loss=2.43] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:54<03:24,  1.59it/s, Train Loss=1.39, validation loss=2.43] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:55<03:24,  1.59it/s, Train Loss=1.58, validation loss=2.42] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:55<03:33,  1.52it/s, Train Loss=1.58, validation loss=2.42] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:55<03:33,  1.52it/s, Train Loss=2.94, validation loss=2.43] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:55<03:29,  1.54it/s, Train Loss=2.94, validation loss=2.43] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:56<03:29,  1.54it/s, Train Loss=3.01, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:56<03:27,  1.55it/s, Train Loss=3.01, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:56<03:27,  1.55it/s, Train Loss=2.8, validation loss=2.42]  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:56<03:24,  1.57it/s, Train Loss=2.8, validation loss=2.42] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:57<03:24,  1.57it/s, Train Loss=1.97, validation loss=2.4] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:57<03:20,  1.59it/s, Train Loss=1.97, validation loss=2.4] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:58<03:20,  1.59it/s, Train Loss=2.37, validation loss=2.41] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:58<03:18,  1.60it/s, Train Loss=2.37, validation loss=2.41] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:58<03:18,  1.60it/s, Train Loss=1.97, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:58<03:15,  1.63it/s, Train Loss=1.97, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:59<03:15,  1.63it/s, Train Loss=3.07, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:59<03:31,  1.50it/s, Train Loss=3.07, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [02:00<03:31,  1.50it/s, Train Loss=1.73, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [02:00<03:29,  1.51it/s, Train Loss=1.73, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [02:00<03:29,  1.51it/s, Train Loss=3.35, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [02:00<03:22,  1.55it/s, Train Loss=3.35, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [02:01<03:22,  1.55it/s, Train Loss=1.76, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:01<03:22,  1.55it/s, Train Loss=1.76, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:02<03:22,  1.55it/s, Train Loss=3.23, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:02<03:20,  1.56it/s, Train Loss=3.23, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:02<03:20,  1.56it/s, Train Loss=2.33, validation loss=2.42] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:02<03:23,  1.53it/s, Train Loss=2.33, validation loss=2.42] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:03<03:23,  1.53it/s, Train Loss=2.02, validation loss=2.41] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:03<03:18,  1.57it/s, Train Loss=2.02, validation loss=2.41] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:04<03:18,  1.57it/s, Train Loss=2.4, validation loss=2.42]  38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:04<03:18,  1.56it/s, Train Loss=2.4, validation loss=2.42] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:04<03:18,  1.56it/s, Train Loss=2.18, validation loss=2.42] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:04<03:15,  1.58it/s, Train Loss=2.18, validation loss=2.42] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:05<03:15,  1.58it/s, Train Loss=1.89, validation loss=2.39] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:05<03:14,  1.59it/s, Train Loss=1.89, validation loss=2.39] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:05<03:14,  1.59it/s, Train Loss=1.5, validation loss=2.43]  39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:05<03:13,  1.59it/s, Train Loss=1.5, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:06<03:13,  1.59it/s, Train Loss=1.93, validation loss=2.41] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:06<03:11,  1.60it/s, Train Loss=1.93, validation loss=2.41] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:07<03:11,  1.60it/s, Train Loss=1.42, validation loss=2.44] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:07<03:15,  1.56it/s, Train Loss=1.42, validation loss=2.44] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:07<03:15,  1.56it/s, Train Loss=2.79, validation loss=2.44] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:07<03:11,  1.59it/s, Train Loss=2.79, validation loss=2.44] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:08<03:11,  1.59it/s, Train Loss=1.5, validation loss=2.45]  39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:08<03:11,  1.58it/s, Train Loss=1.5, validation loss=2.45] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:09<03:11,  1.58it/s, Train Loss=3.79, validation loss=2.42] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:09<03:10,  1.58it/s, Train Loss=3.79, validation loss=2.42] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:09<03:10,  1.58it/s, Train Loss=1.52, validation loss=2.41] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:09<03:13,  1.56it/s, Train Loss=1.52, validation loss=2.41] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:10<03:13,  1.56it/s, Train Loss=2.13, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:10<03:12,  1.56it/s, Train Loss=2.13, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:11<03:12,  1.56it/s, Train Loss=3.39, validation loss=2.42] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:11<03:10,  1.57it/s, Train Loss=3.39, validation loss=2.42] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:11<03:10,  1.57it/s, Train Loss=1.33, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:11<03:07,  1.59it/s, Train Loss=1.33, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:12<03:07,  1.59it/s, Train Loss=1.91, validation loss=2.41] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:12<03:08,  1.57it/s, Train Loss=1.91, validation loss=2.41] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:12<03:08,  1.57it/s, Train Loss=2.47, validation loss=2.41] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:12<03:08,  1.57it/s, Train Loss=2.47, validation loss=2.41] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:13<03:08,  1.57it/s, Train Loss=1.7, validation loss=2.4]   41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:13<03:05,  1.59it/s, Train Loss=1.7, validation loss=2.4] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:14<03:05,  1.59it/s, Train Loss=2.4, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:14<03:11,  1.53it/s, Train Loss=2.4, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:14<03:11,  1.53it/s, Train Loss=1.89, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:14<03:10,  1.54it/s, Train Loss=1.89, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:15<03:10,  1.54it/s, Train Loss=2.89, validation loss=2.41] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:15<03:08,  1.55it/s, Train Loss=2.89, validation loss=2.41] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:16<03:08,  1.55it/s, Train Loss=1.52, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:16<03:06,  1.56it/s, Train Loss=1.52, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:16<03:06,  1.56it/s, Train Loss=2.18, validation loss=2.41] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:16<03:06,  1.56it/s, Train Loss=2.18, validation loss=2.41] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:17<03:06,  1.56it/s, Train Loss=2.87, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:17<03:13,  1.50it/s, Train Loss=2.87, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:18<03:13,  1.50it/s, Train Loss=3.29, validation loss=2.42] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:18<03:11,  1.51it/s, Train Loss=3.29, validation loss=2.42] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:18<03:11,  1.51it/s, Train Loss=2.56, validation loss=2.41] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:18<03:07,  1.53it/s, Train Loss=2.56, validation loss=2.41] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:19<03:07,  1.53it/s, Train Loss=3.39, validation loss=2.4]  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:19<03:03,  1.56it/s, Train Loss=3.39, validation loss=2.4] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:20<03:03,  1.56it/s, Train Loss=1.59, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:20<03:01,  1.57it/s, Train Loss=1.59, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:20<03:01,  1.57it/s, Train Loss=3.8, validation loss=2.43]  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:20<03:00,  1.57it/s, Train Loss=3.8, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:21<03:00,  1.57it/s, Train Loss=1.5, validation loss=2.42] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:21<03:06,  1.51it/s, Train Loss=1.5, validation loss=2.42] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:22<03:06,  1.51it/s, Train Loss=2.42, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:22<03:03,  1.53it/s, Train Loss=2.42, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:22<03:03,  1.53it/s, Train Loss=1.8, validation loss=2.4]   44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:22<03:01,  1.55it/s, Train Loss=1.8, validation loss=2.4] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:23<03:01,  1.55it/s, Train Loss=2.69, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:23<02:59,  1.56it/s, Train Loss=2.69, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:23<02:59,  1.56it/s, Train Loss=2.25, validation loss=2.4]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:23<02:55,  1.59it/s, Train Loss=2.25, validation loss=2.4] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:24<02:55,  1.59it/s, Train Loss=1.95, validation loss=2.4] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:24<03:01,  1.53it/s, Train Loss=1.95, validation loss=2.4] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:25<03:01,  1.53it/s, Train Loss=2, validation loss=2.41]   45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:25<03:00,  1.53it/s, Train Loss=2, validation loss=2.41] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:25<03:00,  1.53it/s, Train Loss=1.51, validation loss=2.43] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:25<02:57,  1.56it/s, Train Loss=1.51, validation loss=2.43] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:26<02:57,  1.56it/s, Train Loss=1.83, validation loss=2.41] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:26<02:55,  1.56it/s, Train Loss=1.83, validation loss=2.41] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:27<02:55,  1.56it/s, Train Loss=3.07, validation loss=2.41] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:27<02:56,  1.55it/s, Train Loss=3.07, validation loss=2.41] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:27<02:56,  1.55it/s, Train Loss=2.6, validation loss=2.41]  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:27<02:52,  1.58it/s, Train Loss=2.6, validation loss=2.41] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:28<02:52,  1.58it/s, Train Loss=2.56, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:28<02:59,  1.51it/s, Train Loss=2.56, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:29<02:59,  1.51it/s, Train Loss=2.75, validation loss=2.4]  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:29<02:57,  1.53it/s, Train Loss=2.75, validation loss=2.4] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:29<02:57,  1.53it/s, Train Loss=2.51, validation loss=2.4] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:29<02:53,  1.56it/s, Train Loss=2.51, validation loss=2.4] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:30<02:53,  1.56it/s, Train Loss=1.78, validation loss=2.4] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:30<03:04,  1.46it/s, Train Loss=1.78, validation loss=2.4] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:31<03:04,  1.46it/s, Train Loss=3.43, validation loss=2.41] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:31<02:59,  1.49it/s, Train Loss=3.43, validation loss=2.41] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:31<02:59,  1.49it/s, Train Loss=1.83, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:31<02:57,  1.50it/s, Train Loss=1.83, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:32<02:57,  1.50it/s, Train Loss=1.34, validation loss=2.4]  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:32<03:00,  1.47it/s, Train Loss=1.34, validation loss=2.4] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:33<03:00,  1.47it/s, Train Loss=2.13, validation loss=2.39] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:33<02:55,  1.51it/s, Train Loss=2.13, validation loss=2.39] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:33<02:55,  1.51it/s, Train Loss=2.05, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:33<02:52,  1.53it/s, Train Loss=2.05, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:34<02:52,  1.53it/s, Train Loss=1.63, validation loss=2.4]  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:34<02:50,  1.54it/s, Train Loss=1.63, validation loss=2.4] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:35<02:50,  1.54it/s, Train Loss=2.64, validation loss=2.41] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:35<02:48,  1.56it/s, Train Loss=2.64, validation loss=2.41] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:35<02:48,  1.56it/s, Train Loss=1.97, validation loss=2.4]  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:35<02:53,  1.51it/s, Train Loss=1.97, validation loss=2.4] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:36<02:53,  1.51it/s, Train Loss=2.23, validation loss=2.41] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:36<02:49,  1.53it/s, Train Loss=2.23, validation loss=2.41] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:37<02:49,  1.53it/s, Train Loss=1.32, validation loss=2.41] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:37<02:47,  1.55it/s, Train Loss=1.32, validation loss=2.41] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:37<02:47,  1.55it/s, Train Loss=2.53, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:37<02:46,  1.55it/s, Train Loss=2.53, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:38<02:46,  1.55it/s, Train Loss=2.71, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:38<02:43,  1.58it/s, Train Loss=2.71, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:38<02:43,  1.58it/s, Train Loss=3.09, validation loss=2.41] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:38<02:42,  1.58it/s, Train Loss=3.09, validation loss=2.41] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:39<02:42,  1.58it/s, Train Loss=2.05, validation loss=2.43] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:39<02:49,  1.51it/s, Train Loss=2.05, validation loss=2.43] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:40<02:49,  1.51it/s, Train Loss=1.38, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:40<02:45,  1.53it/s, Train Loss=1.38, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:40<02:45,  1.53it/s, Train Loss=1.81, validation loss=2.38] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:40<02:43,  1.55it/s, Train Loss=1.81, validation loss=2.38] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:41<02:43,  1.55it/s, Train Loss=1.89, validation loss=2.41] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:41<02:40,  1.57it/s, Train Loss=1.89, validation loss=2.41] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:42<02:40,  1.57it/s, Train Loss=3.79, validation loss=2.39] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:42<02:38,  1.58it/s, Train Loss=3.79, validation loss=2.39] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:42<02:38,  1.58it/s, Train Loss=3.14, validation loss=2.4]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:42<02:45,  1.51it/s, Train Loss=3.14, validation loss=2.4] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:43<02:45,  1.51it/s, Train Loss=1.7, validation loss=2.4]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:43<02:41,  1.54it/s, Train Loss=1.7, validation loss=2.4] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:44<02:41,  1.54it/s, Train Loss=2.31, validation loss=2.41] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:44<02:40,  1.54it/s, Train Loss=2.31, validation loss=2.41] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:44<02:40,  1.54it/s, Train Loss=3.2, validation loss=2.39]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:44<02:36,  1.57it/s, Train Loss=3.2, validation loss=2.39] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:45<02:36,  1.57it/s, Train Loss=1.1, validation loss=2.4]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:45<02:39,  1.54it/s, Train Loss=1.1, validation loss=2.4] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:46<02:39,  1.54it/s, Train Loss=1.26, validation loss=2.4] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:46<02:36,  1.56it/s, Train Loss=1.26, validation loss=2.4] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:46<02:36,  1.56it/s, Train Loss=1.33, validation loss=2.4] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:46<02:39,  1.53it/s, Train Loss=1.33, validation loss=2.4] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:47<02:39,  1.53it/s, Train Loss=2.18, validation loss=2.39] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:47<02:37,  1.55it/s, Train Loss=2.18, validation loss=2.39] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:47<02:37,  1.55it/s, Train Loss=2.37, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:47<02:35,  1.56it/s, Train Loss=2.37, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:48<02:35,  1.56it/s, Train Loss=2.82, validation loss=2.43] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:48<02:34,  1.56it/s, Train Loss=2.82, validation loss=2.43] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:49<02:34,  1.56it/s, Train Loss=2.55, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:49<02:31,  1.59it/s, Train Loss=2.55, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:49<02:31,  1.59it/s, Train Loss=1.58, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:49<02:35,  1.54it/s, Train Loss=1.58, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:50<02:35,  1.54it/s, Train Loss=2.79, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:50<02:31,  1.57it/s, Train Loss=2.79, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:51<02:31,  1.57it/s, Train Loss=2.36, validation loss=2.41] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:51<02:28,  1.60it/s, Train Loss=2.36, validation loss=2.41] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:51<02:28,  1.60it/s, Train Loss=2.98, validation loss=2.4]  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:51<02:27,  1.60it/s, Train Loss=2.98, validation loss=2.4] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:52<02:27,  1.60it/s, Train Loss=1.27, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:52<02:26,  1.61it/s, Train Loss=1.27, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:52<02:26,  1.61it/s, Train Loss=2.55, validation loss=2.41] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:52<02:26,  1.60it/s, Train Loss=2.55, validation loss=2.41] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:53<02:26,  1.60it/s, Train Loss=2.88, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:53<02:25,  1.60it/s, Train Loss=2.88, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:54<02:25,  1.60it/s, Train Loss=3.05, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:54<02:27,  1.57it/s, Train Loss=3.05, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:54<02:27,  1.57it/s, Train Loss=1.86, validation loss=2.41] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:54<02:25,  1.59it/s, Train Loss=1.86, validation loss=2.41] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:55<02:25,  1.59it/s, Train Loss=3.41, validation loss=2.41] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:55<02:23,  1.61it/s, Train Loss=3.41, validation loss=2.41] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:56<02:23,  1.61it/s, Train Loss=2.3, validation loss=2.39]  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:56<02:22,  1.61it/s, Train Loss=2.3, validation loss=2.39] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:56<02:22,  1.61it/s, Train Loss=1.58, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:56<02:24,  1.58it/s, Train Loss=1.58, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:57<02:24,  1.58it/s, Train Loss=2.55, validation loss=2.43] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:57<02:27,  1.54it/s, Train Loss=2.55, validation loss=2.43] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:58<02:27,  1.54it/s, Train Loss=2.05, validation loss=2.4]  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:58<02:26,  1.54it/s, Train Loss=2.05, validation loss=2.4] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:58<02:26,  1.54it/s, Train Loss=2.23, validation loss=2.39] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:58<02:23,  1.57it/s, Train Loss=2.23, validation loss=2.39] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:59<02:23,  1.57it/s, Train Loss=1.76, validation loss=2.39] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:59<02:25,  1.54it/s, Train Loss=1.76, validation loss=2.39] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [03:00<02:25,  1.54it/s, Train Loss=3.6, validation loss=2.39]  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [03:00<02:22,  1.56it/s, Train Loss=3.6, validation loss=2.39] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [03:00<02:22,  1.56it/s, Train Loss=2.39, validation loss=2.4] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [03:00<02:33,  1.45it/s, Train Loss=2.39, validation loss=2.4] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [03:01<02:33,  1.45it/s, Train Loss=1.81, validation loss=2.41] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:01<02:37,  1.40it/s, Train Loss=1.81, validation loss=2.41] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:02<02:37,  1.40it/s, Train Loss=1.87, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:02<02:30,  1.46it/s, Train Loss=1.87, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:02<02:30,  1.46it/s, Train Loss=3.04, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:02<02:25,  1.50it/s, Train Loss=3.04, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:03<02:25,  1.50it/s, Train Loss=1.72, validation loss=2.4]  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:03<02:23,  1.52it/s, Train Loss=1.72, validation loss=2.4] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:04<02:23,  1.52it/s, Train Loss=1.7, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:04<02:25,  1.49it/s, Train Loss=1.7, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:04<02:25,  1.49it/s, Train Loss=1.97, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:04<02:21,  1.52it/s, Train Loss=1.97, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:05<02:21,  1.52it/s, Train Loss=2.25, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:05<02:18,  1.56it/s, Train Loss=2.25, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:06<02:18,  1.56it/s, Train Loss=2.09, validation loss=2.41] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:06<02:14,  1.59it/s, Train Loss=2.09, validation loss=2.41] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:06<02:14,  1.59it/s, Train Loss=1.91, validation loss=2.4]  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:06<02:13,  1.60it/s, Train Loss=1.91, validation loss=2.4] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:07<02:13,  1.60it/s, Train Loss=2.47, validation loss=2.4] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:07<02:13,  1.59it/s, Train Loss=2.47, validation loss=2.4] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:07<02:13,  1.59it/s, Train Loss=2.96, validation loss=2.4] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:07<02:11,  1.61it/s, Train Loss=2.96, validation loss=2.4] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:08<02:11,  1.61it/s, Train Loss=2.51, validation loss=2.41] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:08<02:11,  1.59it/s, Train Loss=2.51, validation loss=2.41] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:09<02:11,  1.59it/s, Train Loss=1.25, validation loss=2.4]  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:09<02:16,  1.53it/s, Train Loss=1.25, validation loss=2.4] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:09<02:16,  1.53it/s, Train Loss=2.37, validation loss=2.4] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:09<02:13,  1.56it/s, Train Loss=2.37, validation loss=2.4] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:10<02:13,  1.56it/s, Train Loss=2.37, validation loss=2.4] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:10<02:12,  1.56it/s, Train Loss=2.37, validation loss=2.4] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:11<02:12,  1.56it/s, Train Loss=1.7, validation loss=2.39] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:11<02:13,  1.55it/s, Train Loss=1.7, validation loss=2.39] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:11<02:13,  1.55it/s, Train Loss=2.65, validation loss=2.4] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:11<02:16,  1.50it/s, Train Loss=2.65, validation loss=2.4] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:12<02:16,  1.50it/s, Train Loss=2.55, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:12<02:14,  1.51it/s, Train Loss=2.55, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:13<02:14,  1.51it/s, Train Loss=2.38, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:13<02:11,  1.54it/s, Train Loss=2.38, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:13<02:11,  1.54it/s, Train Loss=1.72, validation loss=2.42] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:13<02:10,  1.55it/s, Train Loss=1.72, validation loss=2.42] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:14<02:10,  1.55it/s, Train Loss=2.37, validation loss=2.41] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:14<02:09,  1.56it/s, Train Loss=2.37, validation loss=2.41] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:15<02:09,  1.56it/s, Train Loss=2.82, validation loss=2.39] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:15<02:07,  1.57it/s, Train Loss=2.82, validation loss=2.39] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:15<02:07,  1.57it/s, Train Loss=1.4, validation loss=2.38]  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:15<02:05,  1.59it/s, Train Loss=1.4, validation loss=2.38] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:16<02:05,  1.59it/s, Train Loss=1.58, validation loss=2.38] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:16<02:07,  1.55it/s, Train Loss=1.58, validation loss=2.38] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:16<02:07,  1.55it/s, Train Loss=1.6, validation loss=2.41]  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:16<02:07,  1.55it/s, Train Loss=1.6, validation loss=2.41] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:17<02:07,  1.55it/s, Train Loss=1.05, validation loss=2.41] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:17<02:06,  1.55it/s, Train Loss=1.05, validation loss=2.41] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:18<02:06,  1.55it/s, Train Loss=2.6, validation loss=2.41]  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:18<02:05,  1.55it/s, Train Loss=2.6, validation loss=2.41] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:18<02:05,  1.55it/s, Train Loss=2.22, validation loss=2.44] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:18<02:07,  1.52it/s, Train Loss=2.22, validation loss=2.44] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:19<02:07,  1.52it/s, Train Loss=2.48, validation loss=2.41] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:19<02:05,  1.54it/s, Train Loss=2.48, validation loss=2.41] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:20<02:05,  1.54it/s, Train Loss=2.49, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:20<02:03,  1.55it/s, Train Loss=2.49, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:20<02:03,  1.55it/s, Train Loss=2.02, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:20<02:01,  1.57it/s, Train Loss=2.02, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:21<02:01,  1.57it/s, Train Loss=2.55, validation loss=2.39] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:21<02:00,  1.58it/s, Train Loss=2.55, validation loss=2.39] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:22<02:00,  1.58it/s, Train Loss=2.59, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:22<01:59,  1.59it/s, Train Loss=2.59, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:22<01:59,  1.59it/s, Train Loss=2.7, validation loss=2.41]  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:22<01:57,  1.59it/s, Train Loss=2.7, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:23<01:57,  1.59it/s, Train Loss=1.36, validation loss=2.43] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:23<02:00,  1.55it/s, Train Loss=1.36, validation loss=2.43] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:24<02:00,  1.55it/s, Train Loss=2.5, validation loss=2.42]  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:24<01:59,  1.55it/s, Train Loss=2.5, validation loss=2.42] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:24<01:59,  1.55it/s, Train Loss=2.11, validation loss=2.4] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:24<01:57,  1.57it/s, Train Loss=2.11, validation loss=2.4] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:25<01:57,  1.57it/s, Train Loss=2.12, validation loss=2.42] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:25<01:57,  1.56it/s, Train Loss=2.12, validation loss=2.42] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:25<01:57,  1.56it/s, Train Loss=2.05, validation loss=2.4]  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:25<01:56,  1.57it/s, Train Loss=2.05, validation loss=2.4] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:26<01:56,  1.57it/s, Train Loss=1.45, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:26<01:59,  1.52it/s, Train Loss=1.45, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:27<01:59,  1.52it/s, Train Loss=2.85, validation loss=2.38] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:27<01:58,  1.53it/s, Train Loss=2.85, validation loss=2.38] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:27<01:58,  1.53it/s, Train Loss=3.23, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:27<01:54,  1.57it/s, Train Loss=3.23, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:28<01:54,  1.57it/s, Train Loss=2.52, validation loss=2.38] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:28<01:53,  1.58it/s, Train Loss=2.52, validation loss=2.38] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:29<01:53,  1.58it/s, Train Loss=3.07, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:29<01:52,  1.59it/s, Train Loss=3.07, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:29<01:52,  1.59it/s, Train Loss=1.98, validation loss=2.43] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:29<01:55,  1.53it/s, Train Loss=1.98, validation loss=2.43] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:30<01:55,  1.53it/s, Train Loss=2.56, validation loss=2.41] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:30<01:53,  1.55it/s, Train Loss=2.56, validation loss=2.41] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:31<01:53,  1.55it/s, Train Loss=1.23, validation loss=2.42] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:31<01:51,  1.57it/s, Train Loss=1.23, validation loss=2.42] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:31<01:51,  1.57it/s, Train Loss=2.22, validation loss=2.44] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:31<01:51,  1.55it/s, Train Loss=2.22, validation loss=2.44] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:32<01:51,  1.55it/s, Train Loss=1.7, validation loss=2.43]  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:32<01:49,  1.58it/s, Train Loss=1.7, validation loss=2.43] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:32<01:49,  1.58it/s, Train Loss=2.52, validation loss=2.4] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:32<01:48,  1.58it/s, Train Loss=2.52, validation loss=2.4] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:33<01:48,  1.58it/s, Train Loss=1.58, validation loss=2.4] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:33<01:47,  1.59it/s, Train Loss=1.58, validation loss=2.4] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:34<01:47,  1.59it/s, Train Loss=1.32, validation loss=2.39] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:34<01:51,  1.52it/s, Train Loss=1.32, validation loss=2.39] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:34<01:51,  1.52it/s, Train Loss=2.87, validation loss=2.37] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:34<01:48,  1.56it/s, Train Loss=2.87, validation loss=2.37] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:35<01:48,  1.56it/s, Train Loss=1.75, validation loss=2.42] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:35<01:46,  1.58it/s, Train Loss=1.75, validation loss=2.42] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:36<01:46,  1.58it/s, Train Loss=2.99, validation loss=2.4]  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:36<01:46,  1.57it/s, Train Loss=2.99, validation loss=2.4] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:36<01:46,  1.57it/s, Train Loss=1.96, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:36<01:49,  1.51it/s, Train Loss=1.96, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:37<01:49,  1.51it/s, Train Loss=2.34, validation loss=2.38] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:37<01:47,  1.54it/s, Train Loss=2.34, validation loss=2.38] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:38<01:47,  1.54it/s, Train Loss=1.72, validation loss=2.4]  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:38<01:45,  1.55it/s, Train Loss=1.72, validation loss=2.4] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:38<01:45,  1.55it/s, Train Loss=3.12, validation loss=2.43] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:38<01:43,  1.58it/s, Train Loss=3.12, validation loss=2.43] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:39<01:43,  1.58it/s, Train Loss=2.24, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:39<01:42,  1.57it/s, Train Loss=2.24, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:40<01:42,  1.57it/s, Train Loss=1.44, validation loss=2.4]  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:40<01:41,  1.58it/s, Train Loss=1.44, validation loss=2.4] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:40<01:41,  1.58it/s, Train Loss=2.01, validation loss=2.39] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:40<01:40,  1.59it/s, Train Loss=2.01, validation loss=2.39] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:41<01:40,  1.59it/s, Train Loss=1.43, validation loss=2.41] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:41<01:44,  1.52it/s, Train Loss=1.43, validation loss=2.41] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:41<01:44,  1.52it/s, Train Loss=2.69, validation loss=2.4]  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:41<01:41,  1.56it/s, Train Loss=2.69, validation loss=2.4] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:42<01:41,  1.56it/s, Train Loss=1.55, validation loss=2.43] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:42<01:40,  1.56it/s, Train Loss=1.55, validation loss=2.43] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:43<01:40,  1.56it/s, Train Loss=2.67, validation loss=2.39] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:43<01:38,  1.58it/s, Train Loss=2.67, validation loss=2.39] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:43<01:38,  1.58it/s, Train Loss=2.62, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:43<01:44,  1.49it/s, Train Loss=2.62, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:44<01:44,  1.49it/s, Train Loss=1.98, validation loss=2.39] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:44<01:42,  1.51it/s, Train Loss=1.98, validation loss=2.39] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:45<01:42,  1.51it/s, Train Loss=2.87, validation loss=2.4]  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:45<01:39,  1.54it/s, Train Loss=2.87, validation loss=2.4] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:45<01:39,  1.54it/s, Train Loss=3.2, validation loss=2.4]  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:45<01:38,  1.55it/s, Train Loss=3.2, validation loss=2.4] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:46<01:38,  1.55it/s, Train Loss=1.99, validation loss=2.41] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:46<01:36,  1.57it/s, Train Loss=1.99, validation loss=2.41] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:47<01:36,  1.57it/s, Train Loss=2.4, validation loss=2.4]   70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:47<01:35,  1.56it/s, Train Loss=2.4, validation loss=2.4] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:47<01:35,  1.56it/s, Train Loss=1.93, validation loss=2.4] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:47<01:34,  1.58it/s, Train Loss=1.93, validation loss=2.4] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:48<01:34,  1.58it/s, Train Loss=1.76, validation loss=2.39] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:48<01:36,  1.54it/s, Train Loss=1.76, validation loss=2.39] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:49<01:36,  1.54it/s, Train Loss=3.26, validation loss=2.4]  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:49<01:33,  1.57it/s, Train Loss=3.26, validation loss=2.4] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:49<01:33,  1.57it/s, Train Loss=2.12, validation loss=2.39] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:49<01:33,  1.56it/s, Train Loss=2.12, validation loss=2.39] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:50<01:33,  1.56it/s, Train Loss=2, validation loss=2.42]    71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:50<01:34,  1.54it/s, Train Loss=2, validation loss=2.42] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:51<01:34,  1.54it/s, Train Loss=1.67, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:51<01:36,  1.50it/s, Train Loss=1.67, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:51<01:36,  1.50it/s, Train Loss=2.57, validation loss=2.4]  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:51<01:33,  1.53it/s, Train Loss=2.57, validation loss=2.4] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:52<01:33,  1.53it/s, Train Loss=3.08, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:52<01:32,  1.54it/s, Train Loss=3.08, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:52<01:32,  1.54it/s, Train Loss=1.34, validation loss=2.39] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:52<01:30,  1.56it/s, Train Loss=1.34, validation loss=2.39] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:53<01:30,  1.56it/s, Train Loss=2, validation loss=2.38]    72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:53<01:29,  1.56it/s, Train Loss=2, validation loss=2.38] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:54<01:29,  1.56it/s, Train Loss=2.35, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:54<01:28,  1.57it/s, Train Loss=2.35, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:54<01:28,  1.57it/s, Train Loss=3.06, validation loss=2.4]  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:54<01:27,  1.58it/s, Train Loss=3.06, validation loss=2.4] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:55<01:27,  1.58it/s, Train Loss=1.6, validation loss=2.39] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:55<01:29,  1.53it/s, Train Loss=1.6, validation loss=2.39] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:56<01:29,  1.53it/s, Train Loss=2.4, validation loss=2.4]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:56<01:28,  1.54it/s, Train Loss=2.4, validation loss=2.4] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:56<01:28,  1.54it/s, Train Loss=1.94, validation loss=2.39] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:56<01:27,  1.54it/s, Train Loss=1.94, validation loss=2.39] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:57<01:27,  1.54it/s, Train Loss=1.29, validation loss=2.4]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:57<01:27,  1.54it/s, Train Loss=1.29, validation loss=2.4] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:58<01:27,  1.54it/s, Train Loss=1.69, validation loss=2.39] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:58<01:28,  1.51it/s, Train Loss=1.69, validation loss=2.39] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:58<01:28,  1.51it/s, Train Loss=2.18, validation loss=2.38] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:58<01:25,  1.54it/s, Train Loss=2.18, validation loss=2.38] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:59<01:25,  1.54it/s, Train Loss=2.47, validation loss=2.42] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:59<01:25,  1.54it/s, Train Loss=2.47, validation loss=2.42] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [04:00<01:25,  1.54it/s, Train Loss=0.916, validation loss=2.4] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [04:00<01:23,  1.56it/s, Train Loss=0.916, validation loss=2.4] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [04:00<01:23,  1.56it/s, Train Loss=2.02, validation loss=2.4]  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [04:00<01:26,  1.49it/s, Train Loss=2.02, validation loss=2.4] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [04:01<01:26,  1.49it/s, Train Loss=2.07, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [04:01<01:24,  1.52it/s, Train Loss=2.07, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [04:02<01:24,  1.52it/s, Train Loss=1.56, validation loss=2.4]  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:02<01:23,  1.53it/s, Train Loss=1.56, validation loss=2.4] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:02<01:23,  1.53it/s, Train Loss=3.78, validation loss=2.4] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:02<01:21,  1.54it/s, Train Loss=3.78, validation loss=2.4] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:03<01:21,  1.54it/s, Train Loss=2.1, validation loss=2.4]  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:03<01:20,  1.56it/s, Train Loss=2.1, validation loss=2.4] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:04<01:20,  1.56it/s, Train Loss=2.21, validation loss=2.4] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:04<01:24,  1.46it/s, Train Loss=2.21, validation loss=2.4] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:05<01:24,  1.46it/s, Train Loss=2.79, validation loss=2.38] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:05<01:32,  1.33it/s, Train Loss=2.79, validation loss=2.38] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:05<01:32,  1.33it/s, Train Loss=2.38, validation loss=2.38] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:05<01:26,  1.41it/s, Train Loss=2.38, validation loss=2.38] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:06<01:26,  1.41it/s, Train Loss=1.94, validation loss=2.42] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:06<01:21,  1.48it/s, Train Loss=1.94, validation loss=2.42] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:06<01:21,  1.48it/s, Train Loss=2.09, validation loss=2.42] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:06<01:18,  1.53it/s, Train Loss=2.09, validation loss=2.42] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:07<01:18,  1.53it/s, Train Loss=3.09, validation loss=2.4]  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:07<01:15,  1.58it/s, Train Loss=3.09, validation loss=2.4] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:08<01:15,  1.58it/s, Train Loss=1.52, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:08<01:12,  1.63it/s, Train Loss=1.52, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:08<01:12,  1.63it/s, Train Loss=1.88, validation loss=2.4]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:08<01:10,  1.67it/s, Train Loss=1.88, validation loss=2.4] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:09<01:10,  1.67it/s, Train Loss=2.26, validation loss=2.39] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:09<01:09,  1.67it/s, Train Loss=2.26, validation loss=2.39] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:09<01:09,  1.67it/s, Train Loss=2.61, validation loss=2.38] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:09<01:09,  1.66it/s, Train Loss=2.61, validation loss=2.38] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:10<01:09,  1.66it/s, Train Loss=1.13, validation loss=2.4]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:10<01:09,  1.65it/s, Train Loss=1.13, validation loss=2.4] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:11<01:09,  1.65it/s, Train Loss=1.68, validation loss=2.39] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:11<01:08,  1.65it/s, Train Loss=1.68, validation loss=2.39] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:11<01:08,  1.65it/s, Train Loss=2.38, validation loss=2.4]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:11<01:06,  1.68it/s, Train Loss=2.38, validation loss=2.4] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:12<01:06,  1.68it/s, Train Loss=2.52, validation loss=2.42] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:12<01:06,  1.67it/s, Train Loss=2.52, validation loss=2.42] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:12<01:06,  1.67it/s, Train Loss=1.34, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:12<01:05,  1.69it/s, Train Loss=1.34, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:13<01:05,  1.69it/s, Train Loss=2.29, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:13<01:05,  1.68it/s, Train Loss=2.29, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:13<01:05,  1.68it/s, Train Loss=2.7, validation loss=2.41]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:13<01:03,  1.69it/s, Train Loss=2.7, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:14<01:03,  1.69it/s, Train Loss=2.77, validation loss=2.37] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:14<01:03,  1.68it/s, Train Loss=2.77, validation loss=2.37] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:15<01:03,  1.68it/s, Train Loss=2.07, validation loss=2.38] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:15<01:03,  1.66it/s, Train Loss=2.07, validation loss=2.38] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:15<01:03,  1.66it/s, Train Loss=2.4, validation loss=2.38]  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:15<01:03,  1.67it/s, Train Loss=2.4, validation loss=2.38] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:16<01:03,  1.67it/s, Train Loss=1.5, validation loss=2.42] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:16<01:02,  1.66it/s, Train Loss=1.5, validation loss=2.42] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:16<01:02,  1.66it/s, Train Loss=2.96, validation loss=2.4] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:16<01:02,  1.65it/s, Train Loss=2.96, validation loss=2.4] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:17<01:02,  1.65it/s, Train Loss=3.2, validation loss=2.41] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:17<01:02,  1.64it/s, Train Loss=3.2, validation loss=2.41] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:18<01:02,  1.64it/s, Train Loss=2.14, validation loss=2.39] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:18<01:01,  1.64it/s, Train Loss=2.14, validation loss=2.39] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:18<01:01,  1.64it/s, Train Loss=2.75, validation loss=2.38] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:18<01:01,  1.63it/s, Train Loss=2.75, validation loss=2.38] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:19<01:01,  1.63it/s, Train Loss=4.15, validation loss=2.4]  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:19<00:59,  1.66it/s, Train Loss=4.15, validation loss=2.4] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:20<00:59,  1.66it/s, Train Loss=1.85, validation loss=2.38] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:20<00:58,  1.67it/s, Train Loss=1.85, validation loss=2.38] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:20<00:58,  1.67it/s, Train Loss=2.14, validation loss=2.39] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:20<00:57,  1.68it/s, Train Loss=2.14, validation loss=2.39] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:21<00:57,  1.68it/s, Train Loss=1.61, validation loss=2.38] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:21<00:57,  1.66it/s, Train Loss=1.61, validation loss=2.38] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:21<00:57,  1.66it/s, Train Loss=2.07, validation loss=2.39] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:21<00:56,  1.67it/s, Train Loss=2.07, validation loss=2.39] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:22<00:56,  1.67it/s, Train Loss=1.95, validation loss=2.38] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:22<00:55,  1.68it/s, Train Loss=1.95, validation loss=2.38] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:23<00:55,  1.68it/s, Train Loss=3.04, validation loss=2.38] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:23<00:56,  1.64it/s, Train Loss=3.04, validation loss=2.38] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:23<00:56,  1.64it/s, Train Loss=3.12, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:23<00:55,  1.66it/s, Train Loss=3.12, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:24<00:55,  1.66it/s, Train Loss=3.28, validation loss=2.38] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:24<00:54,  1.67it/s, Train Loss=3.28, validation loss=2.38] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:24<00:54,  1.67it/s, Train Loss=1.72, validation loss=2.38] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:24<00:54,  1.66it/s, Train Loss=1.72, validation loss=2.38] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:25<00:54,  1.66it/s, Train Loss=3.07, validation loss=2.38] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:25<00:53,  1.66it/s, Train Loss=3.07, validation loss=2.38] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:26<00:53,  1.66it/s, Train Loss=3, validation loss=2.39]    82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:26<00:53,  1.66it/s, Train Loss=3, validation loss=2.39] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:26<00:53,  1.66it/s, Train Loss=2.01, validation loss=2.39] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:26<00:53,  1.63it/s, Train Loss=2.01, validation loss=2.39] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:27<00:53,  1.63it/s, Train Loss=1.76, validation loss=2.4]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:27<00:52,  1.65it/s, Train Loss=1.76, validation loss=2.4] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:27<00:52,  1.65it/s, Train Loss=2.28, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:27<00:51,  1.66it/s, Train Loss=2.28, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:28<00:51,  1.66it/s, Train Loss=2.16, validation loss=2.4]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:28<00:51,  1.63it/s, Train Loss=2.16, validation loss=2.4] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:29<00:51,  1.63it/s, Train Loss=2.39, validation loss=2.42] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:29<00:51,  1.60it/s, Train Loss=2.39, validation loss=2.42] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:29<00:51,  1.60it/s, Train Loss=1.91, validation loss=2.4]  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:29<00:50,  1.62it/s, Train Loss=1.91, validation loss=2.4] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:30<00:50,  1.62it/s, Train Loss=2.38, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:30<00:48,  1.66it/s, Train Loss=2.38, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:30<00:48,  1.66it/s, Train Loss=1.12, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:30<00:47,  1.68it/s, Train Loss=1.12, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:31<00:47,  1.68it/s, Train Loss=1.79, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:31<00:47,  1.66it/s, Train Loss=1.79, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:32<00:47,  1.66it/s, Train Loss=3.84, validation loss=2.39] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:32<00:47,  1.65it/s, Train Loss=3.84, validation loss=2.39] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:32<00:47,  1.65it/s, Train Loss=1.77, validation loss=2.38] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:32<00:47,  1.61it/s, Train Loss=1.77, validation loss=2.38] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:33<00:47,  1.61it/s, Train Loss=2.07, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:33<00:46,  1.63it/s, Train Loss=2.07, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:33<00:46,  1.63it/s, Train Loss=2.05, validation loss=2.39] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:33<00:45,  1.66it/s, Train Loss=2.05, validation loss=2.39] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:34<00:45,  1.66it/s, Train Loss=2.26, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:34<00:44,  1.67it/s, Train Loss=2.26, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:35<00:44,  1.67it/s, Train Loss=1.62, validation loss=2.4]  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:35<00:44,  1.65it/s, Train Loss=1.62, validation loss=2.4] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:35<00:44,  1.65it/s, Train Loss=3.09, validation loss=2.4] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:35<00:43,  1.66it/s, Train Loss=3.09, validation loss=2.4] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:36<00:43,  1.66it/s, Train Loss=2.22, validation loss=2.4] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:36<00:42,  1.68it/s, Train Loss=2.22, validation loss=2.4] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:36<00:42,  1.68it/s, Train Loss=1.56, validation loss=2.4] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:36<00:41,  1.68it/s, Train Loss=1.56, validation loss=2.4] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:37<00:41,  1.68it/s, Train Loss=2.05, validation loss=2.36] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:37<00:40,  1.69it/s, Train Loss=2.05, validation loss=2.36] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:38<00:40,  1.69it/s, Train Loss=3.47, validation loss=2.4]  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:38<00:39,  1.71it/s, Train Loss=3.47, validation loss=2.4] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:38<00:39,  1.71it/s, Train Loss=1.17, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:38<00:39,  1.71it/s, Train Loss=1.17, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:39<00:39,  1.71it/s, Train Loss=2.71, validation loss=2.42] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:39<00:38,  1.70it/s, Train Loss=2.71, validation loss=2.42] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:39<00:38,  1.70it/s, Train Loss=1.66, validation loss=2.42] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:39<00:38,  1.70it/s, Train Loss=1.66, validation loss=2.42] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:40<00:38,  1.70it/s, Train Loss=1.83, validation loss=2.4]  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:40<00:37,  1.70it/s, Train Loss=1.83, validation loss=2.4] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:41<00:37,  1.70it/s, Train Loss=1.6, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:41<00:37,  1.68it/s, Train Loss=1.6, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:41<00:37,  1.68it/s, Train Loss=1.28, validation loss=2.42] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:41<00:37,  1.67it/s, Train Loss=1.28, validation loss=2.42] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:42<00:37,  1.67it/s, Train Loss=2.16, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:42<00:36,  1.67it/s, Train Loss=2.16, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:42<00:36,  1.67it/s, Train Loss=2.18, validation loss=2.4]  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:42<00:35,  1.67it/s, Train Loss=2.18, validation loss=2.4] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:43<00:35,  1.67it/s, Train Loss=2.42, validation loss=2.39] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:43<00:34,  1.69it/s, Train Loss=2.42, validation loss=2.39] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:44<00:34,  1.69it/s, Train Loss=2.24, validation loss=2.39] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:44<00:34,  1.69it/s, Train Loss=2.24, validation loss=2.39] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:44<00:34,  1.69it/s, Train Loss=2.04, validation loss=2.38] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:44<00:33,  1.70it/s, Train Loss=2.04, validation loss=2.38] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:45<00:33,  1.70it/s, Train Loss=1.49, validation loss=2.39] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:45<00:32,  1.70it/s, Train Loss=1.49, validation loss=2.39] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:45<00:32,  1.70it/s, Train Loss=1.67, validation loss=2.38] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:45<00:32,  1.69it/s, Train Loss=1.67, validation loss=2.38] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:46<00:32,  1.69it/s, Train Loss=2.07, validation loss=2.39] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:46<00:32,  1.67it/s, Train Loss=2.07, validation loss=2.39] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:47<00:32,  1.67it/s, Train Loss=1.86, validation loss=2.44] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:47<00:31,  1.66it/s, Train Loss=1.86, validation loss=2.44] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:47<00:31,  1.66it/s, Train Loss=2.69, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:47<00:31,  1.64it/s, Train Loss=2.69, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:48<00:31,  1.64it/s, Train Loss=1.98, validation loss=2.39] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:48<00:30,  1.66it/s, Train Loss=1.98, validation loss=2.39] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:48<00:30,  1.66it/s, Train Loss=3.06, validation loss=2.38] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:48<00:30,  1.65it/s, Train Loss=3.06, validation loss=2.38] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:49<00:30,  1.65it/s, Train Loss=2.41, validation loss=2.38] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:49<00:29,  1.67it/s, Train Loss=2.41, validation loss=2.38] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:50<00:29,  1.67it/s, Train Loss=2.41, validation loss=2.4]  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:50<00:28,  1.66it/s, Train Loss=2.41, validation loss=2.4] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:50<00:28,  1.66it/s, Train Loss=1.92, validation loss=2.42] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:50<00:28,  1.68it/s, Train Loss=1.92, validation loss=2.42] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:51<00:28,  1.68it/s, Train Loss=2.88, validation loss=2.4]  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:51<00:27,  1.68it/s, Train Loss=2.88, validation loss=2.4] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:51<00:27,  1.68it/s, Train Loss=2.02, validation loss=2.4] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:51<00:27,  1.65it/s, Train Loss=2.02, validation loss=2.4] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:52<00:27,  1.65it/s, Train Loss=1.52, validation loss=2.42] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:52<00:26,  1.67it/s, Train Loss=1.52, validation loss=2.42] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:53<00:26,  1.67it/s, Train Loss=1.65, validation loss=2.38] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:53<00:25,  1.67it/s, Train Loss=1.65, validation loss=2.38] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:53<00:25,  1.67it/s, Train Loss=3.21, validation loss=2.38] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:53<00:25,  1.68it/s, Train Loss=3.21, validation loss=2.38] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:54<00:25,  1.68it/s, Train Loss=2.32, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:54<00:24,  1.67it/s, Train Loss=2.32, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:54<00:24,  1.67it/s, Train Loss=1.25, validation loss=2.43] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:54<00:24,  1.65it/s, Train Loss=1.25, validation loss=2.43] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:55<00:24,  1.65it/s, Train Loss=2.43, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:55<00:23,  1.67it/s, Train Loss=2.43, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:56<00:23,  1.67it/s, Train Loss=2.01, validation loss=2.39] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:56<00:22,  1.67it/s, Train Loss=2.01, validation loss=2.39] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:56<00:22,  1.67it/s, Train Loss=3.22, validation loss=2.4]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:56<00:22,  1.66it/s, Train Loss=3.22, validation loss=2.4] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:57<00:22,  1.66it/s, Train Loss=2.09, validation loss=2.39] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:57<00:21,  1.65it/s, Train Loss=2.09, validation loss=2.39] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:57<00:21,  1.65it/s, Train Loss=3.19, validation loss=2.4]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:57<00:20,  1.68it/s, Train Loss=3.19, validation loss=2.4] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:58<00:20,  1.68it/s, Train Loss=2.31, validation loss=2.42] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:58<00:20,  1.69it/s, Train Loss=2.31, validation loss=2.42] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:59<00:20,  1.69it/s, Train Loss=1.77, validation loss=2.38] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [04:59<00:19,  1.67it/s, Train Loss=1.77, validation loss=2.38] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [04:59<00:19,  1.67it/s, Train Loss=2.17, validation loss=2.37] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [04:59<00:19,  1.66it/s, Train Loss=2.17, validation loss=2.37] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:00<00:19,  1.66it/s, Train Loss=2.1, validation loss=2.4]   94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:00<00:18,  1.65it/s, Train Loss=2.1, validation loss=2.4] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:00<00:18,  1.65it/s, Train Loss=2.44, validation loss=2.37] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:00<00:17,  1.68it/s, Train Loss=2.44, validation loss=2.37] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:01<00:17,  1.68it/s, Train Loss=1.89, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:01<00:17,  1.66it/s, Train Loss=1.89, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:02<00:17,  1.66it/s, Train Loss=2.2, validation loss=2.39]  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:02<00:16,  1.66it/s, Train Loss=2.2, validation loss=2.39] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:02<00:16,  1.66it/s, Train Loss=2.22, validation loss=2.39] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:02<00:15,  1.69it/s, Train Loss=2.22, validation loss=2.39] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:03<00:15,  1.69it/s, Train Loss=3.54, validation loss=2.39] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:03<00:15,  1.68it/s, Train Loss=3.54, validation loss=2.39] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:03<00:15,  1.68it/s, Train Loss=1.95, validation loss=2.4]  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:03<00:14,  1.68it/s, Train Loss=1.95, validation loss=2.4] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:04<00:14,  1.68it/s, Train Loss=1.91, validation loss=2.39] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:04<00:14,  1.67it/s, Train Loss=1.91, validation loss=2.39] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:04<00:14,  1.67it/s, Train Loss=2.79, validation loss=2.41] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:04<00:13,  1.69it/s, Train Loss=2.79, validation loss=2.41] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:05<00:13,  1.69it/s, Train Loss=1.6, validation loss=2.39]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:05<00:13,  1.69it/s, Train Loss=1.6, validation loss=2.39] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:06<00:13,  1.69it/s, Train Loss=2.1, validation loss=2.4]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:06<00:12,  1.69it/s, Train Loss=2.1, validation loss=2.4] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:06<00:12,  1.69it/s, Train Loss=2.69, validation loss=2.39] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:06<00:11,  1.69it/s, Train Loss=2.69, validation loss=2.39] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:07<00:11,  1.69it/s, Train Loss=1.37, validation loss=2.42] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:07<00:11,  1.67it/s, Train Loss=1.37, validation loss=2.42] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:07<00:11,  1.67it/s, Train Loss=1.84, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:07<00:10,  1.66it/s, Train Loss=1.84, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:08<00:10,  1.66it/s, Train Loss=2.03, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:08<00:10,  1.69it/s, Train Loss=2.03, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:09<00:10,  1.69it/s, Train Loss=1.9, validation loss=2.38]  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:09<00:09,  1.64it/s, Train Loss=1.9, validation loss=2.38] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:09<00:09,  1.64it/s, Train Loss=1.77, validation loss=2.39] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:09<00:09,  1.63it/s, Train Loss=1.77, validation loss=2.39] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:10<00:09,  1.63it/s, Train Loss=2.8, validation loss=2.4]   97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:10<00:08,  1.64it/s, Train Loss=2.8, validation loss=2.4] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:11<00:08,  1.64it/s, Train Loss=1.31, validation loss=2.39] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:11<00:07,  1.63it/s, Train Loss=1.31, validation loss=2.39] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:11<00:07,  1.63it/s, Train Loss=2.03, validation loss=2.4]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:11<00:07,  1.66it/s, Train Loss=2.03, validation loss=2.4] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:12<00:07,  1.66it/s, Train Loss=2.15, validation loss=2.42] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:12<00:06,  1.65it/s, Train Loss=2.15, validation loss=2.42] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:12<00:06,  1.65it/s, Train Loss=1.46, validation loss=2.43] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:12<00:06,  1.64it/s, Train Loss=1.46, validation loss=2.43] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:13<00:06,  1.64it/s, Train Loss=2.05, validation loss=2.4]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:13<00:05,  1.63it/s, Train Loss=2.05, validation loss=2.4] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:14<00:05,  1.63it/s, Train Loss=1.49, validation loss=2.41] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:14<00:04,  1.61it/s, Train Loss=1.49, validation loss=2.41] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:14<00:04,  1.61it/s, Train Loss=2.56, validation loss=2.39] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:14<00:04,  1.60it/s, Train Loss=2.56, validation loss=2.39] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:15<00:04,  1.60it/s, Train Loss=3.25, validation loss=2.38] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:15<00:03,  1.64it/s, Train Loss=3.25, validation loss=2.38] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:15<00:03,  1.64it/s, Train Loss=2.54, validation loss=2.39] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:15<00:02,  1.67it/s, Train Loss=2.54, validation loss=2.39] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:16<00:02,  1.67it/s, Train Loss=3, validation loss=2.4]     99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:16<00:02,  1.69it/s, Train Loss=3, validation loss=2.4] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:17<00:02,  1.69it/s, Train Loss=3.27, validation loss=2.38] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:17<00:01,  1.69it/s, Train Loss=3.27, validation loss=2.38] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:17<00:01,  1.69it/s, Train Loss=1.68, validation loss=2.38]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:17<00:01,  1.67it/s, Train Loss=1.68, validation loss=2.38]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:18<00:01,  1.67it/s, Train Loss=1.62, validation loss=2.41]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:18<00:00,  1.66it/s, Train Loss=1.62, validation loss=2.41]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:18<00:00,  1.66it/s, Train Loss=1.71, validation loss=2.39]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:18<00:00,  1.69it/s, Train Loss=1.71, validation loss=2.39]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:18<00:00,  1.57it/s, Train Loss=1.71, validation loss=2.39]
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.004 MB of 0.004 MB uploadedwandb: | 0.004 MB of 0.004 MB uploadedwandb: / 0.004 MB of 0.004 MB uploadedwandb: - 0.013 MB of 0.018 MB uploaded (0.002 MB deduped)wandb: \ 0.013 MB of 0.018 MB uploaded (0.002 MB deduped)wandb: | 0.018 MB of 0.018 MB uploaded (0.002 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 8.8%             
wandb: 
wandb: Run history:
wandb:                       Loss â–†â–†â–„â–„â–†â–…â–‡â–†â–…â–…â–‡â–†â–ƒâ–‚â–„â–ƒâ–…â–†â–ˆâ–‡â–‚â–‡â–ƒâ–…â–…â–‡â–ƒâ–†â–„â–„â–„â–‚â–‡â–â–ƒâ–†â–â–„â–ƒâ–‡
wandb:                    Loss_AD â–…â–ƒâ–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–„â–ƒâ–„â–ƒ
wandb:                  Loss_EMCI â–‡â–‡â–ˆâ–‡â–†â–…â–…â–…â–„â–†â–‚â–…â–…â–ƒâ–„â–ƒâ–„â–†â–…â–„â–â–„â–„â–…â–…â–…â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–…â–„â–…
wandb:                   Loss_FTD â–…â–„â–„â–„â–„â–ˆâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒ
wandb:                  Loss_LMCI â–†â–†â–‡â–†â–…â–†â–…â–„â–…â–…â–ˆâ–…â–…â–…â–„â–ƒâ–…â–†â–„â–„â–â–„â–…â–…â–…â–†â–„â–…â–…â–„â–„â–„â–…â–„â–…â–„â–„â–…â–…â–„
wandb:                   Loss_MCI â–‡â–‡â–‡â–‡â–†â–„â–…â–…â–…â–†â–ƒâ–…â–…â–ƒâ–„â–ƒâ–„â–†â–„â–„â–â–„â–…â–…â–„â–ˆâ–…â–„â–…â–„â–„â–„â–…â–„â–„â–„â–ƒâ–…â–…â–„
wandb:                    Loss_PD â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–†â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚
wandb:                         Lr â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                Test AUC_PR â–â–ˆâ–†â–†â–…â–…â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:               Test AUC_ROC â–…â–ˆâ–†â–†â–…â–…â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 Test Epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:               Train AUC_PR â–†â–†â–…â–ˆâ–†â–†â–†â–ƒâ–„â–‚â–ƒâ–ƒâ–â–ƒâ–„â–‡â–†â–…â–„â–„â–„â–ƒâ–†â–ƒâ–â–…â–„â–…â–„â–…â–„â–„â–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–…â–…
wandb:              Train AUC_ROC â–†â–ˆâ–†â–†â–†â–„â–†â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–â–ƒâ–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–…â–ƒâ–„â–„â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–…â–â–‚â–ƒ
wandb:                Train Epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    loss_CN â–ƒâ–„â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–ˆâ–‚â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–„â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚
wandb:            rersults_AUC_PR â–†â–†â–…â–ˆâ–†â–†â–†â–ƒâ–„â–‚â–ƒâ–ƒâ–â–ƒâ–„â–‡â–†â–…â–„â–„â–„â–ƒâ–†â–ƒâ–â–…â–„â–…â–„â–…â–„â–„â–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–…â–…
wandb:         rersults_AUC_PR_AD â–ˆâ–„â–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–„â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–â–‚â–ƒâ–ƒ
wandb:    rersults_AUC_PR_AD_test â–‚â–ˆâ–†â–…â–„â–„â–ƒâ–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       rersults_AUC_PR_EMCI â–ƒâ–„â–…â–ˆâ–…â–‡â–†â–ƒâ–…â–‚â–ƒâ–‚â–â–‡â–…â–‡â–†â–†â–„â–…â–„â–ƒâ–‡â–„â–â–†â–„â–…â–…â–…â–…â–†â–ƒâ–‚â–ƒâ–ƒâ–†â–„â–…â–†
wandb:  rersults_AUC_PR_EMCI_test â–‚â–ˆâ–†â–†â–…â–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        rersults_AUC_PR_FTD â–â–ƒâ–…â–†â–…â–‡â–†â–„â–†â–„â–„â–„â–„â–„â–†â–‡â–†â–†â–†â–†â–…â–…â–ˆâ–†â–ƒâ–†â–…â–†â–†â–†â–†â–‡â–…â–„â–…â–…â–ˆâ–…â–†â–‡
wandb:   rersults_AUC_PR_FTD_test â–â–ˆâ–†â–†â–…â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:       rersults_AUC_PR_LMCI â–„â–…â–†â–ˆâ–…â–‡â–†â–ƒâ–…â–‚â–ƒâ–ƒâ–â–ƒâ–…â–‡â–…â–†â–„â–…â–„â–ƒâ–†â–„â–‚â–†â–„â–…â–„â–†â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–…â–†
wandb:  rersults_AUC_PR_LMCI_test â–â–ˆâ–†â–†â–…â–„â–ƒâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        rersults_AUC_PR_MCI â–‡â–‡â–…â–ˆâ–†â–…â–†â–ƒâ–„â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–ˆâ–„â–…â–ƒâ–ƒâ–„â–‚â–…â–‚â–‚â–…â–„â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–â–‚â–‚â–‡â–‚â–„â–…
wandb:   rersults_AUC_PR_MCI_test â–â–ˆâ–†â–†â–…â–…â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         rersults_AUC_PR_PD â–ƒâ–ƒâ–â–„â–ƒâ–â–ƒâ–„â–†â–‚â–ƒâ–„â–„â–‡â–‚â–…â–‡â–…â–‡â–ƒâ–„â–†â–…â–„â–…â–ˆâ–†â–„â–†â–‡â–†â–ƒâ–†â–„â–…â–„â–‚â–„â–…â–‡
wandb:    rersults_AUC_PR_PD_test â–â–†â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:       rersults_AUC_PR_test â–â–ˆâ–†â–†â–…â–…â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           rersults_AUC_ROC â–†â–ˆâ–†â–†â–†â–„â–†â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–â–ƒâ–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–…â–ƒâ–„â–„â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–…â–â–‚â–ƒ
wandb:        rersults_AUC_ROC_AD â–ˆâ–‡â–†â–…â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚
wandb:   rersults_AUC_ROC_AD_test â–†â–ˆâ–†â–†â–…â–…â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      rersults_AUC_ROC_EMCI â–†â–ˆâ–‡â–‡â–†â–…â–†â–ƒâ–„â–ƒâ–…â–ƒâ–†â–â–ƒâ–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–…â–„â–‚â–ƒâ–…â–ƒâ–„â–„â–„â–…â–„â–„â–â–ƒâ–…â–â–ƒâ–ƒ
wandb: rersults_AUC_ROC_EMCI_test â–†â–ˆâ–†â–†â–…â–„â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       rersults_AUC_ROC_FTD â–„â–ˆâ–†â–…â–…â–…â–…â–‚â–„â–ƒâ–„â–ƒâ–„â–â–„â–„â–…â–…â–ƒâ–ƒâ–„â–ƒâ–…â–…â–‚â–ƒâ–…â–ƒâ–„â–…â–„â–…â–„â–„â–â–ƒâ–†â–â–ƒâ–ƒ
wandb:  rersults_AUC_ROC_FTD_test â–…â–ˆâ–†â–†â–„â–„â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      rersults_AUC_ROC_LMCI â–†â–ˆâ–‡â–†â–…â–…â–…â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–â–ƒâ–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–â–ƒâ–…â–â–‚â–ƒ
wandb: rersults_AUC_ROC_LMCI_test â–…â–ˆâ–†â–†â–…â–„â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       rersults_AUC_ROC_MCI â–†â–ˆâ–†â–†â–†â–„â–…â–‚â–ƒâ–ƒâ–„â–„â–„â–‚â–ƒâ–„â–…â–…â–ƒâ–ƒâ–„â–„â–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–„â–ƒâ–„â–„â–„â–‚â–ƒâ–…â–â–‚â–ƒ
wandb:  rersults_AUC_ROC_MCI_test â–„â–ˆâ–‡â–†â–…â–…â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        rersults_AUC_ROC_PD â–‡â–ˆâ–…â–†â–†â–ƒâ–„â–ƒâ–„â–ƒâ–„â–„â–„â–ƒâ–„â–„â–†â–„â–…â–‚â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–‚â–ƒâ–„â–â–…â–…â–„â–‚â–ƒâ–ƒ
wandb:   rersults_AUC_ROC_PD_test â–â–ˆâ–‡â–‡â–†â–†â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:      rersults_AUC_ROC_test â–…â–ˆâ–†â–†â–…â–…â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:               test_Loss_AD â–ˆâ–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–
wandb:               test_Loss_CN â–ˆâ–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–
wandb:             test_Loss_EMCI â–ˆâ–ˆâ–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚
wandb:              test_Loss_FTD â–…â–ˆâ–‡â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb:             test_Loss_LMCI â–‡â–ˆâ–‡â–…â–„â–„â–„â–ƒâ–„â–„â–…â–„â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–â–‚â–ƒ
wandb:              test_Loss_MCI â–ˆâ–†â–…â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–‚â–â–â–‚â–‚â–
wandb:               test_Loss_PD â–ˆâ–„â–„â–…â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–„â–„â–‚â–‚â–„
wandb:                  test_loss â–ˆâ–‡â–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–‚â–‚â–â–â–â–‚â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:                       Loss 1.71034
wandb:                    Loss_AD 0.09042
wandb:                  Loss_EMCI 0.41408
wandb:                   Loss_FTD 0.07726
wandb:                  Loss_LMCI 0.16577
wandb:                   Loss_MCI 0.37613
wandb:                    Loss_PD 0.06529
wandb:                         Lr 3e-05
wandb:                Test AUC_PR 0.2949
wandb:               Test AUC_ROC 0.51972
wandb:                 Test Epoch 500
wandb:               Train AUC_PR 0.29269
wandb:              Train AUC_ROC 0.5236
wandb:                Train Epoch 500
wandb:                    loss_CN 0.52138
wandb:            rersults_AUC_PR 0.29269
wandb:         rersults_AUC_PR_AD 0.1582
wandb:    rersults_AUC_PR_AD_test 0.15782
wandb:       rersults_AUC_PR_EMCI 0.37786
wandb:  rersults_AUC_PR_EMCI_test 0.36997
wandb:        rersults_AUC_PR_FTD 0.3566
wandb:   rersults_AUC_PR_FTD_test 0.35014
wandb:       rersults_AUC_PR_LMCI 0.32113
wandb:  rersults_AUC_PR_LMCI_test 0.31984
wandb:        rersults_AUC_PR_MCI 0.2622
wandb:   rersults_AUC_PR_MCI_test 0.26997
wandb:         rersults_AUC_PR_PD 0.15305
wandb:    rersults_AUC_PR_PD_test 0.15301
wandb:       rersults_AUC_PR_test 0.2949
wandb:           rersults_AUC_ROC 0.5236
wandb:        rersults_AUC_ROC_AD 0.42581
wandb:   rersults_AUC_ROC_AD_test 0.45131
wandb:      rersults_AUC_ROC_EMCI 0.53741
wandb: rersults_AUC_ROC_EMCI_test 0.51771
wandb:       rersults_AUC_ROC_FTD 0.55285
wandb:  rersults_AUC_ROC_FTD_test 0.53153
wandb:      rersults_AUC_ROC_LMCI 0.52817
wandb: rersults_AUC_ROC_LMCI_test 0.51566
wandb:       rersults_AUC_ROC_MCI 0.51854
wandb:  rersults_AUC_ROC_MCI_test 0.52837
wandb:        rersults_AUC_ROC_PD 0.47253
wandb:   rersults_AUC_ROC_PD_test 0.54252
wandb:      rersults_AUC_ROC_test 0.51972
wandb:               test_Loss_AD 0.17766
wandb:               test_Loss_CN 0.50496
wandb:             test_Loss_EMCI 0.44027
wandb:              test_Loss_FTD 0.09656
wandb:             test_Loss_LMCI 0.46482
wandb:              test_Loss_MCI 0.43544
wandb:               test_Loss_PD 0.26836
wandb:                  test_loss 2.38807
wandb: 
wandb: ğŸš€ View run lunar-sound-61 at: https://wandb.ai/thomas-borsani1/MTL_experiment/runs/xtbdo4fk
wandb: â­ï¸ View project at: https://wandb.ai/thomas-borsani1/MTL_experiment
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_160922-xtbdo4fk/logs

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 362
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=0, validation loss=0]  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=5.44, validation loss=3.57]  0%|          | 1/500 [00:00<04:57,  1.68it/s, Train Loss=5.44, validation loss=3.57]  0%|          | 1/500 [00:01<04:57,  1.68it/s, Train Loss=4.58, validation loss=3.2]   0%|          | 2/500 [00:01<04:51,  1.71it/s, Train Loss=4.58, validation loss=3.2]  0%|          | 2/500 [00:01<04:51,  1.71it/s, Train Loss=6.58, validation loss=3.1]  1%|          | 3/500 [00:01<04:58,  1.66it/s, Train Loss=6.58, validation loss=3.1]  1%|          | 3/500 [00:02<04:58,  1.66it/s, Train Loss=1.67, validation loss=2.9]  1%|          | 4/500 [00:02<04:54,  1.68it/s, Train Loss=1.67, validation loss=2.9]  1%|          | 4/500 [00:02<04:54,  1.68it/s, Train Loss=3.88, validation loss=2.86]  1%|          | 5/500 [00:02<04:54,  1.68it/s, Train Loss=3.88, validation loss=2.86]  1%|          | 5/500 [00:03<04:54,  1.68it/s, Train Loss=2.05, validation loss=2.79]  1%|          | 6/500 [00:03<04:52,  1.69it/s, Train Loss=2.05, validation loss=2.79]  1%|          | 6/500 [00:04<04:52,  1.69it/s, Train Loss=3.63, validation loss=2.83]  1%|â–         | 7/500 [00:04<04:51,  1.69it/s, Train Loss=3.63, validation loss=2.83]  1%|â–         | 7/500 [00:04<04:51,  1.69it/s, Train Loss=2.37, validation loss=2.82]  2%|â–         | 8/500 [00:04<04:51,  1.69it/s, Train Loss=2.37, validation loss=2.82]  2%|â–         | 8/500 [00:05<04:51,  1.69it/s, Train Loss=3.07, validation loss=2.76]  2%|â–         | 9/500 [00:05<04:53,  1.67it/s, Train Loss=3.07, validation loss=2.76]  2%|â–         | 9/500 [00:05<04:53,  1.67it/s, Train Loss=2.97, validation loss=2.77]  2%|â–         | 10/500 [00:05<04:51,  1.68it/s, Train Loss=2.97, validation loss=2.77]  2%|â–         | 10/500 [00:06<04:51,  1.68it/s, Train Loss=2.27, validation loss=2.78]  2%|â–         | 11/500 [00:06<04:47,  1.70it/s, Train Loss=2.27, validation loss=2.78]  2%|â–         | 11/500 [00:07<04:47,  1.70it/s, Train Loss=2.91, validation loss=2.75]  2%|â–         | 12/500 [00:07<04:50,  1.68it/s, Train Loss=2.91, validation loss=2.75]  2%|â–         | 12/500 [00:07<04:50,  1.68it/s, Train Loss=1.99, validation loss=2.77]  3%|â–         | 13/500 [00:07<04:45,  1.71it/s, Train Loss=1.99, validation loss=2.77]  3%|â–         | 13/500 [00:08<04:45,  1.71it/s, Train Loss=2.8, validation loss=2.75]   3%|â–         | 14/500 [00:08<04:46,  1.70it/s, Train Loss=2.8, validation loss=2.75]  3%|â–         | 14/500 [00:08<04:46,  1.70it/s, Train Loss=1.93, validation loss=2.72]  3%|â–         | 15/500 [00:08<04:43,  1.71it/s, Train Loss=1.93, validation loss=2.72]  3%|â–         | 15/500 [00:09<04:43,  1.71it/s, Train Loss=3.83, validation loss=2.71]  3%|â–         | 16/500 [00:09<04:44,  1.70it/s, Train Loss=3.83, validation loss=2.71]  3%|â–         | 16/500 [00:10<04:44,  1.70it/s, Train Loss=1.79, validation loss=2.73]  3%|â–         | 17/500 [00:10<04:43,  1.70it/s, Train Loss=1.79, validation loss=2.73]  3%|â–         | 17/500 [00:10<04:43,  1.70it/s, Train Loss=3.46, validation loss=2.76]  4%|â–         | 18/500 [00:10<04:48,  1.67it/s, Train Loss=3.46, validation loss=2.76]  4%|â–         | 18/500 [00:11<04:48,  1.67it/s, Train Loss=1.92, validation loss=2.71]  4%|â–         | 19/500 [00:11<04:48,  1.67it/s, Train Loss=1.92, validation loss=2.71]  4%|â–         | 19/500 [00:11<04:48,  1.67it/s, Train Loss=2.68, validation loss=2.69]  4%|â–         | 20/500 [00:11<04:45,  1.68it/s, Train Loss=2.68, validation loss=2.69]  4%|â–         | 20/500 [00:12<04:45,  1.68it/s, Train Loss=3.44, validation loss=2.67]  4%|â–         | 21/500 [00:12<04:44,  1.68it/s, Train Loss=3.44, validation loss=2.67]  4%|â–         | 21/500 [00:13<04:44,  1.68it/s, Train Loss=1.92, validation loss=2.7]   4%|â–         | 22/500 [00:13<04:47,  1.66it/s, Train Loss=1.92, validation loss=2.7]  4%|â–         | 22/500 [00:13<04:47,  1.66it/s, Train Loss=2.27, validation loss=2.72]  5%|â–         | 23/500 [00:13<04:49,  1.65it/s, Train Loss=2.27, validation loss=2.72]  5%|â–         | 23/500 [00:14<04:49,  1.65it/s, Train Loss=4.43, validation loss=2.71]  5%|â–         | 24/500 [00:14<04:45,  1.67it/s, Train Loss=4.43, validation loss=2.71]  5%|â–         | 24/500 [00:14<04:45,  1.67it/s, Train Loss=2.78, validation loss=2.68]  5%|â–Œ         | 25/500 [00:14<04:50,  1.63it/s, Train Loss=2.78, validation loss=2.68]  5%|â–Œ         | 25/500 [00:15<04:50,  1.63it/s, Train Loss=2.48, validation loss=2.65]  5%|â–Œ         | 26/500 [00:15<04:50,  1.63it/s, Train Loss=2.48, validation loss=2.65]  5%|â–Œ         | 26/500 [00:16<04:50,  1.63it/s, Train Loss=4.31, validation loss=2.65]  5%|â–Œ         | 27/500 [00:16<04:48,  1.64it/s, Train Loss=4.31, validation loss=2.65]  5%|â–Œ         | 27/500 [00:16<04:48,  1.64it/s, Train Loss=3.02, validation loss=2.64]  6%|â–Œ         | 28/500 [00:16<04:49,  1.63it/s, Train Loss=3.02, validation loss=2.64]  6%|â–Œ         | 28/500 [00:17<04:49,  1.63it/s, Train Loss=2.71, validation loss=2.66]  6%|â–Œ         | 29/500 [00:17<04:48,  1.63it/s, Train Loss=2.71, validation loss=2.66]  6%|â–Œ         | 29/500 [00:17<04:48,  1.63it/s, Train Loss=3.58, validation loss=2.69]  6%|â–Œ         | 30/500 [00:17<04:45,  1.65it/s, Train Loss=3.58, validation loss=2.69]  6%|â–Œ         | 30/500 [00:18<04:45,  1.65it/s, Train Loss=3.58, validation loss=2.63]  6%|â–Œ         | 31/500 [00:18<04:41,  1.66it/s, Train Loss=3.58, validation loss=2.63]  6%|â–Œ         | 31/500 [00:19<04:41,  1.66it/s, Train Loss=3.2, validation loss=2.64]   6%|â–‹         | 32/500 [00:19<04:39,  1.67it/s, Train Loss=3.2, validation loss=2.64]  6%|â–‹         | 32/500 [00:19<04:39,  1.67it/s, Train Loss=4.23, validation loss=2.65]  7%|â–‹         | 33/500 [00:19<04:42,  1.65it/s, Train Loss=4.23, validation loss=2.65]  7%|â–‹         | 33/500 [00:20<04:42,  1.65it/s, Train Loss=2.8, validation loss=2.62]   7%|â–‹         | 34/500 [00:20<04:39,  1.67it/s, Train Loss=2.8, validation loss=2.62]  7%|â–‹         | 34/500 [00:20<04:39,  1.67it/s, Train Loss=2.2, validation loss=2.63]  7%|â–‹         | 35/500 [00:20<04:38,  1.67it/s, Train Loss=2.2, validation loss=2.63]  7%|â–‹         | 35/500 [00:21<04:38,  1.67it/s, Train Loss=2, validation loss=2.63]    7%|â–‹         | 36/500 [00:21<04:37,  1.67it/s, Train Loss=2, validation loss=2.63]  7%|â–‹         | 36/500 [00:22<04:37,  1.67it/s, Train Loss=2.79, validation loss=2.64]  7%|â–‹         | 37/500 [00:22<04:39,  1.66it/s, Train Loss=2.79, validation loss=2.64]  7%|â–‹         | 37/500 [00:22<04:39,  1.66it/s, Train Loss=3.79, validation loss=2.59]  8%|â–Š         | 38/500 [00:22<04:39,  1.65it/s, Train Loss=3.79, validation loss=2.59]  8%|â–Š         | 38/500 [00:23<04:39,  1.65it/s, Train Loss=2.42, validation loss=2.61]  8%|â–Š         | 39/500 [00:23<04:46,  1.61it/s, Train Loss=2.42, validation loss=2.61]  8%|â–Š         | 39/500 [00:24<04:46,  1.61it/s, Train Loss=2.37, validation loss=2.6]   8%|â–Š         | 40/500 [00:24<04:43,  1.62it/s, Train Loss=2.37, validation loss=2.6]  8%|â–Š         | 40/500 [00:24<04:43,  1.62it/s, Train Loss=2.61, validation loss=2.6]  8%|â–Š         | 41/500 [00:24<04:40,  1.64it/s, Train Loss=2.61, validation loss=2.6]  8%|â–Š         | 41/500 [00:25<04:40,  1.64it/s, Train Loss=4.3, validation loss=2.63]  8%|â–Š         | 42/500 [00:25<04:45,  1.61it/s, Train Loss=4.3, validation loss=2.63]  8%|â–Š         | 42/500 [00:25<04:45,  1.61it/s, Train Loss=4.43, validation loss=2.6]  9%|â–Š         | 43/500 [00:25<04:39,  1.64it/s, Train Loss=4.43, validation loss=2.6]  9%|â–Š         | 43/500 [00:26<04:39,  1.64it/s, Train Loss=2.39, validation loss=2.59]  9%|â–‰         | 44/500 [00:26<04:39,  1.63it/s, Train Loss=2.39, validation loss=2.59]  9%|â–‰         | 44/500 [00:27<04:39,  1.63it/s, Train Loss=1.54, validation loss=2.61]  9%|â–‰         | 45/500 [00:27<04:35,  1.65it/s, Train Loss=1.54, validation loss=2.61]  9%|â–‰         | 45/500 [00:27<04:35,  1.65it/s, Train Loss=1.55, validation loss=2.63]  9%|â–‰         | 46/500 [00:27<04:35,  1.65it/s, Train Loss=1.55, validation loss=2.63]  9%|â–‰         | 46/500 [00:28<04:35,  1.65it/s, Train Loss=3.14, validation loss=2.59]  9%|â–‰         | 47/500 [00:28<04:36,  1.64it/s, Train Loss=3.14, validation loss=2.59]  9%|â–‰         | 47/500 [00:28<04:36,  1.64it/s, Train Loss=3.16, validation loss=2.58] 10%|â–‰         | 48/500 [00:28<04:38,  1.62it/s, Train Loss=3.16, validation loss=2.58] 10%|â–‰         | 48/500 [00:29<04:38,  1.62it/s, Train Loss=1.95, validation loss=2.58] 10%|â–‰         | 49/500 [00:29<04:35,  1.64it/s, Train Loss=1.95, validation loss=2.58] 10%|â–‰         | 49/500 [00:30<04:35,  1.64it/s, Train Loss=3.84, validation loss=2.57] 10%|â–ˆ         | 50/500 [00:30<04:32,  1.65it/s, Train Loss=3.84, validation loss=2.57] 10%|â–ˆ         | 50/500 [00:30<04:32,  1.65it/s, Train Loss=5.52, validation loss=2.57] 10%|â–ˆ         | 51/500 [00:30<04:33,  1.64it/s, Train Loss=5.52, validation loss=2.57] 10%|â–ˆ         | 51/500 [00:31<04:33,  1.64it/s, Train Loss=3.7, validation loss=2.56]  10%|â–ˆ         | 52/500 [00:31<04:36,  1.62it/s, Train Loss=3.7, validation loss=2.56] 10%|â–ˆ         | 52/500 [00:31<04:36,  1.62it/s, Train Loss=2.52, validation loss=2.57] 11%|â–ˆ         | 53/500 [00:31<04:35,  1.62it/s, Train Loss=2.52, validation loss=2.57] 11%|â–ˆ         | 53/500 [00:32<04:35,  1.62it/s, Train Loss=3.34, validation loss=2.56] 11%|â–ˆ         | 54/500 [00:32<04:37,  1.61it/s, Train Loss=3.34, validation loss=2.56] 11%|â–ˆ         | 54/500 [00:33<04:37,  1.61it/s, Train Loss=2.81, validation loss=2.53] 11%|â–ˆ         | 55/500 [00:33<04:33,  1.62it/s, Train Loss=2.81, validation loss=2.53] 11%|â–ˆ         | 55/500 [00:33<04:33,  1.62it/s, Train Loss=2.54, validation loss=2.56] 11%|â–ˆ         | 56/500 [00:33<04:28,  1.65it/s, Train Loss=2.54, validation loss=2.56] 11%|â–ˆ         | 56/500 [00:34<04:28,  1.65it/s, Train Loss=3.13, validation loss=2.55] 11%|â–ˆâ–        | 57/500 [00:34<04:28,  1.65it/s, Train Loss=3.13, validation loss=2.55] 11%|â–ˆâ–        | 57/500 [00:35<04:28,  1.65it/s, Train Loss=1.92, validation loss=2.55] 12%|â–ˆâ–        | 58/500 [00:35<04:28,  1.64it/s, Train Loss=1.92, validation loss=2.55] 12%|â–ˆâ–        | 58/500 [00:35<04:28,  1.64it/s, Train Loss=2.67, validation loss=2.53] 12%|â–ˆâ–        | 59/500 [00:35<04:26,  1.65it/s, Train Loss=2.67, validation loss=2.53] 12%|â–ˆâ–        | 59/500 [00:36<04:26,  1.65it/s, Train Loss=2.36, validation loss=2.55] 12%|â–ˆâ–        | 60/500 [00:36<04:25,  1.66it/s, Train Loss=2.36, validation loss=2.55] 12%|â–ˆâ–        | 60/500 [00:36<04:25,  1.66it/s, Train Loss=1.76, validation loss=2.54] 12%|â–ˆâ–        | 61/500 [00:36<04:23,  1.67it/s, Train Loss=1.76, validation loss=2.54] 12%|â–ˆâ–        | 61/500 [00:37<04:23,  1.67it/s, Train Loss=2.43, validation loss=2.54] 12%|â–ˆâ–        | 62/500 [00:37<04:19,  1.69it/s, Train Loss=2.43, validation loss=2.54] 12%|â–ˆâ–        | 62/500 [00:37<04:19,  1.69it/s, Train Loss=2.35, validation loss=2.55] 13%|â–ˆâ–        | 63/500 [00:37<04:20,  1.68it/s, Train Loss=2.35, validation loss=2.55] 13%|â–ˆâ–        | 63/500 [00:38<04:20,  1.68it/s, Train Loss=2.59, validation loss=2.55] 13%|â–ˆâ–        | 64/500 [00:38<04:19,  1.68it/s, Train Loss=2.59, validation loss=2.55] 13%|â–ˆâ–        | 64/500 [00:39<04:19,  1.68it/s, Train Loss=3.1, validation loss=2.52]  13%|â–ˆâ–        | 65/500 [00:39<04:17,  1.69it/s, Train Loss=3.1, validation loss=2.52] 13%|â–ˆâ–        | 65/500 [00:39<04:17,  1.69it/s, Train Loss=2.37, validation loss=2.51] 13%|â–ˆâ–        | 66/500 [00:39<04:17,  1.68it/s, Train Loss=2.37, validation loss=2.51] 13%|â–ˆâ–        | 66/500 [00:40<04:17,  1.68it/s, Train Loss=1.76, validation loss=2.53] 13%|â–ˆâ–        | 67/500 [00:40<04:20,  1.66it/s, Train Loss=1.76, validation loss=2.53] 13%|â–ˆâ–        | 67/500 [00:40<04:20,  1.66it/s, Train Loss=1.81, validation loss=2.52] 14%|â–ˆâ–        | 68/500 [00:40<04:20,  1.66it/s, Train Loss=1.81, validation loss=2.52] 14%|â–ˆâ–        | 68/500 [00:41<04:20,  1.66it/s, Train Loss=3.15, validation loss=2.52] 14%|â–ˆâ–        | 69/500 [00:41<04:21,  1.65it/s, Train Loss=3.15, validation loss=2.52] 14%|â–ˆâ–        | 69/500 [00:42<04:21,  1.65it/s, Train Loss=3.01, validation loss=2.49] 14%|â–ˆâ–        | 70/500 [00:42<04:19,  1.66it/s, Train Loss=3.01, validation loss=2.49] 14%|â–ˆâ–        | 70/500 [00:42<04:19,  1.66it/s, Train Loss=3.28, validation loss=2.51] 14%|â–ˆâ–        | 71/500 [00:42<04:21,  1.64it/s, Train Loss=3.28, validation loss=2.51] 14%|â–ˆâ–        | 71/500 [00:43<04:21,  1.64it/s, Train Loss=2.51, validation loss=2.48] 14%|â–ˆâ–        | 72/500 [00:43<04:19,  1.65it/s, Train Loss=2.51, validation loss=2.48] 14%|â–ˆâ–        | 72/500 [00:43<04:19,  1.65it/s, Train Loss=3.11, validation loss=2.49] 15%|â–ˆâ–        | 73/500 [00:43<04:14,  1.68it/s, Train Loss=3.11, validation loss=2.49] 15%|â–ˆâ–        | 73/500 [00:44<04:14,  1.68it/s, Train Loss=1.92, validation loss=2.49] 15%|â–ˆâ–        | 74/500 [00:44<04:12,  1.69it/s, Train Loss=1.92, validation loss=2.49] 15%|â–ˆâ–        | 74/500 [00:45<04:12,  1.69it/s, Train Loss=3.16, validation loss=2.52] 15%|â–ˆâ–Œ        | 75/500 [00:45<04:09,  1.71it/s, Train Loss=3.16, validation loss=2.52] 15%|â–ˆâ–Œ        | 75/500 [00:45<04:09,  1.71it/s, Train Loss=2.64, validation loss=2.53] 15%|â–ˆâ–Œ        | 76/500 [00:45<04:10,  1.69it/s, Train Loss=2.64, validation loss=2.53] 15%|â–ˆâ–Œ        | 76/500 [00:46<04:10,  1.69it/s, Train Loss=3.16, validation loss=2.5]  15%|â–ˆâ–Œ        | 77/500 [00:46<04:07,  1.71it/s, Train Loss=3.16, validation loss=2.5] 15%|â–ˆâ–Œ        | 77/500 [00:46<04:07,  1.71it/s, Train Loss=2.16, validation loss=2.51] 16%|â–ˆâ–Œ        | 78/500 [00:46<04:07,  1.71it/s, Train Loss=2.16, validation loss=2.51] 16%|â–ˆâ–Œ        | 78/500 [00:47<04:07,  1.71it/s, Train Loss=2.35, validation loss=2.5]  16%|â–ˆâ–Œ        | 79/500 [00:47<04:08,  1.70it/s, Train Loss=2.35, validation loss=2.5] 16%|â–ˆâ–Œ        | 79/500 [00:48<04:08,  1.70it/s, Train Loss=1.78, validation loss=2.5] 16%|â–ˆâ–Œ        | 80/500 [00:48<04:07,  1.70it/s, Train Loss=1.78, validation loss=2.5] 16%|â–ˆâ–Œ        | 80/500 [00:48<04:07,  1.70it/s, Train Loss=3.47, validation loss=2.51] 16%|â–ˆâ–Œ        | 81/500 [00:48<04:05,  1.71it/s, Train Loss=3.47, validation loss=2.51] 16%|â–ˆâ–Œ        | 81/500 [00:49<04:05,  1.71it/s, Train Loss=3.42, validation loss=2.51] 16%|â–ˆâ–‹        | 82/500 [00:49<04:09,  1.68it/s, Train Loss=3.42, validation loss=2.51] 16%|â–ˆâ–‹        | 82/500 [00:49<04:09,  1.68it/s, Train Loss=2.76, validation loss=2.49] 17%|â–ˆâ–‹        | 83/500 [00:49<04:06,  1.69it/s, Train Loss=2.76, validation loss=2.49] 17%|â–ˆâ–‹        | 83/500 [00:50<04:06,  1.69it/s, Train Loss=1.91, validation loss=2.51] 17%|â–ˆâ–‹        | 84/500 [00:50<04:03,  1.71it/s, Train Loss=1.91, validation loss=2.51] 17%|â–ˆâ–‹        | 84/500 [00:51<04:03,  1.71it/s, Train Loss=3.18, validation loss=2.47] 17%|â–ˆâ–‹        | 85/500 [00:51<04:08,  1.67it/s, Train Loss=3.18, validation loss=2.47] 17%|â–ˆâ–‹        | 85/500 [00:51<04:08,  1.67it/s, Train Loss=1.72, validation loss=2.5]  17%|â–ˆâ–‹        | 86/500 [00:51<04:09,  1.66it/s, Train Loss=1.72, validation loss=2.5] 17%|â–ˆâ–‹        | 86/500 [00:52<04:09,  1.66it/s, Train Loss=1.93, validation loss=2.49] 17%|â–ˆâ–‹        | 87/500 [00:52<04:10,  1.65it/s, Train Loss=1.93, validation loss=2.49] 17%|â–ˆâ–‹        | 87/500 [00:52<04:10,  1.65it/s, Train Loss=1.76, validation loss=2.48] 18%|â–ˆâ–Š        | 88/500 [00:52<04:06,  1.67it/s, Train Loss=1.76, validation loss=2.48] 18%|â–ˆâ–Š        | 88/500 [00:53<04:06,  1.67it/s, Train Loss=3.69, validation loss=2.5]  18%|â–ˆâ–Š        | 89/500 [00:53<04:05,  1.68it/s, Train Loss=3.69, validation loss=2.5] 18%|â–ˆâ–Š        | 89/500 [00:54<04:05,  1.68it/s, Train Loss=2.11, validation loss=2.48] 18%|â–ˆâ–Š        | 90/500 [00:54<04:04,  1.67it/s, Train Loss=2.11, validation loss=2.48] 18%|â–ˆâ–Š        | 90/500 [00:54<04:04,  1.67it/s, Train Loss=4.06, validation loss=2.46] 18%|â–ˆâ–Š        | 91/500 [00:54<04:05,  1.66it/s, Train Loss=4.06, validation loss=2.46] 18%|â–ˆâ–Š        | 91/500 [00:55<04:05,  1.66it/s, Train Loss=1.67, validation loss=2.48] 18%|â–ˆâ–Š        | 92/500 [00:55<04:01,  1.69it/s, Train Loss=1.67, validation loss=2.48] 18%|â–ˆâ–Š        | 92/500 [00:55<04:01,  1.69it/s, Train Loss=2.83, validation loss=2.44] 19%|â–ˆâ–Š        | 93/500 [00:55<03:59,  1.70it/s, Train Loss=2.83, validation loss=2.44] 19%|â–ˆâ–Š        | 93/500 [00:56<03:59,  1.70it/s, Train Loss=2.31, validation loss=2.47] 19%|â–ˆâ–‰        | 94/500 [00:56<04:01,  1.68it/s, Train Loss=2.31, validation loss=2.47] 19%|â–ˆâ–‰        | 94/500 [00:57<04:01,  1.68it/s, Train Loss=2.17, validation loss=2.45] 19%|â–ˆâ–‰        | 95/500 [00:57<03:56,  1.71it/s, Train Loss=2.17, validation loss=2.45] 19%|â–ˆâ–‰        | 95/500 [00:57<03:56,  1.71it/s, Train Loss=2.34, validation loss=2.44] 19%|â–ˆâ–‰        | 96/500 [00:57<04:01,  1.67it/s, Train Loss=2.34, validation loss=2.44] 19%|â–ˆâ–‰        | 96/500 [00:58<04:01,  1.67it/s, Train Loss=1.54, validation loss=2.44] 19%|â–ˆâ–‰        | 97/500 [00:58<04:04,  1.65it/s, Train Loss=1.54, validation loss=2.44] 19%|â–ˆâ–‰        | 97/500 [00:58<04:04,  1.65it/s, Train Loss=2.21, validation loss=2.46] 20%|â–ˆâ–‰        | 98/500 [00:58<04:00,  1.67it/s, Train Loss=2.21, validation loss=2.46] 20%|â–ˆâ–‰        | 98/500 [00:59<04:00,  1.67it/s, Train Loss=2.37, validation loss=2.45] 20%|â–ˆâ–‰        | 99/500 [00:59<04:03,  1.65it/s, Train Loss=2.37, validation loss=2.45]####################################################################################################
--------------------------------------------- Epoch:100 ---------------------------------------------
-- Training set:
Loss: 1.8109230995178223, Lr: 0.0005
Average AUC ROC: 0.52                Average AUC PR: 0.29
 20%|â–ˆâ–‰        | 99/500 [01:00<04:03,  1.65it/s, Train Loss=1.81, validation loss=2.44] 20%|â–ˆâ–ˆ        | 100/500 [01:00<04:00,  1.67it/s, Train Loss=1.81, validation loss=2.44]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.435157410800457
Average AUC ROC: 0.57                    Average AUC PR: 0.32
 20%|â–ˆâ–ˆ        | 100/500 [01:00<04:00,  1.67it/s, Train Loss=2.09, validation loss=2.43] 20%|â–ˆâ–ˆ        | 101/500 [01:00<03:57,  1.68it/s, Train Loss=2.09, validation loss=2.43] 20%|â–ˆâ–ˆ        | 101/500 [01:01<03:57,  1.68it/s, Train Loss=1.58, validation loss=2.44] 20%|â–ˆâ–ˆ        | 102/500 [01:01<03:57,  1.67it/s, Train Loss=1.58, validation loss=2.44] 20%|â–ˆâ–ˆ        | 102/500 [01:01<03:57,  1.67it/s, Train Loss=3.47, validation loss=2.45] 21%|â–ˆâ–ˆ        | 103/500 [01:01<03:52,  1.71it/s, Train Loss=3.47, validation loss=2.45] 21%|â–ˆâ–ˆ        | 103/500 [01:02<03:52,  1.71it/s, Train Loss=2.12, validation loss=2.45] 21%|â–ˆâ–ˆ        | 104/500 [01:02<03:53,  1.70it/s, Train Loss=2.12, validation loss=2.45] 21%|â–ˆâ–ˆ        | 104/500 [01:02<03:53,  1.70it/s, Train Loss=1.99, validation loss=2.45] 21%|â–ˆâ–ˆ        | 105/500 [01:02<03:52,  1.70it/s, Train Loss=1.99, validation loss=2.45] 21%|â–ˆâ–ˆ        | 105/500 [01:03<03:52,  1.70it/s, Train Loss=3.57, validation loss=2.45] 21%|â–ˆâ–ˆ        | 106/500 [01:03<03:50,  1.71it/s, Train Loss=3.57, validation loss=2.45] 21%|â–ˆâ–ˆ        | 106/500 [01:04<03:50,  1.71it/s, Train Loss=2.76, validation loss=2.47] 21%|â–ˆâ–ˆâ–       | 107/500 [01:04<03:53,  1.68it/s, Train Loss=2.76, validation loss=2.47] 21%|â–ˆâ–ˆâ–       | 107/500 [01:04<03:53,  1.68it/s, Train Loss=2.58, validation loss=2.45] 22%|â–ˆâ–ˆâ–       | 108/500 [01:04<03:50,  1.70it/s, Train Loss=2.58, validation loss=2.45] 22%|â–ˆâ–ˆâ–       | 108/500 [01:05<03:50,  1.70it/s, Train Loss=2.49, validation loss=2.42] 22%|â–ˆâ–ˆâ–       | 109/500 [01:05<03:48,  1.71it/s, Train Loss=2.49, validation loss=2.42] 22%|â–ˆâ–ˆâ–       | 109/500 [01:05<03:48,  1.71it/s, Train Loss=1.8, validation loss=2.43]  22%|â–ˆâ–ˆâ–       | 110/500 [01:05<03:49,  1.70it/s, Train Loss=1.8, validation loss=2.43] 22%|â–ˆâ–ˆâ–       | 110/500 [01:06<03:49,  1.70it/s, Train Loss=2.28, validation loss=2.44] 22%|â–ˆâ–ˆâ–       | 111/500 [01:06<03:50,  1.69it/s, Train Loss=2.28, validation loss=2.44] 22%|â–ˆâ–ˆâ–       | 111/500 [01:07<03:50,  1.69it/s, Train Loss=2.22, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 112/500 [01:07<03:52,  1.67it/s, Train Loss=2.22, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 112/500 [01:07<03:52,  1.67it/s, Train Loss=1.8, validation loss=2.44]  23%|â–ˆâ–ˆâ–       | 113/500 [01:07<03:49,  1.68it/s, Train Loss=1.8, validation loss=2.44] 23%|â–ˆâ–ˆâ–       | 113/500 [01:08<03:49,  1.68it/s, Train Loss=2.36, validation loss=2.43] 23%|â–ˆâ–ˆâ–       | 114/500 [01:08<03:53,  1.65it/s, Train Loss=2.36, validation loss=2.43] 23%|â–ˆâ–ˆâ–       | 114/500 [01:08<03:53,  1.65it/s, Train Loss=3.54, validation loss=2.43] 23%|â–ˆâ–ˆâ–       | 115/500 [01:08<03:54,  1.64it/s, Train Loss=3.54, validation loss=2.43] 23%|â–ˆâ–ˆâ–       | 115/500 [01:09<03:54,  1.64it/s, Train Loss=1.92, validation loss=2.44] 23%|â–ˆâ–ˆâ–       | 116/500 [01:09<03:54,  1.64it/s, Train Loss=1.92, validation loss=2.44] 23%|â–ˆâ–ˆâ–       | 116/500 [01:10<03:54,  1.64it/s, Train Loss=2.39, validation loss=2.44] 23%|â–ˆâ–ˆâ–       | 117/500 [01:10<03:51,  1.65it/s, Train Loss=2.39, validation loss=2.44] 23%|â–ˆâ–ˆâ–       | 117/500 [01:10<03:51,  1.65it/s, Train Loss=1.69, validation loss=2.43] 24%|â–ˆâ–ˆâ–       | 118/500 [01:10<03:50,  1.66it/s, Train Loss=1.69, validation loss=2.43] 24%|â–ˆâ–ˆâ–       | 118/500 [01:11<03:50,  1.66it/s, Train Loss=2.7, validation loss=2.42]  24%|â–ˆâ–ˆâ–       | 119/500 [01:11<03:46,  1.68it/s, Train Loss=2.7, validation loss=2.42] 24%|â–ˆâ–ˆâ–       | 119/500 [01:11<03:46,  1.68it/s, Train Loss=1.73, validation loss=2.43] 24%|â–ˆâ–ˆâ–       | 120/500 [01:11<03:47,  1.67it/s, Train Loss=1.73, validation loss=2.43] 24%|â–ˆâ–ˆâ–       | 120/500 [01:12<03:47,  1.67it/s, Train Loss=2.34, validation loss=2.42] 24%|â–ˆâ–ˆâ–       | 121/500 [01:12<03:48,  1.66it/s, Train Loss=2.34, validation loss=2.42] 24%|â–ˆâ–ˆâ–       | 121/500 [01:13<03:48,  1.66it/s, Train Loss=1.98, validation loss=2.42] 24%|â–ˆâ–ˆâ–       | 122/500 [01:13<03:46,  1.67it/s, Train Loss=1.98, validation loss=2.42] 24%|â–ˆâ–ˆâ–       | 122/500 [01:13<03:46,  1.67it/s, Train Loss=2.11, validation loss=2.44] 25%|â–ˆâ–ˆâ–       | 123/500 [01:13<03:43,  1.68it/s, Train Loss=2.11, validation loss=2.44] 25%|â–ˆâ–ˆâ–       | 123/500 [01:14<03:43,  1.68it/s, Train Loss=1.93, validation loss=2.42] 25%|â–ˆâ–ˆâ–       | 124/500 [01:14<03:43,  1.68it/s, Train Loss=1.93, validation loss=2.42] 25%|â–ˆâ–ˆâ–       | 124/500 [01:14<03:43,  1.68it/s, Train Loss=2.43, validation loss=2.41] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:14<03:39,  1.71it/s, Train Loss=2.43, validation loss=2.41] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:15<03:39,  1.71it/s, Train Loss=4.32, validation loss=2.43] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:15<03:39,  1.70it/s, Train Loss=4.32, validation loss=2.43] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:16<03:39,  1.70it/s, Train Loss=3.03, validation loss=2.41] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:16<03:39,  1.70it/s, Train Loss=3.03, validation loss=2.41] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:16<03:39,  1.70it/s, Train Loss=2.39, validation loss=2.43] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:16<03:37,  1.71it/s, Train Loss=2.39, validation loss=2.43] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:17<03:37,  1.71it/s, Train Loss=1.51, validation loss=2.42] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:17<03:41,  1.67it/s, Train Loss=1.51, validation loss=2.42] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:17<03:41,  1.67it/s, Train Loss=2.49, validation loss=2.4]  26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:17<03:38,  1.70it/s, Train Loss=2.49, validation loss=2.4] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:18<03:38,  1.70it/s, Train Loss=2.02, validation loss=2.41] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:18<03:43,  1.65it/s, Train Loss=2.02, validation loss=2.41] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:19<03:43,  1.65it/s, Train Loss=1.95, validation loss=2.4]  26%|â–ˆâ–ˆâ–‹       | 132/500 [01:19<03:42,  1.66it/s, Train Loss=1.95, validation loss=2.4] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:19<03:42,  1.66it/s, Train Loss=2.02, validation loss=2.41] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:19<03:39,  1.67it/s, Train Loss=2.02, validation loss=2.41] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:20<03:39,  1.67it/s, Train Loss=2.11, validation loss=2.42] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:20<03:43,  1.64it/s, Train Loss=2.11, validation loss=2.42] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:20<03:43,  1.64it/s, Train Loss=2.34, validation loss=2.42] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:20<03:45,  1.62it/s, Train Loss=2.34, validation loss=2.42] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:21<03:45,  1.62it/s, Train Loss=1.83, validation loss=2.42] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:21<03:45,  1.61it/s, Train Loss=1.83, validation loss=2.42] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:22<03:45,  1.61it/s, Train Loss=1.94, validation loss=2.4]  27%|â–ˆâ–ˆâ–‹       | 137/500 [01:22<03:46,  1.60it/s, Train Loss=1.94, validation loss=2.4] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:22<03:46,  1.60it/s, Train Loss=3.29, validation loss=2.39] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:22<03:41,  1.64it/s, Train Loss=3.29, validation loss=2.39] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:23<03:41,  1.64it/s, Train Loss=3.45, validation loss=2.39] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:23<03:38,  1.65it/s, Train Loss=3.45, validation loss=2.39] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:23<03:38,  1.65it/s, Train Loss=2.17, validation loss=2.41] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:23<03:34,  1.68it/s, Train Loss=2.17, validation loss=2.41] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:24<03:34,  1.68it/s, Train Loss=2.63, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:24<03:37,  1.65it/s, Train Loss=2.63, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:25<03:37,  1.65it/s, Train Loss=1.74, validation loss=2.41] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:25<03:37,  1.64it/s, Train Loss=1.74, validation loss=2.41] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:25<03:37,  1.64it/s, Train Loss=1.95, validation loss=2.4]  29%|â–ˆâ–ˆâ–Š       | 143/500 [01:25<03:37,  1.64it/s, Train Loss=1.95, validation loss=2.4] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:26<03:37,  1.64it/s, Train Loss=1.57, validation loss=2.41] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:26<03:34,  1.66it/s, Train Loss=1.57, validation loss=2.41] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:27<03:34,  1.66it/s, Train Loss=3.1, validation loss=2.42]  29%|â–ˆâ–ˆâ–‰       | 145/500 [01:27<03:36,  1.64it/s, Train Loss=3.1, validation loss=2.42] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:27<03:36,  1.64it/s, Train Loss=1.72, validation loss=2.43] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:27<03:31,  1.68it/s, Train Loss=1.72, validation loss=2.43] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:28<03:31,  1.68it/s, Train Loss=1.87, validation loss=2.4]  29%|â–ˆâ–ˆâ–‰       | 147/500 [01:28<03:29,  1.69it/s, Train Loss=1.87, validation loss=2.4] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:28<03:29,  1.69it/s, Train Loss=2.1, validation loss=2.4]  30%|â–ˆâ–ˆâ–‰       | 148/500 [01:28<03:27,  1.70it/s, Train Loss=2.1, validation loss=2.4] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:29<03:27,  1.70it/s, Train Loss=2.56, validation loss=2.41] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:29<03:31,  1.66it/s, Train Loss=2.56, validation loss=2.41] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:29<03:31,  1.66it/s, Train Loss=3.19, validation loss=2.43] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:29<03:29,  1.67it/s, Train Loss=3.19, validation loss=2.43] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:30<03:29,  1.67it/s, Train Loss=1.92, validation loss=2.41] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:30<03:29,  1.67it/s, Train Loss=1.92, validation loss=2.41] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:31<03:29,  1.67it/s, Train Loss=2.3, validation loss=2.39]  30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:31<03:29,  1.66it/s, Train Loss=2.3, validation loss=2.39] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:31<03:29,  1.66it/s, Train Loss=1.98, validation loss=2.41] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:31<03:27,  1.67it/s, Train Loss=1.98, validation loss=2.41] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:32<03:27,  1.67it/s, Train Loss=1.46, validation loss=2.39] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:32<03:27,  1.66it/s, Train Loss=1.46, validation loss=2.39] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:32<03:27,  1.66it/s, Train Loss=1.95, validation loss=2.39] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:32<03:28,  1.66it/s, Train Loss=1.95, validation loss=2.39] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:33<03:28,  1.66it/s, Train Loss=2.67, validation loss=2.41] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:33<03:27,  1.66it/s, Train Loss=2.67, validation loss=2.41] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:34<03:27,  1.66it/s, Train Loss=2.15, validation loss=2.42] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:34<03:23,  1.68it/s, Train Loss=2.15, validation loss=2.42] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:34<03:23,  1.68it/s, Train Loss=2.01, validation loss=2.4]  32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:34<03:21,  1.70it/s, Train Loss=2.01, validation loss=2.4] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:35<03:21,  1.70it/s, Train Loss=1.73, validation loss=2.38] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:35<03:22,  1.69it/s, Train Loss=1.73, validation loss=2.38] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:35<03:22,  1.69it/s, Train Loss=3.32, validation loss=2.39] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:35<03:22,  1.68it/s, Train Loss=3.32, validation loss=2.39] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:36<03:22,  1.68it/s, Train Loss=2.33, validation loss=2.4]  32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:36<03:19,  1.70it/s, Train Loss=2.33, validation loss=2.4] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:37<03:19,  1.70it/s, Train Loss=1.67, validation loss=2.41] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:37<03:19,  1.70it/s, Train Loss=1.67, validation loss=2.41] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:37<03:19,  1.70it/s, Train Loss=2.5, validation loss=2.39]  33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:37<03:18,  1.70it/s, Train Loss=2.5, validation loss=2.39] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:38<03:18,  1.70it/s, Train Loss=2.21, validation loss=2.39] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:38<03:20,  1.67it/s, Train Loss=2.21, validation loss=2.39] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:38<03:20,  1.67it/s, Train Loss=2.02, validation loss=2.42] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:38<03:18,  1.68it/s, Train Loss=2.02, validation loss=2.42] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:39<03:18,  1.68it/s, Train Loss=1.4, validation loss=2.42]  33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:39<03:16,  1.70it/s, Train Loss=1.4, validation loss=2.42] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:40<03:16,  1.70it/s, Train Loss=2.17, validation loss=2.39] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:40<03:18,  1.68it/s, Train Loss=2.17, validation loss=2.39] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:40<03:18,  1.68it/s, Train Loss=2.37, validation loss=2.39] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:40<03:17,  1.68it/s, Train Loss=2.37, validation loss=2.39] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:41<03:17,  1.68it/s, Train Loss=2.1, validation loss=2.4]   34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:41<03:15,  1.70it/s, Train Loss=2.1, validation loss=2.4] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:41<03:15,  1.70it/s, Train Loss=1.81, validation loss=2.41] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:41<03:14,  1.70it/s, Train Loss=1.81, validation loss=2.41] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:42<03:14,  1.70it/s, Train Loss=1.85, validation loss=2.39] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:42<03:14,  1.69it/s, Train Loss=1.85, validation loss=2.39] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:43<03:14,  1.69it/s, Train Loss=3.26, validation loss=2.4]  34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:43<03:16,  1.67it/s, Train Loss=3.26, validation loss=2.4] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:43<03:16,  1.67it/s, Train Loss=2.36, validation loss=2.38] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:43<03:15,  1.68it/s, Train Loss=2.36, validation loss=2.38] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:44<03:15,  1.68it/s, Train Loss=1.91, validation loss=2.38] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:44<03:11,  1.70it/s, Train Loss=1.91, validation loss=2.38] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:44<03:11,  1.70it/s, Train Loss=1.83, validation loss=2.38] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:44<03:12,  1.68it/s, Train Loss=1.83, validation loss=2.38] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:45<03:12,  1.68it/s, Train Loss=2.41, validation loss=2.4]  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:45<03:13,  1.68it/s, Train Loss=2.41, validation loss=2.4] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:46<03:13,  1.68it/s, Train Loss=1.63, validation loss=2.38] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:46<03:14,  1.66it/s, Train Loss=1.63, validation loss=2.38] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:46<03:14,  1.66it/s, Train Loss=2.54, validation loss=2.39] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:46<03:13,  1.67it/s, Train Loss=2.54, validation loss=2.39] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:47<03:13,  1.67it/s, Train Loss=2.42, validation loss=2.41] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:47<03:13,  1.66it/s, Train Loss=2.42, validation loss=2.41] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:47<03:13,  1.66it/s, Train Loss=3.36, validation loss=2.4]  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:47<03:13,  1.65it/s, Train Loss=3.36, validation loss=2.4] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:48<03:13,  1.65it/s, Train Loss=2.32, validation loss=2.4] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:48<03:14,  1.64it/s, Train Loss=2.32, validation loss=2.4] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:49<03:14,  1.64it/s, Train Loss=1.85, validation loss=2.39] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:49<03:11,  1.66it/s, Train Loss=1.85, validation loss=2.39] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:49<03:11,  1.66it/s, Train Loss=2.32, validation loss=2.41] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:49<03:15,  1.62it/s, Train Loss=2.32, validation loss=2.41] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:50<03:15,  1.62it/s, Train Loss=2.21, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:50<03:14,  1.62it/s, Train Loss=2.21, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:50<03:14,  1.62it/s, Train Loss=1.63, validation loss=2.4]  37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:50<03:09,  1.66it/s, Train Loss=1.63, validation loss=2.4] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:51<03:09,  1.66it/s, Train Loss=1.25, validation loss=2.37] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [01:51<03:09,  1.66it/s, Train Loss=1.25, validation loss=2.37] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [01:52<03:09,  1.66it/s, Train Loss=2.33, validation loss=2.38] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [01:52<03:09,  1.65it/s, Train Loss=2.33, validation loss=2.38] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [01:52<03:09,  1.65it/s, Train Loss=1.97, validation loss=2.39] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [01:52<03:07,  1.66it/s, Train Loss=1.97, validation loss=2.39] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [01:53<03:07,  1.66it/s, Train Loss=2.57, validation loss=2.38] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [01:53<03:09,  1.64it/s, Train Loss=2.57, validation loss=2.38] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [01:53<03:09,  1.64it/s, Train Loss=2.28, validation loss=2.42] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [01:53<03:06,  1.66it/s, Train Loss=2.28, validation loss=2.42] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [01:54<03:06,  1.66it/s, Train Loss=2.04, validation loss=2.4]  38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [01:54<03:08,  1.64it/s, Train Loss=2.04, validation loss=2.4] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [01:55<03:08,  1.64it/s, Train Loss=3.2, validation loss=2.38] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [01:55<03:06,  1.65it/s, Train Loss=3.2, validation loss=2.38] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [01:55<03:06,  1.65it/s, Train Loss=2.09, validation loss=2.38] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [01:55<03:04,  1.67it/s, Train Loss=2.09, validation loss=2.38] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [01:56<03:04,  1.67it/s, Train Loss=1.96, validation loss=2.39] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [01:56<03:03,  1.67it/s, Train Loss=1.96, validation loss=2.39] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [01:56<03:03,  1.67it/s, Train Loss=1.84, validation loss=2.4]  39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [01:56<03:02,  1.67it/s, Train Loss=1.84, validation loss=2.4] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [01:57<03:02,  1.67it/s, Train Loss=1.76, validation loss=2.38] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [01:57<03:02,  1.67it/s, Train Loss=1.76, validation loss=2.38] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [01:58<03:02,  1.67it/s, Train Loss=1.18, validation loss=2.38] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [01:58<03:01,  1.67it/s, Train Loss=1.18, validation loss=2.38] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [01:58<03:01,  1.67it/s, Train Loss=1.84, validation loss=2.38] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [01:58<02:58,  1.69it/s, Train Loss=1.84, validation loss=2.38] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [01:59<02:58,  1.69it/s, Train Loss=1.68, validation loss=2.39] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [01:59<03:00,  1.66it/s, Train Loss=1.68, validation loss=2.39]####################################################################################################
--------------------------------------------- Epoch:200 ---------------------------------------------
-- Training set:
Loss: 2.9142730236053467, Lr: 0.00025
Average AUC ROC: 0.51                Average AUC PR: 0.29
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [01:59<03:00,  1.66it/s, Train Loss=2.91, validation loss=2.37] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [01:59<03:00,  1.66it/s, Train Loss=2.91, validation loss=2.37]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.3719702139496803
Average AUC ROC: 0.56                    Average AUC PR: 0.31
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:00<03:00,  1.66it/s, Train Loss=4.06, validation loss=2.37] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:00<02:59,  1.66it/s, Train Loss=4.06, validation loss=2.37] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:01<02:59,  1.66it/s, Train Loss=1.69, validation loss=2.38] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:01<02:58,  1.67it/s, Train Loss=1.69, validation loss=2.38] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:01<02:58,  1.67it/s, Train Loss=2.13, validation loss=2.37] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:01<02:56,  1.68it/s, Train Loss=2.13, validation loss=2.37] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:02<02:56,  1.68it/s, Train Loss=2.28, validation loss=2.36] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:02<02:54,  1.69it/s, Train Loss=2.28, validation loss=2.36] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:02<02:54,  1.69it/s, Train Loss=1.75, validation loss=2.36] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:02<02:55,  1.68it/s, Train Loss=1.75, validation loss=2.36] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:03<02:55,  1.68it/s, Train Loss=1.96, validation loss=2.36] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:03<03:00,  1.63it/s, Train Loss=1.96, validation loss=2.36] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:04<03:00,  1.63it/s, Train Loss=2.05, validation loss=2.38] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:04<02:59,  1.64it/s, Train Loss=2.05, validation loss=2.38] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:04<02:59,  1.64it/s, Train Loss=2.1, validation loss=2.37]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:04<02:58,  1.64it/s, Train Loss=2.1, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:05<02:58,  1.64it/s, Train Loss=2.4, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:05<02:53,  1.67it/s, Train Loss=2.4, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:05<02:53,  1.67it/s, Train Loss=1.31, validation loss=2.38] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:05<02:54,  1.66it/s, Train Loss=1.31, validation loss=2.38] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:06<02:54,  1.66it/s, Train Loss=2.37, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:06<02:53,  1.67it/s, Train Loss=2.37, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:07<02:53,  1.67it/s, Train Loss=2.05, validation loss=2.39] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:07<02:52,  1.67it/s, Train Loss=2.05, validation loss=2.39] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:07<02:52,  1.67it/s, Train Loss=2.15, validation loss=2.38] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:07<02:59,  1.60it/s, Train Loss=2.15, validation loss=2.38] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:08<02:59,  1.60it/s, Train Loss=3.49, validation loss=2.37] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:08<03:01,  1.58it/s, Train Loss=3.49, validation loss=2.37] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:09<03:01,  1.58it/s, Train Loss=1.79, validation loss=2.38] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:09<03:03,  1.55it/s, Train Loss=1.79, validation loss=2.38] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:09<03:03,  1.55it/s, Train Loss=2.25, validation loss=2.36] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:09<03:05,  1.53it/s, Train Loss=2.25, validation loss=2.36] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:10<03:05,  1.53it/s, Train Loss=2.09, validation loss=2.39] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:10<03:00,  1.57it/s, Train Loss=2.09, validation loss=2.39] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:11<03:00,  1.57it/s, Train Loss=2.41, validation loss=2.38] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:11<02:57,  1.59it/s, Train Loss=2.41, validation loss=2.38] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:11<02:57,  1.59it/s, Train Loss=1.95, validation loss=2.38] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:11<02:58,  1.57it/s, Train Loss=1.95, validation loss=2.38] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:12<02:58,  1.57it/s, Train Loss=3.06, validation loss=2.37] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:12<02:54,  1.61it/s, Train Loss=3.06, validation loss=2.37] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:12<02:54,  1.61it/s, Train Loss=1.99, validation loss=2.37] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:12<02:50,  1.64it/s, Train Loss=1.99, validation loss=2.37] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:13<02:50,  1.64it/s, Train Loss=1.69, validation loss=2.38] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:13<02:49,  1.64it/s, Train Loss=1.69, validation loss=2.38] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:14<02:49,  1.64it/s, Train Loss=1.84, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:14<02:58,  1.56it/s, Train Loss=1.84, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:14<02:58,  1.56it/s, Train Loss=1.74, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:14<02:55,  1.57it/s, Train Loss=1.74, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:15<02:55,  1.57it/s, Train Loss=2.89, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:15<03:04,  1.49it/s, Train Loss=2.89, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:16<03:04,  1.49it/s, Train Loss=3.69, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:16<03:04,  1.48it/s, Train Loss=3.69, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:16<03:04,  1.48it/s, Train Loss=1.81, validation loss=2.38] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:16<03:08,  1.45it/s, Train Loss=1.81, validation loss=2.38] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:17<03:08,  1.45it/s, Train Loss=3.62, validation loss=2.36] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:17<03:12,  1.41it/s, Train Loss=3.62, validation loss=2.36] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:18<03:12,  1.41it/s, Train Loss=1.93, validation loss=2.35] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:18<03:17,  1.37it/s, Train Loss=1.93, validation loss=2.35] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:19<03:17,  1.37it/s, Train Loss=2.99, validation loss=2.37] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:19<03:16,  1.37it/s, Train Loss=2.99, validation loss=2.37] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:19<03:16,  1.37it/s, Train Loss=2.34, validation loss=2.37] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:19<03:04,  1.46it/s, Train Loss=2.34, validation loss=2.37] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:20<03:04,  1.46it/s, Train Loss=1.94, validation loss=2.37] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:20<02:55,  1.53it/s, Train Loss=1.94, validation loss=2.37] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:21<02:55,  1.53it/s, Train Loss=3.34, validation loss=2.37] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:21<02:51,  1.55it/s, Train Loss=3.34, validation loss=2.37] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:21<02:51,  1.55it/s, Train Loss=1.88, validation loss=2.37] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:21<02:46,  1.59it/s, Train Loss=1.88, validation loss=2.37] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:22<02:46,  1.59it/s, Train Loss=2.36, validation loss=2.39] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:22<02:45,  1.60it/s, Train Loss=2.36, validation loss=2.39] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:22<02:45,  1.60it/s, Train Loss=1.2, validation loss=2.36]  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:22<02:43,  1.61it/s, Train Loss=1.2, validation loss=2.36] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:23<02:43,  1.61it/s, Train Loss=1.99, validation loss=2.35] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:23<02:40,  1.63it/s, Train Loss=1.99, validation loss=2.35] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:24<02:40,  1.63it/s, Train Loss=3.15, validation loss=2.36] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:24<02:39,  1.65it/s, Train Loss=3.15, validation loss=2.36] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:24<02:39,  1.65it/s, Train Loss=2.09, validation loss=2.38] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:24<02:39,  1.64it/s, Train Loss=2.09, validation loss=2.38] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:25<02:39,  1.64it/s, Train Loss=1.73, validation loss=2.38] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:25<02:38,  1.64it/s, Train Loss=1.73, validation loss=2.38] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:25<02:38,  1.64it/s, Train Loss=1.93, validation loss=2.36] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:25<02:37,  1.64it/s, Train Loss=1.93, validation loss=2.36] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:26<02:37,  1.64it/s, Train Loss=1.54, validation loss=2.38] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:26<02:35,  1.66it/s, Train Loss=1.54, validation loss=2.38] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:27<02:35,  1.66it/s, Train Loss=3.07, validation loss=2.37] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:27<02:35,  1.66it/s, Train Loss=3.07, validation loss=2.37] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:27<02:35,  1.66it/s, Train Loss=1.95, validation loss=2.37] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:27<02:35,  1.65it/s, Train Loss=1.95, validation loss=2.37] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:28<02:35,  1.65it/s, Train Loss=2.57, validation loss=2.37] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:28<02:33,  1.66it/s, Train Loss=2.57, validation loss=2.37] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:28<02:33,  1.66it/s, Train Loss=2.17, validation loss=2.36] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:28<02:31,  1.68it/s, Train Loss=2.17, validation loss=2.36] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:29<02:31,  1.68it/s, Train Loss=2.37, validation loss=2.37] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:29<02:31,  1.67it/s, Train Loss=2.37, validation loss=2.37] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:30<02:31,  1.67it/s, Train Loss=1.41, validation loss=2.37] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:30<02:33,  1.65it/s, Train Loss=1.41, validation loss=2.37] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:30<02:33,  1.65it/s, Train Loss=1.78, validation loss=2.37] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:30<02:29,  1.67it/s, Train Loss=1.78, validation loss=2.37] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:31<02:29,  1.67it/s, Train Loss=2.1, validation loss=2.35]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:31<02:28,  1.68it/s, Train Loss=2.1, validation loss=2.35] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:31<02:28,  1.68it/s, Train Loss=2.19, validation loss=2.35] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:31<02:27,  1.69it/s, Train Loss=2.19, validation loss=2.35] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:32<02:27,  1.69it/s, Train Loss=2.3, validation loss=2.37]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:32<02:27,  1.68it/s, Train Loss=2.3, validation loss=2.37] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:33<02:27,  1.68it/s, Train Loss=1.8, validation loss=2.37] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:33<02:25,  1.69it/s, Train Loss=1.8, validation loss=2.37] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:33<02:25,  1.69it/s, Train Loss=2.36, validation loss=2.37] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:33<02:26,  1.68it/s, Train Loss=2.36, validation loss=2.37] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:34<02:26,  1.68it/s, Train Loss=2.56, validation loss=2.34] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:34<02:25,  1.69it/s, Train Loss=2.56, validation loss=2.34] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:34<02:25,  1.69it/s, Train Loss=2.17, validation loss=2.36] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:34<02:25,  1.68it/s, Train Loss=2.17, validation loss=2.36] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:35<02:25,  1.68it/s, Train Loss=2.3, validation loss=2.37]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:35<02:23,  1.70it/s, Train Loss=2.3, validation loss=2.37] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:36<02:23,  1.70it/s, Train Loss=1.93, validation loss=2.37] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:36<02:25,  1.66it/s, Train Loss=1.93, validation loss=2.37] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:36<02:25,  1.66it/s, Train Loss=3.86, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:36<02:24,  1.67it/s, Train Loss=3.86, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:37<02:24,  1.67it/s, Train Loss=4.1, validation loss=2.36]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:37<02:27,  1.63it/s, Train Loss=4.1, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:37<02:27,  1.63it/s, Train Loss=3.06, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:37<02:25,  1.64it/s, Train Loss=3.06, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:38<02:25,  1.64it/s, Train Loss=2.59, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:38<02:25,  1.64it/s, Train Loss=2.59, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:39<02:25,  1.64it/s, Train Loss=2.33, validation loss=2.38] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:39<02:23,  1.66it/s, Train Loss=2.33, validation loss=2.38] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:39<02:23,  1.66it/s, Train Loss=2.27, validation loss=2.36] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:39<02:20,  1.68it/s, Train Loss=2.27, validation loss=2.36] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:40<02:20,  1.68it/s, Train Loss=1.77, validation loss=2.37] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:40<02:17,  1.70it/s, Train Loss=1.77, validation loss=2.37] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:40<02:17,  1.70it/s, Train Loss=2.2, validation loss=2.37]  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:40<02:15,  1.73it/s, Train Loss=2.2, validation loss=2.37] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:41<02:15,  1.73it/s, Train Loss=4.88, validation loss=2.37] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:41<02:16,  1.70it/s, Train Loss=4.88, validation loss=2.37] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:41<02:16,  1.70it/s, Train Loss=2.36, validation loss=2.37] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:41<02:19,  1.67it/s, Train Loss=2.36, validation loss=2.37] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:42<02:19,  1.67it/s, Train Loss=2.07, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:42<02:18,  1.67it/s, Train Loss=2.07, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:43<02:18,  1.67it/s, Train Loss=2.62, validation loss=2.37] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:43<02:18,  1.66it/s, Train Loss=2.62, validation loss=2.37] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:43<02:18,  1.66it/s, Train Loss=1.91, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:43<02:18,  1.66it/s, Train Loss=1.91, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:44<02:18,  1.66it/s, Train Loss=1.91, validation loss=2.37] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:44<02:15,  1.68it/s, Train Loss=1.91, validation loss=2.37] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:44<02:15,  1.68it/s, Train Loss=1.71, validation loss=2.36] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:44<02:15,  1.68it/s, Train Loss=1.71, validation loss=2.36] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:45<02:15,  1.68it/s, Train Loss=3.01, validation loss=2.36] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:45<02:14,  1.68it/s, Train Loss=3.01, validation loss=2.36] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:46<02:14,  1.68it/s, Train Loss=2.16, validation loss=2.36] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:46<02:14,  1.67it/s, Train Loss=2.16, validation loss=2.36] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:46<02:14,  1.67it/s, Train Loss=2, validation loss=2.38]    55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:46<02:14,  1.66it/s, Train Loss=2, validation loss=2.38] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:47<02:14,  1.66it/s, Train Loss=2.7, validation loss=2.38] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:47<02:12,  1.69it/s, Train Loss=2.7, validation loss=2.38] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:47<02:12,  1.69it/s, Train Loss=1.89, validation loss=2.36] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:47<02:10,  1.71it/s, Train Loss=1.89, validation loss=2.36] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:48<02:10,  1.71it/s, Train Loss=2.96, validation loss=2.37] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [02:48<02:11,  1.69it/s, Train Loss=2.96, validation loss=2.37] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [02:49<02:11,  1.69it/s, Train Loss=2.22, validation loss=2.37] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [02:49<02:08,  1.71it/s, Train Loss=2.22, validation loss=2.37] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [02:49<02:08,  1.71it/s, Train Loss=1.67, validation loss=2.36] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [02:49<02:07,  1.71it/s, Train Loss=1.67, validation loss=2.36] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [02:50<02:07,  1.71it/s, Train Loss=1.16, validation loss=2.38] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [02:50<02:06,  1.72it/s, Train Loss=1.16, validation loss=2.38] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [02:50<02:06,  1.72it/s, Train Loss=2.46, validation loss=2.37] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [02:50<02:09,  1.68it/s, Train Loss=2.46, validation loss=2.37] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [02:51<02:09,  1.68it/s, Train Loss=3.04, validation loss=2.36] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [02:51<02:08,  1.69it/s, Train Loss=3.04, validation loss=2.36] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [02:52<02:08,  1.69it/s, Train Loss=2.04, validation loss=2.37] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [02:52<02:06,  1.70it/s, Train Loss=2.04, validation loss=2.37] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [02:52<02:06,  1.70it/s, Train Loss=2.52, validation loss=2.37] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [02:52<02:06,  1.70it/s, Train Loss=2.52, validation loss=2.37] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [02:53<02:06,  1.70it/s, Train Loss=1.81, validation loss=2.38] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [02:53<02:06,  1.69it/s, Train Loss=1.81, validation loss=2.38] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [02:53<02:06,  1.69it/s, Train Loss=3.16, validation loss=2.37] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [02:53<02:06,  1.67it/s, Train Loss=3.16, validation loss=2.37] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [02:54<02:06,  1.67it/s, Train Loss=1.71, validation loss=2.36] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [02:54<02:05,  1.68it/s, Train Loss=1.71, validation loss=2.36] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [02:55<02:05,  1.68it/s, Train Loss=2.36, validation loss=2.37] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [02:55<02:05,  1.67it/s, Train Loss=2.36, validation loss=2.37] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [02:55<02:05,  1.67it/s, Train Loss=1.96, validation loss=2.37] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [02:55<02:05,  1.67it/s, Train Loss=1.96, validation loss=2.37] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [02:56<02:05,  1.67it/s, Train Loss=2.29, validation loss=2.35] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [02:56<02:04,  1.67it/s, Train Loss=2.29, validation loss=2.35] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [02:56<02:04,  1.67it/s, Train Loss=1.35, validation loss=2.37] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [02:56<02:01,  1.70it/s, Train Loss=1.35, validation loss=2.37] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [02:57<02:01,  1.70it/s, Train Loss=3.16, validation loss=2.36] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [02:57<02:01,  1.70it/s, Train Loss=3.16, validation loss=2.36] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [02:58<02:01,  1.70it/s, Train Loss=2, validation loss=2.37]    59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [02:58<02:02,  1.67it/s, Train Loss=2, validation loss=2.37] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [02:58<02:02,  1.67it/s, Train Loss=2.2, validation loss=2.35] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [02:58<02:01,  1.68it/s, Train Loss=2.2, validation loss=2.35] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [02:59<02:01,  1.68it/s, Train Loss=1.73, validation loss=2.37] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [02:59<02:00,  1.69it/s, Train Loss=1.73, validation loss=2.37] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [02:59<02:00,  1.69it/s, Train Loss=2.58, validation loss=2.35] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [02:59<01:58,  1.71it/s, Train Loss=2.58, validation loss=2.35] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:00<01:58,  1.71it/s, Train Loss=1.99, validation loss=2.35] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:00<01:59,  1.68it/s, Train Loss=1.99, validation loss=2.35]####################################################################################################
--------------------------------------------- Epoch:300 ---------------------------------------------
-- Training set:
Loss: 2.0769591331481934, Lr: 0.000125
Average AUC ROC: 0.53                Average AUC PR: 0.28
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:00<01:59,  1.68it/s, Train Loss=2.08, validation loss=2.36] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:00<01:56,  1.72it/s, Train Loss=2.08, validation loss=2.36]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.359179802238941
Average AUC ROC: 0.56                    Average AUC PR: 0.31
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:01<01:56,  1.72it/s, Train Loss=2.21, validation loss=2.35] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:01<01:55,  1.73it/s, Train Loss=2.21, validation loss=2.35] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:02<01:55,  1.73it/s, Train Loss=2.34, validation loss=2.37] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:02<01:55,  1.71it/s, Train Loss=2.34, validation loss=2.37] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:02<01:55,  1.71it/s, Train Loss=1.82, validation loss=2.38] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:02<01:55,  1.70it/s, Train Loss=1.82, validation loss=2.38] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:03<01:55,  1.70it/s, Train Loss=1.38, validation loss=2.37] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:03<01:54,  1.71it/s, Train Loss=1.38, validation loss=2.37] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:03<01:54,  1.71it/s, Train Loss=1.85, validation loss=2.36] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:03<01:53,  1.72it/s, Train Loss=1.85, validation loss=2.36] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:04<01:53,  1.72it/s, Train Loss=2.94, validation loss=2.35] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:04<01:51,  1.74it/s, Train Loss=2.94, validation loss=2.35] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:05<01:51,  1.74it/s, Train Loss=2.55, validation loss=2.36] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:05<01:53,  1.70it/s, Train Loss=2.55, validation loss=2.36] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:05<01:53,  1.70it/s, Train Loss=1.85, validation loss=2.38] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:05<01:54,  1.68it/s, Train Loss=1.85, validation loss=2.38] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:06<01:54,  1.68it/s, Train Loss=2.13, validation loss=2.37] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:06<01:52,  1.69it/s, Train Loss=2.13, validation loss=2.37] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:06<01:52,  1.69it/s, Train Loss=2.18, validation loss=2.36] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:06<01:51,  1.70it/s, Train Loss=2.18, validation loss=2.36] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:07<01:51,  1.70it/s, Train Loss=2.67, validation loss=2.35] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:07<01:52,  1.69it/s, Train Loss=2.67, validation loss=2.35] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:08<01:52,  1.69it/s, Train Loss=3.12, validation loss=2.37] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:08<01:52,  1.67it/s, Train Loss=3.12, validation loss=2.37] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:08<01:52,  1.67it/s, Train Loss=1.92, validation loss=2.36] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:08<01:52,  1.67it/s, Train Loss=1.92, validation loss=2.36] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:09<01:52,  1.67it/s, Train Loss=1.69, validation loss=2.37] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:09<01:50,  1.68it/s, Train Loss=1.69, validation loss=2.37] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:09<01:50,  1.68it/s, Train Loss=2.15, validation loss=2.35] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:09<01:51,  1.66it/s, Train Loss=2.15, validation loss=2.35] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:10<01:51,  1.66it/s, Train Loss=2.98, validation loss=2.34] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:10<01:50,  1.66it/s, Train Loss=2.98, validation loss=2.34] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:11<01:50,  1.66it/s, Train Loss=1.33, validation loss=2.35] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:11<01:48,  1.68it/s, Train Loss=1.33, validation loss=2.35] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:11<01:48,  1.68it/s, Train Loss=2.61, validation loss=2.38] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:11<01:49,  1.66it/s, Train Loss=2.61, validation loss=2.38] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:12<01:49,  1.66it/s, Train Loss=3.79, validation loss=2.35] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:12<01:48,  1.67it/s, Train Loss=3.79, validation loss=2.35] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:12<01:48,  1.67it/s, Train Loss=2.6, validation loss=2.34]  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:12<01:48,  1.66it/s, Train Loss=2.6, validation loss=2.34] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:13<01:48,  1.66it/s, Train Loss=2.74, validation loss=2.36] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:13<01:47,  1.66it/s, Train Loss=2.74, validation loss=2.36] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:14<01:47,  1.66it/s, Train Loss=3.6, validation loss=2.35]  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:14<01:49,  1.63it/s, Train Loss=3.6, validation loss=2.35] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:14<01:49,  1.63it/s, Train Loss=2.41, validation loss=2.37] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:14<01:47,  1.65it/s, Train Loss=2.41, validation loss=2.37] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:15<01:47,  1.65it/s, Train Loss=1.86, validation loss=2.36] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:15<01:46,  1.65it/s, Train Loss=1.86, validation loss=2.36] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:15<01:46,  1.65it/s, Train Loss=1.45, validation loss=2.34] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:15<01:46,  1.64it/s, Train Loss=1.45, validation loss=2.34] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:16<01:46,  1.64it/s, Train Loss=1.83, validation loss=2.35] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:16<01:45,  1.65it/s, Train Loss=1.83, validation loss=2.35] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:17<01:45,  1.65it/s, Train Loss=1.69, validation loss=2.34] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:17<01:43,  1.68it/s, Train Loss=1.69, validation loss=2.34] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:17<01:43,  1.68it/s, Train Loss=1.81, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:17<01:45,  1.64it/s, Train Loss=1.81, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:18<01:45,  1.64it/s, Train Loss=2.16, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:18<01:44,  1.64it/s, Train Loss=2.16, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:18<01:44,  1.64it/s, Train Loss=1.16, validation loss=2.36] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:18<01:41,  1.67it/s, Train Loss=1.16, validation loss=2.36] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:19<01:41,  1.67it/s, Train Loss=1.48, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:19<01:41,  1.66it/s, Train Loss=1.48, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:20<01:41,  1.66it/s, Train Loss=1.77, validation loss=2.34] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:20<01:40,  1.67it/s, Train Loss=1.77, validation loss=2.34] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:20<01:40,  1.67it/s, Train Loss=2.14, validation loss=2.35] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:20<01:39,  1.68it/s, Train Loss=2.14, validation loss=2.35] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:21<01:39,  1.68it/s, Train Loss=3, validation loss=2.37]    67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:21<01:38,  1.68it/s, Train Loss=3, validation loss=2.37] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:21<01:38,  1.68it/s, Train Loss=1.79, validation loss=2.36] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:21<01:38,  1.68it/s, Train Loss=1.79, validation loss=2.36] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:22<01:38,  1.68it/s, Train Loss=2.13, validation loss=2.36] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:22<01:37,  1.69it/s, Train Loss=2.13, validation loss=2.36] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:23<01:37,  1.69it/s, Train Loss=1.96, validation loss=2.37] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:23<01:36,  1.69it/s, Train Loss=1.96, validation loss=2.37] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:23<01:36,  1.69it/s, Train Loss=3.25, validation loss=2.35] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:23<01:35,  1.70it/s, Train Loss=3.25, validation loss=2.35] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:24<01:35,  1.70it/s, Train Loss=2.57, validation loss=2.34] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:24<01:35,  1.69it/s, Train Loss=2.57, validation loss=2.34] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:24<01:35,  1.69it/s, Train Loss=1.67, validation loss=2.34] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:24<01:33,  1.71it/s, Train Loss=1.67, validation loss=2.34] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:25<01:33,  1.71it/s, Train Loss=3.59, validation loss=2.37] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:25<01:33,  1.69it/s, Train Loss=3.59, validation loss=2.37] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:25<01:33,  1.69it/s, Train Loss=1.89, validation loss=2.34] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:25<01:33,  1.70it/s, Train Loss=1.89, validation loss=2.34] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:26<01:33,  1.70it/s, Train Loss=2.5, validation loss=2.35]  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:26<01:33,  1.68it/s, Train Loss=2.5, validation loss=2.35] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:27<01:33,  1.68it/s, Train Loss=2.58, validation loss=2.36] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:27<01:31,  1.70it/s, Train Loss=2.58, validation loss=2.36] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:27<01:31,  1.70it/s, Train Loss=1.63, validation loss=2.35] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:27<01:32,  1.68it/s, Train Loss=1.63, validation loss=2.35] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:28<01:32,  1.68it/s, Train Loss=1.74, validation loss=2.34] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:28<01:32,  1.67it/s, Train Loss=1.74, validation loss=2.34] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:28<01:32,  1.67it/s, Train Loss=2.09, validation loss=2.35] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:28<01:31,  1.68it/s, Train Loss=2.09, validation loss=2.35] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:29<01:31,  1.68it/s, Train Loss=2.6, validation loss=2.35]  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:29<01:31,  1.66it/s, Train Loss=2.6, validation loss=2.35] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:30<01:31,  1.66it/s, Train Loss=1.98, validation loss=2.34] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:30<01:30,  1.68it/s, Train Loss=1.98, validation loss=2.34] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:30<01:30,  1.68it/s, Train Loss=3.9, validation loss=2.35]  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:30<01:28,  1.70it/s, Train Loss=3.9, validation loss=2.35] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:31<01:28,  1.70it/s, Train Loss=2.02, validation loss=2.36] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:31<01:27,  1.70it/s, Train Loss=2.02, validation loss=2.36] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:31<01:27,  1.70it/s, Train Loss=2.46, validation loss=2.34] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:31<01:26,  1.71it/s, Train Loss=2.46, validation loss=2.34] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:32<01:26,  1.71it/s, Train Loss=2.28, validation loss=2.34] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:32<01:25,  1.72it/s, Train Loss=2.28, validation loss=2.34] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:33<01:25,  1.72it/s, Train Loss=2.26, validation loss=2.35] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:33<01:25,  1.72it/s, Train Loss=2.26, validation loss=2.35] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:33<01:25,  1.72it/s, Train Loss=2.09, validation loss=2.35] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:33<01:24,  1.71it/s, Train Loss=2.09, validation loss=2.35] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:34<01:24,  1.71it/s, Train Loss=4.11, validation loss=2.33] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:34<01:25,  1.69it/s, Train Loss=4.11, validation loss=2.33] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:34<01:25,  1.69it/s, Train Loss=2.39, validation loss=2.35] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:34<01:24,  1.69it/s, Train Loss=2.39, validation loss=2.35] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:35<01:24,  1.69it/s, Train Loss=1.73, validation loss=2.35] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:35<01:24,  1.69it/s, Train Loss=1.73, validation loss=2.35] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:36<01:24,  1.69it/s, Train Loss=2.18, validation loss=2.34] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:36<01:25,  1.65it/s, Train Loss=2.18, validation loss=2.34] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:36<01:25,  1.65it/s, Train Loss=2.14, validation loss=2.35] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:36<01:25,  1.64it/s, Train Loss=2.14, validation loss=2.35] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:37<01:25,  1.64it/s, Train Loss=1.4, validation loss=2.35]  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:37<01:24,  1.65it/s, Train Loss=1.4, validation loss=2.35] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:37<01:24,  1.65it/s, Train Loss=2.01, validation loss=2.36] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:37<01:23,  1.65it/s, Train Loss=2.01, validation loss=2.36] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:38<01:23,  1.65it/s, Train Loss=2.31, validation loss=2.36] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:38<01:22,  1.66it/s, Train Loss=2.31, validation loss=2.36] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:39<01:22,  1.66it/s, Train Loss=3.2, validation loss=2.38]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:39<01:20,  1.69it/s, Train Loss=3.2, validation loss=2.38] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:39<01:20,  1.69it/s, Train Loss=2.38, validation loss=2.36] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:39<01:21,  1.66it/s, Train Loss=2.38, validation loss=2.36] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:40<01:21,  1.66it/s, Train Loss=2.23, validation loss=2.35] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:40<01:19,  1.68it/s, Train Loss=2.23, validation loss=2.35] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:40<01:19,  1.68it/s, Train Loss=2.13, validation loss=2.37] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:40<01:19,  1.68it/s, Train Loss=2.13, validation loss=2.37] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:41<01:19,  1.68it/s, Train Loss=1.88, validation loss=2.33] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:41<01:20,  1.65it/s, Train Loss=1.88, validation loss=2.33] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:42<01:20,  1.65it/s, Train Loss=1.8, validation loss=2.36]  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:42<01:19,  1.65it/s, Train Loss=1.8, validation loss=2.36] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:42<01:19,  1.65it/s, Train Loss=3.11, validation loss=2.35] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:42<01:18,  1.67it/s, Train Loss=3.11, validation loss=2.35] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:43<01:18,  1.67it/s, Train Loss=1.45, validation loss=2.36] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:43<01:17,  1.66it/s, Train Loss=1.45, validation loss=2.36] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:43<01:17,  1.66it/s, Train Loss=1.8, validation loss=2.35]  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [03:43<01:17,  1.65it/s, Train Loss=1.8, validation loss=2.35] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [03:44<01:17,  1.65it/s, Train Loss=1.48, validation loss=2.34] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [03:44<01:17,  1.65it/s, Train Loss=1.48, validation loss=2.34] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [03:45<01:17,  1.65it/s, Train Loss=2.02, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [03:45<01:16,  1.65it/s, Train Loss=2.02, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [03:45<01:16,  1.65it/s, Train Loss=2.7, validation loss=2.36]  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [03:45<01:16,  1.64it/s, Train Loss=2.7, validation loss=2.36] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [03:46<01:16,  1.64it/s, Train Loss=1.57, validation loss=2.36] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [03:46<01:15,  1.63it/s, Train Loss=1.57, validation loss=2.36] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [03:46<01:15,  1.63it/s, Train Loss=1.57, validation loss=2.33] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [03:46<01:14,  1.65it/s, Train Loss=1.57, validation loss=2.33] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [03:47<01:14,  1.65it/s, Train Loss=3.6, validation loss=2.33]  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [03:47<01:13,  1.65it/s, Train Loss=3.6, validation loss=2.33] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [03:48<01:13,  1.65it/s, Train Loss=1.52, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [03:48<01:12,  1.68it/s, Train Loss=1.52, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [03:48<01:12,  1.68it/s, Train Loss=2.16, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [03:48<01:12,  1.65it/s, Train Loss=2.16, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [03:49<01:12,  1.65it/s, Train Loss=3.57, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [03:49<01:11,  1.67it/s, Train Loss=3.57, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [03:49<01:11,  1.67it/s, Train Loss=1.44, validation loss=2.35] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [03:49<01:10,  1.67it/s, Train Loss=1.44, validation loss=2.35] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [03:50<01:10,  1.67it/s, Train Loss=3.12, validation loss=2.35] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [03:50<01:09,  1.68it/s, Train Loss=3.12, validation loss=2.35] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [03:51<01:09,  1.68it/s, Train Loss=1.62, validation loss=2.34] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [03:51<01:08,  1.68it/s, Train Loss=1.62, validation loss=2.34] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [03:51<01:08,  1.68it/s, Train Loss=1.82, validation loss=2.34] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [03:51<01:08,  1.68it/s, Train Loss=1.82, validation loss=2.34] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [03:52<01:08,  1.68it/s, Train Loss=1.87, validation loss=2.35] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [03:52<01:08,  1.66it/s, Train Loss=1.87, validation loss=2.35] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [03:52<01:08,  1.66it/s, Train Loss=2.99, validation loss=2.36] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [03:52<01:08,  1.66it/s, Train Loss=2.99, validation loss=2.36] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [03:53<01:08,  1.66it/s, Train Loss=3.23, validation loss=2.34] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [03:53<01:07,  1.66it/s, Train Loss=3.23, validation loss=2.34] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [03:54<01:07,  1.66it/s, Train Loss=2.55, validation loss=2.35] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [03:54<01:07,  1.65it/s, Train Loss=2.55, validation loss=2.35] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [03:54<01:07,  1.65it/s, Train Loss=3.37, validation loss=2.35] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [03:54<01:06,  1.66it/s, Train Loss=3.37, validation loss=2.35] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [03:55<01:06,  1.66it/s, Train Loss=1.6, validation loss=2.36]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [03:55<01:04,  1.68it/s, Train Loss=1.6, validation loss=2.36] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [03:55<01:04,  1.68it/s, Train Loss=2.15, validation loss=2.34] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [03:55<01:04,  1.68it/s, Train Loss=2.15, validation loss=2.34] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [03:56<01:04,  1.68it/s, Train Loss=2.31, validation loss=2.35] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [03:56<01:03,  1.68it/s, Train Loss=2.31, validation loss=2.35] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [03:57<01:03,  1.68it/s, Train Loss=3.08, validation loss=2.35] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [03:57<01:02,  1.69it/s, Train Loss=3.08, validation loss=2.35] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [03:57<01:02,  1.69it/s, Train Loss=1.47, validation loss=2.35] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [03:57<01:02,  1.67it/s, Train Loss=1.47, validation loss=2.35] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [03:58<01:02,  1.67it/s, Train Loss=3.27, validation loss=2.34] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [03:58<01:02,  1.66it/s, Train Loss=3.27, validation loss=2.34] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [03:59<01:02,  1.66it/s, Train Loss=2.39, validation loss=2.37] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [03:59<01:04,  1.59it/s, Train Loss=2.39, validation loss=2.37] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [03:59<01:04,  1.59it/s, Train Loss=3.64, validation loss=2.35] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [03:59<01:05,  1.56it/s, Train Loss=3.64, validation loss=2.35] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:00<01:05,  1.56it/s, Train Loss=2.81, validation loss=2.36] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:00<01:04,  1.57it/s, Train Loss=2.81, validation loss=2.36]####################################################################################################
--------------------------------------------- Epoch:400 ---------------------------------------------
-- Training set:
Loss: 2.013913154602051, Lr: 6.25e-05
Average AUC ROC: 0.52                Average AUC PR: 0.29
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:00<01:04,  1.57it/s, Train Loss=2.01, validation loss=2.35] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:00<01:04,  1.56it/s, Train Loss=2.01, validation loss=2.35]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.3524006828665733
Average AUC ROC: 0.56                    Average AUC PR: 0.31
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:01<01:04,  1.56it/s, Train Loss=2.74, validation loss=2.35] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:01<01:04,  1.54it/s, Train Loss=2.74, validation loss=2.35] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:02<01:04,  1.54it/s, Train Loss=2.18, validation loss=2.34] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:02<01:03,  1.53it/s, Train Loss=2.18, validation loss=2.34] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:02<01:03,  1.53it/s, Train Loss=2.48, validation loss=2.36] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:02<01:03,  1.52it/s, Train Loss=2.48, validation loss=2.36] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:03<01:03,  1.52it/s, Train Loss=2.71, validation loss=2.36] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:03<01:03,  1.52it/s, Train Loss=2.71, validation loss=2.36] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:04<01:03,  1.52it/s, Train Loss=1.71, validation loss=2.35] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:04<01:04,  1.47it/s, Train Loss=1.71, validation loss=2.35] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:04<01:04,  1.47it/s, Train Loss=2.55, validation loss=2.34] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:04<01:02,  1.51it/s, Train Loss=2.55, validation loss=2.34] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:05<01:02,  1.51it/s, Train Loss=2.69, validation loss=2.34] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:05<01:00,  1.53it/s, Train Loss=2.69, validation loss=2.34] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:06<01:00,  1.53it/s, Train Loss=2.75, validation loss=2.35] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:06<01:00,  1.52it/s, Train Loss=2.75, validation loss=2.35] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:06<01:00,  1.52it/s, Train Loss=1.97, validation loss=2.35] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:06<00:59,  1.54it/s, Train Loss=1.97, validation loss=2.35] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:07<00:59,  1.54it/s, Train Loss=2.16, validation loss=2.36] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:07<00:57,  1.57it/s, Train Loss=2.16, validation loss=2.36] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:08<00:57,  1.57it/s, Train Loss=1.37, validation loss=2.34] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:08<00:56,  1.57it/s, Train Loss=1.37, validation loss=2.34] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:08<00:56,  1.57it/s, Train Loss=2.03, validation loss=2.36] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:08<00:55,  1.60it/s, Train Loss=2.03, validation loss=2.36] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:09<00:55,  1.60it/s, Train Loss=2.45, validation loss=2.35] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:09<00:54,  1.60it/s, Train Loss=2.45, validation loss=2.35] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:09<00:54,  1.60it/s, Train Loss=2.54, validation loss=2.36] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:09<00:53,  1.62it/s, Train Loss=2.54, validation loss=2.36] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:10<00:53,  1.62it/s, Train Loss=2.54, validation loss=2.34] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:10<00:53,  1.60it/s, Train Loss=2.54, validation loss=2.34] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:11<00:53,  1.60it/s, Train Loss=1.8, validation loss=2.35]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:11<00:52,  1.59it/s, Train Loss=1.8, validation loss=2.35] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:11<00:52,  1.59it/s, Train Loss=1.59, validation loss=2.36] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:11<00:52,  1.57it/s, Train Loss=1.59, validation loss=2.36] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:12<00:52,  1.57it/s, Train Loss=2.65, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:12<00:52,  1.56it/s, Train Loss=2.65, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:13<00:52,  1.56it/s, Train Loss=2.44, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:13<00:51,  1.56it/s, Train Loss=2.44, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:13<00:51,  1.56it/s, Train Loss=1.91, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:13<00:50,  1.57it/s, Train Loss=1.91, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:14<00:50,  1.57it/s, Train Loss=2.23, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:14<00:50,  1.57it/s, Train Loss=2.23, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:15<00:50,  1.57it/s, Train Loss=2.22, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:15<00:50,  1.55it/s, Train Loss=2.22, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:15<00:50,  1.55it/s, Train Loss=1.85, validation loss=2.35] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:15<00:49,  1.56it/s, Train Loss=1.85, validation loss=2.35] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:16<00:49,  1.56it/s, Train Loss=2.31, validation loss=2.35] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:16<00:48,  1.57it/s, Train Loss=2.31, validation loss=2.35] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:17<00:48,  1.57it/s, Train Loss=2.95, validation loss=2.35] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:17<00:47,  1.57it/s, Train Loss=2.95, validation loss=2.35] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:17<00:47,  1.57it/s, Train Loss=2.05, validation loss=2.34] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:17<00:48,  1.54it/s, Train Loss=2.05, validation loss=2.34] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:18<00:48,  1.54it/s, Train Loss=2.4, validation loss=2.35]  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:18<00:47,  1.55it/s, Train Loss=2.4, validation loss=2.35] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:18<00:47,  1.55it/s, Train Loss=2.5, validation loss=2.37] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:18<00:45,  1.57it/s, Train Loss=2.5, validation loss=2.37] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:19<00:45,  1.57it/s, Train Loss=3.46, validation loss=2.37] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:19<00:46,  1.53it/s, Train Loss=3.46, validation loss=2.37] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:20<00:46,  1.53it/s, Train Loss=1.88, validation loss=2.34] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:20<00:47,  1.49it/s, Train Loss=1.88, validation loss=2.34] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:21<00:47,  1.49it/s, Train Loss=2.87, validation loss=2.35] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:21<00:46,  1.49it/s, Train Loss=2.87, validation loss=2.35] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:21<00:46,  1.49it/s, Train Loss=2.55, validation loss=2.35] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:21<00:45,  1.51it/s, Train Loss=2.55, validation loss=2.35] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:22<00:45,  1.51it/s, Train Loss=2.35, validation loss=2.35] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:22<00:44,  1.51it/s, Train Loss=2.35, validation loss=2.35] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:22<00:44,  1.51it/s, Train Loss=3.66, validation loss=2.34] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:22<00:43,  1.53it/s, Train Loss=3.66, validation loss=2.34] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:23<00:43,  1.53it/s, Train Loss=2.26, validation loss=2.35] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:23<00:42,  1.54it/s, Train Loss=2.26, validation loss=2.35] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:24<00:42,  1.54it/s, Train Loss=2.63, validation loss=2.36] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:24<00:41,  1.53it/s, Train Loss=2.63, validation loss=2.36] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:24<00:41,  1.53it/s, Train Loss=1.59, validation loss=2.35] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:24<00:40,  1.55it/s, Train Loss=1.59, validation loss=2.35] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:25<00:40,  1.55it/s, Train Loss=3, validation loss=2.36]    88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:25<00:39,  1.56it/s, Train Loss=3, validation loss=2.36] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:26<00:39,  1.56it/s, Train Loss=1.13, validation loss=2.37] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:26<00:38,  1.57it/s, Train Loss=1.13, validation loss=2.37] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:26<00:38,  1.57it/s, Train Loss=1.72, validation loss=2.35] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:26<00:38,  1.56it/s, Train Loss=1.72, validation loss=2.35] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:27<00:38,  1.56it/s, Train Loss=2.43, validation loss=2.37] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:27<00:37,  1.57it/s, Train Loss=2.43, validation loss=2.37] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:28<00:37,  1.57it/s, Train Loss=2.06, validation loss=2.35] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:28<00:37,  1.56it/s, Train Loss=2.06, validation loss=2.35] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:28<00:37,  1.56it/s, Train Loss=1.82, validation loss=2.35] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:28<00:36,  1.56it/s, Train Loss=1.82, validation loss=2.35] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:29<00:36,  1.56it/s, Train Loss=2.16, validation loss=2.35] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:29<00:35,  1.57it/s, Train Loss=2.16, validation loss=2.35] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:29<00:35,  1.57it/s, Train Loss=2.08, validation loss=2.36] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:29<00:34,  1.59it/s, Train Loss=2.08, validation loss=2.36] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:30<00:34,  1.59it/s, Train Loss=1.18, validation loss=2.35] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:30<00:33,  1.62it/s, Train Loss=1.18, validation loss=2.35] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:31<00:33,  1.62it/s, Train Loss=1.58, validation loss=2.35] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:31<00:33,  1.60it/s, Train Loss=1.58, validation loss=2.35] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:31<00:33,  1.60it/s, Train Loss=1.9, validation loss=2.33]  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:31<00:33,  1.55it/s, Train Loss=1.9, validation loss=2.33] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:32<00:33,  1.55it/s, Train Loss=1.14, validation loss=2.35] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:32<00:32,  1.57it/s, Train Loss=1.14, validation loss=2.35] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:33<00:32,  1.57it/s, Train Loss=1.55, validation loss=2.35] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:33<00:32,  1.56it/s, Train Loss=1.55, validation loss=2.35] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:33<00:32,  1.56it/s, Train Loss=2.81, validation loss=2.36] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:33<00:31,  1.55it/s, Train Loss=2.81, validation loss=2.36] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:34<00:31,  1.55it/s, Train Loss=1.41, validation loss=2.35] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:34<00:31,  1.53it/s, Train Loss=1.41, validation loss=2.35] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:35<00:31,  1.53it/s, Train Loss=2.05, validation loss=2.33] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:35<00:30,  1.52it/s, Train Loss=2.05, validation loss=2.33] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:35<00:30,  1.52it/s, Train Loss=2.45, validation loss=2.34] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:35<00:29,  1.53it/s, Train Loss=2.45, validation loss=2.34] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:36<00:29,  1.53it/s, Train Loss=2.03, validation loss=2.35] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:36<00:28,  1.56it/s, Train Loss=2.03, validation loss=2.35] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:37<00:28,  1.56it/s, Train Loss=2.61, validation loss=2.36] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:37<00:28,  1.56it/s, Train Loss=2.61, validation loss=2.36] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:37<00:28,  1.56it/s, Train Loss=2.6, validation loss=2.35]  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:37<00:27,  1.58it/s, Train Loss=2.6, validation loss=2.35] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:38<00:27,  1.58it/s, Train Loss=3.74, validation loss=2.36] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:38<00:26,  1.57it/s, Train Loss=3.74, validation loss=2.36] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:38<00:26,  1.57it/s, Train Loss=2.72, validation loss=2.35] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:38<00:26,  1.55it/s, Train Loss=2.72, validation loss=2.35] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:39<00:26,  1.55it/s, Train Loss=2.24, validation loss=2.34] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:39<00:25,  1.57it/s, Train Loss=2.24, validation loss=2.34] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:40<00:25,  1.57it/s, Train Loss=2.62, validation loss=2.35] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:40<00:24,  1.58it/s, Train Loss=2.62, validation loss=2.35] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:40<00:24,  1.58it/s, Train Loss=2.43, validation loss=2.36] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:40<00:23,  1.59it/s, Train Loss=2.43, validation loss=2.36] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:41<00:23,  1.59it/s, Train Loss=1.66, validation loss=2.35] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:41<00:23,  1.60it/s, Train Loss=1.66, validation loss=2.35] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:42<00:23,  1.60it/s, Train Loss=2.67, validation loss=2.35] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:42<00:22,  1.60it/s, Train Loss=2.67, validation loss=2.35] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:42<00:22,  1.60it/s, Train Loss=1.94, validation loss=2.35] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:42<00:22,  1.55it/s, Train Loss=1.94, validation loss=2.35] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:43<00:22,  1.55it/s, Train Loss=2.2, validation loss=2.38]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:43<00:21,  1.57it/s, Train Loss=2.2, validation loss=2.38] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:44<00:21,  1.57it/s, Train Loss=1.59, validation loss=2.34] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [04:44<00:21,  1.53it/s, Train Loss=1.59, validation loss=2.34] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [04:44<00:21,  1.53it/s, Train Loss=3.32, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [04:44<00:20,  1.57it/s, Train Loss=3.32, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [04:45<00:20,  1.57it/s, Train Loss=1.77, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [04:45<00:20,  1.52it/s, Train Loss=1.77, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [04:46<00:20,  1.52it/s, Train Loss=1.47, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [04:46<00:21,  1.41it/s, Train Loss=1.47, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [04:46<00:21,  1.41it/s, Train Loss=2.58, validation loss=2.36] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [04:46<00:20,  1.41it/s, Train Loss=2.58, validation loss=2.36] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [04:47<00:20,  1.41it/s, Train Loss=2.09, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [04:47<00:19,  1.45it/s, Train Loss=2.09, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [04:48<00:19,  1.45it/s, Train Loss=2.3, validation loss=2.34]  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [04:48<00:17,  1.51it/s, Train Loss=2.3, validation loss=2.34] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [04:48<00:17,  1.51it/s, Train Loss=4.64, validation loss=2.35] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [04:48<00:16,  1.54it/s, Train Loss=4.64, validation loss=2.35] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [04:49<00:16,  1.54it/s, Train Loss=2.25, validation loss=2.38] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [04:49<00:16,  1.55it/s, Train Loss=2.25, validation loss=2.38] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [04:50<00:16,  1.55it/s, Train Loss=2.32, validation loss=2.34] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [04:50<00:15,  1.55it/s, Train Loss=2.32, validation loss=2.34] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [04:50<00:15,  1.55it/s, Train Loss=4.59, validation loss=2.34] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [04:50<00:15,  1.53it/s, Train Loss=4.59, validation loss=2.34] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [04:51<00:15,  1.53it/s, Train Loss=1.5, validation loss=2.35]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [04:51<00:14,  1.55it/s, Train Loss=1.5, validation loss=2.35] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [04:52<00:14,  1.55it/s, Train Loss=2.31, validation loss=2.37] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [04:52<00:13,  1.54it/s, Train Loss=2.31, validation loss=2.37] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [04:52<00:13,  1.54it/s, Train Loss=1.72, validation loss=2.35] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [04:52<00:12,  1.56it/s, Train Loss=1.72, validation loss=2.35] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [04:53<00:12,  1.56it/s, Train Loss=1.99, validation loss=2.35] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [04:53<00:12,  1.56it/s, Train Loss=1.99, validation loss=2.35] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [04:53<00:12,  1.56it/s, Train Loss=2.2, validation loss=2.36]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [04:53<00:11,  1.56it/s, Train Loss=2.2, validation loss=2.36] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [04:54<00:11,  1.56it/s, Train Loss=1.99, validation loss=2.36] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [04:54<00:10,  1.57it/s, Train Loss=1.99, validation loss=2.36] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [04:55<00:10,  1.57it/s, Train Loss=1.37, validation loss=2.35] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [04:55<00:10,  1.51it/s, Train Loss=1.37, validation loss=2.35] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [04:55<00:10,  1.51it/s, Train Loss=2.58, validation loss=2.35] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [04:55<00:09,  1.54it/s, Train Loss=2.58, validation loss=2.35] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [04:56<00:09,  1.54it/s, Train Loss=2.39, validation loss=2.35] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [04:56<00:08,  1.56it/s, Train Loss=2.39, validation loss=2.35] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [04:57<00:08,  1.56it/s, Train Loss=1.93, validation loss=2.35] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [04:57<00:08,  1.57it/s, Train Loss=1.93, validation loss=2.35] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [04:57<00:08,  1.57it/s, Train Loss=1.82, validation loss=2.36] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [04:57<00:07,  1.58it/s, Train Loss=1.82, validation loss=2.36] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [04:58<00:07,  1.58it/s, Train Loss=2.83, validation loss=2.34] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [04:58<00:06,  1.59it/s, Train Loss=2.83, validation loss=2.34] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [04:59<00:06,  1.59it/s, Train Loss=2.5, validation loss=2.34]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [04:59<00:06,  1.58it/s, Train Loss=2.5, validation loss=2.34] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [04:59<00:06,  1.58it/s, Train Loss=2.2, validation loss=2.35] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [04:59<00:05,  1.60it/s, Train Loss=2.2, validation loss=2.35] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:00<00:05,  1.60it/s, Train Loss=3.44, validation loss=2.34] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:00<00:05,  1.54it/s, Train Loss=3.44, validation loss=2.34] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:00<00:05,  1.54it/s, Train Loss=2.56, validation loss=2.34] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:00<00:04,  1.55it/s, Train Loss=2.56, validation loss=2.34] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:01<00:04,  1.55it/s, Train Loss=2.1, validation loss=2.35]  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:01<00:03,  1.56it/s, Train Loss=2.1, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:02<00:03,  1.56it/s, Train Loss=3.58, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:02<00:03,  1.53it/s, Train Loss=3.58, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:02<00:03,  1.53it/s, Train Loss=2.21, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:02<00:02,  1.54it/s, Train Loss=2.21, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:03<00:02,  1.54it/s, Train Loss=1.54, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:03<00:01,  1.56it/s, Train Loss=1.54, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:04<00:01,  1.56it/s, Train Loss=1.88, validation loss=2.36]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:04<00:01,  1.56it/s, Train Loss=1.88, validation loss=2.36]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:04<00:01,  1.56it/s, Train Loss=1.43, validation loss=2.34]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:04<00:00,  1.56it/s, Train Loss=1.43, validation loss=2.34]####################################################################################################
--------------------------------------------- Epoch:500 ---------------------------------------------
-- Training set:
Loss: 2.040360689163208, Lr: 3.125e-05
Average AUC ROC: 0.52                Average AUC PR: 0.29
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:05<00:00,  1.56it/s, Train Loss=2.04, validation loss=2.33]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:05<00:00,  1.56it/s, Train Loss=2.04, validation loss=2.33]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:05<00:00,  1.64it/s, Train Loss=2.04, validation loss=2.33]
----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.3297343626618385
Average AUC ROC: 0.56                    Average AUC PR: 0.31

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 191
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=0, validation loss=0]  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=3.63, validation loss=3.28]  0%|          | 1/500 [00:00<05:09,  1.61it/s, Train Loss=3.63, validation loss=3.28]  0%|          | 1/500 [00:01<05:09,  1.61it/s, Train Loss=3.5, validation loss=3.06]   0%|          | 2/500 [00:01<05:10,  1.60it/s, Train Loss=3.5, validation loss=3.06]  0%|          | 2/500 [00:01<05:10,  1.60it/s, Train Loss=3.93, validation loss=2.91]  1%|          | 3/500 [00:01<05:02,  1.64it/s, Train Loss=3.93, validation loss=2.91]  1%|          | 3/500 [00:02<05:02,  1.64it/s, Train Loss=2.66, validation loss=2.81]  1%|          | 4/500 [00:02<05:01,  1.65it/s, Train Loss=2.66, validation loss=2.81]  1%|          | 4/500 [00:03<05:01,  1.65it/s, Train Loss=2, validation loss=2.75]     1%|          | 5/500 [00:03<05:13,  1.58it/s, Train Loss=2, validation loss=2.75]  1%|          | 5/500 [00:03<05:13,  1.58it/s, Train Loss=2.63, validation loss=2.71]  1%|          | 6/500 [00:03<05:08,  1.60it/s, Train Loss=2.63, validation loss=2.71]  1%|          | 6/500 [00:04<05:08,  1.60it/s, Train Loss=2.93, validation loss=2.67]  1%|â–         | 7/500 [00:04<05:07,  1.60it/s, Train Loss=2.93, validation loss=2.67]  1%|â–         | 7/500 [00:05<05:07,  1.60it/s, Train Loss=5.53, validation loss=2.66]  2%|â–         | 8/500 [00:05<05:33,  1.47it/s, Train Loss=5.53, validation loss=2.66]  2%|â–         | 8/500 [00:05<05:33,  1.47it/s, Train Loss=3.7, validation loss=2.68]   2%|â–         | 9/500 [00:05<05:42,  1.43it/s, Train Loss=3.7, validation loss=2.68]  2%|â–         | 9/500 [00:06<05:42,  1.43it/s, Train Loss=2.2, validation loss=2.65]  2%|â–         | 10/500 [00:06<05:33,  1.47it/s, Train Loss=2.2, validation loss=2.65]  2%|â–         | 10/500 [00:07<05:33,  1.47it/s, Train Loss=1.43, validation loss=2.65]  2%|â–         | 11/500 [00:07<05:24,  1.51it/s, Train Loss=1.43, validation loss=2.65]  2%|â–         | 11/500 [00:07<05:24,  1.51it/s, Train Loss=2.74, validation loss=2.67]  2%|â–         | 12/500 [00:07<05:23,  1.51it/s, Train Loss=2.74, validation loss=2.67]  2%|â–         | 12/500 [00:08<05:23,  1.51it/s, Train Loss=2.41, validation loss=2.67]  3%|â–         | 13/500 [00:08<05:16,  1.54it/s, Train Loss=2.41, validation loss=2.67]  3%|â–         | 13/500 [00:09<05:16,  1.54it/s, Train Loss=4.63, validation loss=2.69]  3%|â–         | 14/500 [00:09<05:12,  1.56it/s, Train Loss=4.63, validation loss=2.69]  3%|â–         | 14/500 [00:09<05:12,  1.56it/s, Train Loss=4.67, validation loss=2.69]  3%|â–         | 15/500 [00:09<05:24,  1.49it/s, Train Loss=4.67, validation loss=2.69]  3%|â–         | 15/500 [00:10<05:24,  1.49it/s, Train Loss=3.03, validation loss=2.69]  3%|â–         | 16/500 [00:10<05:11,  1.55it/s, Train Loss=3.03, validation loss=2.69]  3%|â–         | 16/500 [00:11<05:11,  1.55it/s, Train Loss=2.73, validation loss=2.72]  3%|â–         | 17/500 [00:11<05:11,  1.55it/s, Train Loss=2.73, validation loss=2.72]  3%|â–         | 17/500 [00:11<05:11,  1.55it/s, Train Loss=1.93, validation loss=2.69]  4%|â–         | 18/500 [00:11<05:04,  1.58it/s, Train Loss=1.93, validation loss=2.69]  4%|â–         | 18/500 [00:12<05:04,  1.58it/s, Train Loss=4.32, validation loss=2.66]  4%|â–         | 19/500 [00:12<05:13,  1.53it/s, Train Loss=4.32, validation loss=2.66]  4%|â–         | 19/500 [00:12<05:13,  1.53it/s, Train Loss=3.24, validation loss=2.67]  4%|â–         | 20/500 [00:12<05:13,  1.53it/s, Train Loss=3.24, validation loss=2.67]  4%|â–         | 20/500 [00:13<05:13,  1.53it/s, Train Loss=4.45, validation loss=2.65]  4%|â–         | 21/500 [00:13<05:12,  1.53it/s, Train Loss=4.45, validation loss=2.65]  4%|â–         | 21/500 [00:14<05:12,  1.53it/s, Train Loss=2.84, validation loss=2.67]  4%|â–         | 22/500 [00:14<05:04,  1.57it/s, Train Loss=2.84, validation loss=2.67]  4%|â–         | 22/500 [00:14<05:04,  1.57it/s, Train Loss=2.07, validation loss=2.66]  5%|â–         | 23/500 [00:14<05:00,  1.59it/s, Train Loss=2.07, validation loss=2.66]  5%|â–         | 23/500 [00:15<05:00,  1.59it/s, Train Loss=1.96, validation loss=2.66]  5%|â–         | 24/500 [00:15<04:56,  1.61it/s, Train Loss=1.96, validation loss=2.66]  5%|â–         | 24/500 [00:16<04:56,  1.61it/s, Train Loss=4.5, validation loss=2.64]   5%|â–Œ         | 25/500 [00:16<04:57,  1.60it/s, Train Loss=4.5, validation loss=2.64]  5%|â–Œ         | 25/500 [00:16<04:57,  1.60it/s, Train Loss=3.62, validation loss=2.64]  5%|â–Œ         | 26/500 [00:16<05:09,  1.53it/s, Train Loss=3.62, validation loss=2.64]  5%|â–Œ         | 26/500 [00:17<05:09,  1.53it/s, Train Loss=2.16, validation loss=2.63]  5%|â–Œ         | 27/500 [00:17<05:05,  1.55it/s, Train Loss=2.16, validation loss=2.63]  5%|â–Œ         | 27/500 [00:18<05:05,  1.55it/s, Train Loss=2.3, validation loss=2.62]   6%|â–Œ         | 28/500 [00:18<05:04,  1.55it/s, Train Loss=2.3, validation loss=2.62]  6%|â–Œ         | 28/500 [00:18<05:04,  1.55it/s, Train Loss=1.82, validation loss=2.64]  6%|â–Œ         | 29/500 [00:18<04:57,  1.58it/s, Train Loss=1.82, validation loss=2.64]  6%|â–Œ         | 29/500 [00:19<04:57,  1.58it/s, Train Loss=2.84, validation loss=2.62]  6%|â–Œ         | 30/500 [00:19<05:03,  1.55it/s, Train Loss=2.84, validation loss=2.62]  6%|â–Œ         | 30/500 [00:19<05:03,  1.55it/s, Train Loss=2.29, validation loss=2.63]  6%|â–Œ         | 31/500 [00:19<05:01,  1.56it/s, Train Loss=2.29, validation loss=2.63]  6%|â–Œ         | 31/500 [00:20<05:01,  1.56it/s, Train Loss=1.66, validation loss=2.64]  6%|â–‹         | 32/500 [00:20<05:00,  1.56it/s, Train Loss=1.66, validation loss=2.64]  6%|â–‹         | 32/500 [00:21<05:00,  1.56it/s, Train Loss=3.23, validation loss=2.63]  7%|â–‹         | 33/500 [00:21<05:06,  1.52it/s, Train Loss=3.23, validation loss=2.63]  7%|â–‹         | 33/500 [00:21<05:06,  1.52it/s, Train Loss=1.67, validation loss=2.63]  7%|â–‹         | 34/500 [00:21<05:02,  1.54it/s, Train Loss=1.67, validation loss=2.63]  7%|â–‹         | 34/500 [00:22<05:02,  1.54it/s, Train Loss=2.86, validation loss=2.63]  7%|â–‹         | 35/500 [00:22<04:58,  1.56it/s, Train Loss=2.86, validation loss=2.63]  7%|â–‹         | 35/500 [00:23<04:58,  1.56it/s, Train Loss=2.99, validation loss=2.62]  7%|â–‹         | 36/500 [00:23<04:53,  1.58it/s, Train Loss=2.99, validation loss=2.62]  7%|â–‹         | 36/500 [00:23<04:53,  1.58it/s, Train Loss=2.52, validation loss=2.62]  7%|â–‹         | 37/500 [00:23<04:49,  1.60it/s, Train Loss=2.52, validation loss=2.62]  7%|â–‹         | 37/500 [00:24<04:49,  1.60it/s, Train Loss=2.58, validation loss=2.64]  8%|â–Š         | 38/500 [00:24<04:45,  1.62it/s, Train Loss=2.58, validation loss=2.64]  8%|â–Š         | 38/500 [00:25<04:45,  1.62it/s, Train Loss=2.41, validation loss=2.62]  8%|â–Š         | 39/500 [00:25<04:46,  1.61it/s, Train Loss=2.41, validation loss=2.62]  8%|â–Š         | 39/500 [00:25<04:46,  1.61it/s, Train Loss=2.56, validation loss=2.62]  8%|â–Š         | 40/500 [00:25<04:57,  1.55it/s, Train Loss=2.56, validation loss=2.62]  8%|â–Š         | 40/500 [00:26<04:57,  1.55it/s, Train Loss=2.92, validation loss=2.6]   8%|â–Š         | 41/500 [00:26<04:53,  1.56it/s, Train Loss=2.92, validation loss=2.6]  8%|â–Š         | 41/500 [00:26<04:53,  1.56it/s, Train Loss=1.9, validation loss=2.6]   8%|â–Š         | 42/500 [00:26<04:51,  1.57it/s, Train Loss=1.9, validation loss=2.6]  8%|â–Š         | 42/500 [00:27<04:51,  1.57it/s, Train Loss=2.3, validation loss=2.58]  9%|â–Š         | 43/500 [00:27<04:52,  1.56it/s, Train Loss=2.3, validation loss=2.58]  9%|â–Š         | 43/500 [00:28<04:52,  1.56it/s, Train Loss=2.34, validation loss=2.61]  9%|â–‰         | 44/500 [00:28<04:57,  1.53it/s, Train Loss=2.34, validation loss=2.61]  9%|â–‰         | 44/500 [00:28<04:57,  1.53it/s, Train Loss=4.04, validation loss=2.58]  9%|â–‰         | 45/500 [00:28<04:52,  1.56it/s, Train Loss=4.04, validation loss=2.58]  9%|â–‰         | 45/500 [00:29<04:52,  1.56it/s, Train Loss=3.13, validation loss=2.55]  9%|â–‰         | 46/500 [00:29<04:44,  1.60it/s, Train Loss=3.13, validation loss=2.55]  9%|â–‰         | 46/500 [00:30<04:44,  1.60it/s, Train Loss=1.6, validation loss=2.59]   9%|â–‰         | 47/500 [00:30<05:05,  1.48it/s, Train Loss=1.6, validation loss=2.59]  9%|â–‰         | 47/500 [00:31<05:05,  1.48it/s, Train Loss=3.76, validation loss=2.56] 10%|â–‰         | 48/500 [00:31<05:09,  1.46it/s, Train Loss=3.76, validation loss=2.56] 10%|â–‰         | 48/500 [00:31<05:09,  1.46it/s, Train Loss=2.88, validation loss=2.57] 10%|â–‰         | 49/500 [00:31<05:01,  1.50it/s, Train Loss=2.88, validation loss=2.57] 10%|â–‰         | 49/500 [00:32<05:01,  1.50it/s, Train Loss=2.31, validation loss=2.54] 10%|â–ˆ         | 50/500 [00:32<04:53,  1.53it/s, Train Loss=2.31, validation loss=2.54] 10%|â–ˆ         | 50/500 [00:32<04:53,  1.53it/s, Train Loss=3.57, validation loss=2.53] 10%|â–ˆ         | 51/500 [00:32<04:49,  1.55it/s, Train Loss=3.57, validation loss=2.53] 10%|â–ˆ         | 51/500 [00:33<04:49,  1.55it/s, Train Loss=2.09, validation loss=2.57] 10%|â–ˆ         | 52/500 [00:33<04:45,  1.57it/s, Train Loss=2.09, validation loss=2.57] 10%|â–ˆ         | 52/500 [00:34<04:45,  1.57it/s, Train Loss=4.7, validation loss=2.57]  11%|â–ˆ         | 53/500 [00:34<04:40,  1.59it/s, Train Loss=4.7, validation loss=2.57] 11%|â–ˆ         | 53/500 [00:34<04:40,  1.59it/s, Train Loss=2.66, validation loss=2.57] 11%|â–ˆ         | 54/500 [00:34<04:41,  1.58it/s, Train Loss=2.66, validation loss=2.57] 11%|â–ˆ         | 54/500 [00:35<04:41,  1.58it/s, Train Loss=1.64, validation loss=2.58] 11%|â–ˆ         | 55/500 [00:35<04:50,  1.53it/s, Train Loss=1.64, validation loss=2.58] 11%|â–ˆ         | 55/500 [00:36<04:50,  1.53it/s, Train Loss=2.47, validation loss=2.54] 11%|â–ˆ         | 56/500 [00:36<04:45,  1.56it/s, Train Loss=2.47, validation loss=2.54] 11%|â–ˆ         | 56/500 [00:36<04:45,  1.56it/s, Train Loss=3.73, validation loss=2.56] 11%|â–ˆâ–        | 57/500 [00:36<04:37,  1.59it/s, Train Loss=3.73, validation loss=2.56] 11%|â–ˆâ–        | 57/500 [00:37<04:37,  1.59it/s, Train Loss=2.08, validation loss=2.54] 12%|â–ˆâ–        | 58/500 [00:37<04:40,  1.58it/s, Train Loss=2.08, validation loss=2.54] 12%|â–ˆâ–        | 58/500 [00:37<04:40,  1.58it/s, Train Loss=2.65, validation loss=2.55] 12%|â–ˆâ–        | 59/500 [00:37<04:36,  1.59it/s, Train Loss=2.65, validation loss=2.55] 12%|â–ˆâ–        | 59/500 [00:38<04:36,  1.59it/s, Train Loss=3.14, validation loss=2.57] 12%|â–ˆâ–        | 60/500 [00:38<04:33,  1.61it/s, Train Loss=3.14, validation loss=2.57] 12%|â–ˆâ–        | 60/500 [00:39<04:33,  1.61it/s, Train Loss=3.02, validation loss=2.54] 12%|â–ˆâ–        | 61/500 [00:39<04:31,  1.62it/s, Train Loss=3.02, validation loss=2.54] 12%|â–ˆâ–        | 61/500 [00:39<04:31,  1.62it/s, Train Loss=3.61, validation loss=2.53] 12%|â–ˆâ–        | 62/500 [00:39<04:44,  1.54it/s, Train Loss=3.61, validation loss=2.53] 12%|â–ˆâ–        | 62/500 [00:40<04:44,  1.54it/s, Train Loss=2.59, validation loss=2.55] 13%|â–ˆâ–        | 63/500 [00:40<04:45,  1.53it/s, Train Loss=2.59, validation loss=2.55] 13%|â–ˆâ–        | 63/500 [00:41<04:45,  1.53it/s, Train Loss=3.59, validation loss=2.56] 13%|â–ˆâ–        | 64/500 [00:41<04:42,  1.55it/s, Train Loss=3.59, validation loss=2.56] 13%|â–ˆâ–        | 64/500 [00:41<04:42,  1.55it/s, Train Loss=2.29, validation loss=2.55] 13%|â–ˆâ–        | 65/500 [00:41<04:36,  1.57it/s, Train Loss=2.29, validation loss=2.55] 13%|â–ˆâ–        | 65/500 [00:42<04:36,  1.57it/s, Train Loss=2.03, validation loss=2.53] 13%|â–ˆâ–        | 66/500 [00:42<04:35,  1.57it/s, Train Loss=2.03, validation loss=2.53] 13%|â–ˆâ–        | 66/500 [00:42<04:35,  1.57it/s, Train Loss=2.24, validation loss=2.54] 13%|â–ˆâ–        | 67/500 [00:42<04:28,  1.62it/s, Train Loss=2.24, validation loss=2.54] 13%|â–ˆâ–        | 67/500 [00:43<04:28,  1.62it/s, Train Loss=2.75, validation loss=2.53] 14%|â–ˆâ–        | 68/500 [00:43<04:29,  1.60it/s, Train Loss=2.75, validation loss=2.53] 14%|â–ˆâ–        | 68/500 [00:44<04:29,  1.60it/s, Train Loss=3.45, validation loss=2.54] 14%|â–ˆâ–        | 69/500 [00:44<04:37,  1.55it/s, Train Loss=3.45, validation loss=2.54] 14%|â–ˆâ–        | 69/500 [00:44<04:37,  1.55it/s, Train Loss=2.03, validation loss=2.54] 14%|â–ˆâ–        | 70/500 [00:44<04:31,  1.58it/s, Train Loss=2.03, validation loss=2.54] 14%|â–ˆâ–        | 70/500 [00:45<04:31,  1.58it/s, Train Loss=3.05, validation loss=2.53] 14%|â–ˆâ–        | 71/500 [00:45<04:31,  1.58it/s, Train Loss=3.05, validation loss=2.53] 14%|â–ˆâ–        | 71/500 [00:46<04:31,  1.58it/s, Train Loss=2.71, validation loss=2.53] 14%|â–ˆâ–        | 72/500 [00:46<04:33,  1.57it/s, Train Loss=2.71, validation loss=2.53] 14%|â–ˆâ–        | 72/500 [00:46<04:33,  1.57it/s, Train Loss=2.52, validation loss=2.53] 15%|â–ˆâ–        | 73/500 [00:46<04:33,  1.56it/s, Train Loss=2.52, validation loss=2.53] 15%|â–ˆâ–        | 73/500 [00:47<04:33,  1.56it/s, Train Loss=2.21, validation loss=2.52] 15%|â–ˆâ–        | 74/500 [00:47<04:31,  1.57it/s, Train Loss=2.21, validation loss=2.52] 15%|â–ˆâ–        | 74/500 [00:48<04:31,  1.57it/s, Train Loss=2.43, validation loss=2.52] 15%|â–ˆâ–Œ        | 75/500 [00:48<04:33,  1.55it/s, Train Loss=2.43, validation loss=2.52] 15%|â–ˆâ–Œ        | 75/500 [00:48<04:33,  1.55it/s, Train Loss=4.16, validation loss=2.54] 15%|â–ˆâ–Œ        | 76/500 [00:48<04:42,  1.50it/s, Train Loss=4.16, validation loss=2.54] 15%|â–ˆâ–Œ        | 76/500 [00:49<04:42,  1.50it/s, Train Loss=1.96, validation loss=2.53] 15%|â–ˆâ–Œ        | 77/500 [00:49<04:37,  1.52it/s, Train Loss=1.96, validation loss=2.53] 15%|â–ˆâ–Œ        | 77/500 [00:50<04:37,  1.52it/s, Train Loss=2.81, validation loss=2.51] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:33,  1.54it/s, Train Loss=2.81, validation loss=2.51] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:33,  1.54it/s, Train Loss=2.33, validation loss=2.5]  16%|â–ˆâ–Œ        | 79/500 [00:50<04:38,  1.51it/s, Train Loss=2.33, validation loss=2.5] 16%|â–ˆâ–Œ        | 79/500 [00:51<04:38,  1.51it/s, Train Loss=2.28, validation loss=2.48] 16%|â–ˆâ–Œ        | 80/500 [00:51<04:47,  1.46it/s, Train Loss=2.28, validation loss=2.48] 16%|â–ˆâ–Œ        | 80/500 [00:52<04:47,  1.46it/s, Train Loss=3.9, validation loss=2.5]   16%|â–ˆâ–Œ        | 81/500 [00:52<04:41,  1.49it/s, Train Loss=3.9, validation loss=2.5] 16%|â–ˆâ–Œ        | 81/500 [00:52<04:41,  1.49it/s, Train Loss=2.93, validation loss=2.47] 16%|â–ˆâ–‹        | 82/500 [00:52<04:52,  1.43it/s, Train Loss=2.93, validation loss=2.47] 16%|â–ˆâ–‹        | 82/500 [00:53<04:52,  1.43it/s, Train Loss=2.7, validation loss=2.49]  17%|â–ˆâ–‹        | 83/500 [00:53<04:41,  1.48it/s, Train Loss=2.7, validation loss=2.49] 17%|â–ˆâ–‹        | 83/500 [00:54<04:41,  1.48it/s, Train Loss=1.97, validation loss=2.5] 17%|â–ˆâ–‹        | 84/500 [00:54<04:36,  1.51it/s, Train Loss=1.97, validation loss=2.5] 17%|â–ˆâ–‹        | 84/500 [00:54<04:36,  1.51it/s, Train Loss=2.92, validation loss=2.49] 17%|â–ˆâ–‹        | 85/500 [00:54<04:26,  1.55it/s, Train Loss=2.92, validation loss=2.49] 17%|â–ˆâ–‹        | 85/500 [00:55<04:26,  1.55it/s, Train Loss=2.69, validation loss=2.5]  17%|â–ˆâ–‹        | 86/500 [00:55<04:28,  1.54it/s, Train Loss=2.69, validation loss=2.5] 17%|â–ˆâ–‹        | 86/500 [00:56<04:28,  1.54it/s, Train Loss=2.06, validation loss=2.5] 17%|â–ˆâ–‹        | 87/500 [00:56<04:21,  1.58it/s, Train Loss=2.06, validation loss=2.5] 17%|â–ˆâ–‹        | 87/500 [00:56<04:21,  1.58it/s, Train Loss=2.93, validation loss=2.5] 18%|â–ˆâ–Š        | 88/500 [00:56<04:18,  1.59it/s, Train Loss=2.93, validation loss=2.5] 18%|â–ˆâ–Š        | 88/500 [00:57<04:18,  1.59it/s, Train Loss=1.61, validation loss=2.5] 18%|â–ˆâ–Š        | 89/500 [00:57<04:26,  1.54it/s, Train Loss=1.61, validation loss=2.5] 18%|â–ˆâ–Š        | 89/500 [00:58<04:26,  1.54it/s, Train Loss=1.92, validation loss=2.5] 18%|â–ˆâ–Š        | 90/500 [00:58<04:22,  1.56it/s, Train Loss=1.92, validation loss=2.5] 18%|â–ˆâ–Š        | 90/500 [00:58<04:22,  1.56it/s, Train Loss=2.86, validation loss=2.49] 18%|â–ˆâ–Š        | 91/500 [00:58<04:16,  1.59it/s, Train Loss=2.86, validation loss=2.49] 18%|â–ˆâ–Š        | 91/500 [00:59<04:16,  1.59it/s, Train Loss=3.06, validation loss=2.49] 18%|â–ˆâ–Š        | 92/500 [00:59<04:12,  1.62it/s, Train Loss=3.06, validation loss=2.49] 18%|â–ˆâ–Š        | 92/500 [00:59<04:12,  1.62it/s, Train Loss=3, validation loss=2.48]    19%|â–ˆâ–Š        | 93/500 [00:59<04:13,  1.61it/s, Train Loss=3, validation loss=2.48] 19%|â–ˆâ–Š        | 93/500 [01:00<04:13,  1.61it/s, Train Loss=1.88, validation loss=2.48] 19%|â–ˆâ–‰        | 94/500 [01:00<04:11,  1.62it/s, Train Loss=1.88, validation loss=2.48] 19%|â–ˆâ–‰        | 94/500 [01:01<04:11,  1.62it/s, Train Loss=2.38, validation loss=2.49] 19%|â–ˆâ–‰        | 95/500 [01:01<04:10,  1.61it/s, Train Loss=2.38, validation loss=2.49] 19%|â–ˆâ–‰        | 95/500 [01:01<04:10,  1.61it/s, Train Loss=3.23, validation loss=2.47] 19%|â–ˆâ–‰        | 96/500 [01:01<04:10,  1.61it/s, Train Loss=3.23, validation loss=2.47] 19%|â–ˆâ–‰        | 96/500 [01:02<04:10,  1.61it/s, Train Loss=1.63, validation loss=2.48] 19%|â–ˆâ–‰        | 97/500 [01:02<04:08,  1.62it/s, Train Loss=1.63, validation loss=2.48] 19%|â–ˆâ–‰        | 97/500 [01:02<04:08,  1.62it/s, Train Loss=2.09, validation loss=2.47] 20%|â–ˆâ–‰        | 98/500 [01:02<04:16,  1.57it/s, Train Loss=2.09, validation loss=2.47] 20%|â–ˆâ–‰        | 98/500 [01:03<04:16,  1.57it/s, Train Loss=1.65, validation loss=2.48] 20%|â–ˆâ–‰        | 99/500 [01:03<04:13,  1.58it/s, Train Loss=1.65, validation loss=2.48]####################################################################################################
--------------------------------------------- Epoch:100 ---------------------------------------------
-- Training set:
Loss: 1.6529027223587036, Lr: 0.0005
Average AUC ROC: 0.52                Average AUC PR: 0.3
 20%|â–ˆâ–‰        | 99/500 [01:04<04:13,  1.58it/s, Train Loss=1.65, validation loss=2.49] 20%|â–ˆâ–ˆ        | 100/500 [01:04<04:13,  1.58it/s, Train Loss=1.65, validation loss=2.49]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.4897162169218063
Average AUC ROC: 0.57                    Average AUC PR: 0.33
 20%|â–ˆâ–ˆ        | 100/500 [01:04<04:13,  1.58it/s, Train Loss=2.12, validation loss=2.48] 20%|â–ˆâ–ˆ        | 101/500 [01:04<04:10,  1.59it/s, Train Loss=2.12, validation loss=2.48] 20%|â–ˆâ–ˆ        | 101/500 [01:05<04:10,  1.59it/s, Train Loss=2.79, validation loss=2.49] 20%|â–ˆâ–ˆ        | 102/500 [01:05<04:08,  1.60it/s, Train Loss=2.79, validation loss=2.49] 20%|â–ˆâ–ˆ        | 102/500 [01:06<04:08,  1.60it/s, Train Loss=2.24, validation loss=2.48] 21%|â–ˆâ–ˆ        | 103/500 [01:06<04:07,  1.61it/s, Train Loss=2.24, validation loss=2.48] 21%|â–ˆâ–ˆ        | 103/500 [01:06<04:07,  1.61it/s, Train Loss=1.55, validation loss=2.47] 21%|â–ˆâ–ˆ        | 104/500 [01:06<04:06,  1.61it/s, Train Loss=1.55, validation loss=2.47] 21%|â–ˆâ–ˆ        | 104/500 [01:07<04:06,  1.61it/s, Train Loss=3.78, validation loss=2.46] 21%|â–ˆâ–ˆ        | 105/500 [01:07<04:02,  1.63it/s, Train Loss=3.78, validation loss=2.46] 21%|â–ˆâ–ˆ        | 105/500 [01:08<04:02,  1.63it/s, Train Loss=1.14, validation loss=2.47] 21%|â–ˆâ–ˆ        | 106/500 [01:08<04:12,  1.56it/s, Train Loss=1.14, validation loss=2.47] 21%|â–ˆâ–ˆ        | 106/500 [01:08<04:12,  1.56it/s, Train Loss=2.42, validation loss=2.46] 21%|â–ˆâ–ˆâ–       | 107/500 [01:08<04:08,  1.58it/s, Train Loss=2.42, validation loss=2.46] 21%|â–ˆâ–ˆâ–       | 107/500 [01:09<04:08,  1.58it/s, Train Loss=2.99, validation loss=2.47] 22%|â–ˆâ–ˆâ–       | 108/500 [01:09<04:04,  1.60it/s, Train Loss=2.99, validation loss=2.47] 22%|â–ˆâ–ˆâ–       | 108/500 [01:09<04:04,  1.60it/s, Train Loss=2.99, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 109/500 [01:09<04:03,  1.60it/s, Train Loss=2.99, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 109/500 [01:10<04:03,  1.60it/s, Train Loss=1.92, validation loss=2.47] 22%|â–ˆâ–ˆâ–       | 110/500 [01:10<04:03,  1.60it/s, Train Loss=1.92, validation loss=2.47] 22%|â–ˆâ–ˆâ–       | 110/500 [01:11<04:03,  1.60it/s, Train Loss=4.27, validation loss=2.47] 22%|â–ˆâ–ˆâ–       | 111/500 [01:11<04:06,  1.58it/s, Train Loss=4.27, validation loss=2.47] 22%|â–ˆâ–ˆâ–       | 111/500 [01:11<04:06,  1.58it/s, Train Loss=3.61, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 112/500 [01:11<04:18,  1.50it/s, Train Loss=3.61, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 112/500 [01:12<04:18,  1.50it/s, Train Loss=3.51, validation loss=2.47] 23%|â–ˆâ–ˆâ–       | 113/500 [01:12<04:07,  1.57it/s, Train Loss=3.51, validation loss=2.47] 23%|â–ˆâ–ˆâ–       | 113/500 [01:13<04:07,  1.57it/s, Train Loss=3.23, validation loss=2.47] 23%|â–ˆâ–ˆâ–       | 114/500 [01:13<04:13,  1.52it/s, Train Loss=3.23, validation loss=2.47] 23%|â–ˆâ–ˆâ–       | 114/500 [01:13<04:13,  1.52it/s, Train Loss=1.88, validation loss=2.46] 23%|â–ˆâ–ˆâ–       | 115/500 [01:13<04:09,  1.54it/s, Train Loss=1.88, validation loss=2.46] 23%|â–ˆâ–ˆâ–       | 115/500 [01:14<04:09,  1.54it/s, Train Loss=3.57, validation loss=2.48] 23%|â–ˆâ–ˆâ–       | 116/500 [01:14<04:05,  1.57it/s, Train Loss=3.57, validation loss=2.48] 23%|â–ˆâ–ˆâ–       | 116/500 [01:14<04:05,  1.57it/s, Train Loss=2.24, validation loss=2.47] 23%|â–ˆâ–ˆâ–       | 117/500 [01:14<04:01,  1.59it/s, Train Loss=2.24, validation loss=2.47] 23%|â–ˆâ–ˆâ–       | 117/500 [01:15<04:01,  1.59it/s, Train Loss=1.91, validation loss=2.46] 24%|â–ˆâ–ˆâ–       | 118/500 [01:15<04:00,  1.59it/s, Train Loss=1.91, validation loss=2.46] 24%|â–ˆâ–ˆâ–       | 118/500 [01:16<04:00,  1.59it/s, Train Loss=1.68, validation loss=2.47] 24%|â–ˆâ–ˆâ–       | 119/500 [01:16<03:59,  1.59it/s, Train Loss=1.68, validation loss=2.47] 24%|â–ˆâ–ˆâ–       | 119/500 [01:16<03:59,  1.59it/s, Train Loss=1.82, validation loss=2.46] 24%|â–ˆâ–ˆâ–       | 120/500 [01:16<03:54,  1.62it/s, Train Loss=1.82, validation loss=2.46] 24%|â–ˆâ–ˆâ–       | 120/500 [01:17<03:54,  1.62it/s, Train Loss=2.93, validation loss=2.45] 24%|â–ˆâ–ˆâ–       | 121/500 [01:17<03:51,  1.64it/s, Train Loss=2.93, validation loss=2.45] 24%|â–ˆâ–ˆâ–       | 121/500 [01:18<03:51,  1.64it/s, Train Loss=2.27, validation loss=2.45] 24%|â–ˆâ–ˆâ–       | 122/500 [01:18<03:59,  1.58it/s, Train Loss=2.27, validation loss=2.45] 24%|â–ˆâ–ˆâ–       | 122/500 [01:18<03:59,  1.58it/s, Train Loss=1.69, validation loss=2.45] 25%|â–ˆâ–ˆâ–       | 123/500 [01:18<03:58,  1.58it/s, Train Loss=1.69, validation loss=2.45] 25%|â–ˆâ–ˆâ–       | 123/500 [01:19<03:58,  1.58it/s, Train Loss=1.49, validation loss=2.46] 25%|â–ˆâ–ˆâ–       | 124/500 [01:19<03:58,  1.58it/s, Train Loss=1.49, validation loss=2.46] 25%|â–ˆâ–ˆâ–       | 124/500 [01:20<03:58,  1.58it/s, Train Loss=1.79, validation loss=2.47] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:20<03:56,  1.59it/s, Train Loss=1.79, validation loss=2.47] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:20<03:56,  1.59it/s, Train Loss=3.2, validation loss=2.46]  25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:20<03:59,  1.56it/s, Train Loss=3.2, validation loss=2.46] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:21<03:59,  1.56it/s, Train Loss=2.92, validation loss=2.46] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:21<03:56,  1.58it/s, Train Loss=2.92, validation loss=2.46] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:21<03:56,  1.58it/s, Train Loss=3.51, validation loss=2.45] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:21<03:53,  1.59it/s, Train Loss=3.51, validation loss=2.45] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:22<03:53,  1.59it/s, Train Loss=1.9, validation loss=2.46]  26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:22<03:51,  1.60it/s, Train Loss=1.9, validation loss=2.46] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:23<03:51,  1.60it/s, Train Loss=2.14, validation loss=2.45] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:23<03:57,  1.56it/s, Train Loss=2.14, validation loss=2.45] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:23<03:57,  1.56it/s, Train Loss=1.61, validation loss=2.46] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:23<03:53,  1.58it/s, Train Loss=1.61, validation loss=2.46] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:24<03:53,  1.58it/s, Train Loss=2.44, validation loss=2.45] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:24<03:54,  1.57it/s, Train Loss=2.44, validation loss=2.45] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:25<03:54,  1.57it/s, Train Loss=2.81, validation loss=2.44] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:25<03:55,  1.56it/s, Train Loss=2.81, validation loss=2.44] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:25<03:55,  1.56it/s, Train Loss=2.86, validation loss=2.45] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:25<03:54,  1.56it/s, Train Loss=2.86, validation loss=2.45] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:26<03:54,  1.56it/s, Train Loss=2.33, validation loss=2.46] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:26<03:49,  1.59it/s, Train Loss=2.33, validation loss=2.46] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:26<03:49,  1.59it/s, Train Loss=2.21, validation loss=2.45] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:26<03:47,  1.60it/s, Train Loss=2.21, validation loss=2.45] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:27<03:47,  1.60it/s, Train Loss=3.32, validation loss=2.45] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:27<03:54,  1.55it/s, Train Loss=3.32, validation loss=2.45] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:28<03:54,  1.55it/s, Train Loss=2.56, validation loss=2.46] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:28<03:50,  1.57it/s, Train Loss=2.56, validation loss=2.46] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:28<03:50,  1.57it/s, Train Loss=2.46, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:28<03:46,  1.60it/s, Train Loss=2.46, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:29<03:46,  1.60it/s, Train Loss=1.94, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:29<03:48,  1.58it/s, Train Loss=1.94, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:30<03:48,  1.58it/s, Train Loss=2.45, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:30<03:47,  1.58it/s, Train Loss=2.45, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:30<03:47,  1.58it/s, Train Loss=2.51, validation loss=2.46] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:30<03:43,  1.60it/s, Train Loss=2.51, validation loss=2.46] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:31<03:43,  1.60it/s, Train Loss=2.54, validation loss=2.46] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:31<03:41,  1.61it/s, Train Loss=2.54, validation loss=2.46] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:32<03:41,  1.61it/s, Train Loss=3.18, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:32<03:53,  1.53it/s, Train Loss=3.18, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:32<03:53,  1.53it/s, Train Loss=2.61, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:32<03:47,  1.56it/s, Train Loss=2.61, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:33<03:47,  1.56it/s, Train Loss=3.48, validation loss=2.44] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:33<03:57,  1.49it/s, Train Loss=3.48, validation loss=2.44] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:34<03:57,  1.49it/s, Train Loss=1.6, validation loss=2.45]  29%|â–ˆâ–ˆâ–‰       | 147/500 [01:34<03:53,  1.51it/s, Train Loss=1.6, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:34<03:53,  1.51it/s, Train Loss=3.42, validation loss=2.45] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:34<03:45,  1.56it/s, Train Loss=3.42, validation loss=2.45] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:35<03:45,  1.56it/s, Train Loss=2.98, validation loss=2.45] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:35<03:42,  1.58it/s, Train Loss=2.98, validation loss=2.45] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:35<03:42,  1.58it/s, Train Loss=2.02, validation loss=2.46] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:35<03:40,  1.59it/s, Train Loss=2.02, validation loss=2.46] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:36<03:40,  1.59it/s, Train Loss=2.43, validation loss=2.45] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:36<03:35,  1.62it/s, Train Loss=2.43, validation loss=2.45] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:37<03:35,  1.62it/s, Train Loss=2.62, validation loss=2.44] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:37<03:35,  1.61it/s, Train Loss=2.62, validation loss=2.44] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:37<03:35,  1.61it/s, Train Loss=2.5, validation loss=2.44]  31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:37<03:34,  1.62it/s, Train Loss=2.5, validation loss=2.44] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:38<03:34,  1.62it/s, Train Loss=1.7, validation loss=2.44] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:38<03:51,  1.50it/s, Train Loss=1.7, validation loss=2.44] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:39<03:51,  1.50it/s, Train Loss=2.75, validation loss=2.43] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:39<03:45,  1.53it/s, Train Loss=2.75, validation loss=2.43] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:39<03:45,  1.53it/s, Train Loss=2.06, validation loss=2.43] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:39<03:41,  1.55it/s, Train Loss=2.06, validation loss=2.43] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:40<03:41,  1.55it/s, Train Loss=1.8, validation loss=2.44]  31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:40<03:41,  1.55it/s, Train Loss=1.8, validation loss=2.44] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:41<03:41,  1.55it/s, Train Loss=2.23, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:41<03:40,  1.55it/s, Train Loss=2.23, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:41<03:40,  1.55it/s, Train Loss=4.19, validation loss=2.44] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:41<03:37,  1.56it/s, Train Loss=4.19, validation loss=2.44] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:42<03:37,  1.56it/s, Train Loss=2.52, validation loss=2.44] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:42<03:36,  1.57it/s, Train Loss=2.52, validation loss=2.44] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:43<03:36,  1.57it/s, Train Loss=3.04, validation loss=2.44] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:43<03:51,  1.47it/s, Train Loss=3.04, validation loss=2.44] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:43<03:51,  1.47it/s, Train Loss=1.77, validation loss=2.44] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:43<03:46,  1.49it/s, Train Loss=1.77, validation loss=2.44] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:44<03:46,  1.49it/s, Train Loss=2.9, validation loss=2.43]  33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:44<03:42,  1.52it/s, Train Loss=2.9, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:45<03:42,  1.52it/s, Train Loss=1.85, validation loss=2.44] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:45<03:40,  1.52it/s, Train Loss=1.85, validation loss=2.44] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:45<03:40,  1.52it/s, Train Loss=2.26, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:45<03:38,  1.54it/s, Train Loss=2.26, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:46<03:38,  1.54it/s, Train Loss=1.54, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:46<03:32,  1.57it/s, Train Loss=1.54, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:46<03:32,  1.57it/s, Train Loss=2.59, validation loss=2.42] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:46<03:33,  1.56it/s, Train Loss=2.59, validation loss=2.42] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:47<03:33,  1.56it/s, Train Loss=1.59, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:47<03:35,  1.54it/s, Train Loss=1.59, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:48<03:35,  1.54it/s, Train Loss=2.39, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:48<03:32,  1.56it/s, Train Loss=2.39, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:48<03:32,  1.56it/s, Train Loss=2.44, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:48<03:30,  1.57it/s, Train Loss=2.44, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:49<03:30,  1.57it/s, Train Loss=1.66, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:49<03:28,  1.58it/s, Train Loss=1.66, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:50<03:28,  1.58it/s, Train Loss=2.6, validation loss=2.43]  34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:50<03:23,  1.61it/s, Train Loss=2.6, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:50<03:23,  1.61it/s, Train Loss=3.04, validation loss=2.43] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:50<03:19,  1.64it/s, Train Loss=3.04, validation loss=2.43] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:51<03:19,  1.64it/s, Train Loss=2.94, validation loss=2.45] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:51<03:18,  1.64it/s, Train Loss=2.94, validation loss=2.45] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:51<03:18,  1.64it/s, Train Loss=1.87, validation loss=2.45] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:51<03:20,  1.62it/s, Train Loss=1.87, validation loss=2.45] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:52<03:20,  1.62it/s, Train Loss=2.44, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:52<03:31,  1.53it/s, Train Loss=2.44, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:53<03:31,  1.53it/s, Train Loss=2.99, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:53<03:26,  1.56it/s, Train Loss=2.99, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:53<03:26,  1.56it/s, Train Loss=1.97, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:53<03:22,  1.59it/s, Train Loss=1.97, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:54<03:22,  1.59it/s, Train Loss=1.68, validation loss=2.43] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:54<03:21,  1.60it/s, Train Loss=1.68, validation loss=2.43] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:55<03:21,  1.60it/s, Train Loss=2.67, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:55<03:22,  1.58it/s, Train Loss=2.67, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:55<03:22,  1.58it/s, Train Loss=1.68, validation loss=2.43] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:55<03:20,  1.59it/s, Train Loss=1.68, validation loss=2.43] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:56<03:20,  1.59it/s, Train Loss=2.01, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:56<03:17,  1.61it/s, Train Loss=2.01, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:57<03:17,  1.61it/s, Train Loss=1.89, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:57<03:29,  1.51it/s, Train Loss=1.89, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:57<03:29,  1.51it/s, Train Loss=3.47, validation loss=2.44] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:57<03:44,  1.41it/s, Train Loss=3.47, validation loss=2.44] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:58<03:44,  1.41it/s, Train Loss=2.26, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:58<03:34,  1.47it/s, Train Loss=2.26, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:59<03:34,  1.47it/s, Train Loss=3.11, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [01:59<03:24,  1.53it/s, Train Loss=3.11, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [01:59<03:24,  1.53it/s, Train Loss=1.86, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [01:59<03:23,  1.54it/s, Train Loss=1.86, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:00<03:23,  1.54it/s, Train Loss=2.37, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:00<03:19,  1.56it/s, Train Loss=2.37, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:00<03:19,  1.56it/s, Train Loss=1.99, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:00<03:15,  1.59it/s, Train Loss=1.99, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:01<03:15,  1.59it/s, Train Loss=1.94, validation loss=2.44] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:01<03:18,  1.56it/s, Train Loss=1.94, validation loss=2.44] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:02<03:18,  1.56it/s, Train Loss=1.86, validation loss=2.44] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:02<03:13,  1.59it/s, Train Loss=1.86, validation loss=2.44] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:02<03:13,  1.59it/s, Train Loss=2.05, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:02<03:10,  1.62it/s, Train Loss=2.05, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:03<03:10,  1.62it/s, Train Loss=2.12, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:03<03:11,  1.60it/s, Train Loss=2.12, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:04<03:11,  1.60it/s, Train Loss=2.12, validation loss=2.44] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:04<03:10,  1.60it/s, Train Loss=2.12, validation loss=2.44] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:04<03:10,  1.60it/s, Train Loss=1.87, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:04<03:08,  1.62it/s, Train Loss=1.87, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:05<03:08,  1.62it/s, Train Loss=2.61, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:05<03:07,  1.62it/s, Train Loss=2.61, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:06<03:07,  1.62it/s, Train Loss=1.7, validation loss=2.44]  39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:06<03:14,  1.56it/s, Train Loss=1.7, validation loss=2.44] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:06<03:14,  1.56it/s, Train Loss=1.73, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:06<03:11,  1.58it/s, Train Loss=1.73, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:07<03:11,  1.58it/s, Train Loss=2.13, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:07<03:08,  1.60it/s, Train Loss=2.13, validation loss=2.43]####################################################################################################
--------------------------------------------- Epoch:200 ---------------------------------------------
-- Training set:
Loss: 2.865382194519043, Lr: 0.00025
Average AUC ROC: 0.53                Average AUC PR: 0.29
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:07<03:08,  1.60it/s, Train Loss=2.87, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:07<03:06,  1.61it/s, Train Loss=2.87, validation loss=2.43]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.434660777449608
Average AUC ROC: 0.56                    Average AUC PR: 0.32
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:08<03:06,  1.61it/s, Train Loss=2.26, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:08<03:09,  1.58it/s, Train Loss=2.26, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:09<03:09,  1.58it/s, Train Loss=1.61, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:09<03:08,  1.58it/s, Train Loss=1.61, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:09<03:08,  1.58it/s, Train Loss=1.68, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:09<03:05,  1.60it/s, Train Loss=1.68, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:10<03:05,  1.60it/s, Train Loss=2.22, validation loss=2.42] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:10<03:04,  1.61it/s, Train Loss=2.22, validation loss=2.42] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:11<03:04,  1.61it/s, Train Loss=3.03, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:11<03:12,  1.54it/s, Train Loss=3.03, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:11<03:12,  1.54it/s, Train Loss=2.56, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:11<03:07,  1.57it/s, Train Loss=2.56, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:12<03:07,  1.57it/s, Train Loss=2.42, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:12<03:06,  1.57it/s, Train Loss=2.42, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:12<03:06,  1.57it/s, Train Loss=1.92, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:12<03:02,  1.60it/s, Train Loss=1.92, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:13<03:02,  1.60it/s, Train Loss=2.82, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:13<03:00,  1.61it/s, Train Loss=2.82, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:14<03:00,  1.61it/s, Train Loss=2.94, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:14<02:58,  1.62it/s, Train Loss=2.94, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:14<02:58,  1.62it/s, Train Loss=4.25, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:14<02:58,  1.62it/s, Train Loss=4.25, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:15<02:58,  1.62it/s, Train Loss=3.19, validation loss=2.44] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:15<03:07,  1.54it/s, Train Loss=3.19, validation loss=2.44] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:16<03:07,  1.54it/s, Train Loss=1.55, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:16<03:03,  1.57it/s, Train Loss=1.55, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:16<03:03,  1.57it/s, Train Loss=2.07, validation loss=2.42] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:16<03:00,  1.58it/s, Train Loss=2.07, validation loss=2.42] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:17<03:00,  1.58it/s, Train Loss=1.94, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:17<02:58,  1.60it/s, Train Loss=1.94, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:17<02:58,  1.60it/s, Train Loss=2.17, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:17<02:59,  1.59it/s, Train Loss=2.17, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:18<02:59,  1.59it/s, Train Loss=2.51, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:18<02:58,  1.58it/s, Train Loss=2.51, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:19<02:58,  1.58it/s, Train Loss=1.94, validation loss=2.44] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:19<02:58,  1.58it/s, Train Loss=1.94, validation loss=2.44] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:19<02:58,  1.58it/s, Train Loss=3.26, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:19<03:04,  1.52it/s, Train Loss=3.26, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:20<03:04,  1.52it/s, Train Loss=3.28, validation loss=2.41] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:20<02:59,  1.56it/s, Train Loss=3.28, validation loss=2.41] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:21<02:59,  1.56it/s, Train Loss=2.27, validation loss=2.42] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:21<02:59,  1.56it/s, Train Loss=2.27, validation loss=2.42] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:21<02:59,  1.56it/s, Train Loss=2.18, validation loss=2.45] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:21<02:53,  1.60it/s, Train Loss=2.18, validation loss=2.45] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:22<02:53,  1.60it/s, Train Loss=1.63, validation loss=2.43] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:22<02:51,  1.62it/s, Train Loss=1.63, validation loss=2.43] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:23<02:51,  1.62it/s, Train Loss=1.88, validation loss=2.42] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:23<02:56,  1.57it/s, Train Loss=1.88, validation loss=2.42] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:23<02:56,  1.57it/s, Train Loss=2.02, validation loss=2.42] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:23<03:09,  1.45it/s, Train Loss=2.02, validation loss=2.42] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:24<03:09,  1.45it/s, Train Loss=3.77, validation loss=2.43] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:24<03:09,  1.44it/s, Train Loss=3.77, validation loss=2.43] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:25<03:09,  1.44it/s, Train Loss=2.3, validation loss=2.44]  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:25<03:05,  1.47it/s, Train Loss=2.3, validation loss=2.44] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:25<03:05,  1.47it/s, Train Loss=3.2, validation loss=2.42] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:25<03:00,  1.51it/s, Train Loss=3.2, validation loss=2.42] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:26<03:00,  1.51it/s, Train Loss=1.41, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:26<02:55,  1.54it/s, Train Loss=1.41, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:27<02:55,  1.54it/s, Train Loss=3.88, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:27<02:54,  1.55it/s, Train Loss=3.88, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:27<02:54,  1.55it/s, Train Loss=1.32, validation loss=2.42] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:27<02:49,  1.58it/s, Train Loss=1.32, validation loss=2.42] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:28<02:49,  1.58it/s, Train Loss=2.12, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:28<02:55,  1.53it/s, Train Loss=2.12, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:29<02:55,  1.53it/s, Train Loss=2.26, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:29<02:53,  1.54it/s, Train Loss=2.26, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:29<02:53,  1.54it/s, Train Loss=1.78, validation loss=2.44] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:29<02:49,  1.57it/s, Train Loss=1.78, validation loss=2.44] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:30<02:49,  1.57it/s, Train Loss=1.79, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:30<02:48,  1.58it/s, Train Loss=1.79, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:30<02:48,  1.58it/s, Train Loss=2.4, validation loss=2.42]  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:30<02:48,  1.57it/s, Train Loss=2.4, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:31<02:48,  1.57it/s, Train Loss=1.49, validation loss=2.43] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:31<02:44,  1.60it/s, Train Loss=1.49, validation loss=2.43] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:32<02:44,  1.60it/s, Train Loss=1.8, validation loss=2.43]  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:32<02:43,  1.61it/s, Train Loss=1.8, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:32<02:43,  1.61it/s, Train Loss=2.71, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:32<02:41,  1.62it/s, Train Loss=2.71, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:33<02:41,  1.62it/s, Train Loss=1.48, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:33<02:49,  1.53it/s, Train Loss=1.48, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:34<02:49,  1.53it/s, Train Loss=3.09, validation loss=2.42] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:34<02:48,  1.54it/s, Train Loss=3.09, validation loss=2.42] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:34<02:48,  1.54it/s, Train Loss=2.61, validation loss=2.42] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:34<02:47,  1.54it/s, Train Loss=2.61, validation loss=2.42] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:35<02:47,  1.54it/s, Train Loss=1.92, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:35<02:44,  1.56it/s, Train Loss=1.92, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:35<02:44,  1.56it/s, Train Loss=1.33, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:35<02:40,  1.60it/s, Train Loss=1.33, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:36<02:40,  1.60it/s, Train Loss=2.26, validation loss=2.43] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:36<02:38,  1.61it/s, Train Loss=2.26, validation loss=2.43] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:37<02:38,  1.61it/s, Train Loss=2.8, validation loss=2.42]  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:37<02:44,  1.55it/s, Train Loss=2.8, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:37<02:44,  1.55it/s, Train Loss=2.27, validation loss=2.43] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:37<02:42,  1.56it/s, Train Loss=2.27, validation loss=2.43] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:38<02:42,  1.56it/s, Train Loss=1.89, validation loss=2.43] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:38<02:38,  1.59it/s, Train Loss=1.89, validation loss=2.43] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:39<02:38,  1.59it/s, Train Loss=1.51, validation loss=2.41] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:39<02:35,  1.62it/s, Train Loss=1.51, validation loss=2.41] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:39<02:35,  1.62it/s, Train Loss=1.55, validation loss=2.44] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:39<02:34,  1.62it/s, Train Loss=1.55, validation loss=2.44] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:40<02:34,  1.62it/s, Train Loss=1.9, validation loss=2.42]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:40<02:32,  1.64it/s, Train Loss=1.9, validation loss=2.42] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:40<02:32,  1.64it/s, Train Loss=2.41, validation loss=2.41] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:40<02:31,  1.63it/s, Train Loss=2.41, validation loss=2.41] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:41<02:31,  1.63it/s, Train Loss=1.78, validation loss=2.43] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:41<02:31,  1.63it/s, Train Loss=1.78, validation loss=2.43] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:42<02:31,  1.63it/s, Train Loss=1.83, validation loss=2.44] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:42<02:36,  1.57it/s, Train Loss=1.83, validation loss=2.44] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:42<02:36,  1.57it/s, Train Loss=1.99, validation loss=2.42] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:42<02:34,  1.59it/s, Train Loss=1.99, validation loss=2.42] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:43<02:34,  1.59it/s, Train Loss=4.03, validation loss=2.43] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:43<02:33,  1.59it/s, Train Loss=4.03, validation loss=2.43] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:44<02:33,  1.59it/s, Train Loss=2.09, validation loss=2.41] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:44<02:33,  1.58it/s, Train Loss=2.09, validation loss=2.41] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:44<02:33,  1.58it/s, Train Loss=2.82, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:44<02:32,  1.58it/s, Train Loss=2.82, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:45<02:32,  1.58it/s, Train Loss=3.38, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:45<02:30,  1.61it/s, Train Loss=3.38, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:45<02:30,  1.61it/s, Train Loss=1.92, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:45<02:28,  1.61it/s, Train Loss=1.92, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:46<02:28,  1.61it/s, Train Loss=1.66, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:46<02:31,  1.57it/s, Train Loss=1.66, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:47<02:31,  1.57it/s, Train Loss=1.99, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:47<02:29,  1.59it/s, Train Loss=1.99, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:47<02:29,  1.59it/s, Train Loss=3.3, validation loss=2.41]  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:47<02:26,  1.61it/s, Train Loss=3.3, validation loss=2.41] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:48<02:26,  1.61it/s, Train Loss=2.32, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:48<02:31,  1.56it/s, Train Loss=2.32, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:49<02:31,  1.56it/s, Train Loss=2.41, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:49<02:38,  1.49it/s, Train Loss=2.41, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:49<02:38,  1.49it/s, Train Loss=2.16, validation loss=2.43] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:49<02:32,  1.54it/s, Train Loss=2.16, validation loss=2.43] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:50<02:32,  1.54it/s, Train Loss=1.51, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:50<02:36,  1.49it/s, Train Loss=1.51, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:51<02:36,  1.49it/s, Train Loss=2.2, validation loss=2.43]  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:51<02:32,  1.52it/s, Train Loss=2.2, validation loss=2.43] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:51<02:32,  1.52it/s, Train Loss=2.27, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:51<02:30,  1.54it/s, Train Loss=2.27, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:52<02:30,  1.54it/s, Train Loss=1.66, validation loss=2.41] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:52<02:25,  1.58it/s, Train Loss=1.66, validation loss=2.41] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:53<02:25,  1.58it/s, Train Loss=2.3, validation loss=2.4]   54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:53<02:22,  1.61it/s, Train Loss=2.3, validation loss=2.4] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:53<02:22,  1.61it/s, Train Loss=2.18, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:53<02:20,  1.62it/s, Train Loss=2.18, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:54<02:20,  1.62it/s, Train Loss=2.22, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:54<02:21,  1.60it/s, Train Loss=2.22, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:54<02:21,  1.60it/s, Train Loss=2.01, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:54<02:21,  1.60it/s, Train Loss=2.01, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:55<02:21,  1.60it/s, Train Loss=2.59, validation loss=2.44] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:55<02:20,  1.60it/s, Train Loss=2.59, validation loss=2.44] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:56<02:20,  1.60it/s, Train Loss=2, validation loss=2.42]    55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:56<02:20,  1.60it/s, Train Loss=2, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:56<02:20,  1.60it/s, Train Loss=3.16, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:56<02:27,  1.51it/s, Train Loss=3.16, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:57<02:27,  1.51it/s, Train Loss=2.78, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:57<02:24,  1.54it/s, Train Loss=2.78, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:58<02:24,  1.54it/s, Train Loss=2.79, validation loss=2.41] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [02:58<02:20,  1.57it/s, Train Loss=2.79, validation loss=2.41] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [02:58<02:20,  1.57it/s, Train Loss=1.58, validation loss=2.41] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [02:58<02:19,  1.57it/s, Train Loss=1.58, validation loss=2.41] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [02:59<02:19,  1.57it/s, Train Loss=2.26, validation loss=2.41] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [02:59<02:19,  1.57it/s, Train Loss=2.26, validation loss=2.41] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:00<02:19,  1.57it/s, Train Loss=2.14, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:00<02:19,  1.56it/s, Train Loss=2.14, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:00<02:19,  1.56it/s, Train Loss=2.1, validation loss=2.42]  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:00<02:19,  1.56it/s, Train Loss=2.1, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:01<02:19,  1.56it/s, Train Loss=2.77, validation loss=2.41] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:01<02:16,  1.58it/s, Train Loss=2.77, validation loss=2.41] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:02<02:16,  1.58it/s, Train Loss=2.72, validation loss=2.41] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:02<02:23,  1.50it/s, Train Loss=2.72, validation loss=2.41] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:02<02:23,  1.50it/s, Train Loss=2.42, validation loss=2.4]  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:02<02:21,  1.51it/s, Train Loss=2.42, validation loss=2.4] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:03<02:21,  1.51it/s, Train Loss=2.99, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:03<02:17,  1.55it/s, Train Loss=2.99, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:03<02:17,  1.55it/s, Train Loss=2.43, validation loss=2.42] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:03<02:13,  1.59it/s, Train Loss=2.43, validation loss=2.42] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:04<02:13,  1.59it/s, Train Loss=2.12, validation loss=2.42] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:04<02:15,  1.56it/s, Train Loss=2.12, validation loss=2.42] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:05<02:15,  1.56it/s, Train Loss=2.04, validation loss=2.41] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:05<02:13,  1.58it/s, Train Loss=2.04, validation loss=2.41] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:05<02:13,  1.58it/s, Train Loss=3.43, validation loss=2.42] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:05<02:12,  1.58it/s, Train Loss=3.43, validation loss=2.42] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:06<02:12,  1.58it/s, Train Loss=2.21, validation loss=2.41] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:06<02:10,  1.60it/s, Train Loss=2.21, validation loss=2.41] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:07<02:10,  1.60it/s, Train Loss=2.52, validation loss=2.42] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:07<02:17,  1.51it/s, Train Loss=2.52, validation loss=2.42] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:07<02:17,  1.51it/s, Train Loss=1.81, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:07<02:13,  1.55it/s, Train Loss=1.81, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:08<02:13,  1.55it/s, Train Loss=3.63, validation loss=2.4]  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:08<02:10,  1.57it/s, Train Loss=3.63, validation loss=2.4] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:09<02:10,  1.57it/s, Train Loss=1.67, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:09<02:14,  1.52it/s, Train Loss=1.67, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:09<02:14,  1.52it/s, Train Loss=1.35, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:09<02:10,  1.56it/s, Train Loss=1.35, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:10<02:10,  1.56it/s, Train Loss=2.31, validation loss=2.41] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:10<02:09,  1.56it/s, Train Loss=2.31, validation loss=2.41] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:11<02:09,  1.56it/s, Train Loss=2.04, validation loss=2.41] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:11<02:07,  1.57it/s, Train Loss=2.04, validation loss=2.41]####################################################################################################
--------------------------------------------- Epoch:300 ---------------------------------------------
-- Training set:
Loss: 1.9902288913726807, Lr: 0.000125
Average AUC ROC: 0.53                Average AUC PR: 0.3
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:11<02:07,  1.57it/s, Train Loss=1.99, validation loss=2.42] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:11<02:05,  1.60it/s, Train Loss=1.99, validation loss=2.42]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.4155751764774323
Average AUC ROC: 0.56                    Average AUC PR: 0.32
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:12<02:05,  1.60it/s, Train Loss=2.42, validation loss=2.42] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:12<02:11,  1.52it/s, Train Loss=2.42, validation loss=2.42] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:12<02:11,  1.52it/s, Train Loss=2.89, validation loss=2.42] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:12<02:06,  1.56it/s, Train Loss=2.89, validation loss=2.42] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:13<02:06,  1.56it/s, Train Loss=2.95, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:13<02:03,  1.59it/s, Train Loss=2.95, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:14<02:03,  1.59it/s, Train Loss=1.81, validation loss=2.41] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:14<02:06,  1.55it/s, Train Loss=1.81, validation loss=2.41] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:14<02:06,  1.55it/s, Train Loss=4.1, validation loss=2.4]   61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:14<02:08,  1.52it/s, Train Loss=4.1, validation loss=2.4] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:15<02:08,  1.52it/s, Train Loss=2.41, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:15<02:05,  1.55it/s, Train Loss=2.41, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:16<02:05,  1.55it/s, Train Loss=2.16, validation loss=2.41] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:16<02:03,  1.56it/s, Train Loss=2.16, validation loss=2.41] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:16<02:03,  1.56it/s, Train Loss=2.51, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:16<02:01,  1.58it/s, Train Loss=2.51, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:17<02:01,  1.58it/s, Train Loss=2.89, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:17<02:03,  1.55it/s, Train Loss=2.89, validation loss=2.41] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:18<02:03,  1.55it/s, Train Loss=2.75, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:18<02:07,  1.49it/s, Train Loss=2.75, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:18<02:07,  1.49it/s, Train Loss=2.18, validation loss=2.4]  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:18<02:04,  1.52it/s, Train Loss=2.18, validation loss=2.4] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:19<02:04,  1.52it/s, Train Loss=2.12, validation loss=2.4] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:19<01:59,  1.57it/s, Train Loss=2.12, validation loss=2.4] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:20<01:59,  1.57it/s, Train Loss=2.15, validation loss=2.41] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:20<01:58,  1.58it/s, Train Loss=2.15, validation loss=2.41] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:20<01:58,  1.58it/s, Train Loss=1.72, validation loss=2.41] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:20<01:55,  1.61it/s, Train Loss=1.72, validation loss=2.41] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:21<01:55,  1.61it/s, Train Loss=1.76, validation loss=2.42] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:21<01:53,  1.63it/s, Train Loss=1.76, validation loss=2.42] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:21<01:53,  1.63it/s, Train Loss=1.41, validation loss=2.41] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:21<01:54,  1.61it/s, Train Loss=1.41, validation loss=2.41] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:22<01:54,  1.61it/s, Train Loss=2.11, validation loss=2.41] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:22<01:53,  1.61it/s, Train Loss=2.11, validation loss=2.41] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:23<01:53,  1.61it/s, Train Loss=1.92, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:23<01:59,  1.53it/s, Train Loss=1.92, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:23<01:59,  1.53it/s, Train Loss=1.21, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:23<01:56,  1.56it/s, Train Loss=1.21, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:24<01:56,  1.56it/s, Train Loss=1.31, validation loss=2.43] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:24<01:54,  1.58it/s, Train Loss=1.31, validation loss=2.43] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:25<01:54,  1.58it/s, Train Loss=2.12, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:25<01:53,  1.58it/s, Train Loss=2.12, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:25<01:53,  1.58it/s, Train Loss=1.96, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:25<01:51,  1.60it/s, Train Loss=1.96, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:26<01:51,  1.60it/s, Train Loss=2.57, validation loss=2.41] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:26<01:51,  1.59it/s, Train Loss=2.57, validation loss=2.41] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:26<01:51,  1.59it/s, Train Loss=1.73, validation loss=2.4]  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:26<01:52,  1.56it/s, Train Loss=1.73, validation loss=2.4] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:27<01:52,  1.56it/s, Train Loss=2.1, validation loss=2.4]  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:27<01:50,  1.58it/s, Train Loss=2.1, validation loss=2.4] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:28<01:50,  1.58it/s, Train Loss=1.96, validation loss=2.4] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:28<01:53,  1.53it/s, Train Loss=1.96, validation loss=2.4] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:28<01:53,  1.53it/s, Train Loss=2.47, validation loss=2.41] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:28<01:50,  1.57it/s, Train Loss=2.47, validation loss=2.41] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:29<01:50,  1.57it/s, Train Loss=2.91, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:29<01:47,  1.61it/s, Train Loss=2.91, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:30<01:47,  1.61it/s, Train Loss=1.76, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:30<01:47,  1.59it/s, Train Loss=1.76, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:30<01:47,  1.59it/s, Train Loss=2.68, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:30<01:46,  1.60it/s, Train Loss=2.68, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:31<01:46,  1.60it/s, Train Loss=2.21, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:31<01:46,  1.58it/s, Train Loss=2.21, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:32<01:46,  1.58it/s, Train Loss=2.34, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:32<01:45,  1.59it/s, Train Loss=2.34, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:32<01:45,  1.59it/s, Train Loss=1.54, validation loss=2.4]  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:32<01:49,  1.52it/s, Train Loss=1.54, validation loss=2.4] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:33<01:49,  1.52it/s, Train Loss=2.8, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:33<01:47,  1.54it/s, Train Loss=2.8, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:34<01:47,  1.54it/s, Train Loss=1.46, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:34<01:45,  1.56it/s, Train Loss=1.46, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:34<01:45,  1.56it/s, Train Loss=1.53, validation loss=2.41] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:34<01:49,  1.50it/s, Train Loss=1.53, validation loss=2.41] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:35<01:49,  1.50it/s, Train Loss=1.76, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:35<01:52,  1.45it/s, Train Loss=1.76, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:36<01:52,  1.45it/s, Train Loss=3.31, validation loss=2.41] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:36<01:48,  1.50it/s, Train Loss=3.31, validation loss=2.41] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:36<01:48,  1.50it/s, Train Loss=2.51, validation loss=2.41] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:36<01:45,  1.53it/s, Train Loss=2.51, validation loss=2.41] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:37<01:45,  1.53it/s, Train Loss=2.6, validation loss=2.42]  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:37<01:43,  1.55it/s, Train Loss=2.6, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:38<01:43,  1.55it/s, Train Loss=2, validation loss=2.41]   68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:38<01:46,  1.49it/s, Train Loss=2, validation loss=2.41] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:38<01:46,  1.49it/s, Train Loss=2.28, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:38<01:45,  1.49it/s, Train Loss=2.28, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:39<01:45,  1.49it/s, Train Loss=1.6, validation loss=2.41]  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:39<01:41,  1.55it/s, Train Loss=1.6, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:39<01:41,  1.55it/s, Train Loss=1.88, validation loss=2.42] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:39<01:41,  1.53it/s, Train Loss=1.88, validation loss=2.42] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:40<01:41,  1.53it/s, Train Loss=2.59, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:40<01:39,  1.56it/s, Train Loss=2.59, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:41<01:39,  1.56it/s, Train Loss=3.27, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:41<01:37,  1.58it/s, Train Loss=3.27, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:41<01:37,  1.58it/s, Train Loss=2.14, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:41<01:34,  1.61it/s, Train Loss=2.14, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:42<01:34,  1.61it/s, Train Loss=3.02, validation loss=2.41] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:42<01:34,  1.61it/s, Train Loss=3.02, validation loss=2.41] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:43<01:34,  1.61it/s, Train Loss=1.62, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:43<01:38,  1.53it/s, Train Loss=1.62, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:43<01:38,  1.53it/s, Train Loss=2.62, validation loss=2.41] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:43<01:35,  1.56it/s, Train Loss=2.62, validation loss=2.41] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:44<01:35,  1.56it/s, Train Loss=4.43, validation loss=2.41] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:44<01:34,  1.57it/s, Train Loss=4.43, validation loss=2.41] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:45<01:34,  1.57it/s, Train Loss=2.32, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:45<01:33,  1.59it/s, Train Loss=2.32, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:45<01:33,  1.59it/s, Train Loss=2.33, validation loss=2.42] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:45<01:31,  1.60it/s, Train Loss=2.33, validation loss=2.42] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:46<01:31,  1.60it/s, Train Loss=1.96, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:46<01:30,  1.61it/s, Train Loss=1.96, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:46<01:30,  1.61it/s, Train Loss=1.73, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:46<01:29,  1.62it/s, Train Loss=1.73, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:47<01:29,  1.62it/s, Train Loss=2.5, validation loss=2.41]  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:47<01:28,  1.63it/s, Train Loss=2.5, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:48<01:28,  1.63it/s, Train Loss=2.29, validation loss=2.42] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:48<01:32,  1.55it/s, Train Loss=2.29, validation loss=2.42] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:48<01:32,  1.55it/s, Train Loss=1.71, validation loss=2.42] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:48<01:29,  1.59it/s, Train Loss=1.71, validation loss=2.42] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:49<01:29,  1.59it/s, Train Loss=1.77, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:49<01:27,  1.60it/s, Train Loss=1.77, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:50<01:27,  1.60it/s, Train Loss=1.88, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:50<01:27,  1.59it/s, Train Loss=1.88, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:50<01:27,  1.59it/s, Train Loss=2.16, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:50<01:27,  1.60it/s, Train Loss=2.16, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:51<01:27,  1.60it/s, Train Loss=1.64, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:51<01:25,  1.61it/s, Train Loss=1.64, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:51<01:25,  1.61it/s, Train Loss=1.9, validation loss=2.42]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:51<01:24,  1.62it/s, Train Loss=1.9, validation loss=2.42] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:52<01:24,  1.62it/s, Train Loss=1.53, validation loss=2.41] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:52<01:22,  1.65it/s, Train Loss=1.53, validation loss=2.41] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:53<01:22,  1.65it/s, Train Loss=2.07, validation loss=2.41] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:53<01:27,  1.55it/s, Train Loss=2.07, validation loss=2.41] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:53<01:27,  1.55it/s, Train Loss=1.82, validation loss=2.4]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:53<01:24,  1.59it/s, Train Loss=1.82, validation loss=2.4] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:54<01:24,  1.59it/s, Train Loss=2.98, validation loss=2.41] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:54<01:24,  1.58it/s, Train Loss=2.98, validation loss=2.41] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:55<01:24,  1.58it/s, Train Loss=1.46, validation loss=2.42] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:55<01:23,  1.57it/s, Train Loss=1.46, validation loss=2.42] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:55<01:23,  1.57it/s, Train Loss=2.02, validation loss=2.4]  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:55<01:22,  1.59it/s, Train Loss=2.02, validation loss=2.4] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:56<01:22,  1.59it/s, Train Loss=1.77, validation loss=2.42] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:56<01:21,  1.59it/s, Train Loss=1.77, validation loss=2.42] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:56<01:21,  1.59it/s, Train Loss=3.59, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:56<01:21,  1.59it/s, Train Loss=3.59, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:57<01:21,  1.59it/s, Train Loss=2.13, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [03:57<01:24,  1.52it/s, Train Loss=2.13, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [03:58<01:24,  1.52it/s, Train Loss=2.22, validation loss=2.4]  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [03:58<01:22,  1.54it/s, Train Loss=2.22, validation loss=2.4] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [03:58<01:22,  1.54it/s, Train Loss=1.96, validation loss=2.41] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [03:58<01:20,  1.56it/s, Train Loss=1.96, validation loss=2.41] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [03:59<01:20,  1.56it/s, Train Loss=1.96, validation loss=2.41] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [03:59<01:20,  1.56it/s, Train Loss=1.96, validation loss=2.41] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:00<01:20,  1.56it/s, Train Loss=1.97, validation loss=2.4]  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:00<01:21,  1.53it/s, Train Loss=1.97, validation loss=2.4] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:00<01:21,  1.53it/s, Train Loss=2.14, validation loss=2.4] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:00<01:23,  1.47it/s, Train Loss=2.14, validation loss=2.4] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:01<01:23,  1.47it/s, Train Loss=2.79, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:01<01:20,  1.51it/s, Train Loss=2.79, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:02<01:20,  1.51it/s, Train Loss=2.04, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:02<01:18,  1.54it/s, Train Loss=2.04, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:02<01:18,  1.54it/s, Train Loss=1.81, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:02<01:21,  1.47it/s, Train Loss=1.81, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:03<01:21,  1.47it/s, Train Loss=2.46, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:03<01:18,  1.51it/s, Train Loss=2.46, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:04<01:18,  1.51it/s, Train Loss=1.94, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:04<01:16,  1.54it/s, Train Loss=1.94, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:04<01:16,  1.54it/s, Train Loss=1.38, validation loss=2.41] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:04<01:15,  1.56it/s, Train Loss=1.38, validation loss=2.41] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:05<01:15,  1.56it/s, Train Loss=2.07, validation loss=2.4]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:05<01:13,  1.57it/s, Train Loss=2.07, validation loss=2.4] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:06<01:13,  1.57it/s, Train Loss=1.62, validation loss=2.41] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:06<01:13,  1.56it/s, Train Loss=1.62, validation loss=2.41] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:06<01:13,  1.56it/s, Train Loss=1.68, validation loss=2.41] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:06<01:11,  1.59it/s, Train Loss=1.68, validation loss=2.41] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:07<01:11,  1.59it/s, Train Loss=1.73, validation loss=2.4]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:07<01:10,  1.60it/s, Train Loss=1.73, validation loss=2.4] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:07<01:10,  1.60it/s, Train Loss=2.08, validation loss=2.42] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:07<01:10,  1.60it/s, Train Loss=2.08, validation loss=2.42] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:08<01:10,  1.60it/s, Train Loss=2.16, validation loss=2.42] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:08<01:09,  1.59it/s, Train Loss=2.16, validation loss=2.42] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:09<01:09,  1.59it/s, Train Loss=4.36, validation loss=2.4]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:09<01:12,  1.51it/s, Train Loss=4.36, validation loss=2.4] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:09<01:12,  1.51it/s, Train Loss=3.07, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:09<01:11,  1.53it/s, Train Loss=3.07, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:10<01:11,  1.53it/s, Train Loss=2.72, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:10<01:10,  1.54it/s, Train Loss=2.72, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:11<01:10,  1.54it/s, Train Loss=3.36, validation loss=2.41] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:11<01:09,  1.55it/s, Train Loss=3.36, validation loss=2.41] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:11<01:09,  1.55it/s, Train Loss=2.78, validation loss=2.41] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:11<01:07,  1.56it/s, Train Loss=2.78, validation loss=2.41] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:12<01:07,  1.56it/s, Train Loss=3.23, validation loss=2.4]  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:12<01:06,  1.58it/s, Train Loss=3.23, validation loss=2.4] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:13<01:06,  1.58it/s, Train Loss=2.55, validation loss=2.4] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:13<01:05,  1.59it/s, Train Loss=2.55, validation loss=2.4] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:13<01:05,  1.59it/s, Train Loss=1.73, validation loss=2.41] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:13<01:04,  1.61it/s, Train Loss=1.73, validation loss=2.41] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:14<01:04,  1.61it/s, Train Loss=2.23, validation loss=2.4]  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:14<01:02,  1.64it/s, Train Loss=2.23, validation loss=2.4] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:14<01:02,  1.64it/s, Train Loss=1.3, validation loss=2.41] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:14<01:03,  1.60it/s, Train Loss=1.3, validation loss=2.41]####################################################################################################
--------------------------------------------- Epoch:400 ---------------------------------------------
-- Training set:
Loss: 1.8112423419952393, Lr: 6.25e-05
Average AUC ROC: 0.51                Average AUC PR: 0.28
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:15<01:03,  1.60it/s, Train Loss=1.81, validation loss=2.41] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:15<01:03,  1.58it/s, Train Loss=1.81, validation loss=2.41]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.409763015806675
Average AUC ROC: 0.56                    Average AUC PR: 0.32
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:16<01:03,  1.58it/s, Train Loss=4.03, validation loss=2.4]  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:16<01:02,  1.59it/s, Train Loss=4.03, validation loss=2.4] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:16<01:02,  1.59it/s, Train Loss=1.92, validation loss=2.4] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:16<01:00,  1.61it/s, Train Loss=1.92, validation loss=2.4] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:17<01:00,  1.61it/s, Train Loss=2.55, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:17<00:59,  1.63it/s, Train Loss=2.55, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:18<00:59,  1.63it/s, Train Loss=1.88, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:18<00:59,  1.61it/s, Train Loss=1.88, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:18<00:59,  1.61it/s, Train Loss=1.3, validation loss=2.41]  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:18<01:00,  1.57it/s, Train Loss=1.3, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:19<01:00,  1.57it/s, Train Loss=2.29, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:19<00:59,  1.59it/s, Train Loss=2.29, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:20<00:59,  1.59it/s, Train Loss=3.59, validation loss=2.42] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:20<00:59,  1.57it/s, Train Loss=3.59, validation loss=2.42] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:20<00:59,  1.57it/s, Train Loss=2.12, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:20<01:04,  1.43it/s, Train Loss=2.12, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:21<01:04,  1.43it/s, Train Loss=2.3, validation loss=2.41]  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:21<01:03,  1.44it/s, Train Loss=2.3, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:22<01:03,  1.44it/s, Train Loss=2.9, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:22<00:59,  1.50it/s, Train Loss=2.9, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:22<00:59,  1.50it/s, Train Loss=2.43, validation loss=2.4] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:22<00:58,  1.53it/s, Train Loss=2.43, validation loss=2.4] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:23<00:58,  1.53it/s, Train Loss=1.91, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:23<00:56,  1.56it/s, Train Loss=1.91, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:24<00:56,  1.56it/s, Train Loss=2.08, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:24<00:57,  1.52it/s, Train Loss=2.08, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:24<00:57,  1.52it/s, Train Loss=2.65, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:24<00:55,  1.55it/s, Train Loss=2.65, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:25<00:55,  1.55it/s, Train Loss=1.86, validation loss=2.4]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:25<00:57,  1.49it/s, Train Loss=1.86, validation loss=2.4] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:26<00:57,  1.49it/s, Train Loss=1.9, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:26<00:56,  1.48it/s, Train Loss=1.9, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:26<00:56,  1.48it/s, Train Loss=1.82, validation loss=2.4] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:26<00:59,  1.40it/s, Train Loss=1.82, validation loss=2.4] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:27<00:59,  1.40it/s, Train Loss=2.45, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:27<00:59,  1.37it/s, Train Loss=2.45, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:28<00:59,  1.37it/s, Train Loss=1.92, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:28<00:58,  1.38it/s, Train Loss=1.92, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:28<00:58,  1.38it/s, Train Loss=2.51, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:28<00:54,  1.46it/s, Train Loss=2.51, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:29<00:54,  1.46it/s, Train Loss=3.87, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:29<00:52,  1.51it/s, Train Loss=3.87, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:30<00:52,  1.51it/s, Train Loss=1.99, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:30<00:50,  1.53it/s, Train Loss=1.99, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:30<00:50,  1.53it/s, Train Loss=2.08, validation loss=2.4]  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:30<00:48,  1.57it/s, Train Loss=2.08, validation loss=2.4] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:31<00:48,  1.57it/s, Train Loss=1.91, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:31<00:47,  1.60it/s, Train Loss=1.91, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:32<00:47,  1.60it/s, Train Loss=1.86, validation loss=2.4]  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:32<00:48,  1.56it/s, Train Loss=1.86, validation loss=2.4] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:32<00:48,  1.56it/s, Train Loss=1.42, validation loss=2.4] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:32<00:51,  1.44it/s, Train Loss=1.42, validation loss=2.4] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:33<00:51,  1.44it/s, Train Loss=2.13, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:33<00:50,  1.44it/s, Train Loss=2.13, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:34<00:50,  1.44it/s, Train Loss=1.74, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:34<00:50,  1.44it/s, Train Loss=1.74, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:35<00:50,  1.44it/s, Train Loss=2.49, validation loss=2.4]  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:35<00:50,  1.39it/s, Train Loss=2.49, validation loss=2.4] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:35<00:50,  1.39it/s, Train Loss=2.08, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:35<00:51,  1.36it/s, Train Loss=2.08, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:36<00:51,  1.36it/s, Train Loss=1.92, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:36<00:52,  1.33it/s, Train Loss=1.92, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:37<00:52,  1.33it/s, Train Loss=1.9, validation loss=2.4]   86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:37<00:52,  1.30it/s, Train Loss=1.9, validation loss=2.4] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:38<00:52,  1.30it/s, Train Loss=2.23, validation loss=2.4] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:38<00:51,  1.30it/s, Train Loss=2.23, validation loss=2.4] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:38<00:51,  1.30it/s, Train Loss=1.71, validation loss=2.4] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:38<00:48,  1.37it/s, Train Loss=1.71, validation loss=2.4] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:39<00:48,  1.37it/s, Train Loss=2.62, validation loss=2.4] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:39<00:45,  1.43it/s, Train Loss=2.62, validation loss=2.4] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:40<00:45,  1.43it/s, Train Loss=1.61, validation loss=2.4] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:40<00:43,  1.47it/s, Train Loss=1.61, validation loss=2.4] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:40<00:43,  1.47it/s, Train Loss=2.47, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:40<00:41,  1.50it/s, Train Loss=2.47, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:41<00:41,  1.50it/s, Train Loss=2.04, validation loss=2.4]  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:41<00:41,  1.48it/s, Train Loss=2.04, validation loss=2.4] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:42<00:41,  1.48it/s, Train Loss=1.77, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:42<00:40,  1.51it/s, Train Loss=1.77, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:42<00:40,  1.51it/s, Train Loss=3.78, validation loss=2.4]  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:42<00:41,  1.44it/s, Train Loss=3.78, validation loss=2.4] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:43<00:41,  1.44it/s, Train Loss=1.92, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:43<00:39,  1.48it/s, Train Loss=1.92, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:44<00:39,  1.48it/s, Train Loss=1.62, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:44<00:37,  1.54it/s, Train Loss=1.62, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:44<00:37,  1.54it/s, Train Loss=2.46, validation loss=2.41] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:44<00:36,  1.56it/s, Train Loss=2.46, validation loss=2.41] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:45<00:36,  1.56it/s, Train Loss=1.93, validation loss=2.4]  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:45<00:35,  1.58it/s, Train Loss=1.93, validation loss=2.4] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:45<00:35,  1.58it/s, Train Loss=2.55, validation loss=2.4] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:45<00:34,  1.59it/s, Train Loss=2.55, validation loss=2.4] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:46<00:34,  1.59it/s, Train Loss=2.49, validation loss=2.41] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:46<00:33,  1.60it/s, Train Loss=2.49, validation loss=2.41] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:47<00:33,  1.60it/s, Train Loss=2.19, validation loss=2.4]  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:47<00:32,  1.61it/s, Train Loss=2.19, validation loss=2.4] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:47<00:32,  1.61it/s, Train Loss=2.72, validation loss=2.4] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:47<00:32,  1.61it/s, Train Loss=2.72, validation loss=2.4] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:48<00:32,  1.61it/s, Train Loss=2.02, validation loss=2.4] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:48<00:33,  1.52it/s, Train Loss=2.02, validation loss=2.4] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:49<00:33,  1.52it/s, Train Loss=2.08, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:49<00:31,  1.57it/s, Train Loss=2.08, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:49<00:31,  1.57it/s, Train Loss=3.12, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:49<00:30,  1.58it/s, Train Loss=3.12, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:50<00:30,  1.58it/s, Train Loss=1.63, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:50<00:29,  1.60it/s, Train Loss=1.63, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:50<00:29,  1.60it/s, Train Loss=3.1, validation loss=2.4]   91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:50<00:29,  1.61it/s, Train Loss=3.1, validation loss=2.4] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:51<00:29,  1.61it/s, Train Loss=3.09, validation loss=2.41] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:51<00:28,  1.62it/s, Train Loss=3.09, validation loss=2.41] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:52<00:28,  1.62it/s, Train Loss=2.17, validation loss=2.41] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:52<00:27,  1.64it/s, Train Loss=2.17, validation loss=2.41] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:52<00:27,  1.64it/s, Train Loss=1.84, validation loss=2.42] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:52<00:27,  1.63it/s, Train Loss=1.84, validation loss=2.42] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:53<00:27,  1.63it/s, Train Loss=1.36, validation loss=2.41] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:53<00:26,  1.59it/s, Train Loss=1.36, validation loss=2.41] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:54<00:26,  1.59it/s, Train Loss=2.28, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:54<00:27,  1.53it/s, Train Loss=2.28, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:54<00:27,  1.53it/s, Train Loss=2.26, validation loss=2.4]  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:54<00:26,  1.56it/s, Train Loss=2.26, validation loss=2.4] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:55<00:26,  1.56it/s, Train Loss=2, validation loss=2.41]   92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:55<00:25,  1.58it/s, Train Loss=2, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:55<00:25,  1.58it/s, Train Loss=2.17, validation loss=2.4] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:55<00:24,  1.60it/s, Train Loss=2.17, validation loss=2.4] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:56<00:24,  1.60it/s, Train Loss=2.51, validation loss=2.4] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:56<00:23,  1.59it/s, Train Loss=2.51, validation loss=2.4] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:57<00:23,  1.59it/s, Train Loss=2.6, validation loss=2.4]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:57<00:23,  1.58it/s, Train Loss=2.6, validation loss=2.4] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:57<00:23,  1.58it/s, Train Loss=2.48, validation loss=2.4] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:57<00:22,  1.57it/s, Train Loss=2.48, validation loss=2.4] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:58<00:22,  1.57it/s, Train Loss=2.42, validation loss=2.41] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:58<00:21,  1.59it/s, Train Loss=2.42, validation loss=2.41] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:59<00:21,  1.59it/s, Train Loss=2.12, validation loss=2.4]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:59<00:21,  1.59it/s, Train Loss=2.12, validation loss=2.4] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:59<00:21,  1.59it/s, Train Loss=3.66, validation loss=2.4] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [04:59<00:21,  1.52it/s, Train Loss=3.66, validation loss=2.4] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:00<00:21,  1.52it/s, Train Loss=1.75, validation loss=2.42] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:00<00:20,  1.53it/s, Train Loss=1.75, validation loss=2.42] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:01<00:20,  1.53it/s, Train Loss=1.94, validation loss=2.4]  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:01<00:20,  1.54it/s, Train Loss=1.94, validation loss=2.4] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:01<00:20,  1.54it/s, Train Loss=3.19, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:01<00:18,  1.58it/s, Train Loss=3.19, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:02<00:18,  1.58it/s, Train Loss=3.14, validation loss=2.42] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:02<00:18,  1.56it/s, Train Loss=3.14, validation loss=2.42] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:03<00:18,  1.56it/s, Train Loss=1.82, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:03<00:18,  1.50it/s, Train Loss=1.82, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:03<00:18,  1.50it/s, Train Loss=1.91, validation loss=2.41] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:03<00:17,  1.52it/s, Train Loss=1.91, validation loss=2.41] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:04<00:17,  1.52it/s, Train Loss=3.64, validation loss=2.4]  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:04<00:16,  1.55it/s, Train Loss=3.64, validation loss=2.4] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:04<00:16,  1.55it/s, Train Loss=1.66, validation loss=2.42] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:04<00:15,  1.57it/s, Train Loss=1.66, validation loss=2.42] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:05<00:15,  1.57it/s, Train Loss=1.41, validation loss=2.4]  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:05<00:15,  1.58it/s, Train Loss=1.41, validation loss=2.4] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:06<00:15,  1.58it/s, Train Loss=1.64, validation loss=2.4] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:06<00:14,  1.56it/s, Train Loss=1.64, validation loss=2.4] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:06<00:14,  1.56it/s, Train Loss=1.47, validation loss=2.42] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:06<00:14,  1.51it/s, Train Loss=1.47, validation loss=2.42] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:07<00:14,  1.51it/s, Train Loss=1.41, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:07<00:14,  1.47it/s, Train Loss=1.41, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:08<00:14,  1.47it/s, Train Loss=1.92, validation loss=2.4]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:08<00:13,  1.46it/s, Train Loss=1.92, validation loss=2.4] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:09<00:13,  1.46it/s, Train Loss=1.63, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:09<00:12,  1.52it/s, Train Loss=1.63, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:09<00:12,  1.52it/s, Train Loss=1.56, validation loss=2.42] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:09<00:11,  1.54it/s, Train Loss=1.56, validation loss=2.42] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:10<00:11,  1.54it/s, Train Loss=2.83, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:10<00:10,  1.56it/s, Train Loss=2.83, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:10<00:10,  1.56it/s, Train Loss=2.09, validation loss=2.4]  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:10<00:10,  1.58it/s, Train Loss=2.09, validation loss=2.4] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:11<00:10,  1.58it/s, Train Loss=2.41, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:11<00:09,  1.59it/s, Train Loss=2.41, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:12<00:09,  1.59it/s, Train Loss=1.78, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:12<00:08,  1.61it/s, Train Loss=1.78, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:12<00:08,  1.61it/s, Train Loss=1.79, validation loss=2.4]  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:12<00:08,  1.61it/s, Train Loss=1.79, validation loss=2.4] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:13<00:08,  1.61it/s, Train Loss=2.03, validation loss=2.4] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:13<00:07,  1.55it/s, Train Loss=2.03, validation loss=2.4] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:14<00:07,  1.55it/s, Train Loss=2.09, validation loss=2.4] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:14<00:07,  1.57it/s, Train Loss=2.09, validation loss=2.4] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:14<00:07,  1.57it/s, Train Loss=2.43, validation loss=2.41] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:14<00:06,  1.54it/s, Train Loss=2.43, validation loss=2.41] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:15<00:06,  1.54it/s, Train Loss=1.49, validation loss=2.41] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:15<00:05,  1.56it/s, Train Loss=1.49, validation loss=2.41] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:15<00:05,  1.56it/s, Train Loss=2.21, validation loss=2.4]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:15<00:05,  1.58it/s, Train Loss=2.21, validation loss=2.4] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:16<00:05,  1.58it/s, Train Loss=2.61, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:16<00:04,  1.57it/s, Train Loss=2.61, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:17<00:04,  1.57it/s, Train Loss=2.16, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:17<00:03,  1.58it/s, Train Loss=2.16, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:17<00:03,  1.58it/s, Train Loss=2.03, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:17<00:03,  1.59it/s, Train Loss=2.03, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:18<00:03,  1.59it/s, Train Loss=2.78, validation loss=2.42] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:18<00:02,  1.59it/s, Train Loss=2.78, validation loss=2.42] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:19<00:02,  1.59it/s, Train Loss=1.87, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:19<00:01,  1.61it/s, Train Loss=1.87, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:19<00:01,  1.61it/s, Train Loss=2.16, validation loss=2.42]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:19<00:01,  1.55it/s, Train Loss=2.16, validation loss=2.42]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:20<00:01,  1.55it/s, Train Loss=1.76, validation loss=2.41]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:20<00:00,  1.55it/s, Train Loss=1.76, validation loss=2.41]####################################################################################################
--------------------------------------------- Epoch:500 ---------------------------------------------
-- Training set:
Loss: 2.1532578468322754, Lr: 3.125e-05
Average AUC ROC: 0.54                Average AUC PR: 0.29
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:21<00:00,  1.55it/s, Train Loss=2.15, validation loss=2.41]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:21<00:00,  1.58it/s, Train Loss=2.15, validation loss=2.41]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:21<00:00,  1.56it/s, Train Loss=2.15, validation loss=2.41]
/home/students/tborsani/alzheimernet/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.4072040393948555
Average AUC ROC: 0.56                    Average AUC PR: 0.32

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 80
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=0, validation loss=0]  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=3.18, validation loss=3.22]  0%|          | 1/500 [00:00<05:09,  1.61it/s, Train Loss=3.18, validation loss=3.22]  0%|          | 1/500 [00:01<05:09,  1.61it/s, Train Loss=2.15, validation loss=3.08]  0%|          | 2/500 [00:01<05:01,  1.65it/s, Train Loss=2.15, validation loss=3.08]  0%|          | 2/500 [00:01<05:01,  1.65it/s, Train Loss=2.98, validation loss=2.94]  1%|          | 3/500 [00:01<05:07,  1.62it/s, Train Loss=2.98, validation loss=2.94]  1%|          | 3/500 [00:02<05:07,  1.62it/s, Train Loss=2.68, validation loss=2.91]  1%|          | 4/500 [00:02<05:39,  1.46it/s, Train Loss=2.68, validation loss=2.91]  1%|          | 4/500 [00:03<05:39,  1.46it/s, Train Loss=1.96, validation loss=2.82]  1%|          | 5/500 [00:03<05:26,  1.51it/s, Train Loss=1.96, validation loss=2.82]  1%|          | 5/500 [00:03<05:26,  1.51it/s, Train Loss=2.77, validation loss=2.79]  1%|          | 6/500 [00:03<05:24,  1.52it/s, Train Loss=2.77, validation loss=2.79]  1%|          | 6/500 [00:04<05:24,  1.52it/s, Train Loss=3.2, validation loss=2.77]   1%|â–         | 7/500 [00:04<05:16,  1.56it/s, Train Loss=3.2, validation loss=2.77]  1%|â–         | 7/500 [00:05<05:16,  1.56it/s, Train Loss=2.65, validation loss=2.78]  2%|â–         | 8/500 [00:05<05:18,  1.55it/s, Train Loss=2.65, validation loss=2.78]  2%|â–         | 8/500 [00:05<05:18,  1.55it/s, Train Loss=2.94, validation loss=2.75]  2%|â–         | 9/500 [00:05<05:28,  1.50it/s, Train Loss=2.94, validation loss=2.75]  2%|â–         | 9/500 [00:06<05:28,  1.50it/s, Train Loss=3.11, validation loss=2.75]  2%|â–         | 10/500 [00:06<05:16,  1.55it/s, Train Loss=3.11, validation loss=2.75]  2%|â–         | 10/500 [00:07<05:16,  1.55it/s, Train Loss=3.45, validation loss=2.76]  2%|â–         | 11/500 [00:07<05:09,  1.58it/s, Train Loss=3.45, validation loss=2.76]  2%|â–         | 11/500 [00:07<05:09,  1.58it/s, Train Loss=5.45, validation loss=2.73]  2%|â–         | 12/500 [00:07<05:26,  1.49it/s, Train Loss=5.45, validation loss=2.73]  2%|â–         | 12/500 [00:08<05:26,  1.49it/s, Train Loss=3.07, validation loss=2.75]  3%|â–         | 13/500 [00:08<05:14,  1.55it/s, Train Loss=3.07, validation loss=2.75]  3%|â–         | 13/500 [00:09<05:14,  1.55it/s, Train Loss=2.85, validation loss=2.76]  3%|â–         | 14/500 [00:09<05:11,  1.56it/s, Train Loss=2.85, validation loss=2.76]  3%|â–         | 14/500 [00:09<05:11,  1.56it/s, Train Loss=3.15, validation loss=2.72]  3%|â–         | 15/500 [00:09<05:07,  1.57it/s, Train Loss=3.15, validation loss=2.72]  3%|â–         | 15/500 [00:10<05:07,  1.57it/s, Train Loss=1.89, validation loss=2.72]  3%|â–         | 16/500 [00:10<05:04,  1.59it/s, Train Loss=1.89, validation loss=2.72]  3%|â–         | 16/500 [00:10<05:04,  1.59it/s, Train Loss=2.99, validation loss=2.73]  3%|â–         | 17/500 [00:10<05:01,  1.60it/s, Train Loss=2.99, validation loss=2.73]  3%|â–         | 17/500 [00:11<05:01,  1.60it/s, Train Loss=2.43, validation loss=2.71]  4%|â–         | 18/500 [00:11<04:59,  1.61it/s, Train Loss=2.43, validation loss=2.71]  4%|â–         | 18/500 [00:12<04:59,  1.61it/s, Train Loss=3.26, validation loss=2.71]  4%|â–         | 19/500 [00:12<05:02,  1.59it/s, Train Loss=3.26, validation loss=2.71]  4%|â–         | 19/500 [00:12<05:02,  1.59it/s, Train Loss=1.92, validation loss=2.69]  4%|â–         | 20/500 [00:12<05:02,  1.59it/s, Train Loss=1.92, validation loss=2.69]  4%|â–         | 20/500 [00:13<05:02,  1.59it/s, Train Loss=2.18, validation loss=2.69]  4%|â–         | 21/500 [00:13<05:20,  1.49it/s, Train Loss=2.18, validation loss=2.69]  4%|â–         | 21/500 [00:14<05:20,  1.49it/s, Train Loss=3.66, validation loss=2.71]  4%|â–         | 22/500 [00:14<05:16,  1.51it/s, Train Loss=3.66, validation loss=2.71]  4%|â–         | 22/500 [00:14<05:16,  1.51it/s, Train Loss=4.33, validation loss=2.7]   5%|â–         | 23/500 [00:14<05:12,  1.52it/s, Train Loss=4.33, validation loss=2.7]  5%|â–         | 23/500 [00:15<05:12,  1.52it/s, Train Loss=2.38, validation loss=2.68]  5%|â–         | 24/500 [00:15<05:10,  1.53it/s, Train Loss=2.38, validation loss=2.68]  5%|â–         | 24/500 [00:16<05:10,  1.53it/s, Train Loss=1.99, validation loss=2.67]  5%|â–Œ         | 25/500 [00:16<05:08,  1.54it/s, Train Loss=1.99, validation loss=2.67]  5%|â–Œ         | 25/500 [00:16<05:08,  1.54it/s, Train Loss=2.54, validation loss=2.67]  5%|â–Œ         | 26/500 [00:16<05:04,  1.55it/s, Train Loss=2.54, validation loss=2.67]  5%|â–Œ         | 26/500 [00:17<05:04,  1.55it/s, Train Loss=4.03, validation loss=2.62]  5%|â–Œ         | 27/500 [00:17<04:58,  1.59it/s, Train Loss=4.03, validation loss=2.62]  5%|â–Œ         | 27/500 [00:18<04:58,  1.59it/s, Train Loss=1.98, validation loss=2.67]  6%|â–Œ         | 28/500 [00:18<05:00,  1.57it/s, Train Loss=1.98, validation loss=2.67]  6%|â–Œ         | 28/500 [00:18<05:00,  1.57it/s, Train Loss=4.06, validation loss=2.67]  6%|â–Œ         | 29/500 [00:18<05:22,  1.46it/s, Train Loss=4.06, validation loss=2.67]  6%|â–Œ         | 29/500 [00:19<05:22,  1.46it/s, Train Loss=2.4, validation loss=2.66]   6%|â–Œ         | 30/500 [00:19<05:12,  1.50it/s, Train Loss=2.4, validation loss=2.66]  6%|â–Œ         | 30/500 [00:20<05:12,  1.50it/s, Train Loss=2.4, validation loss=2.66]  6%|â–Œ         | 31/500 [00:20<05:03,  1.54it/s, Train Loss=2.4, validation loss=2.66]  6%|â–Œ         | 31/500 [00:20<05:03,  1.54it/s, Train Loss=2.69, validation loss=2.66]  6%|â–‹         | 32/500 [00:20<05:00,  1.56it/s, Train Loss=2.69, validation loss=2.66]  6%|â–‹         | 32/500 [00:21<05:00,  1.56it/s, Train Loss=1.98, validation loss=2.66]  7%|â–‹         | 33/500 [00:21<04:59,  1.56it/s, Train Loss=1.98, validation loss=2.66]  7%|â–‹         | 33/500 [00:21<04:59,  1.56it/s, Train Loss=2.79, validation loss=2.66]  7%|â–‹         | 34/500 [00:21<04:57,  1.57it/s, Train Loss=2.79, validation loss=2.66]  7%|â–‹         | 34/500 [00:22<04:57,  1.57it/s, Train Loss=1.78, validation loss=2.65]  7%|â–‹         | 35/500 [00:22<04:52,  1.59it/s, Train Loss=1.78, validation loss=2.65]  7%|â–‹         | 35/500 [00:23<04:52,  1.59it/s, Train Loss=3.18, validation loss=2.65]  7%|â–‹         | 36/500 [00:23<05:08,  1.50it/s, Train Loss=3.18, validation loss=2.65]  7%|â–‹         | 36/500 [00:23<05:08,  1.50it/s, Train Loss=1.98, validation loss=2.63]  7%|â–‹         | 37/500 [00:23<05:01,  1.54it/s, Train Loss=1.98, validation loss=2.63]  7%|â–‹         | 37/500 [00:24<05:01,  1.54it/s, Train Loss=2.05, validation loss=2.62]  8%|â–Š         | 38/500 [00:24<04:59,  1.54it/s, Train Loss=2.05, validation loss=2.62]  8%|â–Š         | 38/500 [00:25<04:59,  1.54it/s, Train Loss=1.69, validation loss=2.61]  8%|â–Š         | 39/500 [00:25<04:54,  1.57it/s, Train Loss=1.69, validation loss=2.61]  8%|â–Š         | 39/500 [00:25<04:54,  1.57it/s, Train Loss=3.94, validation loss=2.61]  8%|â–Š         | 40/500 [00:25<05:03,  1.52it/s, Train Loss=3.94, validation loss=2.61]  8%|â–Š         | 40/500 [00:26<05:03,  1.52it/s, Train Loss=1.5, validation loss=2.61]   8%|â–Š         | 41/500 [00:26<05:09,  1.49it/s, Train Loss=1.5, validation loss=2.61]  8%|â–Š         | 41/500 [00:27<05:09,  1.49it/s, Train Loss=3.8, validation loss=2.63]  8%|â–Š         | 42/500 [00:27<05:01,  1.52it/s, Train Loss=3.8, validation loss=2.63]  8%|â–Š         | 42/500 [00:27<05:01,  1.52it/s, Train Loss=2.41, validation loss=2.63]  9%|â–Š         | 43/500 [00:27<04:59,  1.53it/s, Train Loss=2.41, validation loss=2.63]  9%|â–Š         | 43/500 [00:28<04:59,  1.53it/s, Train Loss=3.21, validation loss=2.6]   9%|â–‰         | 44/500 [00:28<05:18,  1.43it/s, Train Loss=3.21, validation loss=2.6]  9%|â–‰         | 44/500 [00:29<05:18,  1.43it/s, Train Loss=2.33, validation loss=2.59]  9%|â–‰         | 45/500 [00:29<05:07,  1.48it/s, Train Loss=2.33, validation loss=2.59]  9%|â–‰         | 45/500 [00:29<05:07,  1.48it/s, Train Loss=2.27, validation loss=2.59]  9%|â–‰         | 46/500 [00:29<04:58,  1.52it/s, Train Loss=2.27, validation loss=2.59]  9%|â–‰         | 46/500 [00:30<04:58,  1.52it/s, Train Loss=2.46, validation loss=2.6]   9%|â–‰         | 47/500 [00:30<04:54,  1.54it/s, Train Loss=2.46, validation loss=2.6]  9%|â–‰         | 47/500 [00:31<04:54,  1.54it/s, Train Loss=2.03, validation loss=2.63] 10%|â–‰         | 48/500 [00:31<04:48,  1.57it/s, Train Loss=2.03, validation loss=2.63] 10%|â–‰         | 48/500 [00:31<04:48,  1.57it/s, Train Loss=1.95, validation loss=2.61] 10%|â–‰         | 49/500 [00:31<04:47,  1.57it/s, Train Loss=1.95, validation loss=2.61] 10%|â–‰         | 49/500 [00:32<04:47,  1.57it/s, Train Loss=2.21, validation loss=2.59] 10%|â–ˆ         | 50/500 [00:32<04:41,  1.60it/s, Train Loss=2.21, validation loss=2.59] 10%|â–ˆ         | 50/500 [00:32<04:41,  1.60it/s, Train Loss=3.7, validation loss=2.57]  10%|â–ˆ         | 51/500 [00:32<04:40,  1.60it/s, Train Loss=3.7, validation loss=2.57] 10%|â–ˆ         | 51/500 [00:33<04:40,  1.60it/s, Train Loss=2.25, validation loss=2.58] 10%|â–ˆ         | 52/500 [00:33<04:51,  1.54it/s, Train Loss=2.25, validation loss=2.58] 10%|â–ˆ         | 52/500 [00:34<04:51,  1.54it/s, Train Loss=2.27, validation loss=2.57] 11%|â–ˆ         | 53/500 [00:34<04:55,  1.51it/s, Train Loss=2.27, validation loss=2.57] 11%|â–ˆ         | 53/500 [00:35<04:55,  1.51it/s, Train Loss=2.35, validation loss=2.58] 11%|â–ˆ         | 54/500 [00:35<04:48,  1.54it/s, Train Loss=2.35, validation loss=2.58] 11%|â–ˆ         | 54/500 [00:35<04:48,  1.54it/s, Train Loss=3.19, validation loss=2.57] 11%|â–ˆ         | 55/500 [00:35<04:42,  1.58it/s, Train Loss=3.19, validation loss=2.57] 11%|â–ˆ         | 55/500 [00:36<04:42,  1.58it/s, Train Loss=3.67, validation loss=2.58] 11%|â–ˆ         | 56/500 [00:36<04:37,  1.60it/s, Train Loss=3.67, validation loss=2.58] 11%|â–ˆ         | 56/500 [00:36<04:37,  1.60it/s, Train Loss=2.47, validation loss=2.59] 11%|â–ˆâ–        | 57/500 [00:36<04:32,  1.63it/s, Train Loss=2.47, validation loss=2.59] 11%|â–ˆâ–        | 57/500 [00:37<04:32,  1.63it/s, Train Loss=1.91, validation loss=2.59] 12%|â–ˆâ–        | 58/500 [00:37<04:32,  1.62it/s, Train Loss=1.91, validation loss=2.59] 12%|â–ˆâ–        | 58/500 [00:38<04:32,  1.62it/s, Train Loss=2.25, validation loss=2.56] 12%|â–ˆâ–        | 59/500 [00:38<04:37,  1.59it/s, Train Loss=2.25, validation loss=2.56] 12%|â–ˆâ–        | 59/500 [00:38<04:37,  1.59it/s, Train Loss=3.06, validation loss=2.58] 12%|â–ˆâ–        | 60/500 [00:38<04:32,  1.61it/s, Train Loss=3.06, validation loss=2.58] 12%|â–ˆâ–        | 60/500 [00:39<04:32,  1.61it/s, Train Loss=2.02, validation loss=2.57] 12%|â–ˆâ–        | 61/500 [00:39<04:56,  1.48it/s, Train Loss=2.02, validation loss=2.57] 12%|â–ˆâ–        | 61/500 [00:40<04:56,  1.48it/s, Train Loss=1.72, validation loss=2.57] 12%|â–ˆâ–        | 62/500 [00:40<04:49,  1.51it/s, Train Loss=1.72, validation loss=2.57] 12%|â–ˆâ–        | 62/500 [00:40<04:49,  1.51it/s, Train Loss=2.37, validation loss=2.57] 13%|â–ˆâ–        | 63/500 [00:40<04:43,  1.54it/s, Train Loss=2.37, validation loss=2.57] 13%|â–ˆâ–        | 63/500 [00:41<04:43,  1.54it/s, Train Loss=3.1, validation loss=2.55]  13%|â–ˆâ–        | 64/500 [00:41<04:42,  1.54it/s, Train Loss=3.1, validation loss=2.55] 13%|â–ˆâ–        | 64/500 [00:42<04:42,  1.54it/s, Train Loss=2.02, validation loss=2.55] 13%|â–ˆâ–        | 65/500 [00:42<04:45,  1.52it/s, Train Loss=2.02, validation loss=2.55] 13%|â–ˆâ–        | 65/500 [00:42<04:45,  1.52it/s, Train Loss=4.2, validation loss=2.54]  13%|â–ˆâ–        | 66/500 [00:42<04:41,  1.54it/s, Train Loss=4.2, validation loss=2.54] 13%|â–ˆâ–        | 66/500 [00:43<04:41,  1.54it/s, Train Loss=2.31, validation loss=2.55] 13%|â–ˆâ–        | 67/500 [00:43<04:39,  1.55it/s, Train Loss=2.31, validation loss=2.55] 13%|â–ˆâ–        | 67/500 [00:44<04:39,  1.55it/s, Train Loss=2.12, validation loss=2.55] 14%|â–ˆâ–        | 68/500 [00:44<04:52,  1.48it/s, Train Loss=2.12, validation loss=2.55] 14%|â–ˆâ–        | 68/500 [00:44<04:52,  1.48it/s, Train Loss=2.15, validation loss=2.53] 14%|â–ˆâ–        | 69/500 [00:44<04:44,  1.51it/s, Train Loss=2.15, validation loss=2.53] 14%|â–ˆâ–        | 69/500 [00:45<04:44,  1.51it/s, Train Loss=1.28, validation loss=2.53] 14%|â–ˆâ–        | 70/500 [00:45<04:37,  1.55it/s, Train Loss=1.28, validation loss=2.53] 14%|â–ˆâ–        | 70/500 [00:45<04:37,  1.55it/s, Train Loss=2.6, validation loss=2.52]  14%|â–ˆâ–        | 71/500 [00:45<04:32,  1.57it/s, Train Loss=2.6, validation loss=2.52] 14%|â–ˆâ–        | 71/500 [00:46<04:32,  1.57it/s, Train Loss=2.51, validation loss=2.51] 14%|â–ˆâ–        | 72/500 [00:46<04:35,  1.55it/s, Train Loss=2.51, validation loss=2.51] 14%|â–ˆâ–        | 72/500 [00:47<04:35,  1.55it/s, Train Loss=3.38, validation loss=2.53] 15%|â–ˆâ–        | 73/500 [00:47<04:44,  1.50it/s, Train Loss=3.38, validation loss=2.53] 15%|â–ˆâ–        | 73/500 [00:47<04:44,  1.50it/s, Train Loss=2.08, validation loss=2.52] 15%|â–ˆâ–        | 74/500 [00:47<04:38,  1.53it/s, Train Loss=2.08, validation loss=2.52] 15%|â–ˆâ–        | 74/500 [00:48<04:38,  1.53it/s, Train Loss=3.05, validation loss=2.53] 15%|â–ˆâ–Œ        | 75/500 [00:48<04:32,  1.56it/s, Train Loss=3.05, validation loss=2.53] 15%|â–ˆâ–Œ        | 75/500 [00:49<04:32,  1.56it/s, Train Loss=2.89, validation loss=2.52] 15%|â–ˆâ–Œ        | 76/500 [00:49<04:39,  1.52it/s, Train Loss=2.89, validation loss=2.52] 15%|â–ˆâ–Œ        | 76/500 [00:49<04:39,  1.52it/s, Train Loss=2.98, validation loss=2.53] 15%|â–ˆâ–Œ        | 77/500 [00:49<04:37,  1.52it/s, Train Loss=2.98, validation loss=2.53] 15%|â–ˆâ–Œ        | 77/500 [00:50<04:37,  1.52it/s, Train Loss=2.56, validation loss=2.53] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:30,  1.56it/s, Train Loss=2.56, validation loss=2.53] 16%|â–ˆâ–Œ        | 78/500 [00:51<04:30,  1.56it/s, Train Loss=2.3, validation loss=2.52]  16%|â–ˆâ–Œ        | 79/500 [00:51<04:28,  1.57it/s, Train Loss=2.3, validation loss=2.52] 16%|â–ˆâ–Œ        | 79/500 [00:51<04:28,  1.57it/s, Train Loss=3.39, validation loss=2.49] 16%|â–ˆâ–Œ        | 80/500 [00:51<04:24,  1.59it/s, Train Loss=3.39, validation loss=2.49] 16%|â–ˆâ–Œ        | 80/500 [00:52<04:24,  1.59it/s, Train Loss=2.32, validation loss=2.49] 16%|â–ˆâ–Œ        | 81/500 [00:52<04:26,  1.57it/s, Train Loss=2.32, validation loss=2.49] 16%|â–ˆâ–Œ        | 81/500 [00:52<04:26,  1.57it/s, Train Loss=1.49, validation loss=2.51] 16%|â–ˆâ–‹        | 82/500 [00:52<04:20,  1.60it/s, Train Loss=1.49, validation loss=2.51] 16%|â–ˆâ–‹        | 82/500 [00:53<04:20,  1.60it/s, Train Loss=2.65, validation loss=2.51] 17%|â–ˆâ–‹        | 83/500 [00:53<04:25,  1.57it/s, Train Loss=2.65, validation loss=2.51] 17%|â–ˆâ–‹        | 83/500 [00:54<04:25,  1.57it/s, Train Loss=1.72, validation loss=2.51] 17%|â–ˆâ–‹        | 84/500 [00:54<04:28,  1.55it/s, Train Loss=1.72, validation loss=2.51] 17%|â–ˆâ–‹        | 84/500 [00:54<04:28,  1.55it/s, Train Loss=2.09, validation loss=2.47] 17%|â–ˆâ–‹        | 85/500 [00:54<04:24,  1.57it/s, Train Loss=2.09, validation loss=2.47] 17%|â–ˆâ–‹        | 85/500 [00:55<04:24,  1.57it/s, Train Loss=2.37, validation loss=2.49] 17%|â–ˆâ–‹        | 86/500 [00:55<04:25,  1.56it/s, Train Loss=2.37, validation loss=2.49] 17%|â–ˆâ–‹        | 86/500 [00:56<04:25,  1.56it/s, Train Loss=2.82, validation loss=2.49] 17%|â–ˆâ–‹        | 87/500 [00:56<04:21,  1.58it/s, Train Loss=2.82, validation loss=2.49] 17%|â–ˆâ–‹        | 87/500 [00:56<04:21,  1.58it/s, Train Loss=1.92, validation loss=2.51] 18%|â–ˆâ–Š        | 88/500 [00:56<04:19,  1.59it/s, Train Loss=1.92, validation loss=2.51] 18%|â–ˆâ–Š        | 88/500 [00:57<04:19,  1.59it/s, Train Loss=1.79, validation loss=2.49] 18%|â–ˆâ–Š        | 89/500 [00:57<04:16,  1.60it/s, Train Loss=1.79, validation loss=2.49] 18%|â–ˆâ–Š        | 89/500 [00:58<04:16,  1.60it/s, Train Loss=1.56, validation loss=2.49] 18%|â–ˆâ–Š        | 90/500 [00:58<04:16,  1.60it/s, Train Loss=1.56, validation loss=2.49] 18%|â–ˆâ–Š        | 90/500 [00:58<04:16,  1.60it/s, Train Loss=1.96, validation loss=2.49] 18%|â–ˆâ–Š        | 91/500 [00:58<04:32,  1.50it/s, Train Loss=1.96, validation loss=2.49] 18%|â–ˆâ–Š        | 91/500 [00:59<04:32,  1.50it/s, Train Loss=4.07, validation loss=2.5]  18%|â–ˆâ–Š        | 92/500 [00:59<04:26,  1.53it/s, Train Loss=4.07, validation loss=2.5] 18%|â–ˆâ–Š        | 92/500 [01:00<04:26,  1.53it/s, Train Loss=3.42, validation loss=2.49] 19%|â–ˆâ–Š        | 93/500 [01:00<04:17,  1.58it/s, Train Loss=3.42, validation loss=2.49] 19%|â–ˆâ–Š        | 93/500 [01:00<04:17,  1.58it/s, Train Loss=1.97, validation loss=2.49] 19%|â–ˆâ–‰        | 94/500 [01:00<04:11,  1.61it/s, Train Loss=1.97, validation loss=2.49] 19%|â–ˆâ–‰        | 94/500 [01:01<04:11,  1.61it/s, Train Loss=2.16, validation loss=2.49] 19%|â–ˆâ–‰        | 95/500 [01:01<04:11,  1.61it/s, Train Loss=2.16, validation loss=2.49] 19%|â–ˆâ–‰        | 95/500 [01:01<04:11,  1.61it/s, Train Loss=2.39, validation loss=2.48] 19%|â–ˆâ–‰        | 96/500 [01:01<04:16,  1.57it/s, Train Loss=2.39, validation loss=2.48] 19%|â–ˆâ–‰        | 96/500 [01:02<04:16,  1.57it/s, Train Loss=3.42, validation loss=2.47] 19%|â–ˆâ–‰        | 97/500 [01:02<04:13,  1.59it/s, Train Loss=3.42, validation loss=2.47] 19%|â–ˆâ–‰        | 97/500 [01:03<04:13,  1.59it/s, Train Loss=1.74, validation loss=2.47] 20%|â–ˆâ–‰        | 98/500 [01:03<04:11,  1.60it/s, Train Loss=1.74, validation loss=2.47] 20%|â–ˆâ–‰        | 98/500 [01:03<04:11,  1.60it/s, Train Loss=2.25, validation loss=2.48] 20%|â–ˆâ–‰        | 99/500 [01:03<04:25,  1.51it/s, Train Loss=2.25, validation loss=2.48]####################################################################################################
--------------------------------------------- Epoch:100 ---------------------------------------------
-- Training set:
Loss: 1.8320820331573486, Lr: 0.0005
Average AUC ROC: 0.51                Average AUC PR: 0.28
 20%|â–ˆâ–‰        | 99/500 [01:04<04:25,  1.51it/s, Train Loss=1.83, validation loss=2.46] 20%|â–ˆâ–ˆ        | 100/500 [01:04<04:18,  1.55it/s, Train Loss=1.83, validation loss=2.46]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.4582835733890533
Average AUC ROC: 0.54                    Average AUC PR: 0.31
 20%|â–ˆâ–ˆ        | 100/500 [01:05<04:18,  1.55it/s, Train Loss=1.65, validation loss=2.46] 20%|â–ˆâ–ˆ        | 101/500 [01:05<04:14,  1.57it/s, Train Loss=1.65, validation loss=2.46] 20%|â–ˆâ–ˆ        | 101/500 [01:05<04:14,  1.57it/s, Train Loss=2.23, validation loss=2.44] 20%|â–ˆâ–ˆ        | 102/500 [01:05<04:10,  1.59it/s, Train Loss=2.23, validation loss=2.44] 20%|â–ˆâ–ˆ        | 102/500 [01:06<04:10,  1.59it/s, Train Loss=2.1, validation loss=2.46]  21%|â–ˆâ–ˆ        | 103/500 [01:06<04:07,  1.60it/s, Train Loss=2.1, validation loss=2.46] 21%|â–ˆâ–ˆ        | 103/500 [01:07<04:07,  1.60it/s, Train Loss=2.83, validation loss=2.47] 21%|â–ˆâ–ˆ        | 104/500 [01:07<04:17,  1.54it/s, Train Loss=2.83, validation loss=2.47] 21%|â–ˆâ–ˆ        | 104/500 [01:07<04:17,  1.54it/s, Train Loss=4.37, validation loss=2.47] 21%|â–ˆâ–ˆ        | 105/500 [01:07<04:22,  1.51it/s, Train Loss=4.37, validation loss=2.47] 21%|â–ˆâ–ˆ        | 105/500 [01:08<04:22,  1.51it/s, Train Loss=2.44, validation loss=2.45] 21%|â–ˆâ–ˆ        | 106/500 [01:08<04:24,  1.49it/s, Train Loss=2.44, validation loss=2.45] 21%|â–ˆâ–ˆ        | 106/500 [01:09<04:24,  1.49it/s, Train Loss=1.92, validation loss=2.46] 21%|â–ˆâ–ˆâ–       | 107/500 [01:09<04:21,  1.50it/s, Train Loss=1.92, validation loss=2.46] 21%|â–ˆâ–ˆâ–       | 107/500 [01:09<04:21,  1.50it/s, Train Loss=2.08, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 108/500 [01:09<04:17,  1.52it/s, Train Loss=2.08, validation loss=2.46] 22%|â–ˆâ–ˆâ–       | 108/500 [01:10<04:17,  1.52it/s, Train Loss=2.09, validation loss=2.45] 22%|â–ˆâ–ˆâ–       | 109/500 [01:10<04:11,  1.56it/s, Train Loss=2.09, validation loss=2.45] 22%|â–ˆâ–ˆâ–       | 109/500 [01:10<04:11,  1.56it/s, Train Loss=2.42, validation loss=2.45] 22%|â–ˆâ–ˆâ–       | 110/500 [01:10<04:08,  1.57it/s, Train Loss=2.42, validation loss=2.45] 22%|â–ˆâ–ˆâ–       | 110/500 [01:11<04:08,  1.57it/s, Train Loss=1.52, validation loss=2.45] 22%|â–ˆâ–ˆâ–       | 111/500 [01:11<04:08,  1.56it/s, Train Loss=1.52, validation loss=2.45] 22%|â–ˆâ–ˆâ–       | 111/500 [01:12<04:08,  1.56it/s, Train Loss=1.72, validation loss=2.45] 22%|â–ˆâ–ˆâ–       | 112/500 [01:12<04:05,  1.58it/s, Train Loss=1.72, validation loss=2.45] 22%|â–ˆâ–ˆâ–       | 112/500 [01:12<04:05,  1.58it/s, Train Loss=1.99, validation loss=2.46] 23%|â–ˆâ–ˆâ–       | 113/500 [01:12<04:05,  1.58it/s, Train Loss=1.99, validation loss=2.46] 23%|â–ˆâ–ˆâ–       | 113/500 [01:13<04:05,  1.58it/s, Train Loss=1.98, validation loss=2.45] 23%|â–ˆâ–ˆâ–       | 114/500 [01:13<04:17,  1.50it/s, Train Loss=1.98, validation loss=2.45] 23%|â–ˆâ–ˆâ–       | 114/500 [01:14<04:17,  1.50it/s, Train Loss=1.53, validation loss=2.46] 23%|â–ˆâ–ˆâ–       | 115/500 [01:14<04:10,  1.53it/s, Train Loss=1.53, validation loss=2.46] 23%|â–ˆâ–ˆâ–       | 115/500 [01:14<04:10,  1.53it/s, Train Loss=2.85, validation loss=2.46] 23%|â–ˆâ–ˆâ–       | 116/500 [01:14<04:06,  1.55it/s, Train Loss=2.85, validation loss=2.46] 23%|â–ˆâ–ˆâ–       | 116/500 [01:15<04:06,  1.55it/s, Train Loss=1.92, validation loss=2.45] 23%|â–ˆâ–ˆâ–       | 117/500 [01:15<04:05,  1.56it/s, Train Loss=1.92, validation loss=2.45] 23%|â–ˆâ–ˆâ–       | 117/500 [01:16<04:05,  1.56it/s, Train Loss=3.05, validation loss=2.44] 24%|â–ˆâ–ˆâ–       | 118/500 [01:16<04:01,  1.58it/s, Train Loss=3.05, validation loss=2.44] 24%|â–ˆâ–ˆâ–       | 118/500 [01:16<04:01,  1.58it/s, Train Loss=1.74, validation loss=2.44] 24%|â–ˆâ–ˆâ–       | 119/500 [01:16<03:59,  1.59it/s, Train Loss=1.74, validation loss=2.44] 24%|â–ˆâ–ˆâ–       | 119/500 [01:17<03:59,  1.59it/s, Train Loss=1.65, validation loss=2.43] 24%|â–ˆâ–ˆâ–       | 120/500 [01:17<03:58,  1.60it/s, Train Loss=1.65, validation loss=2.43] 24%|â–ˆâ–ˆâ–       | 120/500 [01:17<03:58,  1.60it/s, Train Loss=2.47, validation loss=2.44] 24%|â–ˆâ–ˆâ–       | 121/500 [01:18<04:03,  1.56it/s, Train Loss=2.47, validation loss=2.44] 24%|â–ˆâ–ˆâ–       | 121/500 [01:18<04:03,  1.56it/s, Train Loss=2, validation loss=2.43]    24%|â–ˆâ–ˆâ–       | 122/500 [01:18<04:07,  1.53it/s, Train Loss=2, validation loss=2.43] 24%|â–ˆâ–ˆâ–       | 122/500 [01:19<04:07,  1.53it/s, Train Loss=2.91, validation loss=2.44] 25%|â–ˆâ–ˆâ–       | 123/500 [01:19<04:04,  1.54it/s, Train Loss=2.91, validation loss=2.44] 25%|â–ˆâ–ˆâ–       | 123/500 [01:19<04:04,  1.54it/s, Train Loss=1.75, validation loss=2.44] 25%|â–ˆâ–ˆâ–       | 124/500 [01:19<03:59,  1.57it/s, Train Loss=1.75, validation loss=2.44] 25%|â–ˆâ–ˆâ–       | 124/500 [01:20<03:59,  1.57it/s, Train Loss=1.74, validation loss=2.43] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:20<04:03,  1.54it/s, Train Loss=1.74, validation loss=2.43] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:21<04:03,  1.54it/s, Train Loss=2.96, validation loss=2.44] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:21<03:57,  1.58it/s, Train Loss=2.96, validation loss=2.44] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:21<03:57,  1.58it/s, Train Loss=1.93, validation loss=2.45] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:21<03:55,  1.58it/s, Train Loss=1.93, validation loss=2.45] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:22<03:55,  1.58it/s, Train Loss=2.45, validation loss=2.43] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:22<03:53,  1.59it/s, Train Loss=2.45, validation loss=2.43] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:23<03:53,  1.59it/s, Train Loss=1.83, validation loss=2.44] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:23<04:09,  1.49it/s, Train Loss=1.83, validation loss=2.44] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:23<04:09,  1.49it/s, Train Loss=2.06, validation loss=2.43] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:23<04:04,  1.51it/s, Train Loss=2.06, validation loss=2.43] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:24<04:04,  1.51it/s, Train Loss=1.88, validation loss=2.43] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:24<03:59,  1.54it/s, Train Loss=1.88, validation loss=2.43] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:25<03:59,  1.54it/s, Train Loss=4.21, validation loss=2.43] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:25<03:53,  1.57it/s, Train Loss=4.21, validation loss=2.43] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:25<03:53,  1.57it/s, Train Loss=3.07, validation loss=2.44] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:25<03:52,  1.58it/s, Train Loss=3.07, validation loss=2.44] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:26<03:52,  1.58it/s, Train Loss=2.43, validation loss=2.43] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:26<03:48,  1.60it/s, Train Loss=2.43, validation loss=2.43] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:26<03:48,  1.60it/s, Train Loss=1.9, validation loss=2.43]  27%|â–ˆâ–ˆâ–‹       | 135/500 [01:26<03:45,  1.62it/s, Train Loss=1.9, validation loss=2.43] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:27<03:45,  1.62it/s, Train Loss=1.81, validation loss=2.44] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:27<03:55,  1.55it/s, Train Loss=1.81, validation loss=2.44] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:28<03:55,  1.55it/s, Train Loss=2.77, validation loss=2.44] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:28<04:02,  1.49it/s, Train Loss=2.77, validation loss=2.44] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:28<04:02,  1.49it/s, Train Loss=1.54, validation loss=2.43] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:28<03:57,  1.52it/s, Train Loss=1.54, validation loss=2.43] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:29<03:57,  1.52it/s, Train Loss=2.47, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:29<03:52,  1.55it/s, Train Loss=2.47, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:30<03:52,  1.55it/s, Train Loss=2.73, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:30<03:50,  1.56it/s, Train Loss=2.73, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:30<03:50,  1.56it/s, Train Loss=1.91, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:30<03:46,  1.59it/s, Train Loss=1.91, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:31<03:46,  1.59it/s, Train Loss=2.81, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:31<03:45,  1.59it/s, Train Loss=2.81, validation loss=2.45] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:32<03:45,  1.59it/s, Train Loss=3.26, validation loss=2.45] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:32<03:45,  1.58it/s, Train Loss=3.26, validation loss=2.45] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:32<03:45,  1.58it/s, Train Loss=3.08, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:32<03:57,  1.50it/s, Train Loss=3.08, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:33<03:57,  1.50it/s, Train Loss=2.41, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:33<03:50,  1.54it/s, Train Loss=2.41, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:34<03:50,  1.54it/s, Train Loss=2.46, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:34<03:47,  1.56it/s, Train Loss=2.46, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:34<03:47,  1.56it/s, Train Loss=1.74, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:34<03:45,  1.57it/s, Train Loss=1.74, validation loss=2.45] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:35<03:45,  1.57it/s, Train Loss=1.81, validation loss=2.45] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:35<03:45,  1.56it/s, Train Loss=1.81, validation loss=2.45] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:36<03:45,  1.56it/s, Train Loss=2.54, validation loss=2.44] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:36<03:46,  1.55it/s, Train Loss=2.54, validation loss=2.44] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:36<03:46,  1.55it/s, Train Loss=2.21, validation loss=2.43] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:36<03:46,  1.55it/s, Train Loss=2.21, validation loss=2.43] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:37<03:46,  1.55it/s, Train Loss=1.57, validation loss=2.43] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:37<03:55,  1.48it/s, Train Loss=1.57, validation loss=2.43] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:38<03:55,  1.48it/s, Train Loss=2.41, validation loss=2.43] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:38<03:49,  1.52it/s, Train Loss=2.41, validation loss=2.43] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:38<03:49,  1.52it/s, Train Loss=2.71, validation loss=2.42] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:38<03:50,  1.50it/s, Train Loss=2.71, validation loss=2.42] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:39<03:50,  1.50it/s, Train Loss=2.37, validation loss=2.44] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:39<03:46,  1.53it/s, Train Loss=2.37, validation loss=2.44] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:39<03:46,  1.53it/s, Train Loss=1.77, validation loss=2.44] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:39<03:42,  1.55it/s, Train Loss=1.77, validation loss=2.44] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:40<03:42,  1.55it/s, Train Loss=2.36, validation loss=2.43] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:40<03:39,  1.57it/s, Train Loss=2.36, validation loss=2.43] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:41<03:39,  1.57it/s, Train Loss=2.06, validation loss=2.43] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:41<03:49,  1.49it/s, Train Loss=2.06, validation loss=2.43] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:41<03:49,  1.49it/s, Train Loss=2.79, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:41<03:43,  1.53it/s, Train Loss=2.79, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:42<03:43,  1.53it/s, Train Loss=2.4, validation loss=2.44]  32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:42<03:44,  1.52it/s, Train Loss=2.4, validation loss=2.44] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:43<03:44,  1.52it/s, Train Loss=2.64, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:43<03:38,  1.55it/s, Train Loss=2.64, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:43<03:38,  1.55it/s, Train Loss=1.35, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:43<03:35,  1.58it/s, Train Loss=1.35, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:44<03:35,  1.58it/s, Train Loss=2.09, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:44<03:35,  1.57it/s, Train Loss=2.09, validation loss=2.43] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:45<03:35,  1.57it/s, Train Loss=1.94, validation loss=2.45] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:45<03:34,  1.57it/s, Train Loss=1.94, validation loss=2.45] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:45<03:34,  1.57it/s, Train Loss=1.16, validation loss=2.44] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:45<03:43,  1.50it/s, Train Loss=1.16, validation loss=2.44] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:46<03:43,  1.50it/s, Train Loss=1.77, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:46<03:37,  1.54it/s, Train Loss=1.77, validation loss=2.43] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:47<03:37,  1.54it/s, Train Loss=2.09, validation loss=2.42] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:47<03:31,  1.58it/s, Train Loss=2.09, validation loss=2.42] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:47<03:31,  1.58it/s, Train Loss=2.28, validation loss=2.42] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:47<03:31,  1.57it/s, Train Loss=2.28, validation loss=2.42] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:48<03:31,  1.57it/s, Train Loss=1.68, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:48<03:45,  1.47it/s, Train Loss=1.68, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:49<03:45,  1.47it/s, Train Loss=2.18, validation loss=2.44] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:49<03:41,  1.49it/s, Train Loss=2.18, validation loss=2.44] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:49<03:41,  1.49it/s, Train Loss=2.29, validation loss=2.42] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:49<03:34,  1.54it/s, Train Loss=2.29, validation loss=2.42] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:50<03:34,  1.54it/s, Train Loss=1.27, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:50<03:43,  1.48it/s, Train Loss=1.27, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:51<03:43,  1.48it/s, Train Loss=2.07, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:51<03:36,  1.51it/s, Train Loss=2.07, validation loss=2.43] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:51<03:36,  1.51it/s, Train Loss=1.73, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:51<03:34,  1.52it/s, Train Loss=1.73, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:52<03:34,  1.52it/s, Train Loss=1.62, validation loss=2.43] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:52<03:28,  1.56it/s, Train Loss=1.62, validation loss=2.43] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:52<03:28,  1.56it/s, Train Loss=2.27, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:52<03:26,  1.57it/s, Train Loss=2.27, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:53<03:26,  1.57it/s, Train Loss=2.67, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:53<03:26,  1.57it/s, Train Loss=2.67, validation loss=2.44] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:54<03:26,  1.57it/s, Train Loss=2.24, validation loss=2.42] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:54<03:26,  1.56it/s, Train Loss=2.24, validation loss=2.42] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:55<03:26,  1.56it/s, Train Loss=3.14, validation loss=2.43] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:55<03:38,  1.47it/s, Train Loss=3.14, validation loss=2.43] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:55<03:38,  1.47it/s, Train Loss=2.32, validation loss=2.42] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:55<03:34,  1.50it/s, Train Loss=2.32, validation loss=2.42] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:56<03:34,  1.50it/s, Train Loss=4.08, validation loss=2.42] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:56<03:27,  1.54it/s, Train Loss=4.08, validation loss=2.42] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:56<03:27,  1.54it/s, Train Loss=2.36, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:56<03:25,  1.55it/s, Train Loss=2.36, validation loss=2.44] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:57<03:25,  1.55it/s, Train Loss=2.81, validation loss=2.42] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:57<03:21,  1.58it/s, Train Loss=2.81, validation loss=2.42] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:58<03:21,  1.58it/s, Train Loss=2.76, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:58<03:18,  1.60it/s, Train Loss=2.76, validation loss=2.42] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:58<03:18,  1.60it/s, Train Loss=1.54, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:58<03:17,  1.60it/s, Train Loss=1.54, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:59<03:17,  1.60it/s, Train Loss=3.94, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:59<03:33,  1.48it/s, Train Loss=3.94, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [02:00<03:33,  1.48it/s, Train Loss=3, validation loss=2.44]    37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:00<03:29,  1.50it/s, Train Loss=3, validation loss=2.44] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:00<03:29,  1.50it/s, Train Loss=1.94, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:00<03:21,  1.55it/s, Train Loss=1.94, validation loss=2.43] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:01<03:21,  1.55it/s, Train Loss=2.05, validation loss=2.44] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:01<03:23,  1.53it/s, Train Loss=2.05, validation loss=2.44] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:02<03:23,  1.53it/s, Train Loss=1.83, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:02<03:20,  1.55it/s, Train Loss=1.83, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:02<03:20,  1.55it/s, Train Loss=2.07, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:02<03:17,  1.57it/s, Train Loss=2.07, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:03<03:17,  1.57it/s, Train Loss=1.61, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:03<03:26,  1.50it/s, Train Loss=1.61, validation loss=2.43] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:04<03:26,  1.50it/s, Train Loss=3.24, validation loss=2.44] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:04<03:25,  1.50it/s, Train Loss=3.24, validation loss=2.44] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:04<03:25,  1.50it/s, Train Loss=2, validation loss=2.45]    39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:04<03:20,  1.53it/s, Train Loss=2, validation loss=2.45] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:05<03:20,  1.53it/s, Train Loss=1.39, validation loss=2.44] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:05<03:15,  1.56it/s, Train Loss=1.39, validation loss=2.44] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:05<03:15,  1.56it/s, Train Loss=1.59, validation loss=2.45] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:05<03:16,  1.55it/s, Train Loss=1.59, validation loss=2.45] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:06<03:16,  1.55it/s, Train Loss=2.46, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:06<03:18,  1.53it/s, Train Loss=2.46, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:07<03:18,  1.53it/s, Train Loss=2.83, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:07<03:18,  1.53it/s, Train Loss=2.83, validation loss=2.43] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:08<03:18,  1.53it/s, Train Loss=1.67, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:08<03:27,  1.45it/s, Train Loss=1.67, validation loss=2.43] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:08<03:27,  1.45it/s, Train Loss=1.32, validation loss=2.44] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:08<03:27,  1.45it/s, Train Loss=1.32, validation loss=2.44]####################################################################################################
--------------------------------------------- Epoch:200 ---------------------------------------------
-- Training set:
Loss: 1.7048289775848389, Lr: 0.00025
Average AUC ROC: 0.54                Average AUC PR: 0.3
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:09<03:27,  1.45it/s, Train Loss=1.7, validation loss=2.44]  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:09<03:21,  1.49it/s, Train Loss=1.7, validation loss=2.44]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.4374672025442123
Average AUC ROC: 0.55                    Average AUC PR: 0.31
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:10<03:21,  1.49it/s, Train Loss=1.86, validation loss=2.44] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:10<03:18,  1.51it/s, Train Loss=1.86, validation loss=2.44] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:10<03:18,  1.51it/s, Train Loss=1.92, validation loss=2.44] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:10<03:12,  1.55it/s, Train Loss=1.92, validation loss=2.44] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:11<03:12,  1.55it/s, Train Loss=1.91, validation loss=2.42] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:11<03:10,  1.56it/s, Train Loss=1.91, validation loss=2.42] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:12<03:10,  1.56it/s, Train Loss=1.56, validation loss=2.44] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:12<03:22,  1.46it/s, Train Loss=1.56, validation loss=2.44] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:12<03:22,  1.46it/s, Train Loss=2.31, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:12<03:15,  1.51it/s, Train Loss=2.31, validation loss=2.43] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:13<03:15,  1.51it/s, Train Loss=2.1, validation loss=2.44]  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:13<03:11,  1.53it/s, Train Loss=2.1, validation loss=2.44] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:13<03:11,  1.53it/s, Train Loss=1.6, validation loss=2.44] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:13<03:07,  1.56it/s, Train Loss=1.6, validation loss=2.44] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:14<03:07,  1.56it/s, Train Loss=1.85, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:14<03:04,  1.58it/s, Train Loss=1.85, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:15<03:04,  1.58it/s, Train Loss=3.05, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:15<03:05,  1.57it/s, Train Loss=3.05, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:15<03:05,  1.57it/s, Train Loss=1.84, validation loss=2.42] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:15<03:13,  1.50it/s, Train Loss=1.84, validation loss=2.42] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:16<03:13,  1.50it/s, Train Loss=1.7, validation loss=2.43]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:16<03:08,  1.53it/s, Train Loss=1.7, validation loss=2.43] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:17<03:08,  1.53it/s, Train Loss=1.49, validation loss=2.42] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:17<03:05,  1.55it/s, Train Loss=1.49, validation loss=2.42] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:17<03:05,  1.55it/s, Train Loss=3.37, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:17<03:03,  1.56it/s, Train Loss=3.37, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:18<03:03,  1.56it/s, Train Loss=1.18, validation loss=2.44] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:18<03:00,  1.58it/s, Train Loss=1.18, validation loss=2.44] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:18<03:00,  1.58it/s, Train Loss=2.46, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:18<02:56,  1.61it/s, Train Loss=2.46, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:19<02:56,  1.61it/s, Train Loss=1.01, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:19<03:07,  1.52it/s, Train Loss=1.01, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:20<03:07,  1.52it/s, Train Loss=1.76, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:20<03:05,  1.52it/s, Train Loss=1.76, validation loss=2.43] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:20<03:05,  1.52it/s, Train Loss=1.9, validation loss=2.43]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:20<03:00,  1.57it/s, Train Loss=1.9, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:21<03:00,  1.57it/s, Train Loss=1.63, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:21<02:59,  1.56it/s, Train Loss=1.63, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:22<02:59,  1.56it/s, Train Loss=4.13, validation loss=2.41] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:22<02:57,  1.57it/s, Train Loss=4.13, validation loss=2.41] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:22<02:57,  1.57it/s, Train Loss=1.9, validation loss=2.42]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:22<02:56,  1.58it/s, Train Loss=1.9, validation loss=2.42] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:23<02:56,  1.58it/s, Train Loss=3.35, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:23<02:54,  1.59it/s, Train Loss=3.35, validation loss=2.43] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:24<02:54,  1.59it/s, Train Loss=4.15, validation loss=2.42] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:24<02:54,  1.58it/s, Train Loss=4.15, validation loss=2.42] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:24<02:54,  1.58it/s, Train Loss=1.9, validation loss=2.43]  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:24<02:53,  1.59it/s, Train Loss=1.9, validation loss=2.43] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:25<02:53,  1.59it/s, Train Loss=2.77, validation loss=2.43] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:25<02:53,  1.58it/s, Train Loss=2.77, validation loss=2.43] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:26<02:53,  1.58it/s, Train Loss=1.93, validation loss=2.42] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:26<03:02,  1.50it/s, Train Loss=1.93, validation loss=2.42] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:26<03:02,  1.50it/s, Train Loss=3.58, validation loss=2.41] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:26<02:58,  1.53it/s, Train Loss=3.58, validation loss=2.41] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:27<02:58,  1.53it/s, Train Loss=1.66, validation loss=2.42] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:27<02:55,  1.55it/s, Train Loss=1.66, validation loss=2.42] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:28<02:55,  1.55it/s, Train Loss=2.55, validation loss=2.42] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:28<02:53,  1.57it/s, Train Loss=2.55, validation loss=2.42] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:28<02:53,  1.57it/s, Train Loss=2.39, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:28<02:50,  1.59it/s, Train Loss=2.39, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:29<02:50,  1.59it/s, Train Loss=2.43, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:29<02:57,  1.51it/s, Train Loss=2.43, validation loss=2.43] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:30<02:57,  1.51it/s, Train Loss=2.93, validation loss=2.42] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:30<02:55,  1.53it/s, Train Loss=2.93, validation loss=2.42] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:30<02:55,  1.53it/s, Train Loss=1.86, validation loss=2.43] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:30<02:50,  1.57it/s, Train Loss=1.86, validation loss=2.43] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:31<02:50,  1.57it/s, Train Loss=1.65, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:31<02:49,  1.57it/s, Train Loss=1.65, validation loss=2.42] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:31<02:49,  1.57it/s, Train Loss=2.96, validation loss=2.43] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:31<02:57,  1.49it/s, Train Loss=2.96, validation loss=2.43] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:32<02:57,  1.49it/s, Train Loss=1.85, validation loss=2.43] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:32<02:54,  1.52it/s, Train Loss=1.85, validation loss=2.43] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:33<02:54,  1.52it/s, Train Loss=2.45, validation loss=2.44] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:33<02:51,  1.53it/s, Train Loss=2.45, validation loss=2.44] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:33<02:51,  1.53it/s, Train Loss=1.62, validation loss=2.42] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:33<02:50,  1.53it/s, Train Loss=1.62, validation loss=2.42] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:34<02:50,  1.53it/s, Train Loss=1.77, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:34<02:48,  1.55it/s, Train Loss=1.77, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:35<02:48,  1.55it/s, Train Loss=1.42, validation loss=2.42] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:35<02:45,  1.57it/s, Train Loss=1.42, validation loss=2.42] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:35<02:45,  1.57it/s, Train Loss=2.16, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:35<02:44,  1.57it/s, Train Loss=2.16, validation loss=2.43] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:36<02:44,  1.57it/s, Train Loss=1.67, validation loss=2.42] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:36<02:42,  1.59it/s, Train Loss=1.67, validation loss=2.42] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:37<02:42,  1.59it/s, Train Loss=1.92, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:37<02:51,  1.50it/s, Train Loss=1.92, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:37<02:51,  1.50it/s, Train Loss=2.29, validation loss=2.43] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:37<02:48,  1.52it/s, Train Loss=2.29, validation loss=2.43] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:38<02:48,  1.52it/s, Train Loss=2.35, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:38<02:44,  1.55it/s, Train Loss=2.35, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:38<02:44,  1.55it/s, Train Loss=3.05, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:38<02:39,  1.59it/s, Train Loss=3.05, validation loss=2.42] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:39<02:39,  1.59it/s, Train Loss=1.84, validation loss=2.44] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:39<02:37,  1.61it/s, Train Loss=1.84, validation loss=2.44] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:40<02:37,  1.61it/s, Train Loss=2.47, validation loss=2.42] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:40<02:35,  1.62it/s, Train Loss=2.47, validation loss=2.42] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:40<02:35,  1.62it/s, Train Loss=2.07, validation loss=2.42] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:40<02:35,  1.62it/s, Train Loss=2.07, validation loss=2.42] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:41<02:35,  1.62it/s, Train Loss=2.2, validation loss=2.42]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:41<02:34,  1.62it/s, Train Loss=2.2, validation loss=2.42] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:42<02:34,  1.62it/s, Train Loss=2.56, validation loss=2.42] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:42<02:45,  1.50it/s, Train Loss=2.56, validation loss=2.42] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:42<02:45,  1.50it/s, Train Loss=2.79, validation loss=2.43] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:42<02:41,  1.54it/s, Train Loss=2.79, validation loss=2.43] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:43<02:41,  1.54it/s, Train Loss=2.04, validation loss=2.43] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:43<02:36,  1.58it/s, Train Loss=2.04, validation loss=2.43] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:44<02:36,  1.58it/s, Train Loss=1.44, validation loss=2.43] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:44<02:37,  1.56it/s, Train Loss=1.44, validation loss=2.43] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:44<02:37,  1.56it/s, Train Loss=2, validation loss=2.42]    51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:44<02:34,  1.58it/s, Train Loss=2, validation loss=2.42] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:45<02:34,  1.58it/s, Train Loss=4.25, validation loss=2.42] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:45<02:32,  1.60it/s, Train Loss=4.25, validation loss=2.42] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:45<02:32,  1.60it/s, Train Loss=1.96, validation loss=2.42] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:45<02:32,  1.59it/s, Train Loss=1.96, validation loss=2.42] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:46<02:32,  1.59it/s, Train Loss=2.43, validation loss=2.43] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:46<02:29,  1.62it/s, Train Loss=2.43, validation loss=2.43] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:47<02:29,  1.62it/s, Train Loss=2.5, validation loss=2.42]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:47<02:35,  1.55it/s, Train Loss=2.5, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:47<02:35,  1.55it/s, Train Loss=2.47, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:47<02:34,  1.55it/s, Train Loss=2.47, validation loss=2.41] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:48<02:34,  1.55it/s, Train Loss=1.56, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:48<02:32,  1.57it/s, Train Loss=1.56, validation loss=2.42] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:49<02:32,  1.57it/s, Train Loss=2.05, validation loss=2.43] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:49<02:29,  1.59it/s, Train Loss=2.05, validation loss=2.43] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:49<02:29,  1.59it/s, Train Loss=1.99, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:49<02:35,  1.53it/s, Train Loss=1.99, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:50<02:35,  1.53it/s, Train Loss=1.58, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:50<02:30,  1.57it/s, Train Loss=1.58, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:51<02:30,  1.57it/s, Train Loss=2.18, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:51<02:28,  1.58it/s, Train Loss=2.18, validation loss=2.42] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:51<02:28,  1.58it/s, Train Loss=2.08, validation loss=2.43] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:51<02:27,  1.59it/s, Train Loss=2.08, validation loss=2.43] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:52<02:27,  1.59it/s, Train Loss=3.07, validation loss=2.41] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:52<02:38,  1.47it/s, Train Loss=3.07, validation loss=2.41] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:53<02:38,  1.47it/s, Train Loss=1.96, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:53<02:34,  1.50it/s, Train Loss=1.96, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:53<02:34,  1.50it/s, Train Loss=1.95, validation loss=2.41] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:53<02:30,  1.53it/s, Train Loss=1.95, validation loss=2.41] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:54<02:30,  1.53it/s, Train Loss=4.47, validation loss=2.43] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:54<02:29,  1.53it/s, Train Loss=4.47, validation loss=2.43] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:54<02:29,  1.53it/s, Train Loss=1.36, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:54<02:26,  1.56it/s, Train Loss=1.36, validation loss=2.42] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:55<02:26,  1.56it/s, Train Loss=2.08, validation loss=2.43] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:55<02:25,  1.56it/s, Train Loss=2.08, validation loss=2.43] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:56<02:25,  1.56it/s, Train Loss=2.99, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:56<02:25,  1.56it/s, Train Loss=2.99, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:56<02:25,  1.56it/s, Train Loss=1.82, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:56<02:23,  1.58it/s, Train Loss=1.82, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:57<02:23,  1.58it/s, Train Loss=1.72, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:57<02:29,  1.51it/s, Train Loss=1.72, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:58<02:29,  1.51it/s, Train Loss=2.65, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:58<02:24,  1.55it/s, Train Loss=2.65, validation loss=2.42] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:58<02:24,  1.55it/s, Train Loss=1.94, validation loss=2.44] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:58<02:21,  1.58it/s, Train Loss=1.94, validation loss=2.44] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:59<02:21,  1.58it/s, Train Loss=2.5, validation loss=2.43]  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:59<02:19,  1.59it/s, Train Loss=2.5, validation loss=2.43] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [03:00<02:19,  1.59it/s, Train Loss=1.71, validation loss=2.43] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:00<02:18,  1.59it/s, Train Loss=1.71, validation loss=2.43] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:00<02:18,  1.59it/s, Train Loss=2.35, validation loss=2.43] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:00<02:18,  1.59it/s, Train Loss=2.35, validation loss=2.43] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:01<02:18,  1.59it/s, Train Loss=3.92, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:01<02:18,  1.59it/s, Train Loss=3.92, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:02<02:18,  1.59it/s, Train Loss=2.9, validation loss=2.42]  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:02<02:22,  1.53it/s, Train Loss=2.9, validation loss=2.42] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:02<02:22,  1.53it/s, Train Loss=2.58, validation loss=2.41] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:02<02:19,  1.55it/s, Train Loss=2.58, validation loss=2.41] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:03<02:19,  1.55it/s, Train Loss=2.19, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:03<02:16,  1.58it/s, Train Loss=2.19, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:03<02:16,  1.58it/s, Train Loss=2.24, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:03<02:15,  1.58it/s, Train Loss=2.24, validation loss=2.42] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:04<02:15,  1.58it/s, Train Loss=1.74, validation loss=2.4]  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:04<02:14,  1.60it/s, Train Loss=1.74, validation loss=2.4] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:05<02:14,  1.60it/s, Train Loss=2.17, validation loss=2.43] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:05<02:12,  1.61it/s, Train Loss=2.17, validation loss=2.43] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:05<02:12,  1.61it/s, Train Loss=1.66, validation loss=2.42] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:05<02:11,  1.61it/s, Train Loss=1.66, validation loss=2.42] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:06<02:11,  1.61it/s, Train Loss=1.8, validation loss=2.43]  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:06<02:10,  1.61it/s, Train Loss=1.8, validation loss=2.43] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:07<02:10,  1.61it/s, Train Loss=1.57, validation loss=2.41] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:07<02:16,  1.54it/s, Train Loss=1.57, validation loss=2.41] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:07<02:16,  1.54it/s, Train Loss=2.31, validation loss=2.41] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:07<02:12,  1.58it/s, Train Loss=2.31, validation loss=2.41] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:08<02:12,  1.58it/s, Train Loss=2.04, validation loss=2.42] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:08<02:09,  1.60it/s, Train Loss=2.04, validation loss=2.42] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:08<02:09,  1.60it/s, Train Loss=1.97, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:08<02:08,  1.61it/s, Train Loss=1.97, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:09<02:08,  1.61it/s, Train Loss=1.61, validation loss=2.42] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:09<02:07,  1.61it/s, Train Loss=1.61, validation loss=2.42] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:10<02:07,  1.61it/s, Train Loss=2.27, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:10<02:11,  1.56it/s, Train Loss=2.27, validation loss=2.41] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:10<02:11,  1.56it/s, Train Loss=2.58, validation loss=2.43] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:10<02:09,  1.57it/s, Train Loss=2.58, validation loss=2.43] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:11<02:09,  1.57it/s, Train Loss=2.6, validation loss=2.43]  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:11<02:07,  1.59it/s, Train Loss=2.6, validation loss=2.43] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:12<02:07,  1.59it/s, Train Loss=1.76, validation loss=2.43] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:12<02:15,  1.49it/s, Train Loss=1.76, validation loss=2.43] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:12<02:15,  1.49it/s, Train Loss=2.08, validation loss=2.41] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:12<02:12,  1.51it/s, Train Loss=2.08, validation loss=2.41]####################################################################################################
--------------------------------------------- Epoch:300 ---------------------------------------------
-- Training set:
Loss: 2.7666516304016113, Lr: 0.000125
Average AUC ROC: 0.52                Average AUC PR: 0.29
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:13<02:12,  1.51it/s, Train Loss=2.77, validation loss=2.41] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:13<02:07,  1.56it/s, Train Loss=2.77, validation loss=2.41]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.4101438224315643
Average AUC ROC: 0.55                    Average AUC PR: 0.31
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:14<02:07,  1.56it/s, Train Loss=2.04, validation loss=2.42] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:14<02:05,  1.58it/s, Train Loss=2.04, validation loss=2.42] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:14<02:05,  1.58it/s, Train Loss=2.04, validation loss=2.44] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:14<02:02,  1.61it/s, Train Loss=2.04, validation loss=2.44] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:15<02:02,  1.61it/s, Train Loss=2.23, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:15<02:01,  1.61it/s, Train Loss=2.23, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:15<02:01,  1.61it/s, Train Loss=2.15, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:15<02:02,  1.60it/s, Train Loss=2.15, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:16<02:02,  1.60it/s, Train Loss=3.18, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:16<02:01,  1.61it/s, Train Loss=3.18, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:17<02:01,  1.61it/s, Train Loss=1.38, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:17<02:08,  1.50it/s, Train Loss=1.38, validation loss=2.42] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:17<02:08,  1.50it/s, Train Loss=1.13, validation loss=2.43] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:17<02:06,  1.53it/s, Train Loss=1.13, validation loss=2.43] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:18<02:06,  1.53it/s, Train Loss=2.52, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:18<02:05,  1.53it/s, Train Loss=2.52, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:19<02:05,  1.53it/s, Train Loss=1.86, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:19<02:02,  1.56it/s, Train Loss=1.86, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:19<02:02,  1.56it/s, Train Loss=1.61, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:19<02:01,  1.56it/s, Train Loss=1.61, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:20<02:01,  1.56it/s, Train Loss=1.62, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:20<01:58,  1.59it/s, Train Loss=1.62, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:21<01:58,  1.59it/s, Train Loss=1.85, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:21<01:57,  1.60it/s, Train Loss=1.85, validation loss=2.42] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:21<01:57,  1.60it/s, Train Loss=2.35, validation loss=2.43] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:21<01:58,  1.58it/s, Train Loss=2.35, validation loss=2.43] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:22<01:58,  1.58it/s, Train Loss=1.82, validation loss=2.42] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:22<02:03,  1.50it/s, Train Loss=1.82, validation loss=2.42] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:23<02:03,  1.50it/s, Train Loss=1.98, validation loss=2.43] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:23<02:01,  1.52it/s, Train Loss=1.98, validation loss=2.43] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:23<02:01,  1.52it/s, Train Loss=2.11, validation loss=2.41] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:23<01:59,  1.54it/s, Train Loss=2.11, validation loss=2.41] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:24<01:59,  1.54it/s, Train Loss=1.67, validation loss=2.42] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:24<01:58,  1.54it/s, Train Loss=1.67, validation loss=2.42] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:24<01:58,  1.54it/s, Train Loss=1.61, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:24<01:57,  1.54it/s, Train Loss=1.61, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:25<01:57,  1.54it/s, Train Loss=1.81, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:25<01:54,  1.58it/s, Train Loss=1.81, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:26<01:54,  1.58it/s, Train Loss=1.95, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:26<01:52,  1.60it/s, Train Loss=1.95, validation loss=2.41] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:26<01:52,  1.60it/s, Train Loss=1.78, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:26<01:56,  1.53it/s, Train Loss=1.78, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:27<01:56,  1.53it/s, Train Loss=1.9, validation loss=2.42]  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:27<01:55,  1.54it/s, Train Loss=1.9, validation loss=2.42] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:28<01:55,  1.54it/s, Train Loss=1.27, validation loss=2.42] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:28<01:52,  1.57it/s, Train Loss=1.27, validation loss=2.42] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:28<01:52,  1.57it/s, Train Loss=2.61, validation loss=2.42] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:28<01:50,  1.59it/s, Train Loss=2.61, validation loss=2.42] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:29<01:50,  1.59it/s, Train Loss=1.91, validation loss=2.41] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:29<01:49,  1.60it/s, Train Loss=1.91, validation loss=2.41] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:30<01:49,  1.60it/s, Train Loss=1.79, validation loss=2.42] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:30<01:56,  1.49it/s, Train Loss=1.79, validation loss=2.42] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:30<01:56,  1.49it/s, Train Loss=1.4, validation loss=2.42]  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:30<01:53,  1.52it/s, Train Loss=1.4, validation loss=2.42] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:31<01:53,  1.52it/s, Train Loss=1.61, validation loss=2.42] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:31<01:49,  1.57it/s, Train Loss=1.61, validation loss=2.42] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:32<01:49,  1.57it/s, Train Loss=2.31, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:32<01:49,  1.56it/s, Train Loss=2.31, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:32<01:49,  1.56it/s, Train Loss=1.95, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:32<01:47,  1.59it/s, Train Loss=1.95, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:33<01:47,  1.59it/s, Train Loss=2.71, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:33<01:46,  1.59it/s, Train Loss=2.71, validation loss=2.41] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:33<01:46,  1.59it/s, Train Loss=1.37, validation loss=2.42] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:33<01:44,  1.61it/s, Train Loss=1.37, validation loss=2.42] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:34<01:44,  1.61it/s, Train Loss=1.83, validation loss=2.41] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:34<01:49,  1.53it/s, Train Loss=1.83, validation loss=2.41] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:35<01:49,  1.53it/s, Train Loss=1.45, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:35<01:46,  1.56it/s, Train Loss=1.45, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:35<01:46,  1.56it/s, Train Loss=2.11, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:35<01:49,  1.51it/s, Train Loss=2.11, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:36<01:49,  1.51it/s, Train Loss=2.28, validation loss=2.43] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:36<01:46,  1.54it/s, Train Loss=2.28, validation loss=2.43] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:37<01:46,  1.54it/s, Train Loss=2.13, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:37<01:41,  1.60it/s, Train Loss=2.13, validation loss=2.42] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:37<01:41,  1.60it/s, Train Loss=2.78, validation loss=2.41] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:37<01:41,  1.59it/s, Train Loss=2.78, validation loss=2.41] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:38<01:41,  1.59it/s, Train Loss=1.11, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:38<01:39,  1.61it/s, Train Loss=1.11, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:38<01:39,  1.61it/s, Train Loss=1.84, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:38<01:40,  1.58it/s, Train Loss=1.84, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:39<01:40,  1.58it/s, Train Loss=3.1, validation loss=2.41]  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:39<01:45,  1.51it/s, Train Loss=3.1, validation loss=2.41] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:40<01:45,  1.51it/s, Train Loss=2.45, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:40<01:42,  1.54it/s, Train Loss=2.45, validation loss=2.42] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:40<01:42,  1.54it/s, Train Loss=1.55, validation loss=2.42] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:40<01:41,  1.55it/s, Train Loss=1.55, validation loss=2.42] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:41<01:41,  1.55it/s, Train Loss=2.45, validation loss=2.43] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:41<01:39,  1.56it/s, Train Loss=2.45, validation loss=2.43] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:42<01:39,  1.56it/s, Train Loss=2.46, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:42<01:37,  1.59it/s, Train Loss=2.46, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:42<01:37,  1.59it/s, Train Loss=2.31, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:42<01:37,  1.58it/s, Train Loss=2.31, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:43<01:37,  1.58it/s, Train Loss=1.66, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:43<01:37,  1.57it/s, Train Loss=1.66, validation loss=2.41] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:44<01:37,  1.57it/s, Train Loss=2.18, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:44<01:43,  1.47it/s, Train Loss=2.18, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:44<01:43,  1.47it/s, Train Loss=1.76, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:44<01:39,  1.52it/s, Train Loss=1.76, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:45<01:39,  1.52it/s, Train Loss=2.52, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:45<01:36,  1.55it/s, Train Loss=2.52, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:46<01:36,  1.55it/s, Train Loss=3.25, validation loss=2.41] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:46<01:35,  1.56it/s, Train Loss=3.25, validation loss=2.41] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:46<01:35,  1.56it/s, Train Loss=3.2, validation loss=2.42]  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:46<01:33,  1.59it/s, Train Loss=3.2, validation loss=2.42] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:47<01:33,  1.59it/s, Train Loss=1.78, validation loss=2.43] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:47<01:31,  1.61it/s, Train Loss=1.78, validation loss=2.43] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:47<01:31,  1.61it/s, Train Loss=1.74, validation loss=2.43] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:47<01:31,  1.59it/s, Train Loss=1.74, validation loss=2.43] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:48<01:31,  1.59it/s, Train Loss=2.83, validation loss=2.42] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:48<01:36,  1.50it/s, Train Loss=2.83, validation loss=2.42] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:49<01:36,  1.50it/s, Train Loss=3.69, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:49<01:33,  1.54it/s, Train Loss=3.69, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:49<01:33,  1.54it/s, Train Loss=2.19, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:49<01:32,  1.54it/s, Train Loss=2.19, validation loss=2.41] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:50<01:32,  1.54it/s, Train Loss=2.3, validation loss=2.4]   72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:50<01:29,  1.59it/s, Train Loss=2.3, validation loss=2.4] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:51<01:29,  1.59it/s, Train Loss=2.27, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:51<01:28,  1.59it/s, Train Loss=2.27, validation loss=2.41] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:51<01:28,  1.59it/s, Train Loss=1.83, validation loss=2.42] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:51<01:28,  1.59it/s, Train Loss=1.83, validation loss=2.42] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:52<01:28,  1.59it/s, Train Loss=2.03, validation loss=2.42] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:52<01:26,  1.61it/s, Train Loss=2.03, validation loss=2.42] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:53<01:26,  1.61it/s, Train Loss=2.67, validation loss=2.42] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:53<01:27,  1.57it/s, Train Loss=2.67, validation loss=2.42] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:53<01:27,  1.57it/s, Train Loss=2.1, validation loss=2.4]   73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:53<01:29,  1.53it/s, Train Loss=2.1, validation loss=2.4] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:54<01:29,  1.53it/s, Train Loss=1.38, validation loss=2.42] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:54<01:26,  1.56it/s, Train Loss=1.38, validation loss=2.42] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:55<01:26,  1.56it/s, Train Loss=1.63, validation loss=2.41] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:55<01:25,  1.58it/s, Train Loss=1.63, validation loss=2.41] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:55<01:25,  1.58it/s, Train Loss=2.44, validation loss=2.41] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:55<01:23,  1.60it/s, Train Loss=2.44, validation loss=2.41] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:56<01:23,  1.60it/s, Train Loss=3.4, validation loss=2.42]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:56<01:26,  1.54it/s, Train Loss=3.4, validation loss=2.42] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:56<01:26,  1.54it/s, Train Loss=2.92, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:56<01:24,  1.56it/s, Train Loss=2.92, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:57<01:24,  1.56it/s, Train Loss=1.65, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:57<01:23,  1.58it/s, Train Loss=1.65, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:58<01:23,  1.58it/s, Train Loss=1.88, validation loss=2.42] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:58<01:27,  1.49it/s, Train Loss=1.88, validation loss=2.42] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:58<01:27,  1.49it/s, Train Loss=2.44, validation loss=2.42] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:58<01:24,  1.53it/s, Train Loss=2.44, validation loss=2.42] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:59<01:24,  1.53it/s, Train Loss=2.37, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [03:59<01:21,  1.56it/s, Train Loss=2.37, validation loss=2.41] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [04:00<01:21,  1.56it/s, Train Loss=1.57, validation loss=2.42] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:00<01:21,  1.57it/s, Train Loss=1.57, validation loss=2.42] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:00<01:21,  1.57it/s, Train Loss=1.63, validation loss=2.43] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:00<01:20,  1.56it/s, Train Loss=1.63, validation loss=2.43] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:01<01:20,  1.56it/s, Train Loss=2.36, validation loss=2.41] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:01<01:19,  1.57it/s, Train Loss=2.36, validation loss=2.41] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:02<01:19,  1.57it/s, Train Loss=2.54, validation loss=2.41] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:02<01:18,  1.58it/s, Train Loss=2.54, validation loss=2.41] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:02<01:18,  1.58it/s, Train Loss=2.55, validation loss=2.41] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:02<01:17,  1.59it/s, Train Loss=2.55, validation loss=2.41] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:03<01:17,  1.59it/s, Train Loss=2.94, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:03<01:22,  1.48it/s, Train Loss=2.94, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:04<01:22,  1.48it/s, Train Loss=3.07, validation loss=2.42] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:04<01:19,  1.53it/s, Train Loss=3.07, validation loss=2.42] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:04<01:19,  1.53it/s, Train Loss=1.76, validation loss=2.42] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:04<01:16,  1.57it/s, Train Loss=1.76, validation loss=2.42] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:05<01:16,  1.57it/s, Train Loss=1.64, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:05<01:14,  1.60it/s, Train Loss=1.64, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:05<01:14,  1.60it/s, Train Loss=2.07, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:05<01:14,  1.59it/s, Train Loss=2.07, validation loss=2.41] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:06<01:14,  1.59it/s, Train Loss=2.27, validation loss=2.41] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:06<01:14,  1.58it/s, Train Loss=2.27, validation loss=2.41] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:07<01:14,  1.58it/s, Train Loss=1.58, validation loss=2.44] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:07<01:13,  1.57it/s, Train Loss=1.58, validation loss=2.44] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:07<01:13,  1.57it/s, Train Loss=2.08, validation loss=2.41] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:07<01:15,  1.53it/s, Train Loss=2.08, validation loss=2.41] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:08<01:15,  1.53it/s, Train Loss=1.93, validation loss=2.4]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:08<01:15,  1.52it/s, Train Loss=1.93, validation loss=2.4] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:09<01:15,  1.52it/s, Train Loss=1.47, validation loss=2.43] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:09<01:13,  1.54it/s, Train Loss=1.47, validation loss=2.43] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:09<01:13,  1.54it/s, Train Loss=2.21, validation loss=2.4]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:09<01:10,  1.58it/s, Train Loss=2.21, validation loss=2.4] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:10<01:10,  1.58it/s, Train Loss=1.52, validation loss=2.42] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:10<01:09,  1.59it/s, Train Loss=1.52, validation loss=2.42] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:11<01:09,  1.59it/s, Train Loss=2.35, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:11<01:08,  1.61it/s, Train Loss=2.35, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:11<01:08,  1.61it/s, Train Loss=2.2, validation loss=2.41]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:11<01:08,  1.59it/s, Train Loss=2.2, validation loss=2.41] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:12<01:08,  1.59it/s, Train Loss=1.23, validation loss=2.42] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:12<01:07,  1.60it/s, Train Loss=1.23, validation loss=2.42] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:13<01:07,  1.60it/s, Train Loss=2.44, validation loss=2.42] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:13<01:10,  1.53it/s, Train Loss=2.44, validation loss=2.42] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:13<01:10,  1.53it/s, Train Loss=2.36, validation loss=2.41] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:13<01:09,  1.54it/s, Train Loss=2.36, validation loss=2.41] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:14<01:09,  1.54it/s, Train Loss=2.52, validation loss=2.4]  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:14<01:07,  1.56it/s, Train Loss=2.52, validation loss=2.4] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:14<01:07,  1.56it/s, Train Loss=4.06, validation loss=2.41] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:14<01:05,  1.58it/s, Train Loss=4.06, validation loss=2.41] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:15<01:05,  1.58it/s, Train Loss=3.07, validation loss=2.4]  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:15<01:05,  1.58it/s, Train Loss=3.07, validation loss=2.4] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:16<01:05,  1.58it/s, Train Loss=3.07, validation loss=2.41] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:16<01:04,  1.59it/s, Train Loss=3.07, validation loss=2.41] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:16<01:04,  1.59it/s, Train Loss=2.18, validation loss=2.43] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:16<01:06,  1.53it/s, Train Loss=2.18, validation loss=2.43]####################################################################################################
--------------------------------------------- Epoch:400 ---------------------------------------------
-- Training set:
Loss: 1.352623701095581, Lr: 6.25e-05
Average AUC ROC: 0.54                Average AUC PR: 0.29
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:17<01:06,  1.53it/s, Train Loss=1.35, validation loss=2.42] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:17<01:03,  1.56it/s, Train Loss=1.35, validation loss=2.42]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.419516831636429
Average AUC ROC: 0.55                    Average AUC PR: 0.31
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:18<01:03,  1.56it/s, Train Loss=1.56, validation loss=2.43] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:18<01:07,  1.47it/s, Train Loss=1.56, validation loss=2.43] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:18<01:07,  1.47it/s, Train Loss=1.86, validation loss=2.42] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:18<01:05,  1.50it/s, Train Loss=1.86, validation loss=2.42] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:19<01:05,  1.50it/s, Train Loss=1.96, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:19<01:03,  1.53it/s, Train Loss=1.96, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:20<01:03,  1.53it/s, Train Loss=2.22, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:20<01:01,  1.56it/s, Train Loss=2.22, validation loss=2.41] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:20<01:01,  1.56it/s, Train Loss=2.62, validation loss=2.42] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:20<00:59,  1.58it/s, Train Loss=2.62, validation loss=2.42] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:21<00:59,  1.58it/s, Train Loss=1.62, validation loss=2.43] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:21<00:59,  1.59it/s, Train Loss=1.62, validation loss=2.43] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:21<00:59,  1.59it/s, Train Loss=1.37, validation loss=2.42] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:21<00:57,  1.60it/s, Train Loss=1.37, validation loss=2.42] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:22<00:57,  1.60it/s, Train Loss=1.95, validation loss=2.42] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:22<00:57,  1.59it/s, Train Loss=1.95, validation loss=2.42] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:23<00:57,  1.59it/s, Train Loss=1.88, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:23<01:01,  1.49it/s, Train Loss=1.88, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:23<01:01,  1.49it/s, Train Loss=3.83, validation loss=2.42] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:23<00:58,  1.53it/s, Train Loss=3.83, validation loss=2.42] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:24<00:58,  1.53it/s, Train Loss=1.68, validation loss=2.42] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:24<00:57,  1.56it/s, Train Loss=1.68, validation loss=2.42] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:25<00:57,  1.56it/s, Train Loss=1.63, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:25<00:56,  1.57it/s, Train Loss=1.63, validation loss=2.41] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:25<00:56,  1.57it/s, Train Loss=2.41, validation loss=2.42] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:25<00:55,  1.57it/s, Train Loss=2.41, validation loss=2.42] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:26<00:55,  1.57it/s, Train Loss=1.45, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:26<00:55,  1.56it/s, Train Loss=1.45, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:27<00:55,  1.56it/s, Train Loss=2.35, validation loss=2.42] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:27<00:53,  1.59it/s, Train Loss=2.35, validation loss=2.42] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:27<00:53,  1.59it/s, Train Loss=2.2, validation loss=2.41]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:27<00:56,  1.50it/s, Train Loss=2.2, validation loss=2.41] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:28<00:56,  1.50it/s, Train Loss=1.4, validation loss=2.4]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:28<00:54,  1.53it/s, Train Loss=1.4, validation loss=2.4] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:29<00:54,  1.53it/s, Train Loss=2.37, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:29<00:52,  1.57it/s, Train Loss=2.37, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:29<00:52,  1.57it/s, Train Loss=1.59, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:29<00:51,  1.57it/s, Train Loss=1.59, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:30<00:51,  1.57it/s, Train Loss=1.53, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:30<00:50,  1.60it/s, Train Loss=1.53, validation loss=2.41] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:30<00:50,  1.60it/s, Train Loss=1.82, validation loss=2.4]  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:30<00:49,  1.61it/s, Train Loss=1.82, validation loss=2.4] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:31<00:49,  1.61it/s, Train Loss=1.29, validation loss=2.42] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:31<00:51,  1.51it/s, Train Loss=1.29, validation loss=2.42] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:32<00:51,  1.51it/s, Train Loss=1.33, validation loss=2.42] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:32<00:50,  1.52it/s, Train Loss=1.33, validation loss=2.42] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:32<00:50,  1.52it/s, Train Loss=1.58, validation loss=2.4]  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:32<00:49,  1.55it/s, Train Loss=1.58, validation loss=2.4] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:33<00:49,  1.55it/s, Train Loss=1.26, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:33<00:47,  1.58it/s, Train Loss=1.26, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:34<00:47,  1.58it/s, Train Loss=2.39, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:34<00:46,  1.58it/s, Train Loss=2.39, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:34<00:46,  1.58it/s, Train Loss=1.25, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:34<00:46,  1.57it/s, Train Loss=1.25, validation loss=2.41] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:35<00:46,  1.57it/s, Train Loss=1.07, validation loss=2.42] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:35<00:46,  1.56it/s, Train Loss=1.07, validation loss=2.42] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:36<00:46,  1.56it/s, Train Loss=2.67, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:36<00:48,  1.47it/s, Train Loss=2.67, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:36<00:48,  1.47it/s, Train Loss=2.51, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:36<00:48,  1.46it/s, Train Loss=2.51, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:37<00:48,  1.46it/s, Train Loss=2.08, validation loss=2.4]  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:37<00:45,  1.51it/s, Train Loss=2.08, validation loss=2.4] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:38<00:45,  1.51it/s, Train Loss=3.08, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:38<00:44,  1.54it/s, Train Loss=3.08, validation loss=2.41] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:38<00:44,  1.54it/s, Train Loss=1.73, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:38<00:43,  1.55it/s, Train Loss=1.73, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:39<00:43,  1.55it/s, Train Loss=2.71, validation loss=2.42] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:39<00:42,  1.57it/s, Train Loss=2.71, validation loss=2.42] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:40<00:42,  1.57it/s, Train Loss=3.31, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:40<00:41,  1.58it/s, Train Loss=3.31, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:40<00:41,  1.58it/s, Train Loss=3.36, validation loss=2.4]  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:40<00:43,  1.46it/s, Train Loss=3.36, validation loss=2.4] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:41<00:43,  1.46it/s, Train Loss=2.08, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:41<00:42,  1.49it/s, Train Loss=2.08, validation loss=2.41] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:42<00:42,  1.49it/s, Train Loss=1.27, validation loss=2.4]  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:42<00:40,  1.54it/s, Train Loss=1.27, validation loss=2.4] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:42<00:40,  1.54it/s, Train Loss=2.43, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:42<00:38,  1.57it/s, Train Loss=2.43, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:43<00:38,  1.57it/s, Train Loss=2.53, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:43<00:38,  1.58it/s, Train Loss=2.53, validation loss=2.41] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:43<00:38,  1.58it/s, Train Loss=2.47, validation loss=2.4]  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:43<00:37,  1.59it/s, Train Loss=2.47, validation loss=2.4] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:44<00:37,  1.59it/s, Train Loss=1.94, validation loss=2.42] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:44<00:36,  1.60it/s, Train Loss=1.94, validation loss=2.42] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:45<00:36,  1.60it/s, Train Loss=1.59, validation loss=2.42] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:45<00:37,  1.50it/s, Train Loss=1.59, validation loss=2.42] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:45<00:37,  1.50it/s, Train Loss=2.47, validation loss=2.41] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:45<00:36,  1.53it/s, Train Loss=2.47, validation loss=2.41] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:46<00:36,  1.53it/s, Train Loss=1.31, validation loss=2.41] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:46<00:35,  1.54it/s, Train Loss=1.31, validation loss=2.41] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:47<00:35,  1.54it/s, Train Loss=2.38, validation loss=2.4]  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:47<00:34,  1.55it/s, Train Loss=2.38, validation loss=2.4] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:47<00:34,  1.55it/s, Train Loss=2.03, validation loss=2.43] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:47<00:33,  1.59it/s, Train Loss=2.03, validation loss=2.43] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:48<00:33,  1.59it/s, Train Loss=1.51, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:48<00:32,  1.59it/s, Train Loss=1.51, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:49<00:32,  1.59it/s, Train Loss=2.15, validation loss=2.4]  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:49<00:31,  1.60it/s, Train Loss=2.15, validation loss=2.4] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:49<00:31,  1.60it/s, Train Loss=1.85, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:49<00:31,  1.58it/s, Train Loss=1.85, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:50<00:31,  1.58it/s, Train Loss=1.44, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:50<00:32,  1.52it/s, Train Loss=1.44, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:51<00:32,  1.52it/s, Train Loss=2.33, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:51<00:31,  1.54it/s, Train Loss=2.33, validation loss=2.41] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:51<00:31,  1.54it/s, Train Loss=1.68, validation loss=2.4]  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:51<00:30,  1.54it/s, Train Loss=1.68, validation loss=2.4] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:52<00:30,  1.54it/s, Train Loss=1.97, validation loss=2.41] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:52<00:29,  1.55it/s, Train Loss=1.97, validation loss=2.41] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:52<00:29,  1.55it/s, Train Loss=2.05, validation loss=2.41] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:52<00:28,  1.58it/s, Train Loss=2.05, validation loss=2.41] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:53<00:28,  1.58it/s, Train Loss=2.02, validation loss=2.4]  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:53<00:27,  1.58it/s, Train Loss=2.02, validation loss=2.4] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:54<00:27,  1.58it/s, Train Loss=1.49, validation loss=2.4] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:54<00:26,  1.60it/s, Train Loss=1.49, validation loss=2.4] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:54<00:26,  1.60it/s, Train Loss=2.42, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:54<00:27,  1.51it/s, Train Loss=2.42, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:55<00:27,  1.51it/s, Train Loss=2.25, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:55<00:26,  1.52it/s, Train Loss=2.25, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:56<00:26,  1.52it/s, Train Loss=2.09, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:56<00:25,  1.55it/s, Train Loss=2.09, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:56<00:25,  1.55it/s, Train Loss=1.87, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:56<00:24,  1.56it/s, Train Loss=1.87, validation loss=2.41] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:57<00:24,  1.56it/s, Train Loss=3.6, validation loss=2.43]  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:57<00:24,  1.52it/s, Train Loss=3.6, validation loss=2.43] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:58<00:24,  1.52it/s, Train Loss=1.22, validation loss=2.41] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:58<00:24,  1.51it/s, Train Loss=1.22, validation loss=2.41] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:59<00:24,  1.51it/s, Train Loss=1.85, validation loss=2.4]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:59<00:25,  1.43it/s, Train Loss=1.85, validation loss=2.4] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:59<00:25,  1.43it/s, Train Loss=1.48, validation loss=2.41] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:59<00:23,  1.49it/s, Train Loss=1.48, validation loss=2.41] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [05:00<00:23,  1.49it/s, Train Loss=2.12, validation loss=2.43] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [05:00<00:22,  1.54it/s, Train Loss=2.12, validation loss=2.43] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [05:00<00:22,  1.54it/s, Train Loss=1.77, validation loss=2.42] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:00<00:21,  1.55it/s, Train Loss=1.77, validation loss=2.42] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:01<00:21,  1.55it/s, Train Loss=1.91, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:01<00:20,  1.58it/s, Train Loss=1.91, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:02<00:20,  1.58it/s, Train Loss=1.58, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:02<00:19,  1.59it/s, Train Loss=1.58, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:02<00:19,  1.59it/s, Train Loss=3.24, validation loss=2.4]  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:02<00:19,  1.56it/s, Train Loss=3.24, validation loss=2.4] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:03<00:19,  1.56it/s, Train Loss=1.88, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:03<00:18,  1.56it/s, Train Loss=1.88, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:03<00:18,  1.56it/s, Train Loss=2, validation loss=2.41]    94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:03<00:17,  1.58it/s, Train Loss=2, validation loss=2.41] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:04<00:17,  1.58it/s, Train Loss=1.94, validation loss=2.42] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:04<00:16,  1.62it/s, Train Loss=1.94, validation loss=2.42] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:05<00:16,  1.62it/s, Train Loss=1.57, validation loss=2.41] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:05<00:15,  1.63it/s, Train Loss=1.57, validation loss=2.41] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:05<00:15,  1.63it/s, Train Loss=2.53, validation loss=2.42] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:05<00:15,  1.63it/s, Train Loss=2.53, validation loss=2.42] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:06<00:15,  1.63it/s, Train Loss=1.7, validation loss=2.4]   95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:06<00:14,  1.62it/s, Train Loss=1.7, validation loss=2.4] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:07<00:14,  1.62it/s, Train Loss=1.99, validation loss=2.4] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:07<00:14,  1.64it/s, Train Loss=1.99, validation loss=2.4] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:07<00:14,  1.64it/s, Train Loss=1.7, validation loss=2.4]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:07<00:14,  1.54it/s, Train Loss=1.7, validation loss=2.4] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:08<00:14,  1.54it/s, Train Loss=1.36, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:08<00:13,  1.54it/s, Train Loss=1.36, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:09<00:13,  1.54it/s, Train Loss=1.74, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:09<00:12,  1.57it/s, Train Loss=1.74, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:09<00:12,  1.57it/s, Train Loss=2.7, validation loss=2.41]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:09<00:11,  1.59it/s, Train Loss=2.7, validation loss=2.41] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:10<00:11,  1.59it/s, Train Loss=1.46, validation loss=2.4] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:10<00:11,  1.59it/s, Train Loss=1.46, validation loss=2.4] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:10<00:11,  1.59it/s, Train Loss=1.7, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:10<00:10,  1.60it/s, Train Loss=1.7, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:11<00:10,  1.60it/s, Train Loss=3.26, validation loss=2.4] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:11<00:10,  1.58it/s, Train Loss=3.26, validation loss=2.4] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:12<00:10,  1.58it/s, Train Loss=1.88, validation loss=2.42] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:12<00:09,  1.50it/s, Train Loss=1.88, validation loss=2.42] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:12<00:09,  1.50it/s, Train Loss=2.71, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:12<00:09,  1.55it/s, Train Loss=2.71, validation loss=2.41] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:13<00:09,  1.55it/s, Train Loss=1.54, validation loss=2.4]  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:13<00:08,  1.59it/s, Train Loss=1.54, validation loss=2.4] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:14<00:08,  1.59it/s, Train Loss=1.91, validation loss=2.41] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:14<00:07,  1.60it/s, Train Loss=1.91, validation loss=2.41] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:14<00:07,  1.60it/s, Train Loss=2.32, validation loss=2.4]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:14<00:06,  1.59it/s, Train Loss=2.32, validation loss=2.4] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:15<00:06,  1.59it/s, Train Loss=2.64, validation loss=2.41] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:15<00:06,  1.62it/s, Train Loss=2.64, validation loss=2.41] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:15<00:06,  1.62it/s, Train Loss=2.22, validation loss=2.42] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:15<00:05,  1.61it/s, Train Loss=2.22, validation loss=2.42] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:16<00:05,  1.61it/s, Train Loss=3.82, validation loss=2.4]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:16<00:05,  1.57it/s, Train Loss=3.82, validation loss=2.4] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:17<00:05,  1.57it/s, Train Loss=2.47, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:17<00:04,  1.54it/s, Train Loss=2.47, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:17<00:04,  1.54it/s, Train Loss=3.08, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:17<00:03,  1.50it/s, Train Loss=3.08, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:18<00:03,  1.50it/s, Train Loss=2.54, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:18<00:03,  1.54it/s, Train Loss=2.54, validation loss=2.41] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:19<00:03,  1.54it/s, Train Loss=1.72, validation loss=2.4]  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:19<00:02,  1.54it/s, Train Loss=1.72, validation loss=2.4] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:19<00:02,  1.54it/s, Train Loss=2.29, validation loss=2.4] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:19<00:01,  1.57it/s, Train Loss=2.29, validation loss=2.4] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:20<00:01,  1.57it/s, Train Loss=2.67, validation loss=2.41]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:20<00:01,  1.50it/s, Train Loss=2.67, validation loss=2.41]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:21<00:01,  1.50it/s, Train Loss=1.99, validation loss=2.4] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:21<00:00,  1.53it/s, Train Loss=1.99, validation loss=2.4]####################################################################################################
--------------------------------------------- Epoch:500 ---------------------------------------------
-- Training set:
Loss: 1.8891396522521973, Lr: 3.125e-05
Average AUC ROC: 0.54                Average AUC PR: 0.29
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:21<00:00,  1.53it/s, Train Loss=1.89, validation loss=2.41]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:21<00:00,  1.56it/s, Train Loss=1.89, validation loss=2.41]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:21<00:00,  1.55it/s, Train Loss=1.89, validation loss=2.41]
----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.4064301252365112
Average AUC ROC: 0.55                    Average AUC PR: 0.31

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 769
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=0, validation loss=0]  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=2.87, validation loss=3.09]  0%|          | 1/500 [00:00<05:12,  1.60it/s, Train Loss=2.87, validation loss=3.09]  0%|          | 1/500 [00:01<05:12,  1.60it/s, Train Loss=3.5, validation loss=2.87]   0%|          | 2/500 [00:01<05:06,  1.62it/s, Train Loss=3.5, validation loss=2.87]  0%|          | 2/500 [00:01<05:06,  1.62it/s, Train Loss=2.17, validation loss=2.89]  1%|          | 3/500 [00:01<05:37,  1.47it/s, Train Loss=2.17, validation loss=2.89]  1%|          | 3/500 [00:02<05:37,  1.47it/s, Train Loss=2.87, validation loss=2.83]  1%|          | 4/500 [00:02<05:27,  1.52it/s, Train Loss=2.87, validation loss=2.83]  1%|          | 4/500 [00:03<05:27,  1.52it/s, Train Loss=3.85, validation loss=2.84]  1%|          | 5/500 [00:03<05:17,  1.56it/s, Train Loss=3.85, validation loss=2.84]  1%|          | 5/500 [00:03<05:17,  1.56it/s, Train Loss=3.51, validation loss=2.8]   1%|          | 6/500 [00:03<05:09,  1.60it/s, Train Loss=3.51, validation loss=2.8]  1%|          | 6/500 [00:04<05:09,  1.60it/s, Train Loss=4.27, validation loss=2.76]  1%|â–         | 7/500 [00:04<05:06,  1.61it/s, Train Loss=4.27, validation loss=2.76]  1%|â–         | 7/500 [00:05<05:06,  1.61it/s, Train Loss=2.17, validation loss=2.8]   2%|â–         | 8/500 [00:05<05:02,  1.63it/s, Train Loss=2.17, validation loss=2.8]  2%|â–         | 8/500 [00:05<05:02,  1.63it/s, Train Loss=3.42, validation loss=2.74]  2%|â–         | 9/500 [00:05<05:02,  1.62it/s, Train Loss=3.42, validation loss=2.74]  2%|â–         | 9/500 [00:06<05:02,  1.62it/s, Train Loss=2.98, validation loss=2.74]  2%|â–         | 10/500 [00:06<05:00,  1.63it/s, Train Loss=2.98, validation loss=2.74]  2%|â–         | 10/500 [00:07<05:00,  1.63it/s, Train Loss=4.18, validation loss=2.73]  2%|â–         | 11/500 [00:07<05:20,  1.52it/s, Train Loss=4.18, validation loss=2.73]  2%|â–         | 11/500 [00:07<05:20,  1.52it/s, Train Loss=2.54, validation loss=2.71]  2%|â–         | 12/500 [00:07<05:13,  1.56it/s, Train Loss=2.54, validation loss=2.71]  2%|â–         | 12/500 [00:08<05:13,  1.56it/s, Train Loss=3.59, validation loss=2.7]   3%|â–         | 13/500 [00:08<05:11,  1.57it/s, Train Loss=3.59, validation loss=2.7]  3%|â–         | 13/500 [00:08<05:11,  1.57it/s, Train Loss=2.9, validation loss=2.73]  3%|â–         | 14/500 [00:08<05:07,  1.58it/s, Train Loss=2.9, validation loss=2.73]  3%|â–         | 14/500 [00:09<05:07,  1.58it/s, Train Loss=2.29, validation loss=2.69]  3%|â–         | 15/500 [00:09<05:02,  1.60it/s, Train Loss=2.29, validation loss=2.69]  3%|â–         | 15/500 [00:10<05:02,  1.60it/s, Train Loss=3.24, validation loss=2.69]  3%|â–         | 16/500 [00:10<05:05,  1.58it/s, Train Loss=3.24, validation loss=2.69]  3%|â–         | 16/500 [00:10<05:05,  1.58it/s, Train Loss=2.13, validation loss=2.7]   3%|â–         | 17/500 [00:10<05:01,  1.60it/s, Train Loss=2.13, validation loss=2.7]  3%|â–         | 17/500 [00:11<05:01,  1.60it/s, Train Loss=2.88, validation loss=2.68]  4%|â–         | 18/500 [00:11<05:11,  1.55it/s, Train Loss=2.88, validation loss=2.68]  4%|â–         | 18/500 [00:12<05:11,  1.55it/s, Train Loss=1.85, validation loss=2.67]  4%|â–         | 19/500 [00:12<05:07,  1.56it/s, Train Loss=1.85, validation loss=2.67]  4%|â–         | 19/500 [00:12<05:07,  1.56it/s, Train Loss=2.6, validation loss=2.68]   4%|â–         | 20/500 [00:12<05:06,  1.57it/s, Train Loss=2.6, validation loss=2.68]  4%|â–         | 20/500 [00:13<05:06,  1.57it/s, Train Loss=2.08, validation loss=2.67]  4%|â–         | 21/500 [00:13<05:05,  1.57it/s, Train Loss=2.08, validation loss=2.67]  4%|â–         | 21/500 [00:13<05:05,  1.57it/s, Train Loss=3.7, validation loss=2.68]   4%|â–         | 22/500 [00:13<04:59,  1.59it/s, Train Loss=3.7, validation loss=2.68]  4%|â–         | 22/500 [00:14<04:59,  1.59it/s, Train Loss=3.75, validation loss=2.65]  5%|â–         | 23/500 [00:14<04:59,  1.59it/s, Train Loss=3.75, validation loss=2.65]  5%|â–         | 23/500 [00:15<04:59,  1.59it/s, Train Loss=1.88, validation loss=2.64]  5%|â–         | 24/500 [00:15<04:55,  1.61it/s, Train Loss=1.88, validation loss=2.64]  5%|â–         | 24/500 [00:15<04:55,  1.61it/s, Train Loss=2.03, validation loss=2.65]  5%|â–Œ         | 25/500 [00:15<05:21,  1.48it/s, Train Loss=2.03, validation loss=2.65]  5%|â–Œ         | 25/500 [00:16<05:21,  1.48it/s, Train Loss=3.06, validation loss=2.66]  5%|â–Œ         | 26/500 [00:16<05:07,  1.54it/s, Train Loss=3.06, validation loss=2.66]  5%|â–Œ         | 26/500 [00:17<05:07,  1.54it/s, Train Loss=2.19, validation loss=2.65]  5%|â–Œ         | 27/500 [00:17<05:00,  1.57it/s, Train Loss=2.19, validation loss=2.65]  5%|â–Œ         | 27/500 [00:17<05:00,  1.57it/s, Train Loss=1.37, validation loss=2.64]  6%|â–Œ         | 28/500 [00:17<04:54,  1.60it/s, Train Loss=1.37, validation loss=2.64]  6%|â–Œ         | 28/500 [00:18<04:54,  1.60it/s, Train Loss=2.37, validation loss=2.63]  6%|â–Œ         | 29/500 [00:18<04:53,  1.60it/s, Train Loss=2.37, validation loss=2.63]  6%|â–Œ         | 29/500 [00:19<04:53,  1.60it/s, Train Loss=2.31, validation loss=2.62]  6%|â–Œ         | 30/500 [00:19<05:02,  1.55it/s, Train Loss=2.31, validation loss=2.62]  6%|â–Œ         | 30/500 [00:19<05:02,  1.55it/s, Train Loss=2.19, validation loss=2.61]  6%|â–Œ         | 31/500 [00:19<05:03,  1.54it/s, Train Loss=2.19, validation loss=2.61]  6%|â–Œ         | 31/500 [00:20<05:03,  1.54it/s, Train Loss=2.12, validation loss=2.64]  6%|â–‹         | 32/500 [00:20<04:54,  1.59it/s, Train Loss=2.12, validation loss=2.64]  6%|â–‹         | 32/500 [00:20<04:54,  1.59it/s, Train Loss=1.95, validation loss=2.61]  7%|â–‹         | 33/500 [00:20<04:50,  1.61it/s, Train Loss=1.95, validation loss=2.61]  7%|â–‹         | 33/500 [00:21<04:50,  1.61it/s, Train Loss=3.12, validation loss=2.61]  7%|â–‹         | 34/500 [00:21<04:52,  1.59it/s, Train Loss=3.12, validation loss=2.61]  7%|â–‹         | 34/500 [00:22<04:52,  1.59it/s, Train Loss=2, validation loss=2.6]      7%|â–‹         | 35/500 [00:22<04:49,  1.61it/s, Train Loss=2, validation loss=2.6]  7%|â–‹         | 35/500 [00:22<04:49,  1.61it/s, Train Loss=4.01, validation loss=2.57]  7%|â–‹         | 36/500 [00:22<04:49,  1.60it/s, Train Loss=4.01, validation loss=2.57]  7%|â–‹         | 36/500 [00:23<04:49,  1.60it/s, Train Loss=2.12, validation loss=2.58]  7%|â–‹         | 37/500 [00:23<04:46,  1.62it/s, Train Loss=2.12, validation loss=2.58]  7%|â–‹         | 37/500 [00:24<04:46,  1.62it/s, Train Loss=2.72, validation loss=2.62]  8%|â–Š         | 38/500 [00:24<04:57,  1.55it/s, Train Loss=2.72, validation loss=2.62]  8%|â–Š         | 38/500 [00:24<04:57,  1.55it/s, Train Loss=2.06, validation loss=2.6]   8%|â–Š         | 39/500 [00:24<04:52,  1.58it/s, Train Loss=2.06, validation loss=2.6]  8%|â–Š         | 39/500 [00:25<04:52,  1.58it/s, Train Loss=2.73, validation loss=2.59]  8%|â–Š         | 40/500 [00:25<04:43,  1.62it/s, Train Loss=2.73, validation loss=2.59]  8%|â–Š         | 40/500 [00:25<04:43,  1.62it/s, Train Loss=3.78, validation loss=2.56]  8%|â–Š         | 41/500 [00:25<04:44,  1.61it/s, Train Loss=3.78, validation loss=2.56]  8%|â–Š         | 41/500 [00:26<04:44,  1.61it/s, Train Loss=2.53, validation loss=2.56]  8%|â–Š         | 42/500 [00:26<04:41,  1.63it/s, Train Loss=2.53, validation loss=2.56]  8%|â–Š         | 42/500 [00:27<04:41,  1.63it/s, Train Loss=2.95, validation loss=2.56]  9%|â–Š         | 43/500 [00:27<04:43,  1.61it/s, Train Loss=2.95, validation loss=2.56]  9%|â–Š         | 43/500 [00:27<04:43,  1.61it/s, Train Loss=2.23, validation loss=2.56]  9%|â–‰         | 44/500 [00:27<04:43,  1.61it/s, Train Loss=2.23, validation loss=2.56]  9%|â–‰         | 44/500 [00:28<04:43,  1.61it/s, Train Loss=2.77, validation loss=2.55]  9%|â–‰         | 45/500 [00:28<04:52,  1.55it/s, Train Loss=2.77, validation loss=2.55]  9%|â–‰         | 45/500 [00:29<04:52,  1.55it/s, Train Loss=2.52, validation loss=2.54]  9%|â–‰         | 46/500 [00:29<04:57,  1.53it/s, Train Loss=2.52, validation loss=2.54]  9%|â–‰         | 46/500 [00:29<04:57,  1.53it/s, Train Loss=2.74, validation loss=2.53]  9%|â–‰         | 47/500 [00:29<04:54,  1.54it/s, Train Loss=2.74, validation loss=2.53]  9%|â–‰         | 47/500 [00:30<04:54,  1.54it/s, Train Loss=1.69, validation loss=2.54] 10%|â–‰         | 48/500 [00:30<04:55,  1.53it/s, Train Loss=1.69, validation loss=2.54] 10%|â–‰         | 48/500 [00:31<04:55,  1.53it/s, Train Loss=2.02, validation loss=2.53] 10%|â–‰         | 49/500 [00:31<04:52,  1.54it/s, Train Loss=2.02, validation loss=2.53] 10%|â–‰         | 49/500 [00:31<04:52,  1.54it/s, Train Loss=3.61, validation loss=2.5]  10%|â–ˆ         | 50/500 [00:31<04:51,  1.54it/s, Train Loss=3.61, validation loss=2.5] 10%|â–ˆ         | 50/500 [00:32<04:51,  1.54it/s, Train Loss=2.44, validation loss=2.52] 10%|â–ˆ         | 51/500 [00:32<05:01,  1.49it/s, Train Loss=2.44, validation loss=2.52] 10%|â–ˆ         | 51/500 [00:33<05:01,  1.49it/s, Train Loss=2.43, validation loss=2.53] 10%|â–ˆ         | 52/500 [00:33<04:55,  1.52it/s, Train Loss=2.43, validation loss=2.53] 10%|â–ˆ         | 52/500 [00:33<04:55,  1.52it/s, Train Loss=2.39, validation loss=2.5]  11%|â–ˆ         | 53/500 [00:33<04:48,  1.55it/s, Train Loss=2.39, validation loss=2.5] 11%|â–ˆ         | 53/500 [00:34<04:48,  1.55it/s, Train Loss=1.65, validation loss=2.52] 11%|â–ˆ         | 54/500 [00:34<04:43,  1.57it/s, Train Loss=1.65, validation loss=2.52] 11%|â–ˆ         | 54/500 [00:34<04:43,  1.57it/s, Train Loss=2.81, validation loss=2.47] 11%|â–ˆ         | 55/500 [00:34<04:44,  1.57it/s, Train Loss=2.81, validation loss=2.47] 11%|â–ˆ         | 55/500 [00:35<04:44,  1.57it/s, Train Loss=3.73, validation loss=2.49] 11%|â–ˆ         | 56/500 [00:35<04:42,  1.57it/s, Train Loss=3.73, validation loss=2.49] 11%|â–ˆ         | 56/500 [00:36<04:42,  1.57it/s, Train Loss=2.67, validation loss=2.47] 11%|â–ˆâ–        | 57/500 [00:36<04:54,  1.50it/s, Train Loss=2.67, validation loss=2.47] 11%|â–ˆâ–        | 57/500 [00:36<04:54,  1.50it/s, Train Loss=2.07, validation loss=2.48] 12%|â–ˆâ–        | 58/500 [00:36<04:45,  1.55it/s, Train Loss=2.07, validation loss=2.48] 12%|â–ˆâ–        | 58/500 [00:37<04:45,  1.55it/s, Train Loss=2.06, validation loss=2.47] 12%|â–ˆâ–        | 59/500 [00:37<04:40,  1.57it/s, Train Loss=2.06, validation loss=2.47] 12%|â–ˆâ–        | 59/500 [00:38<04:40,  1.57it/s, Train Loss=1.43, validation loss=2.49] 12%|â–ˆâ–        | 60/500 [00:38<04:36,  1.59it/s, Train Loss=1.43, validation loss=2.49] 12%|â–ˆâ–        | 60/500 [00:38<04:36,  1.59it/s, Train Loss=1.69, validation loss=2.47] 12%|â–ˆâ–        | 61/500 [00:38<04:38,  1.58it/s, Train Loss=1.69, validation loss=2.47] 12%|â–ˆâ–        | 61/500 [00:39<04:38,  1.58it/s, Train Loss=2.09, validation loss=2.49] 12%|â–ˆâ–        | 62/500 [00:39<04:38,  1.57it/s, Train Loss=2.09, validation loss=2.49] 12%|â–ˆâ–        | 62/500 [00:40<04:38,  1.57it/s, Train Loss=1.35, validation loss=2.45] 13%|â–ˆâ–        | 63/500 [00:40<04:46,  1.53it/s, Train Loss=1.35, validation loss=2.45] 13%|â–ˆâ–        | 63/500 [00:40<04:46,  1.53it/s, Train Loss=2.41, validation loss=2.46] 13%|â–ˆâ–        | 64/500 [00:40<04:59,  1.46it/s, Train Loss=2.41, validation loss=2.46] 13%|â–ˆâ–        | 64/500 [00:41<04:59,  1.46it/s, Train Loss=3.48, validation loss=2.48] 13%|â–ˆâ–        | 65/500 [00:41<04:57,  1.46it/s, Train Loss=3.48, validation loss=2.48] 13%|â–ˆâ–        | 65/500 [00:42<04:57,  1.46it/s, Train Loss=3.03, validation loss=2.46] 13%|â–ˆâ–        | 66/500 [00:42<04:48,  1.50it/s, Train Loss=3.03, validation loss=2.46] 13%|â–ˆâ–        | 66/500 [00:42<04:48,  1.50it/s, Train Loss=1.92, validation loss=2.45] 13%|â–ˆâ–        | 67/500 [00:42<04:38,  1.55it/s, Train Loss=1.92, validation loss=2.45] 13%|â–ˆâ–        | 67/500 [00:43<04:38,  1.55it/s, Train Loss=2.81, validation loss=2.48] 14%|â–ˆâ–        | 68/500 [00:43<04:39,  1.55it/s, Train Loss=2.81, validation loss=2.48] 14%|â–ˆâ–        | 68/500 [00:44<04:39,  1.55it/s, Train Loss=2.55, validation loss=2.46] 14%|â–ˆâ–        | 69/500 [00:44<04:34,  1.57it/s, Train Loss=2.55, validation loss=2.46] 14%|â–ˆâ–        | 69/500 [00:44<04:34,  1.57it/s, Train Loss=2.91, validation loss=2.46] 14%|â–ˆâ–        | 70/500 [00:44<04:30,  1.59it/s, Train Loss=2.91, validation loss=2.46] 14%|â–ˆâ–        | 70/500 [00:45<04:30,  1.59it/s, Train Loss=1.36, validation loss=2.46] 14%|â–ˆâ–        | 71/500 [00:45<04:53,  1.46it/s, Train Loss=1.36, validation loss=2.46] 14%|â–ˆâ–        | 71/500 [00:46<04:53,  1.46it/s, Train Loss=2.25, validation loss=2.44] 14%|â–ˆâ–        | 72/500 [00:46<04:49,  1.48it/s, Train Loss=2.25, validation loss=2.44] 14%|â–ˆâ–        | 72/500 [00:46<04:49,  1.48it/s, Train Loss=2.44, validation loss=2.45] 15%|â–ˆâ–        | 73/500 [00:46<04:45,  1.49it/s, Train Loss=2.44, validation loss=2.45] 15%|â–ˆâ–        | 73/500 [00:47<04:45,  1.49it/s, Train Loss=2.39, validation loss=2.44] 15%|â–ˆâ–        | 74/500 [00:47<04:51,  1.46it/s, Train Loss=2.39, validation loss=2.44] 15%|â–ˆâ–        | 74/500 [00:48<04:51,  1.46it/s, Train Loss=4.49, validation loss=2.43] 15%|â–ˆâ–Œ        | 75/500 [00:48<05:00,  1.41it/s, Train Loss=4.49, validation loss=2.43] 15%|â–ˆâ–Œ        | 75/500 [00:49<05:00,  1.41it/s, Train Loss=1.52, validation loss=2.43] 15%|â–ˆâ–Œ        | 76/500 [00:49<05:17,  1.33it/s, Train Loss=1.52, validation loss=2.43] 15%|â–ˆâ–Œ        | 76/500 [00:49<05:17,  1.33it/s, Train Loss=2.99, validation loss=2.42] 15%|â–ˆâ–Œ        | 77/500 [00:49<04:56,  1.42it/s, Train Loss=2.99, validation loss=2.42] 15%|â–ˆâ–Œ        | 77/500 [00:50<04:56,  1.42it/s, Train Loss=1.72, validation loss=2.45] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:44,  1.48it/s, Train Loss=1.72, validation loss=2.45] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:44,  1.48it/s, Train Loss=4.1, validation loss=2.41]  16%|â–ˆâ–Œ        | 79/500 [00:50<04:38,  1.51it/s, Train Loss=4.1, validation loss=2.41] 16%|â–ˆâ–Œ        | 79/500 [00:51<04:38,  1.51it/s, Train Loss=1.57, validation loss=2.42] 16%|â–ˆâ–Œ        | 80/500 [00:51<04:33,  1.54it/s, Train Loss=1.57, validation loss=2.42] 16%|â–ˆâ–Œ        | 80/500 [00:52<04:33,  1.54it/s, Train Loss=1.73, validation loss=2.41] 16%|â–ˆâ–Œ        | 81/500 [00:52<04:31,  1.54it/s, Train Loss=1.73, validation loss=2.41] 16%|â–ˆâ–Œ        | 81/500 [00:53<04:31,  1.54it/s, Train Loss=1.85, validation loss=2.4]  16%|â–ˆâ–‹        | 82/500 [00:53<04:48,  1.45it/s, Train Loss=1.85, validation loss=2.4] 16%|â–ˆâ–‹        | 82/500 [00:53<04:48,  1.45it/s, Train Loss=2.42, validation loss=2.39] 17%|â–ˆâ–‹        | 83/500 [00:53<04:47,  1.45it/s, Train Loss=2.42, validation loss=2.39] 17%|â–ˆâ–‹        | 83/500 [00:54<04:47,  1.45it/s, Train Loss=2.19, validation loss=2.4]  17%|â–ˆâ–‹        | 84/500 [00:54<04:48,  1.44it/s, Train Loss=2.19, validation loss=2.4] 17%|â–ˆâ–‹        | 84/500 [00:55<04:48,  1.44it/s, Train Loss=3.48, validation loss=2.4] 17%|â–ˆâ–‹        | 85/500 [00:55<04:56,  1.40it/s, Train Loss=3.48, validation loss=2.4] 17%|â–ˆâ–‹        | 85/500 [00:55<04:56,  1.40it/s, Train Loss=2.06, validation loss=2.41] 17%|â–ˆâ–‹        | 86/500 [00:55<05:02,  1.37it/s, Train Loss=2.06, validation loss=2.41] 17%|â–ˆâ–‹        | 86/500 [00:56<05:02,  1.37it/s, Train Loss=2.41, validation loss=2.39] 17%|â–ˆâ–‹        | 87/500 [00:56<05:22,  1.28it/s, Train Loss=2.41, validation loss=2.39] 17%|â–ˆâ–‹        | 87/500 [00:57<05:22,  1.28it/s, Train Loss=2.27, validation loss=2.4]  18%|â–ˆâ–Š        | 88/500 [00:57<05:25,  1.26it/s, Train Loss=2.27, validation loss=2.4] 18%|â–ˆâ–Š        | 88/500 [00:58<05:25,  1.26it/s, Train Loss=3.26, validation loss=2.38] 18%|â–ˆâ–Š        | 89/500 [00:58<05:18,  1.29it/s, Train Loss=3.26, validation loss=2.38] 18%|â–ˆâ–Š        | 89/500 [00:59<05:18,  1.29it/s, Train Loss=2.13, validation loss=2.42] 18%|â–ˆâ–Š        | 90/500 [00:59<04:59,  1.37it/s, Train Loss=2.13, validation loss=2.42] 18%|â–ˆâ–Š        | 90/500 [00:59<04:59,  1.37it/s, Train Loss=2.01, validation loss=2.39] 18%|â–ˆâ–Š        | 91/500 [00:59<04:44,  1.44it/s, Train Loss=2.01, validation loss=2.39] 18%|â–ˆâ–Š        | 91/500 [01:00<04:44,  1.44it/s, Train Loss=1.47, validation loss=2.4]  18%|â–ˆâ–Š        | 92/500 [01:00<04:34,  1.49it/s, Train Loss=1.47, validation loss=2.4] 18%|â–ˆâ–Š        | 92/500 [01:00<04:34,  1.49it/s, Train Loss=2.72, validation loss=2.38] 19%|â–ˆâ–Š        | 93/500 [01:00<04:26,  1.53it/s, Train Loss=2.72, validation loss=2.38] 19%|â–ˆâ–Š        | 93/500 [01:01<04:26,  1.53it/s, Train Loss=1.7, validation loss=2.35]  19%|â–ˆâ–‰        | 94/500 [01:01<04:35,  1.48it/s, Train Loss=1.7, validation loss=2.35] 19%|â–ˆâ–‰        | 94/500 [01:02<04:35,  1.48it/s, Train Loss=2.57, validation loss=2.38] 19%|â–ˆâ–‰        | 95/500 [01:02<04:26,  1.52it/s, Train Loss=2.57, validation loss=2.38] 19%|â–ˆâ–‰        | 95/500 [01:02<04:26,  1.52it/s, Train Loss=1.96, validation loss=2.38] 19%|â–ˆâ–‰        | 96/500 [01:02<04:18,  1.56it/s, Train Loss=1.96, validation loss=2.38] 19%|â–ˆâ–‰        | 96/500 [01:03<04:18,  1.56it/s, Train Loss=2.38, validation loss=2.41] 19%|â–ˆâ–‰        | 97/500 [01:03<04:12,  1.59it/s, Train Loss=2.38, validation loss=2.41] 19%|â–ˆâ–‰        | 97/500 [01:04<04:12,  1.59it/s, Train Loss=1.74, validation loss=2.39] 20%|â–ˆâ–‰        | 98/500 [01:04<04:13,  1.59it/s, Train Loss=1.74, validation loss=2.39] 20%|â–ˆâ–‰        | 98/500 [01:04<04:13,  1.59it/s, Train Loss=2.37, validation loss=2.37] 20%|â–ˆâ–‰        | 99/500 [01:04<04:14,  1.58it/s, Train Loss=2.37, validation loss=2.37]####################################################################################################
--------------------------------------------- Epoch:100 ---------------------------------------------
-- Training set:
Loss: 2.495195150375366, Lr: 0.0005
Average AUC ROC: 0.52                Average AUC PR: 0.29
 20%|â–ˆâ–‰        | 99/500 [01:05<04:14,  1.58it/s, Train Loss=2.5, validation loss=2.38]  20%|â–ˆâ–ˆ        | 100/500 [01:05<04:20,  1.54it/s, Train Loss=2.5, validation loss=2.38]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.381518140435219
Average AUC ROC: 0.56                    Average AUC PR: 0.31
 20%|â–ˆâ–ˆ        | 100/500 [01:06<04:20,  1.54it/s, Train Loss=2.11, validation loss=2.39] 20%|â–ˆâ–ˆ        | 101/500 [01:06<04:22,  1.52it/s, Train Loss=2.11, validation loss=2.39] 20%|â–ˆâ–ˆ        | 101/500 [01:06<04:22,  1.52it/s, Train Loss=2.05, validation loss=2.41] 20%|â–ˆâ–ˆ        | 102/500 [01:06<04:16,  1.55it/s, Train Loss=2.05, validation loss=2.41] 20%|â–ˆâ–ˆ        | 102/500 [01:07<04:16,  1.55it/s, Train Loss=1.99, validation loss=2.38] 21%|â–ˆâ–ˆ        | 103/500 [01:07<04:13,  1.57it/s, Train Loss=1.99, validation loss=2.38] 21%|â–ˆâ–ˆ        | 103/500 [01:07<04:13,  1.57it/s, Train Loss=2.54, validation loss=2.37] 21%|â–ˆâ–ˆ        | 104/500 [01:07<04:12,  1.57it/s, Train Loss=2.54, validation loss=2.37] 21%|â–ˆâ–ˆ        | 104/500 [01:08<04:12,  1.57it/s, Train Loss=2.55, validation loss=2.38] 21%|â–ˆâ–ˆ        | 105/500 [01:08<04:08,  1.59it/s, Train Loss=2.55, validation loss=2.38] 21%|â–ˆâ–ˆ        | 105/500 [01:09<04:08,  1.59it/s, Train Loss=1.63, validation loss=2.38] 21%|â–ˆâ–ˆ        | 106/500 [01:09<04:08,  1.58it/s, Train Loss=1.63, validation loss=2.38] 21%|â–ˆâ–ˆ        | 106/500 [01:09<04:08,  1.58it/s, Train Loss=4.69, validation loss=2.36] 21%|â–ˆâ–ˆâ–       | 107/500 [01:09<04:04,  1.61it/s, Train Loss=4.69, validation loss=2.36] 21%|â–ˆâ–ˆâ–       | 107/500 [01:10<04:04,  1.61it/s, Train Loss=2.2, validation loss=2.37]  22%|â–ˆâ–ˆâ–       | 108/500 [01:10<04:16,  1.53it/s, Train Loss=2.2, validation loss=2.37] 22%|â–ˆâ–ˆâ–       | 108/500 [01:11<04:16,  1.53it/s, Train Loss=2.33, validation loss=2.38] 22%|â–ˆâ–ˆâ–       | 109/500 [01:11<04:09,  1.57it/s, Train Loss=2.33, validation loss=2.38] 22%|â–ˆâ–ˆâ–       | 109/500 [01:11<04:09,  1.57it/s, Train Loss=3.1, validation loss=2.35]  22%|â–ˆâ–ˆâ–       | 110/500 [01:11<04:05,  1.59it/s, Train Loss=3.1, validation loss=2.35] 22%|â–ˆâ–ˆâ–       | 110/500 [01:12<04:05,  1.59it/s, Train Loss=1.75, validation loss=2.4] 22%|â–ˆâ–ˆâ–       | 111/500 [01:12<04:04,  1.59it/s, Train Loss=1.75, validation loss=2.4] 22%|â–ˆâ–ˆâ–       | 111/500 [01:12<04:04,  1.59it/s, Train Loss=3.25, validation loss=2.39] 22%|â–ˆâ–ˆâ–       | 112/500 [01:12<04:03,  1.60it/s, Train Loss=3.25, validation loss=2.39] 22%|â–ˆâ–ˆâ–       | 112/500 [01:13<04:03,  1.60it/s, Train Loss=2.16, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 113/500 [01:13<04:02,  1.60it/s, Train Loss=2.16, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 113/500 [01:14<04:02,  1.60it/s, Train Loss=1.56, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 114/500 [01:14<04:17,  1.50it/s, Train Loss=1.56, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 114/500 [01:14<04:17,  1.50it/s, Train Loss=2.26, validation loss=2.38] 23%|â–ˆâ–ˆâ–       | 115/500 [01:14<04:08,  1.55it/s, Train Loss=2.26, validation loss=2.38] 23%|â–ˆâ–ˆâ–       | 115/500 [01:15<04:08,  1.55it/s, Train Loss=2.1, validation loss=2.38]  23%|â–ˆâ–ˆâ–       | 116/500 [01:15<04:09,  1.54it/s, Train Loss=2.1, validation loss=2.38] 23%|â–ˆâ–ˆâ–       | 116/500 [01:16<04:09,  1.54it/s, Train Loss=2.9, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 117/500 [01:16<04:04,  1.57it/s, Train Loss=2.9, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 117/500 [01:16<04:04,  1.57it/s, Train Loss=1.91, validation loss=2.36] 24%|â–ˆâ–ˆâ–       | 118/500 [01:16<04:02,  1.57it/s, Train Loss=1.91, validation loss=2.36] 24%|â–ˆâ–ˆâ–       | 118/500 [01:17<04:02,  1.57it/s, Train Loss=1.51, validation loss=2.35] 24%|â–ˆâ–ˆâ–       | 119/500 [01:17<03:58,  1.59it/s, Train Loss=1.51, validation loss=2.35] 24%|â–ˆâ–ˆâ–       | 119/500 [01:18<03:58,  1.59it/s, Train Loss=1.58, validation loss=2.35] 24%|â–ˆâ–ˆâ–       | 120/500 [01:18<04:13,  1.50it/s, Train Loss=1.58, validation loss=2.35] 24%|â–ˆâ–ˆâ–       | 120/500 [01:18<04:13,  1.50it/s, Train Loss=2.77, validation loss=2.37] 24%|â–ˆâ–ˆâ–       | 121/500 [01:18<04:08,  1.52it/s, Train Loss=2.77, validation loss=2.37] 24%|â–ˆâ–ˆâ–       | 121/500 [01:19<04:08,  1.52it/s, Train Loss=3.78, validation loss=2.34] 24%|â–ˆâ–ˆâ–       | 122/500 [01:19<04:06,  1.53it/s, Train Loss=3.78, validation loss=2.34] 24%|â–ˆâ–ˆâ–       | 122/500 [01:20<04:06,  1.53it/s, Train Loss=1.13, validation loss=2.37] 25%|â–ˆâ–ˆâ–       | 123/500 [01:20<04:01,  1.56it/s, Train Loss=1.13, validation loss=2.37] 25%|â–ˆâ–ˆâ–       | 123/500 [01:20<04:01,  1.56it/s, Train Loss=5.18, validation loss=2.34] 25%|â–ˆâ–ˆâ–       | 124/500 [01:20<03:56,  1.59it/s, Train Loss=5.18, validation loss=2.34] 25%|â–ˆâ–ˆâ–       | 124/500 [01:21<03:56,  1.59it/s, Train Loss=2.37, validation loss=2.37] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:21<03:53,  1.61it/s, Train Loss=2.37, validation loss=2.37] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:21<03:53,  1.61it/s, Train Loss=1.78, validation loss=2.37] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:21<03:52,  1.61it/s, Train Loss=1.78, validation loss=2.37] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:22<03:52,  1.61it/s, Train Loss=2.21, validation loss=2.37] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:22<04:07,  1.50it/s, Train Loss=2.21, validation loss=2.37] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:23<04:07,  1.50it/s, Train Loss=2.45, validation loss=2.36] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:23<04:03,  1.53it/s, Train Loss=2.45, validation loss=2.36] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:23<04:03,  1.53it/s, Train Loss=1.75, validation loss=2.35] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:23<04:00,  1.54it/s, Train Loss=1.75, validation loss=2.35] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:24<04:00,  1.54it/s, Train Loss=2.91, validation loss=2.36] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:24<03:53,  1.58it/s, Train Loss=2.91, validation loss=2.36] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:25<03:53,  1.58it/s, Train Loss=1.71, validation loss=2.37] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:25<03:49,  1.61it/s, Train Loss=1.71, validation loss=2.37] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:25<03:49,  1.61it/s, Train Loss=1.89, validation loss=2.37] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:25<03:48,  1.61it/s, Train Loss=1.89, validation loss=2.37] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:26<03:48,  1.61it/s, Train Loss=2.37, validation loss=2.37] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:26<03:56,  1.55it/s, Train Loss=2.37, validation loss=2.37] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:27<03:56,  1.55it/s, Train Loss=2.04, validation loss=2.38] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:27<04:00,  1.52it/s, Train Loss=2.04, validation loss=2.38] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:27<04:00,  1.52it/s, Train Loss=2.56, validation loss=2.36] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:27<03:56,  1.54it/s, Train Loss=2.56, validation loss=2.36] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:28<03:56,  1.54it/s, Train Loss=2.05, validation loss=2.34] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:28<03:52,  1.57it/s, Train Loss=2.05, validation loss=2.34] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:29<03:52,  1.57it/s, Train Loss=2.28, validation loss=2.35] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:29<03:53,  1.55it/s, Train Loss=2.28, validation loss=2.35] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:29<03:53,  1.55it/s, Train Loss=2.38, validation loss=2.33] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:29<03:53,  1.55it/s, Train Loss=2.38, validation loss=2.33] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:30<03:53,  1.55it/s, Train Loss=4.58, validation loss=2.33] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:30<04:05,  1.47it/s, Train Loss=4.58, validation loss=2.33] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:31<04:05,  1.47it/s, Train Loss=5.8, validation loss=2.32]  28%|â–ˆâ–ˆâ–Š       | 140/500 [01:31<03:58,  1.51it/s, Train Loss=5.8, validation loss=2.32] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:31<03:58,  1.51it/s, Train Loss=2.13, validation loss=2.33] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:31<03:53,  1.54it/s, Train Loss=2.13, validation loss=2.33] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:32<03:53,  1.54it/s, Train Loss=3.71, validation loss=2.32] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:32<03:51,  1.55it/s, Train Loss=3.71, validation loss=2.32] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:32<03:51,  1.55it/s, Train Loss=4.52, validation loss=2.31] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:32<03:48,  1.56it/s, Train Loss=4.52, validation loss=2.31] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:33<03:48,  1.56it/s, Train Loss=2.44, validation loss=2.33] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:33<03:52,  1.53it/s, Train Loss=2.44, validation loss=2.33] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:34<03:52,  1.53it/s, Train Loss=2.38, validation loss=2.34] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:34<03:51,  1.54it/s, Train Loss=2.38, validation loss=2.34] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:35<03:51,  1.54it/s, Train Loss=3.26, validation loss=2.31] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:35<04:00,  1.47it/s, Train Loss=3.26, validation loss=2.31] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:35<04:00,  1.47it/s, Train Loss=3.36, validation loss=2.31] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:35<03:51,  1.52it/s, Train Loss=3.36, validation loss=2.31] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:36<03:51,  1.52it/s, Train Loss=1.38, validation loss=2.35] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:36<03:48,  1.54it/s, Train Loss=1.38, validation loss=2.35] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:36<03:48,  1.54it/s, Train Loss=2.24, validation loss=2.34] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:36<03:47,  1.54it/s, Train Loss=2.24, validation loss=2.34] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:37<03:47,  1.54it/s, Train Loss=2.02, validation loss=2.35] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:37<03:52,  1.51it/s, Train Loss=2.02, validation loss=2.35] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:38<03:52,  1.51it/s, Train Loss=1.67, validation loss=2.36] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:38<04:00,  1.45it/s, Train Loss=1.67, validation loss=2.36] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:39<04:00,  1.45it/s, Train Loss=3.59, validation loss=2.31] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:39<03:55,  1.48it/s, Train Loss=3.59, validation loss=2.31] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:39<03:55,  1.48it/s, Train Loss=2.63, validation loss=2.32] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:39<03:48,  1.52it/s, Train Loss=2.63, validation loss=2.32] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:40<03:48,  1.52it/s, Train Loss=1.83, validation loss=2.32] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:40<03:43,  1.55it/s, Train Loss=1.83, validation loss=2.32] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:40<03:43,  1.55it/s, Train Loss=3.09, validation loss=2.32] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:40<03:38,  1.58it/s, Train Loss=3.09, validation loss=2.32] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:41<03:38,  1.58it/s, Train Loss=2.84, validation loss=2.35] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:41<03:37,  1.58it/s, Train Loss=2.84, validation loss=2.35] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:42<03:37,  1.58it/s, Train Loss=1.63, validation loss=2.34] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:42<03:48,  1.50it/s, Train Loss=1.63, validation loss=2.34] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:42<03:48,  1.50it/s, Train Loss=2.31, validation loss=2.37] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:42<03:44,  1.52it/s, Train Loss=2.31, validation loss=2.37] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:43<03:44,  1.52it/s, Train Loss=1.68, validation loss=2.33] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:43<03:39,  1.55it/s, Train Loss=1.68, validation loss=2.33] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:44<03:39,  1.55it/s, Train Loss=3.7, validation loss=2.32]  32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:44<03:35,  1.58it/s, Train Loss=3.7, validation loss=2.32] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:44<03:35,  1.58it/s, Train Loss=3.01, validation loss=2.31] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:44<03:33,  1.59it/s, Train Loss=3.01, validation loss=2.31] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:45<03:33,  1.59it/s, Train Loss=1.87, validation loss=2.33] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:45<03:30,  1.61it/s, Train Loss=1.87, validation loss=2.33] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:45<03:30,  1.61it/s, Train Loss=2.98, validation loss=2.32] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:45<03:28,  1.62it/s, Train Loss=2.98, validation loss=2.32] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:46<03:28,  1.62it/s, Train Loss=3.24, validation loss=2.32] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:46<03:37,  1.54it/s, Train Loss=3.24, validation loss=2.32] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:47<03:37,  1.54it/s, Train Loss=1.93, validation loss=2.32] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:47<03:33,  1.57it/s, Train Loss=1.93, validation loss=2.32] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:47<03:33,  1.57it/s, Train Loss=2.6, validation loss=2.34]  33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:47<03:31,  1.58it/s, Train Loss=2.6, validation loss=2.34] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:48<03:31,  1.58it/s, Train Loss=1.9, validation loss=2.31] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:48<03:31,  1.58it/s, Train Loss=1.9, validation loss=2.31] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:49<03:31,  1.58it/s, Train Loss=2.82, validation loss=2.34] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:49<03:28,  1.60it/s, Train Loss=2.82, validation loss=2.34] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:49<03:28,  1.60it/s, Train Loss=1.63, validation loss=2.33] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:49<03:24,  1.62it/s, Train Loss=1.63, validation loss=2.33] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:50<03:24,  1.62it/s, Train Loss=2.9, validation loss=2.31]  34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:50<03:33,  1.55it/s, Train Loss=2.9, validation loss=2.31] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:51<03:33,  1.55it/s, Train Loss=1.94, validation loss=2.31] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:51<03:29,  1.57it/s, Train Loss=1.94, validation loss=2.31] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:51<03:29,  1.57it/s, Train Loss=1.54, validation loss=2.3]  34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:51<03:26,  1.58it/s, Train Loss=1.54, validation loss=2.3] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:52<03:26,  1.58it/s, Train Loss=2.35, validation loss=2.32] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:52<03:24,  1.60it/s, Train Loss=2.35, validation loss=2.32] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:52<03:24,  1.60it/s, Train Loss=1.94, validation loss=2.31] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:52<03:24,  1.59it/s, Train Loss=1.94, validation loss=2.31] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:53<03:24,  1.59it/s, Train Loss=1.57, validation loss=2.3]  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:53<03:24,  1.59it/s, Train Loss=1.57, validation loss=2.3] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:54<03:24,  1.59it/s, Train Loss=2.58, validation loss=2.3] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:54<03:34,  1.51it/s, Train Loss=2.58, validation loss=2.3] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:54<03:34,  1.51it/s, Train Loss=2.45, validation loss=2.31] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:54<03:31,  1.52it/s, Train Loss=2.45, validation loss=2.31] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:55<03:31,  1.52it/s, Train Loss=1.75, validation loss=2.33] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:55<03:31,  1.52it/s, Train Loss=1.75, validation loss=2.33] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:56<03:31,  1.52it/s, Train Loss=3.07, validation loss=2.33] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:56<03:24,  1.57it/s, Train Loss=3.07, validation loss=2.33] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:56<03:24,  1.57it/s, Train Loss=2.3, validation loss=2.31]  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:56<03:23,  1.58it/s, Train Loss=2.3, validation loss=2.31] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:57<03:23,  1.58it/s, Train Loss=1.88, validation loss=2.31] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:57<03:20,  1.59it/s, Train Loss=1.88, validation loss=2.31] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:58<03:20,  1.59it/s, Train Loss=3.38, validation loss=2.31] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:58<03:31,  1.51it/s, Train Loss=3.38, validation loss=2.31] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:58<03:31,  1.51it/s, Train Loss=2.67, validation loss=2.3]  37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:58<03:38,  1.45it/s, Train Loss=2.67, validation loss=2.3] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:59<03:38,  1.45it/s, Train Loss=2.9, validation loss=2.31] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:59<03:33,  1.48it/s, Train Loss=2.9, validation loss=2.31] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [02:00<03:33,  1.48it/s, Train Loss=4.1, validation loss=2.3]  37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [02:00<03:27,  1.52it/s, Train Loss=4.1, validation loss=2.3] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [02:00<03:27,  1.52it/s, Train Loss=1.9, validation loss=2.32] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:00<03:24,  1.53it/s, Train Loss=1.9, validation loss=2.32] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:01<03:24,  1.53it/s, Train Loss=2.08, validation loss=2.33] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:01<03:32,  1.47it/s, Train Loss=2.08, validation loss=2.33] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:02<03:32,  1.47it/s, Train Loss=2.16, validation loss=2.33] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:02<03:29,  1.49it/s, Train Loss=2.16, validation loss=2.33] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:02<03:29,  1.49it/s, Train Loss=2.8, validation loss=2.3]   38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:02<03:25,  1.51it/s, Train Loss=2.8, validation loss=2.3] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:03<03:25,  1.51it/s, Train Loss=2, validation loss=2.3]   38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:03<03:20,  1.54it/s, Train Loss=2, validation loss=2.3] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:04<03:20,  1.54it/s, Train Loss=1.72, validation loss=2.33] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:04<03:18,  1.56it/s, Train Loss=1.72, validation loss=2.33] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:04<03:18,  1.56it/s, Train Loss=1.69, validation loss=2.33] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:04<03:17,  1.56it/s, Train Loss=1.69, validation loss=2.33] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:05<03:17,  1.56it/s, Train Loss=1.56, validation loss=2.31] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:05<03:11,  1.61it/s, Train Loss=1.56, validation loss=2.31] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:05<03:11,  1.61it/s, Train Loss=1.66, validation loss=2.31] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:05<03:09,  1.61it/s, Train Loss=1.66, validation loss=2.31] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:06<03:09,  1.61it/s, Train Loss=1.46, validation loss=2.32] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:06<03:23,  1.50it/s, Train Loss=1.46, validation loss=2.32] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:07<03:23,  1.50it/s, Train Loss=1.76, validation loss=2.31] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:07<03:18,  1.53it/s, Train Loss=1.76, validation loss=2.31] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:07<03:18,  1.53it/s, Train Loss=2.09, validation loss=2.31] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:07<03:14,  1.56it/s, Train Loss=2.09, validation loss=2.31] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:08<03:14,  1.56it/s, Train Loss=2.68, validation loss=2.3]  40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:08<03:10,  1.59it/s, Train Loss=2.68, validation loss=2.3] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:09<03:10,  1.59it/s, Train Loss=2.21, validation loss=2.31] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:09<03:10,  1.58it/s, Train Loss=2.21, validation loss=2.31]####################################################################################################
--------------------------------------------- Epoch:200 ---------------------------------------------
-- Training set:
Loss: 2.406533718109131, Lr: 0.00025
Average AUC ROC: 0.53                Average AUC PR: 0.29
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:09<03:10,  1.58it/s, Train Loss=2.41, validation loss=2.29] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:09<03:09,  1.59it/s, Train Loss=2.41, validation loss=2.29]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.293976306915283
Average AUC ROC: 0.54                    Average AUC PR: 0.3
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:10<03:09,  1.59it/s, Train Loss=1.99, validation loss=2.33] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:10<03:15,  1.53it/s, Train Loss=1.99, validation loss=2.33] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:11<03:15,  1.53it/s, Train Loss=2.21, validation loss=2.3]  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:11<03:11,  1.55it/s, Train Loss=2.21, validation loss=2.3] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:11<03:11,  1.55it/s, Train Loss=3.43, validation loss=2.28] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:11<03:11,  1.55it/s, Train Loss=3.43, validation loss=2.28] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:12<03:11,  1.55it/s, Train Loss=2.3, validation loss=2.29]  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:12<03:09,  1.56it/s, Train Loss=2.3, validation loss=2.29] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:13<03:09,  1.56it/s, Train Loss=2.35, validation loss=2.31] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:13<03:09,  1.56it/s, Train Loss=2.35, validation loss=2.31] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:13<03:09,  1.56it/s, Train Loss=2.87, validation loss=2.31] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:13<03:16,  1.50it/s, Train Loss=2.87, validation loss=2.31] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:14<03:16,  1.50it/s, Train Loss=2.49, validation loss=2.31] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:14<03:14,  1.51it/s, Train Loss=2.49, validation loss=2.31] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:15<03:14,  1.51it/s, Train Loss=1.69, validation loss=2.31] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:15<03:07,  1.56it/s, Train Loss=1.69, validation loss=2.31] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:15<03:07,  1.56it/s, Train Loss=2.45, validation loss=2.3]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:15<03:04,  1.57it/s, Train Loss=2.45, validation loss=2.3] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:16<03:04,  1.57it/s, Train Loss=2.07, validation loss=2.31] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:16<03:05,  1.56it/s, Train Loss=2.07, validation loss=2.31] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:16<03:05,  1.56it/s, Train Loss=1.99, validation loss=2.3]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:16<03:01,  1.59it/s, Train Loss=1.99, validation loss=2.3] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:17<03:01,  1.59it/s, Train Loss=2.68, validation loss=2.3] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:17<02:58,  1.62it/s, Train Loss=2.68, validation loss=2.3] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:18<02:58,  1.62it/s, Train Loss=3.29, validation loss=2.29] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:18<03:06,  1.54it/s, Train Loss=3.29, validation loss=2.29] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:18<03:06,  1.54it/s, Train Loss=2.44, validation loss=2.29] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:18<03:02,  1.57it/s, Train Loss=2.44, validation loss=2.29] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:19<03:02,  1.57it/s, Train Loss=1.83, validation loss=2.3]  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:19<02:59,  1.59it/s, Train Loss=1.83, validation loss=2.3] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:20<02:59,  1.59it/s, Train Loss=1.7, validation loss=2.31] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:20<02:57,  1.60it/s, Train Loss=1.7, validation loss=2.31] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:20<02:57,  1.60it/s, Train Loss=2.63, validation loss=2.28] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:20<02:59,  1.58it/s, Train Loss=2.63, validation loss=2.28] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:21<02:59,  1.58it/s, Train Loss=2.27, validation loss=2.32] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:21<02:55,  1.61it/s, Train Loss=2.27, validation loss=2.32] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:22<02:55,  1.61it/s, Train Loss=2.55, validation loss=2.3]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:22<03:04,  1.53it/s, Train Loss=2.55, validation loss=2.3] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:22<03:04,  1.53it/s, Train Loss=2.18, validation loss=2.29] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:22<03:04,  1.52it/s, Train Loss=2.18, validation loss=2.29] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:23<03:04,  1.52it/s, Train Loss=1.92, validation loss=2.34] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:23<02:58,  1.56it/s, Train Loss=1.92, validation loss=2.34] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:23<02:58,  1.56it/s, Train Loss=2.15, validation loss=2.28] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:23<02:56,  1.58it/s, Train Loss=2.15, validation loss=2.28] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:24<02:56,  1.58it/s, Train Loss=2.09, validation loss=2.3]  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:24<02:54,  1.59it/s, Train Loss=2.09, validation loss=2.3] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:25<02:54,  1.59it/s, Train Loss=2.93, validation loss=2.29] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:25<02:51,  1.61it/s, Train Loss=2.93, validation loss=2.29] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:25<02:51,  1.61it/s, Train Loss=3.46, validation loss=2.3]  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:25<02:59,  1.53it/s, Train Loss=3.46, validation loss=2.3] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:26<02:59,  1.53it/s, Train Loss=1.63, validation loss=2.29] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:26<02:56,  1.55it/s, Train Loss=1.63, validation loss=2.29] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:27<02:56,  1.55it/s, Train Loss=1.91, validation loss=2.31] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:27<02:53,  1.57it/s, Train Loss=1.91, validation loss=2.31] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:27<02:53,  1.57it/s, Train Loss=1.48, validation loss=2.29] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:27<02:51,  1.59it/s, Train Loss=1.48, validation loss=2.29] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:28<02:51,  1.59it/s, Train Loss=2.21, validation loss=2.29] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:28<02:50,  1.59it/s, Train Loss=2.21, validation loss=2.29] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:28<02:50,  1.59it/s, Train Loss=3.55, validation loss=2.29] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:28<02:49,  1.60it/s, Train Loss=3.55, validation loss=2.29] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:29<02:49,  1.60it/s, Train Loss=1.51, validation loss=2.31] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:29<02:47,  1.61it/s, Train Loss=1.51, validation loss=2.31] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:30<02:47,  1.61it/s, Train Loss=2.43, validation loss=2.3]  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:30<02:57,  1.51it/s, Train Loss=2.43, validation loss=2.3] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:30<02:57,  1.51it/s, Train Loss=2.01, validation loss=2.31] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:30<02:52,  1.55it/s, Train Loss=2.01, validation loss=2.31] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:31<02:52,  1.55it/s, Train Loss=1.84, validation loss=2.3]  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:31<02:49,  1.57it/s, Train Loss=1.84, validation loss=2.3] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:32<02:49,  1.57it/s, Train Loss=2.23, validation loss=2.3] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:32<02:48,  1.57it/s, Train Loss=2.23, validation loss=2.3] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:32<02:48,  1.57it/s, Train Loss=2.27, validation loss=2.28] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:32<02:57,  1.49it/s, Train Loss=2.27, validation loss=2.28] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:33<02:57,  1.49it/s, Train Loss=1.9, validation loss=2.29]  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:33<02:52,  1.53it/s, Train Loss=1.9, validation loss=2.29] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:34<02:52,  1.53it/s, Train Loss=1.87, validation loss=2.32] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:34<02:48,  1.55it/s, Train Loss=1.87, validation loss=2.32] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:34<02:48,  1.55it/s, Train Loss=2.28, validation loss=2.3]  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:34<02:45,  1.58it/s, Train Loss=2.28, validation loss=2.3] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:35<02:45,  1.58it/s, Train Loss=1.16, validation loss=2.29] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:35<02:45,  1.57it/s, Train Loss=1.16, validation loss=2.29] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:36<02:45,  1.57it/s, Train Loss=1.59, validation loss=2.31] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:36<02:47,  1.55it/s, Train Loss=1.59, validation loss=2.31] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:36<02:47,  1.55it/s, Train Loss=2.06, validation loss=2.3]  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:36<02:44,  1.57it/s, Train Loss=2.06, validation loss=2.3] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:37<02:44,  1.57it/s, Train Loss=1.59, validation loss=2.32] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:37<02:54,  1.47it/s, Train Loss=1.59, validation loss=2.32] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:38<02:54,  1.47it/s, Train Loss=2.26, validation loss=2.27] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:38<02:49,  1.51it/s, Train Loss=2.26, validation loss=2.27] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:38<02:49,  1.51it/s, Train Loss=2.33, validation loss=2.28] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:38<02:45,  1.54it/s, Train Loss=2.33, validation loss=2.28] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:39<02:45,  1.54it/s, Train Loss=2.08, validation loss=2.3]  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:39<02:43,  1.55it/s, Train Loss=2.08, validation loss=2.3] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:39<02:43,  1.55it/s, Train Loss=2.47, validation loss=2.3] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:39<02:40,  1.58it/s, Train Loss=2.47, validation loss=2.3] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:40<02:40,  1.58it/s, Train Loss=1.97, validation loss=2.32] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:40<02:39,  1.58it/s, Train Loss=1.97, validation loss=2.32] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:41<02:39,  1.58it/s, Train Loss=1.86, validation loss=2.3]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:41<02:47,  1.50it/s, Train Loss=1.86, validation loss=2.3] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:41<02:47,  1.50it/s, Train Loss=1.52, validation loss=2.28] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:41<02:40,  1.56it/s, Train Loss=1.52, validation loss=2.28] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:42<02:40,  1.56it/s, Train Loss=2.26, validation loss=2.29] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:42<02:39,  1.56it/s, Train Loss=2.26, validation loss=2.29] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:43<02:39,  1.56it/s, Train Loss=2.68, validation loss=2.27] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:43<02:38,  1.57it/s, Train Loss=2.68, validation loss=2.27] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:43<02:38,  1.57it/s, Train Loss=2.75, validation loss=2.27] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:43<02:34,  1.60it/s, Train Loss=2.75, validation loss=2.27] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:44<02:34,  1.60it/s, Train Loss=1.69, validation loss=2.28] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:44<02:40,  1.53it/s, Train Loss=1.69, validation loss=2.28] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:45<02:40,  1.53it/s, Train Loss=1.55, validation loss=2.3]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:45<02:38,  1.55it/s, Train Loss=1.55, validation loss=2.3] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:45<02:38,  1.55it/s, Train Loss=1.61, validation loss=2.29] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:45<02:34,  1.58it/s, Train Loss=1.61, validation loss=2.29] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:46<02:34,  1.58it/s, Train Loss=2.51, validation loss=2.27] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:46<02:31,  1.60it/s, Train Loss=2.51, validation loss=2.27] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:46<02:31,  1.60it/s, Train Loss=3.72, validation loss=2.27] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:46<02:30,  1.61it/s, Train Loss=3.72, validation loss=2.27] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:47<02:30,  1.61it/s, Train Loss=2.34, validation loss=2.27] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:47<02:32,  1.58it/s, Train Loss=2.34, validation loss=2.27] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:48<02:32,  1.58it/s, Train Loss=1.74, validation loss=2.28] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:48<02:31,  1.58it/s, Train Loss=1.74, validation loss=2.28] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:48<02:31,  1.58it/s, Train Loss=2.07, validation loss=2.29] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:48<02:36,  1.53it/s, Train Loss=2.07, validation loss=2.29] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:49<02:36,  1.53it/s, Train Loss=1.63, validation loss=2.29] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:49<02:35,  1.53it/s, Train Loss=1.63, validation loss=2.29] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:50<02:35,  1.53it/s, Train Loss=1.51, validation loss=2.28] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:50<02:31,  1.57it/s, Train Loss=1.51, validation loss=2.28] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:50<02:31,  1.57it/s, Train Loss=2.22, validation loss=2.28] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:50<02:32,  1.55it/s, Train Loss=2.22, validation loss=2.28] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:51<02:32,  1.55it/s, Train Loss=1.61, validation loss=2.28] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:51<02:37,  1.49it/s, Train Loss=1.61, validation loss=2.28] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:52<02:37,  1.49it/s, Train Loss=1.23, validation loss=2.29] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:52<02:34,  1.51it/s, Train Loss=1.23, validation loss=2.29] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:52<02:34,  1.51it/s, Train Loss=1.89, validation loss=2.31] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:52<02:29,  1.56it/s, Train Loss=1.89, validation loss=2.31] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:53<02:29,  1.56it/s, Train Loss=2.74, validation loss=2.28] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:53<02:26,  1.58it/s, Train Loss=2.74, validation loss=2.28] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:54<02:26,  1.58it/s, Train Loss=2.47, validation loss=2.26] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:54<02:23,  1.60it/s, Train Loss=2.47, validation loss=2.26] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:54<02:23,  1.60it/s, Train Loss=2.45, validation loss=2.31] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:54<02:22,  1.61it/s, Train Loss=2.45, validation loss=2.31] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:55<02:22,  1.61it/s, Train Loss=2.19, validation loss=2.29] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:55<02:24,  1.59it/s, Train Loss=2.19, validation loss=2.29] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:56<02:24,  1.59it/s, Train Loss=2.36, validation loss=2.27] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:56<02:27,  1.54it/s, Train Loss=2.36, validation loss=2.27] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:56<02:27,  1.54it/s, Train Loss=2.54, validation loss=2.28] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:56<02:27,  1.54it/s, Train Loss=2.54, validation loss=2.28] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:57<02:27,  1.54it/s, Train Loss=1.77, validation loss=2.29] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:57<02:24,  1.57it/s, Train Loss=1.77, validation loss=2.29] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:57<02:24,  1.57it/s, Train Loss=1.99, validation loss=2.28] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:57<02:22,  1.58it/s, Train Loss=1.99, validation loss=2.28] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:58<02:22,  1.58it/s, Train Loss=2.55, validation loss=2.29] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:58<02:23,  1.56it/s, Train Loss=2.55, validation loss=2.29] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:59<02:23,  1.56it/s, Train Loss=2.96, validation loss=2.27] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:59<02:27,  1.51it/s, Train Loss=2.96, validation loss=2.27] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:59<02:27,  1.51it/s, Train Loss=2.12, validation loss=2.27] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:59<02:24,  1.54it/s, Train Loss=2.12, validation loss=2.27] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [03:00<02:24,  1.54it/s, Train Loss=1.36, validation loss=2.3]  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:00<02:23,  1.54it/s, Train Loss=1.36, validation loss=2.3] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:01<02:23,  1.54it/s, Train Loss=1.46, validation loss=2.28] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:01<02:22,  1.55it/s, Train Loss=1.46, validation loss=2.28] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:01<02:22,  1.55it/s, Train Loss=1.22, validation loss=2.28] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:01<02:18,  1.58it/s, Train Loss=1.22, validation loss=2.28] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:02<02:18,  1.58it/s, Train Loss=1.31, validation loss=2.31] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:02<02:16,  1.59it/s, Train Loss=1.31, validation loss=2.31] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:03<02:16,  1.59it/s, Train Loss=1.88, validation loss=2.29] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:03<02:16,  1.59it/s, Train Loss=1.88, validation loss=2.29] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:03<02:16,  1.59it/s, Train Loss=3.27, validation loss=2.32] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:03<02:21,  1.53it/s, Train Loss=3.27, validation loss=2.32] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:04<02:21,  1.53it/s, Train Loss=1.42, validation loss=2.29] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:04<02:15,  1.58it/s, Train Loss=1.42, validation loss=2.29] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:04<02:15,  1.58it/s, Train Loss=1.57, validation loss=2.28] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:04<02:15,  1.58it/s, Train Loss=1.57, validation loss=2.28] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:05<02:15,  1.58it/s, Train Loss=2.5, validation loss=2.28]  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:05<02:14,  1.59it/s, Train Loss=2.5, validation loss=2.28] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:06<02:14,  1.59it/s, Train Loss=1.73, validation loss=2.29] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:06<02:14,  1.58it/s, Train Loss=1.73, validation loss=2.29] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:06<02:14,  1.58it/s, Train Loss=2.21, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:06<02:12,  1.59it/s, Train Loss=2.21, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:07<02:12,  1.59it/s, Train Loss=1.63, validation loss=2.28] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:07<02:19,  1.50it/s, Train Loss=1.63, validation loss=2.28] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:08<02:19,  1.50it/s, Train Loss=2.31, validation loss=2.3]  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:08<02:15,  1.55it/s, Train Loss=2.31, validation loss=2.3] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:08<02:15,  1.55it/s, Train Loss=1.89, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:08<02:12,  1.57it/s, Train Loss=1.89, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:09<02:12,  1.57it/s, Train Loss=1.47, validation loss=2.29] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:09<02:12,  1.56it/s, Train Loss=1.47, validation loss=2.29] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:10<02:12,  1.56it/s, Train Loss=1.48, validation loss=2.32] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:10<02:14,  1.53it/s, Train Loss=1.48, validation loss=2.32] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:10<02:14,  1.53it/s, Train Loss=3.25, validation loss=2.26] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:10<02:12,  1.54it/s, Train Loss=3.25, validation loss=2.26] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:11<02:12,  1.54it/s, Train Loss=1.7, validation loss=2.29]  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:11<02:09,  1.58it/s, Train Loss=1.7, validation loss=2.29] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:12<02:09,  1.58it/s, Train Loss=1.37, validation loss=2.27] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:12<02:08,  1.58it/s, Train Loss=1.37, validation loss=2.27] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:12<02:08,  1.58it/s, Train Loss=2.26, validation loss=2.27] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:12<02:06,  1.59it/s, Train Loss=2.26, validation loss=2.27] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:13<02:06,  1.59it/s, Train Loss=2.36, validation loss=2.28] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:13<02:03,  1.62it/s, Train Loss=2.36, validation loss=2.28]####################################################################################################
--------------------------------------------- Epoch:300 ---------------------------------------------
-- Training set:
Loss: 2.3524551391601562, Lr: 0.000125
Average AUC ROC: 0.52                Average AUC PR: 0.28
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:13<02:03,  1.62it/s, Train Loss=2.35, validation loss=2.28] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:13<02:04,  1.61it/s, Train Loss=2.35, validation loss=2.28]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.2848226130008698
Average AUC ROC: 0.55                    Average AUC PR: 0.3
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:14<02:04,  1.61it/s, Train Loss=1.4, validation loss=2.28]  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:14<02:02,  1.63it/s, Train Loss=1.4, validation loss=2.28] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:15<02:02,  1.63it/s, Train Loss=1.16, validation loss=2.27] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:15<02:06,  1.57it/s, Train Loss=1.16, validation loss=2.27] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:15<02:06,  1.57it/s, Train Loss=2.32, validation loss=2.25] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:15<02:04,  1.58it/s, Train Loss=2.32, validation loss=2.25] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:16<02:04,  1.58it/s, Train Loss=2.9, validation loss=2.27]  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:16<02:03,  1.58it/s, Train Loss=2.9, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:17<02:03,  1.58it/s, Train Loss=2.03, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:17<02:01,  1.60it/s, Train Loss=2.03, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:17<02:01,  1.60it/s, Train Loss=3.38, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:17<02:08,  1.51it/s, Train Loss=3.38, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:18<02:08,  1.51it/s, Train Loss=2.45, validation loss=2.28] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:18<02:06,  1.52it/s, Train Loss=2.45, validation loss=2.28] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:19<02:06,  1.52it/s, Train Loss=2.26, validation loss=2.28] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:19<02:03,  1.56it/s, Train Loss=2.26, validation loss=2.28] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:19<02:03,  1.56it/s, Train Loss=2.99, validation loss=2.26] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:19<02:01,  1.57it/s, Train Loss=2.99, validation loss=2.26] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:20<02:01,  1.57it/s, Train Loss=1.17, validation loss=2.29] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:20<02:03,  1.53it/s, Train Loss=1.17, validation loss=2.29] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:20<02:03,  1.53it/s, Train Loss=1.7, validation loss=2.29]  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:20<02:01,  1.55it/s, Train Loss=1.7, validation loss=2.29] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:21<02:01,  1.55it/s, Train Loss=2.24, validation loss=2.29] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:21<01:59,  1.57it/s, Train Loss=2.24, validation loss=2.29] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:22<01:59,  1.57it/s, Train Loss=2.12, validation loss=2.27] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:22<02:04,  1.51it/s, Train Loss=2.12, validation loss=2.27] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:22<02:04,  1.51it/s, Train Loss=2.76, validation loss=2.26] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:22<02:00,  1.55it/s, Train Loss=2.76, validation loss=2.26] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:23<02:00,  1.55it/s, Train Loss=1.65, validation loss=2.26] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:23<02:00,  1.54it/s, Train Loss=1.65, validation loss=2.26] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:24<02:00,  1.54it/s, Train Loss=3.22, validation loss=2.27] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:24<01:56,  1.57it/s, Train Loss=3.22, validation loss=2.27] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:24<01:56,  1.57it/s, Train Loss=1.71, validation loss=2.28] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:24<02:02,  1.49it/s, Train Loss=1.71, validation loss=2.28] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:25<02:02,  1.49it/s, Train Loss=2.25, validation loss=2.29] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:25<01:59,  1.52it/s, Train Loss=2.25, validation loss=2.29] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:26<01:59,  1.52it/s, Train Loss=1.93, validation loss=2.27] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:26<01:56,  1.56it/s, Train Loss=1.93, validation loss=2.27] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:26<01:56,  1.56it/s, Train Loss=2.21, validation loss=2.26] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:26<01:54,  1.57it/s, Train Loss=2.21, validation loss=2.26] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:27<01:54,  1.57it/s, Train Loss=2.26, validation loss=2.27] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:27<01:53,  1.58it/s, Train Loss=2.26, validation loss=2.27] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:27<01:53,  1.58it/s, Train Loss=2.56, validation loss=2.28] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:27<01:51,  1.59it/s, Train Loss=2.56, validation loss=2.28] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:28<01:51,  1.59it/s, Train Loss=3.35, validation loss=2.27] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:28<01:51,  1.59it/s, Train Loss=3.35, validation loss=2.27] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:29<01:51,  1.59it/s, Train Loss=2.03, validation loss=2.25] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:29<01:55,  1.52it/s, Train Loss=2.03, validation loss=2.25] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:29<01:55,  1.52it/s, Train Loss=1.93, validation loss=2.29] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:29<01:53,  1.54it/s, Train Loss=1.93, validation loss=2.29] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:30<01:53,  1.54it/s, Train Loss=1.5, validation loss=2.28]  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:30<01:51,  1.56it/s, Train Loss=1.5, validation loss=2.28] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:31<01:51,  1.56it/s, Train Loss=2.14, validation loss=2.28] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:31<01:49,  1.58it/s, Train Loss=2.14, validation loss=2.28] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:31<01:49,  1.58it/s, Train Loss=1.68, validation loss=2.29] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:31<01:49,  1.56it/s, Train Loss=1.68, validation loss=2.29] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:32<01:49,  1.56it/s, Train Loss=1.31, validation loss=2.27] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:32<01:53,  1.51it/s, Train Loss=1.31, validation loss=2.27] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:33<01:53,  1.51it/s, Train Loss=2.05, validation loss=2.27] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:33<01:51,  1.53it/s, Train Loss=2.05, validation loss=2.27] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:33<01:51,  1.53it/s, Train Loss=2.13, validation loss=2.26] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:33<01:49,  1.55it/s, Train Loss=2.13, validation loss=2.26] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:34<01:49,  1.55it/s, Train Loss=1.78, validation loss=2.26] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:34<01:47,  1.56it/s, Train Loss=1.78, validation loss=2.26] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:35<01:47,  1.56it/s, Train Loss=1.96, validation loss=2.27] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:35<01:46,  1.57it/s, Train Loss=1.96, validation loss=2.27] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:35<01:46,  1.57it/s, Train Loss=2.05, validation loss=2.28] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:35<01:49,  1.52it/s, Train Loss=2.05, validation loss=2.28] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:36<01:49,  1.52it/s, Train Loss=2.73, validation loss=2.29] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:36<01:50,  1.49it/s, Train Loss=2.73, validation loss=2.29] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:37<01:50,  1.49it/s, Train Loss=2.28, validation loss=2.27] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:37<01:47,  1.52it/s, Train Loss=2.28, validation loss=2.27] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:37<01:47,  1.52it/s, Train Loss=2.22, validation loss=2.3]  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:37<01:44,  1.56it/s, Train Loss=2.22, validation loss=2.3] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:38<01:44,  1.56it/s, Train Loss=2.65, validation loss=2.27] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:38<01:40,  1.61it/s, Train Loss=2.65, validation loss=2.27] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:38<01:40,  1.61it/s, Train Loss=2.77, validation loss=2.26] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:38<01:41,  1.59it/s, Train Loss=2.77, validation loss=2.26] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:39<01:41,  1.59it/s, Train Loss=1.58, validation loss=2.28] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:39<01:40,  1.59it/s, Train Loss=1.58, validation loss=2.28] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:40<01:40,  1.59it/s, Train Loss=1.48, validation loss=2.3]  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:40<01:43,  1.54it/s, Train Loss=1.48, validation loss=2.3] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:40<01:43,  1.54it/s, Train Loss=2.43, validation loss=2.27] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:40<01:42,  1.54it/s, Train Loss=2.43, validation loss=2.27] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:41<01:42,  1.54it/s, Train Loss=1.54, validation loss=2.26] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:41<01:41,  1.55it/s, Train Loss=1.54, validation loss=2.26] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:42<01:41,  1.55it/s, Train Loss=1.51, validation loss=2.28] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:42<01:38,  1.58it/s, Train Loss=1.51, validation loss=2.28] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:42<01:38,  1.58it/s, Train Loss=1.91, validation loss=2.26] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:42<01:37,  1.59it/s, Train Loss=1.91, validation loss=2.26] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:43<01:37,  1.59it/s, Train Loss=1.96, validation loss=2.26] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:43<01:40,  1.53it/s, Train Loss=1.96, validation loss=2.26] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:44<01:40,  1.53it/s, Train Loss=3.03, validation loss=2.3]  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:44<01:37,  1.57it/s, Train Loss=3.03, validation loss=2.3] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:44<01:37,  1.57it/s, Train Loss=2.33, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:44<01:36,  1.57it/s, Train Loss=2.33, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:45<01:36,  1.57it/s, Train Loss=2.25, validation loss=2.29] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:45<01:36,  1.57it/s, Train Loss=2.25, validation loss=2.29] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:45<01:36,  1.57it/s, Train Loss=1.76, validation loss=2.28] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:45<01:34,  1.59it/s, Train Loss=1.76, validation loss=2.28] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:46<01:34,  1.59it/s, Train Loss=2.7, validation loss=2.28]  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:46<01:31,  1.63it/s, Train Loss=2.7, validation loss=2.28] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:47<01:31,  1.63it/s, Train Loss=1.92, validation loss=2.28] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:47<01:30,  1.63it/s, Train Loss=1.92, validation loss=2.28] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:47<01:30,  1.63it/s, Train Loss=1.93, validation loss=2.27] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:47<01:34,  1.56it/s, Train Loss=1.93, validation loss=2.27] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:48<01:34,  1.56it/s, Train Loss=1.52, validation loss=2.28] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:48<01:31,  1.59it/s, Train Loss=1.52, validation loss=2.28] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:49<01:31,  1.59it/s, Train Loss=2.77, validation loss=2.27] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:49<01:31,  1.59it/s, Train Loss=2.77, validation loss=2.27] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:49<01:31,  1.59it/s, Train Loss=1.61, validation loss=2.28] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:49<01:30,  1.59it/s, Train Loss=1.61, validation loss=2.28] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:50<01:30,  1.59it/s, Train Loss=2.77, validation loss=2.26] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:50<01:33,  1.52it/s, Train Loss=2.77, validation loss=2.26] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:51<01:33,  1.52it/s, Train Loss=1.83, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:51<01:34,  1.51it/s, Train Loss=1.83, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:51<01:34,  1.51it/s, Train Loss=2.49, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:51<01:32,  1.52it/s, Train Loss=2.49, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:52<01:32,  1.52it/s, Train Loss=1.93, validation loss=2.25] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:52<01:30,  1.54it/s, Train Loss=1.93, validation loss=2.25] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:53<01:30,  1.54it/s, Train Loss=2.33, validation loss=2.25] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:53<01:30,  1.54it/s, Train Loss=2.33, validation loss=2.25] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:53<01:30,  1.54it/s, Train Loss=1.77, validation loss=2.29] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:53<01:27,  1.57it/s, Train Loss=1.77, validation loss=2.29] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:54<01:27,  1.57it/s, Train Loss=1.34, validation loss=2.29] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:54<01:26,  1.58it/s, Train Loss=1.34, validation loss=2.29] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:55<01:26,  1.58it/s, Train Loss=1.53, validation loss=2.25] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:55<01:29,  1.53it/s, Train Loss=1.53, validation loss=2.25] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:55<01:29,  1.53it/s, Train Loss=1.97, validation loss=2.26] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:55<01:27,  1.54it/s, Train Loss=1.97, validation loss=2.26] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:56<01:27,  1.54it/s, Train Loss=1.47, validation loss=2.28] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:56<01:25,  1.57it/s, Train Loss=1.47, validation loss=2.28] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:56<01:25,  1.57it/s, Train Loss=2.82, validation loss=2.26] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:56<01:24,  1.57it/s, Train Loss=2.82, validation loss=2.26] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:57<01:24,  1.57it/s, Train Loss=2.8, validation loss=2.27]  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:57<01:27,  1.51it/s, Train Loss=2.8, validation loss=2.27] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:58<01:27,  1.51it/s, Train Loss=3.8, validation loss=2.26] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:58<01:25,  1.54it/s, Train Loss=3.8, validation loss=2.26] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:58<01:25,  1.54it/s, Train Loss=1.32, validation loss=2.28] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:58<01:22,  1.58it/s, Train Loss=1.32, validation loss=2.28] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:59<01:22,  1.58it/s, Train Loss=2.96, validation loss=2.25] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:59<01:21,  1.59it/s, Train Loss=2.96, validation loss=2.25] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [04:00<01:21,  1.59it/s, Train Loss=1.86, validation loss=2.29] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [04:00<01:21,  1.56it/s, Train Loss=1.86, validation loss=2.29] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [04:00<01:21,  1.56it/s, Train Loss=2.05, validation loss=2.25] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:00<01:20,  1.58it/s, Train Loss=2.05, validation loss=2.25] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:01<01:20,  1.58it/s, Train Loss=1.49, validation loss=2.28] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:01<01:18,  1.60it/s, Train Loss=1.49, validation loss=2.28] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:02<01:18,  1.60it/s, Train Loss=1.93, validation loss=2.26] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:02<01:21,  1.52it/s, Train Loss=1.93, validation loss=2.26] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:02<01:21,  1.52it/s, Train Loss=1.44, validation loss=2.28] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:02<01:19,  1.57it/s, Train Loss=1.44, validation loss=2.28] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:03<01:19,  1.57it/s, Train Loss=1.93, validation loss=2.25] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:03<01:18,  1.57it/s, Train Loss=1.93, validation loss=2.25] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:03<01:18,  1.57it/s, Train Loss=2.12, validation loss=2.25] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:03<01:17,  1.58it/s, Train Loss=2.12, validation loss=2.25] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:04<01:17,  1.58it/s, Train Loss=1.99, validation loss=2.27] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:04<01:20,  1.51it/s, Train Loss=1.99, validation loss=2.27] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:05<01:20,  1.51it/s, Train Loss=1.95, validation loss=2.27] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:05<01:17,  1.54it/s, Train Loss=1.95, validation loss=2.27] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:05<01:17,  1.54it/s, Train Loss=1.79, validation loss=2.26] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:05<01:16,  1.55it/s, Train Loss=1.79, validation loss=2.26] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:06<01:16,  1.55it/s, Train Loss=1.82, validation loss=2.27] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:06<01:19,  1.48it/s, Train Loss=1.82, validation loss=2.27] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:07<01:19,  1.48it/s, Train Loss=2.28, validation loss=2.27] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:07<01:17,  1.52it/s, Train Loss=2.28, validation loss=2.27] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:07<01:17,  1.52it/s, Train Loss=2.42, validation loss=2.25] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:07<01:14,  1.55it/s, Train Loss=2.42, validation loss=2.25] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:08<01:14,  1.55it/s, Train Loss=2.05, validation loss=2.25] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:08<01:15,  1.52it/s, Train Loss=2.05, validation loss=2.25] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:09<01:15,  1.52it/s, Train Loss=4.1, validation loss=2.25]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:09<01:13,  1.55it/s, Train Loss=4.1, validation loss=2.25] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:09<01:13,  1.55it/s, Train Loss=2.7, validation loss=2.28] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:09<01:11,  1.58it/s, Train Loss=2.7, validation loss=2.28] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:10<01:11,  1.58it/s, Train Loss=3.14, validation loss=2.26] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:10<01:10,  1.59it/s, Train Loss=3.14, validation loss=2.26] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:11<01:10,  1.59it/s, Train Loss=2.44, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:11<01:13,  1.50it/s, Train Loss=2.44, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:11<01:13,  1.50it/s, Train Loss=2.11, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:11<01:11,  1.53it/s, Train Loss=2.11, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:12<01:11,  1.53it/s, Train Loss=2.06, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:12<01:09,  1.56it/s, Train Loss=2.06, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:13<01:09,  1.56it/s, Train Loss=1.86, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:13<01:08,  1.57it/s, Train Loss=1.86, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:13<01:08,  1.57it/s, Train Loss=2.36, validation loss=2.26] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:13<01:07,  1.58it/s, Train Loss=2.36, validation loss=2.26] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:14<01:07,  1.58it/s, Train Loss=3.28, validation loss=2.26] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:14<01:06,  1.60it/s, Train Loss=3.28, validation loss=2.26] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:14<01:06,  1.60it/s, Train Loss=2.52, validation loss=2.25] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:14<01:06,  1.59it/s, Train Loss=2.52, validation loss=2.25] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:15<01:06,  1.59it/s, Train Loss=2.18, validation loss=2.26] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:15<01:09,  1.50it/s, Train Loss=2.18, validation loss=2.26] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:16<01:09,  1.50it/s, Train Loss=1.67, validation loss=2.28] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:16<01:07,  1.52it/s, Train Loss=1.67, validation loss=2.28] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:16<01:07,  1.52it/s, Train Loss=1.72, validation loss=2.31] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:16<01:05,  1.56it/s, Train Loss=1.72, validation loss=2.31] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:17<01:05,  1.56it/s, Train Loss=1.51, validation loss=2.28] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:17<01:04,  1.58it/s, Train Loss=1.51, validation loss=2.28]####################################################################################################
--------------------------------------------- Epoch:400 ---------------------------------------------
-- Training set:
Loss: 2.277811050415039, Lr: 6.25e-05
Average AUC ROC: 0.52                Average AUC PR: 0.28
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:18<01:04,  1.58it/s, Train Loss=2.28, validation loss=2.25] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:18<01:05,  1.53it/s, Train Loss=2.28, validation loss=2.25]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.245857357978821
Average AUC ROC: 0.55                    Average AUC PR: 0.3
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:18<01:05,  1.53it/s, Train Loss=2.26, validation loss=2.27] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:18<01:03,  1.56it/s, Train Loss=2.26, validation loss=2.27] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:19<01:03,  1.56it/s, Train Loss=2.5, validation loss=2.27]  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:19<01:01,  1.59it/s, Train Loss=2.5, validation loss=2.27] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:20<01:01,  1.59it/s, Train Loss=2.06, validation loss=2.28] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:20<01:02,  1.56it/s, Train Loss=2.06, validation loss=2.28] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:20<01:02,  1.56it/s, Train Loss=1.68, validation loss=2.27] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:20<01:01,  1.57it/s, Train Loss=1.68, validation loss=2.27] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:21<01:01,  1.57it/s, Train Loss=1.8, validation loss=2.27]  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:21<01:00,  1.58it/s, Train Loss=1.8, validation loss=2.27] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:21<01:00,  1.58it/s, Train Loss=2.06, validation loss=2.28] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:21<00:58,  1.61it/s, Train Loss=2.06, validation loss=2.28] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:22<00:58,  1.61it/s, Train Loss=1.56, validation loss=2.28] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:22<01:00,  1.54it/s, Train Loss=1.56, validation loss=2.28] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:23<01:00,  1.54it/s, Train Loss=2.02, validation loss=2.27] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:23<00:58,  1.57it/s, Train Loss=2.02, validation loss=2.27] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:23<00:58,  1.57it/s, Train Loss=3.17, validation loss=2.25] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:23<00:57,  1.58it/s, Train Loss=3.17, validation loss=2.25] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:24<00:57,  1.58it/s, Train Loss=2, validation loss=2.26]    82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:24<00:57,  1.58it/s, Train Loss=2, validation loss=2.26] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:25<00:57,  1.58it/s, Train Loss=2.24, validation loss=2.25] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:25<00:56,  1.57it/s, Train Loss=2.24, validation loss=2.25] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:25<00:56,  1.57it/s, Train Loss=1.35, validation loss=2.27] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:25<00:55,  1.58it/s, Train Loss=1.35, validation loss=2.27] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:26<00:55,  1.58it/s, Train Loss=2.07, validation loss=2.26] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:26<00:54,  1.58it/s, Train Loss=2.07, validation loss=2.26] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:27<00:54,  1.58it/s, Train Loss=1.95, validation loss=2.24] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:27<00:59,  1.46it/s, Train Loss=1.95, validation loss=2.24] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:27<00:59,  1.46it/s, Train Loss=1.76, validation loss=2.27] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:27<00:56,  1.51it/s, Train Loss=1.76, validation loss=2.27] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:28<00:56,  1.51it/s, Train Loss=1.99, validation loss=2.28] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:28<00:54,  1.53it/s, Train Loss=1.99, validation loss=2.28] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:29<00:54,  1.53it/s, Train Loss=2.78, validation loss=2.27] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:29<00:53,  1.55it/s, Train Loss=2.78, validation loss=2.27] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:29<00:53,  1.55it/s, Train Loss=2.12, validation loss=2.26] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:29<00:52,  1.57it/s, Train Loss=2.12, validation loss=2.26] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:30<00:52,  1.57it/s, Train Loss=2.61, validation loss=2.26] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:30<00:50,  1.61it/s, Train Loss=2.61, validation loss=2.26] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:30<00:50,  1.61it/s, Train Loss=1.66, validation loss=2.28] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:30<00:50,  1.57it/s, Train Loss=1.66, validation loss=2.28] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:31<00:50,  1.57it/s, Train Loss=2.95, validation loss=2.26] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:31<00:50,  1.56it/s, Train Loss=2.95, validation loss=2.26] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:32<00:50,  1.56it/s, Train Loss=1.62, validation loss=2.3]  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:32<00:49,  1.59it/s, Train Loss=1.62, validation loss=2.3] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:32<00:49,  1.59it/s, Train Loss=2.16, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:32<00:48,  1.60it/s, Train Loss=2.16, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:33<00:48,  1.60it/s, Train Loss=3.21, validation loss=2.25] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:33<00:47,  1.61it/s, Train Loss=3.21, validation loss=2.25] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:34<00:47,  1.61it/s, Train Loss=2.38, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:34<00:46,  1.62it/s, Train Loss=2.38, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:34<00:46,  1.62it/s, Train Loss=2.15, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:34<00:45,  1.63it/s, Train Loss=2.15, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:35<00:45,  1.63it/s, Train Loss=1.71, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:35<00:45,  1.62it/s, Train Loss=1.71, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:35<00:45,  1.62it/s, Train Loss=1.11, validation loss=2.27] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:35<00:45,  1.57it/s, Train Loss=1.11, validation loss=2.27] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:36<00:45,  1.57it/s, Train Loss=1.86, validation loss=2.27] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:36<00:46,  1.54it/s, Train Loss=1.86, validation loss=2.27] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:37<00:46,  1.54it/s, Train Loss=1.8, validation loss=2.25]  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:37<00:44,  1.56it/s, Train Loss=1.8, validation loss=2.25] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:37<00:44,  1.56it/s, Train Loss=1.91, validation loss=2.25] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:37<00:43,  1.59it/s, Train Loss=1.91, validation loss=2.25] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:38<00:43,  1.59it/s, Train Loss=2.56, validation loss=2.25] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:38<00:42,  1.59it/s, Train Loss=2.56, validation loss=2.25] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:39<00:42,  1.59it/s, Train Loss=1.66, validation loss=2.25] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:39<00:43,  1.54it/s, Train Loss=1.66, validation loss=2.25] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:39<00:43,  1.54it/s, Train Loss=1.27, validation loss=2.28] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:39<00:42,  1.56it/s, Train Loss=1.27, validation loss=2.28] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:40<00:42,  1.56it/s, Train Loss=2.17, validation loss=2.3]  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:40<00:41,  1.57it/s, Train Loss=2.17, validation loss=2.3] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:41<00:41,  1.57it/s, Train Loss=2, validation loss=2.29]   87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:41<00:40,  1.60it/s, Train Loss=2, validation loss=2.29] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:41<00:40,  1.60it/s, Train Loss=1.65, validation loss=2.26] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:41<00:39,  1.59it/s, Train Loss=1.65, validation loss=2.26] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:42<00:39,  1.59it/s, Train Loss=1.45, validation loss=2.27] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:42<00:38,  1.60it/s, Train Loss=1.45, validation loss=2.27] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:42<00:38,  1.60it/s, Train Loss=2.28, validation loss=2.26] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:42<00:38,  1.59it/s, Train Loss=2.28, validation loss=2.26] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:43<00:38,  1.59it/s, Train Loss=1.79, validation loss=2.27] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:43<00:37,  1.61it/s, Train Loss=1.79, validation loss=2.27] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:44<00:37,  1.61it/s, Train Loss=2.58, validation loss=2.28] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:44<00:37,  1.55it/s, Train Loss=2.58, validation loss=2.28] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:44<00:37,  1.55it/s, Train Loss=1.47, validation loss=2.26] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:44<00:37,  1.57it/s, Train Loss=1.47, validation loss=2.26] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:45<00:37,  1.57it/s, Train Loss=1.77, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:45<00:35,  1.61it/s, Train Loss=1.77, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:46<00:35,  1.61it/s, Train Loss=1.11, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:46<00:34,  1.61it/s, Train Loss=1.11, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:46<00:34,  1.61it/s, Train Loss=2.75, validation loss=2.26] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:46<00:34,  1.60it/s, Train Loss=2.75, validation loss=2.26] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:47<00:34,  1.60it/s, Train Loss=1.84, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:47<00:33,  1.61it/s, Train Loss=1.84, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:47<00:33,  1.61it/s, Train Loss=2.28, validation loss=2.26] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:47<00:32,  1.61it/s, Train Loss=2.28, validation loss=2.26] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:48<00:32,  1.61it/s, Train Loss=2.53, validation loss=2.25] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:48<00:33,  1.55it/s, Train Loss=2.53, validation loss=2.25] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:49<00:33,  1.55it/s, Train Loss=2.71, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:49<00:33,  1.53it/s, Train Loss=2.71, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:49<00:33,  1.53it/s, Train Loss=1.66, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:49<00:32,  1.54it/s, Train Loss=1.66, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:50<00:32,  1.54it/s, Train Loss=2.38, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:50<00:31,  1.56it/s, Train Loss=2.38, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:51<00:31,  1.56it/s, Train Loss=2.02, validation loss=2.28] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:51<00:30,  1.59it/s, Train Loss=2.02, validation loss=2.28] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:51<00:30,  1.59it/s, Train Loss=1.73, validation loss=2.25] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:51<00:29,  1.61it/s, Train Loss=1.73, validation loss=2.25] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:52<00:29,  1.61it/s, Train Loss=1.37, validation loss=2.28] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:52<00:29,  1.55it/s, Train Loss=1.37, validation loss=2.28] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:53<00:29,  1.55it/s, Train Loss=1.92, validation loss=2.27] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:53<00:28,  1.56it/s, Train Loss=1.92, validation loss=2.27] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:53<00:28,  1.56it/s, Train Loss=1.62, validation loss=2.26] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:53<00:27,  1.58it/s, Train Loss=1.62, validation loss=2.26] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:54<00:27,  1.58it/s, Train Loss=2.74, validation loss=2.26] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:54<00:27,  1.58it/s, Train Loss=2.74, validation loss=2.26] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:54<00:27,  1.58it/s, Train Loss=2.66, validation loss=2.27] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:54<00:26,  1.56it/s, Train Loss=2.66, validation loss=2.27] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:55<00:26,  1.56it/s, Train Loss=1.81, validation loss=2.27] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:55<00:25,  1.60it/s, Train Loss=1.81, validation loss=2.27] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:56<00:25,  1.60it/s, Train Loss=2.2, validation loss=2.25]  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:56<00:24,  1.62it/s, Train Loss=2.2, validation loss=2.25] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:56<00:24,  1.62it/s, Train Loss=2.13, validation loss=2.26] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:56<00:23,  1.63it/s, Train Loss=2.13, validation loss=2.26] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:57<00:23,  1.63it/s, Train Loss=2.07, validation loss=2.27] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:57<00:24,  1.53it/s, Train Loss=2.07, validation loss=2.27] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:58<00:24,  1.53it/s, Train Loss=3.32, validation loss=2.26] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:58<00:24,  1.53it/s, Train Loss=3.32, validation loss=2.26] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:58<00:24,  1.53it/s, Train Loss=2.07, validation loss=2.25] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:58<00:23,  1.53it/s, Train Loss=2.07, validation loss=2.25] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:59<00:23,  1.53it/s, Train Loss=1.24, validation loss=2.25] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:59<00:22,  1.56it/s, Train Loss=1.24, validation loss=2.25] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [05:00<00:22,  1.56it/s, Train Loss=2.31, validation loss=2.26] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [05:00<00:22,  1.51it/s, Train Loss=2.31, validation loss=2.26] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [05:00<00:22,  1.51it/s, Train Loss=1.73, validation loss=2.27] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:00<00:21,  1.55it/s, Train Loss=1.73, validation loss=2.27] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:01<00:21,  1.55it/s, Train Loss=2.28, validation loss=2.26] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:01<00:20,  1.55it/s, Train Loss=2.28, validation loss=2.26] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:02<00:20,  1.55it/s, Train Loss=1.98, validation loss=2.32] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:02<00:20,  1.54it/s, Train Loss=1.98, validation loss=2.32] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:02<00:20,  1.54it/s, Train Loss=1.97, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:02<00:19,  1.56it/s, Train Loss=1.97, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:03<00:19,  1.56it/s, Train Loss=2.27, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:03<00:18,  1.57it/s, Train Loss=2.27, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:03<00:18,  1.57it/s, Train Loss=2.22, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:03<00:17,  1.60it/s, Train Loss=2.22, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:04<00:17,  1.60it/s, Train Loss=1.89, validation loss=2.27] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:04<00:16,  1.59it/s, Train Loss=1.89, validation loss=2.27] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:05<00:16,  1.59it/s, Train Loss=2.45, validation loss=2.28] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:05<00:17,  1.53it/s, Train Loss=2.45, validation loss=2.28] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:05<00:17,  1.53it/s, Train Loss=2.67, validation loss=2.26] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:05<00:16,  1.55it/s, Train Loss=2.67, validation loss=2.26] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:06<00:16,  1.55it/s, Train Loss=2.85, validation loss=2.25] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:06<00:15,  1.56it/s, Train Loss=2.85, validation loss=2.25] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:07<00:15,  1.56it/s, Train Loss=2.12, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:07<00:14,  1.56it/s, Train Loss=2.12, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:07<00:14,  1.56it/s, Train Loss=2.54, validation loss=2.28] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:07<00:13,  1.58it/s, Train Loss=2.54, validation loss=2.28] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:08<00:13,  1.58it/s, Train Loss=2.13, validation loss=2.27] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:08<00:13,  1.58it/s, Train Loss=2.13, validation loss=2.27] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:09<00:13,  1.58it/s, Train Loss=2.85, validation loss=2.26] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:09<00:12,  1.57it/s, Train Loss=2.85, validation loss=2.26] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:09<00:12,  1.57it/s, Train Loss=1.83, validation loss=2.25] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:09<00:12,  1.53it/s, Train Loss=1.83, validation loss=2.25] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:10<00:12,  1.53it/s, Train Loss=2.08, validation loss=2.27] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:10<00:11,  1.55it/s, Train Loss=2.08, validation loss=2.27] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:11<00:11,  1.55it/s, Train Loss=3.19, validation loss=2.26] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:11<00:10,  1.56it/s, Train Loss=3.19, validation loss=2.26] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:11<00:10,  1.56it/s, Train Loss=3.39, validation loss=2.26] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:11<00:10,  1.58it/s, Train Loss=3.39, validation loss=2.26] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:12<00:10,  1.58it/s, Train Loss=2.29, validation loss=2.25] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:12<00:09,  1.59it/s, Train Loss=2.29, validation loss=2.25] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:13<00:09,  1.59it/s, Train Loss=1.49, validation loss=2.27] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:13<00:09,  1.50it/s, Train Loss=1.49, validation loss=2.27] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:13<00:09,  1.50it/s, Train Loss=2.36, validation loss=2.26] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:13<00:08,  1.53it/s, Train Loss=2.36, validation loss=2.26] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:14<00:08,  1.53it/s, Train Loss=1.37, validation loss=2.28] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:14<00:07,  1.56it/s, Train Loss=1.37, validation loss=2.28] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:14<00:07,  1.56it/s, Train Loss=2, validation loss=2.26]    98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:14<00:07,  1.55it/s, Train Loss=2, validation loss=2.26] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:15<00:07,  1.55it/s, Train Loss=4.47, validation loss=2.24] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:15<00:06,  1.56it/s, Train Loss=4.47, validation loss=2.24] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:16<00:06,  1.56it/s, Train Loss=1.47, validation loss=2.26] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:16<00:05,  1.57it/s, Train Loss=1.47, validation loss=2.26] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:16<00:05,  1.57it/s, Train Loss=2.15, validation loss=2.26] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:16<00:05,  1.59it/s, Train Loss=2.15, validation loss=2.26] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:17<00:05,  1.59it/s, Train Loss=1.98, validation loss=2.28] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:17<00:04,  1.57it/s, Train Loss=1.98, validation loss=2.28] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:18<00:04,  1.57it/s, Train Loss=2.31, validation loss=2.3]  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:18<00:04,  1.45it/s, Train Loss=2.31, validation loss=2.3] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:18<00:04,  1.45it/s, Train Loss=2.08, validation loss=2.27] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:18<00:03,  1.49it/s, Train Loss=2.08, validation loss=2.27] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:19<00:03,  1.49it/s, Train Loss=1.71, validation loss=2.28] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:19<00:02,  1.53it/s, Train Loss=1.71, validation loss=2.28] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:20<00:02,  1.53it/s, Train Loss=2.01, validation loss=2.25] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:20<00:01,  1.56it/s, Train Loss=2.01, validation loss=2.25] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:20<00:01,  1.56it/s, Train Loss=1.24, validation loss=2.3] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:20<00:01,  1.54it/s, Train Loss=1.24, validation loss=2.3]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:21<00:01,  1.54it/s, Train Loss=2.53, validation loss=2.27]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:21<00:00,  1.55it/s, Train Loss=2.53, validation loss=2.27]####################################################################################################
--------------------------------------------- Epoch:500 ---------------------------------------------
-- Training set:
Loss: 1.9349008798599243, Lr: 3.125e-05
Average AUC ROC: 0.52                Average AUC PR: 0.28
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:21<00:00,  1.55it/s, Train Loss=1.93, validation loss=2.25]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:21<00:00,  1.57it/s, Train Loss=1.93, validation loss=2.25]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:21<00:00,  1.55it/s, Train Loss=1.93, validation loss=2.25]
----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.2490519359707832
Average AUC ROC: 0.55                    Average AUC PR: 0.3

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 328
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=0, validation loss=0]  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=4.64, validation loss=3.19]  0%|          | 1/500 [00:00<05:32,  1.50it/s, Train Loss=4.64, validation loss=3.19]  0%|          | 1/500 [00:01<05:32,  1.50it/s, Train Loss=3.02, validation loss=2.97]  0%|          | 2/500 [00:01<05:21,  1.55it/s, Train Loss=3.02, validation loss=2.97]  0%|          | 2/500 [00:01<05:21,  1.55it/s, Train Loss=3.49, validation loss=2.83]  1%|          | 3/500 [00:01<05:13,  1.58it/s, Train Loss=3.49, validation loss=2.83]  1%|          | 3/500 [00:02<05:13,  1.58it/s, Train Loss=3.04, validation loss=2.72]  1%|          | 4/500 [00:02<05:09,  1.60it/s, Train Loss=3.04, validation loss=2.72]  1%|          | 4/500 [00:03<05:09,  1.60it/s, Train Loss=3.16, validation loss=2.68]  1%|          | 5/500 [00:03<05:27,  1.51it/s, Train Loss=3.16, validation loss=2.68]  1%|          | 5/500 [00:03<05:27,  1.51it/s, Train Loss=4.03, validation loss=2.6]   1%|          | 6/500 [00:03<05:21,  1.54it/s, Train Loss=4.03, validation loss=2.6]  1%|          | 6/500 [00:04<05:21,  1.54it/s, Train Loss=2.52, validation loss=2.61]  1%|â–         | 7/500 [00:04<05:16,  1.56it/s, Train Loss=2.52, validation loss=2.61]  1%|â–         | 7/500 [00:05<05:16,  1.56it/s, Train Loss=2.56, validation loss=2.59]  2%|â–         | 8/500 [00:05<05:09,  1.59it/s, Train Loss=2.56, validation loss=2.59]  2%|â–         | 8/500 [00:05<05:09,  1.59it/s, Train Loss=2.11, validation loss=2.6]   2%|â–         | 9/500 [00:05<05:20,  1.53it/s, Train Loss=2.11, validation loss=2.6]  2%|â–         | 9/500 [00:06<05:20,  1.53it/s, Train Loss=1.83, validation loss=2.56]  2%|â–         | 10/500 [00:06<05:37,  1.45it/s, Train Loss=1.83, validation loss=2.56]  2%|â–         | 10/500 [00:07<05:37,  1.45it/s, Train Loss=3.92, validation loss=2.59]  2%|â–         | 11/500 [00:07<05:24,  1.51it/s, Train Loss=3.92, validation loss=2.59]  2%|â–         | 11/500 [00:07<05:24,  1.51it/s, Train Loss=4.45, validation loss=2.6]   2%|â–         | 12/500 [00:07<05:13,  1.56it/s, Train Loss=4.45, validation loss=2.6]  2%|â–         | 12/500 [00:08<05:13,  1.56it/s, Train Loss=4.81, validation loss=2.56]  3%|â–         | 13/500 [00:08<05:13,  1.55it/s, Train Loss=4.81, validation loss=2.56]  3%|â–         | 13/500 [00:09<05:13,  1.55it/s, Train Loss=3.56, validation loss=2.54]  3%|â–         | 14/500 [00:09<05:07,  1.58it/s, Train Loss=3.56, validation loss=2.54]  3%|â–         | 14/500 [00:09<05:07,  1.58it/s, Train Loss=3.73, validation loss=2.57]  3%|â–         | 15/500 [00:09<05:06,  1.58it/s, Train Loss=3.73, validation loss=2.57]  3%|â–         | 15/500 [00:10<05:06,  1.58it/s, Train Loss=2.45, validation loss=2.56]  3%|â–         | 16/500 [00:10<05:02,  1.60it/s, Train Loss=2.45, validation loss=2.56]  3%|â–         | 16/500 [00:10<05:02,  1.60it/s, Train Loss=3.79, validation loss=2.54]  3%|â–         | 17/500 [00:10<05:16,  1.53it/s, Train Loss=3.79, validation loss=2.54]  3%|â–         | 17/500 [00:11<05:16,  1.53it/s, Train Loss=2, validation loss=2.54]     4%|â–         | 18/500 [00:11<05:11,  1.55it/s, Train Loss=2, validation loss=2.54]  4%|â–         | 18/500 [00:12<05:11,  1.55it/s, Train Loss=3.63, validation loss=2.53]  4%|â–         | 19/500 [00:12<05:09,  1.55it/s, Train Loss=3.63, validation loss=2.53]  4%|â–         | 19/500 [00:12<05:09,  1.55it/s, Train Loss=3.21, validation loss=2.58]  4%|â–         | 20/500 [00:12<05:05,  1.57it/s, Train Loss=3.21, validation loss=2.58]  4%|â–         | 20/500 [00:13<05:05,  1.57it/s, Train Loss=3.13, validation loss=2.52]  4%|â–         | 21/500 [00:13<05:02,  1.59it/s, Train Loss=3.13, validation loss=2.52]  4%|â–         | 21/500 [00:14<05:02,  1.59it/s, Train Loss=3.68, validation loss=2.53]  4%|â–         | 22/500 [00:14<05:01,  1.59it/s, Train Loss=3.68, validation loss=2.53]  4%|â–         | 22/500 [00:14<05:01,  1.59it/s, Train Loss=2.49, validation loss=2.52]  5%|â–         | 23/500 [00:14<05:03,  1.57it/s, Train Loss=2.49, validation loss=2.52]  5%|â–         | 23/500 [00:15<05:03,  1.57it/s, Train Loss=2.69, validation loss=2.54]  5%|â–         | 24/500 [00:15<05:18,  1.49it/s, Train Loss=2.69, validation loss=2.54]  5%|â–         | 24/500 [00:16<05:18,  1.49it/s, Train Loss=1.75, validation loss=2.52]  5%|â–Œ         | 25/500 [00:16<05:11,  1.53it/s, Train Loss=1.75, validation loss=2.52]  5%|â–Œ         | 25/500 [00:16<05:11,  1.53it/s, Train Loss=2.28, validation loss=2.52]  5%|â–Œ         | 26/500 [00:16<05:05,  1.55it/s, Train Loss=2.28, validation loss=2.52]  5%|â–Œ         | 26/500 [00:17<05:05,  1.55it/s, Train Loss=4.24, validation loss=2.48]  5%|â–Œ         | 27/500 [00:17<05:01,  1.57it/s, Train Loss=4.24, validation loss=2.48]  5%|â–Œ         | 27/500 [00:18<05:01,  1.57it/s, Train Loss=4.24, validation loss=2.48]  6%|â–Œ         | 28/500 [00:18<05:02,  1.56it/s, Train Loss=4.24, validation loss=2.48]  6%|â–Œ         | 28/500 [00:18<05:02,  1.56it/s, Train Loss=3.48, validation loss=2.47]  6%|â–Œ         | 29/500 [00:18<05:16,  1.49it/s, Train Loss=3.48, validation loss=2.47]  6%|â–Œ         | 29/500 [00:19<05:16,  1.49it/s, Train Loss=2.26, validation loss=2.5]   6%|â–Œ         | 30/500 [00:19<05:08,  1.53it/s, Train Loss=2.26, validation loss=2.5]  6%|â–Œ         | 30/500 [00:20<05:08,  1.53it/s, Train Loss=2.42, validation loss=2.47]  6%|â–Œ         | 31/500 [00:20<05:01,  1.56it/s, Train Loss=2.42, validation loss=2.47]  6%|â–Œ         | 31/500 [00:20<05:01,  1.56it/s, Train Loss=2.7, validation loss=2.48]   6%|â–‹         | 32/500 [00:20<04:58,  1.57it/s, Train Loss=2.7, validation loss=2.48]  6%|â–‹         | 32/500 [00:21<04:58,  1.57it/s, Train Loss=3.62, validation loss=2.48]  7%|â–‹         | 33/500 [00:21<04:58,  1.56it/s, Train Loss=3.62, validation loss=2.48]  7%|â–‹         | 33/500 [00:21<04:58,  1.56it/s, Train Loss=3.03, validation loss=2.5]   7%|â–‹         | 34/500 [00:21<04:55,  1.58it/s, Train Loss=3.03, validation loss=2.5]  7%|â–‹         | 34/500 [00:22<04:55,  1.58it/s, Train Loss=2.14, validation loss=2.5]  7%|â–‹         | 35/500 [00:22<04:57,  1.56it/s, Train Loss=2.14, validation loss=2.5]  7%|â–‹         | 35/500 [00:23<04:57,  1.56it/s, Train Loss=3.27, validation loss=2.45]  7%|â–‹         | 36/500 [00:23<05:03,  1.53it/s, Train Loss=3.27, validation loss=2.45]  7%|â–‹         | 36/500 [00:23<05:03,  1.53it/s, Train Loss=3.3, validation loss=2.45]   7%|â–‹         | 37/500 [00:23<04:58,  1.55it/s, Train Loss=3.3, validation loss=2.45]  7%|â–‹         | 37/500 [00:24<04:58,  1.55it/s, Train Loss=2.22, validation loss=2.45]  8%|â–Š         | 38/500 [00:24<04:50,  1.59it/s, Train Loss=2.22, validation loss=2.45]  8%|â–Š         | 38/500 [00:25<04:50,  1.59it/s, Train Loss=1.78, validation loss=2.48]  8%|â–Š         | 39/500 [00:25<04:46,  1.61it/s, Train Loss=1.78, validation loss=2.48]  8%|â–Š         | 39/500 [00:25<04:46,  1.61it/s, Train Loss=1.55, validation loss=2.46]  8%|â–Š         | 40/500 [00:25<04:49,  1.59it/s, Train Loss=1.55, validation loss=2.46]  8%|â–Š         | 40/500 [00:26<04:49,  1.59it/s, Train Loss=3.68, validation loss=2.44]  8%|â–Š         | 41/500 [00:26<05:15,  1.45it/s, Train Loss=3.68, validation loss=2.44]  8%|â–Š         | 41/500 [00:27<05:15,  1.45it/s, Train Loss=1.94, validation loss=2.45]  8%|â–Š         | 42/500 [00:27<05:06,  1.50it/s, Train Loss=1.94, validation loss=2.45]  8%|â–Š         | 42/500 [00:27<05:06,  1.50it/s, Train Loss=1.44, validation loss=2.44]  9%|â–Š         | 43/500 [00:27<05:00,  1.52it/s, Train Loss=1.44, validation loss=2.44]  9%|â–Š         | 43/500 [00:28<05:00,  1.52it/s, Train Loss=2.43, validation loss=2.48]  9%|â–‰         | 44/500 [00:28<04:59,  1.52it/s, Train Loss=2.43, validation loss=2.48]  9%|â–‰         | 44/500 [00:29<04:59,  1.52it/s, Train Loss=2.54, validation loss=2.43]  9%|â–‰         | 45/500 [00:29<04:47,  1.58it/s, Train Loss=2.54, validation loss=2.43]  9%|â–‰         | 45/500 [00:29<04:47,  1.58it/s, Train Loss=2.07, validation loss=2.42]  9%|â–‰         | 46/500 [00:29<04:44,  1.59it/s, Train Loss=2.07, validation loss=2.42]  9%|â–‰         | 46/500 [00:30<04:44,  1.59it/s, Train Loss=2.07, validation loss=2.42]  9%|â–‰         | 47/500 [00:30<04:44,  1.59it/s, Train Loss=2.07, validation loss=2.42]  9%|â–‰         | 47/500 [00:30<04:44,  1.59it/s, Train Loss=2.26, validation loss=2.42] 10%|â–‰         | 48/500 [00:30<04:53,  1.54it/s, Train Loss=2.26, validation loss=2.42] 10%|â–‰         | 48/500 [00:31<04:53,  1.54it/s, Train Loss=2.02, validation loss=2.42] 10%|â–‰         | 49/500 [00:31<04:47,  1.57it/s, Train Loss=2.02, validation loss=2.42] 10%|â–‰         | 49/500 [00:32<04:47,  1.57it/s, Train Loss=2.56, validation loss=2.45] 10%|â–ˆ         | 50/500 [00:32<04:48,  1.56it/s, Train Loss=2.56, validation loss=2.45] 10%|â–ˆ         | 50/500 [00:32<04:48,  1.56it/s, Train Loss=1.83, validation loss=2.41] 10%|â–ˆ         | 51/500 [00:32<04:46,  1.57it/s, Train Loss=1.83, validation loss=2.41] 10%|â–ˆ         | 51/500 [00:33<04:46,  1.57it/s, Train Loss=2.55, validation loss=2.41] 10%|â–ˆ         | 52/500 [00:33<04:40,  1.60it/s, Train Loss=2.55, validation loss=2.41] 10%|â–ˆ         | 52/500 [00:34<04:40,  1.60it/s, Train Loss=2.51, validation loss=2.41] 11%|â–ˆ         | 53/500 [00:34<04:49,  1.54it/s, Train Loss=2.51, validation loss=2.41] 11%|â–ˆ         | 53/500 [00:34<04:49,  1.54it/s, Train Loss=3.11, validation loss=2.41] 11%|â–ˆ         | 54/500 [00:34<04:44,  1.57it/s, Train Loss=3.11, validation loss=2.41] 11%|â–ˆ         | 54/500 [00:35<04:44,  1.57it/s, Train Loss=2.98, validation loss=2.4]  11%|â–ˆ         | 55/500 [00:35<04:41,  1.58it/s, Train Loss=2.98, validation loss=2.4] 11%|â–ˆ         | 55/500 [00:36<04:41,  1.58it/s, Train Loss=3.56, validation loss=2.38] 11%|â–ˆ         | 56/500 [00:36<04:42,  1.57it/s, Train Loss=3.56, validation loss=2.38] 11%|â–ˆ         | 56/500 [00:36<04:42,  1.57it/s, Train Loss=2.15, validation loss=2.4]  11%|â–ˆâ–        | 57/500 [00:36<04:41,  1.57it/s, Train Loss=2.15, validation loss=2.4] 11%|â–ˆâ–        | 57/500 [00:37<04:41,  1.57it/s, Train Loss=3.93, validation loss=2.43] 12%|â–ˆâ–        | 58/500 [00:37<04:38,  1.59it/s, Train Loss=3.93, validation loss=2.43] 12%|â–ˆâ–        | 58/500 [00:37<04:38,  1.59it/s, Train Loss=2.41, validation loss=2.37] 12%|â–ˆâ–        | 59/500 [00:37<04:37,  1.59it/s, Train Loss=2.41, validation loss=2.37] 12%|â–ˆâ–        | 59/500 [00:38<04:37,  1.59it/s, Train Loss=2.63, validation loss=2.38] 12%|â–ˆâ–        | 60/500 [00:38<04:48,  1.52it/s, Train Loss=2.63, validation loss=2.38] 12%|â–ˆâ–        | 60/500 [00:39<04:48,  1.52it/s, Train Loss=2.14, validation loss=2.4]  12%|â–ˆâ–        | 61/500 [00:39<04:44,  1.54it/s, Train Loss=2.14, validation loss=2.4] 12%|â–ˆâ–        | 61/500 [00:39<04:44,  1.54it/s, Train Loss=4.93, validation loss=2.37] 12%|â–ˆâ–        | 62/500 [00:39<04:37,  1.58it/s, Train Loss=4.93, validation loss=2.37] 12%|â–ˆâ–        | 62/500 [00:40<04:37,  1.58it/s, Train Loss=1.19, validation loss=2.4]  13%|â–ˆâ–        | 63/500 [00:40<04:40,  1.56it/s, Train Loss=1.19, validation loss=2.4] 13%|â–ˆâ–        | 63/500 [00:41<04:40,  1.56it/s, Train Loss=1.94, validation loss=2.35] 13%|â–ˆâ–        | 64/500 [00:41<04:41,  1.55it/s, Train Loss=1.94, validation loss=2.35] 13%|â–ˆâ–        | 64/500 [00:41<04:41,  1.55it/s, Train Loss=2.83, validation loss=2.38] 13%|â–ˆâ–        | 65/500 [00:41<04:54,  1.48it/s, Train Loss=2.83, validation loss=2.38] 13%|â–ˆâ–        | 65/500 [00:42<04:54,  1.48it/s, Train Loss=1.7, validation loss=2.36]  13%|â–ˆâ–        | 66/500 [00:42<04:47,  1.51it/s, Train Loss=1.7, validation loss=2.36] 13%|â–ˆâ–        | 66/500 [00:43<04:47,  1.51it/s, Train Loss=2.12, validation loss=2.38] 13%|â–ˆâ–        | 67/500 [00:43<04:41,  1.54it/s, Train Loss=2.12, validation loss=2.38] 13%|â–ˆâ–        | 67/500 [00:43<04:41,  1.54it/s, Train Loss=1.28, validation loss=2.36] 14%|â–ˆâ–        | 68/500 [00:43<04:41,  1.53it/s, Train Loss=1.28, validation loss=2.36] 14%|â–ˆâ–        | 68/500 [00:44<04:41,  1.53it/s, Train Loss=1.8, validation loss=2.38]  14%|â–ˆâ–        | 69/500 [00:44<04:39,  1.54it/s, Train Loss=1.8, validation loss=2.38] 14%|â–ˆâ–        | 69/500 [00:45<04:39,  1.54it/s, Train Loss=2.04, validation loss=2.39] 14%|â–ˆâ–        | 70/500 [00:45<04:36,  1.55it/s, Train Loss=2.04, validation loss=2.39] 14%|â–ˆâ–        | 70/500 [00:45<04:36,  1.55it/s, Train Loss=2.07, validation loss=2.36] 14%|â–ˆâ–        | 71/500 [00:45<04:31,  1.58it/s, Train Loss=2.07, validation loss=2.36] 14%|â–ˆâ–        | 71/500 [00:46<04:31,  1.58it/s, Train Loss=2.37, validation loss=2.35] 14%|â–ˆâ–        | 72/500 [00:46<04:49,  1.48it/s, Train Loss=2.37, validation loss=2.35] 14%|â–ˆâ–        | 72/500 [00:47<04:49,  1.48it/s, Train Loss=1.91, validation loss=2.36] 15%|â–ˆâ–        | 73/500 [00:47<04:40,  1.52it/s, Train Loss=1.91, validation loss=2.36] 15%|â–ˆâ–        | 73/500 [00:47<04:40,  1.52it/s, Train Loss=3.46, validation loss=2.36] 15%|â–ˆâ–        | 74/500 [00:47<04:33,  1.56it/s, Train Loss=3.46, validation loss=2.36] 15%|â–ˆâ–        | 74/500 [00:48<04:33,  1.56it/s, Train Loss=2.84, validation loss=2.35] 15%|â–ˆâ–Œ        | 75/500 [00:48<04:34,  1.55it/s, Train Loss=2.84, validation loss=2.35] 15%|â–ˆâ–Œ        | 75/500 [00:48<04:34,  1.55it/s, Train Loss=2.27, validation loss=2.34] 15%|â–ˆâ–Œ        | 76/500 [00:48<04:32,  1.56it/s, Train Loss=2.27, validation loss=2.34] 15%|â–ˆâ–Œ        | 76/500 [00:49<04:32,  1.56it/s, Train Loss=1.73, validation loss=2.36] 15%|â–ˆâ–Œ        | 77/500 [00:49<04:26,  1.59it/s, Train Loss=1.73, validation loss=2.36] 15%|â–ˆâ–Œ        | 77/500 [00:50<04:26,  1.59it/s, Train Loss=2.27, validation loss=2.35] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:39,  1.51it/s, Train Loss=2.27, validation loss=2.35] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:39,  1.51it/s, Train Loss=3.33, validation loss=2.35] 16%|â–ˆâ–Œ        | 79/500 [00:50<04:37,  1.52it/s, Train Loss=3.33, validation loss=2.35] 16%|â–ˆâ–Œ        | 79/500 [00:51<04:37,  1.52it/s, Train Loss=2.15, validation loss=2.36] 16%|â–ˆâ–Œ        | 80/500 [00:51<04:31,  1.54it/s, Train Loss=2.15, validation loss=2.36] 16%|â–ˆâ–Œ        | 80/500 [00:52<04:31,  1.54it/s, Train Loss=2.5, validation loss=2.35]  16%|â–ˆâ–Œ        | 81/500 [00:52<04:27,  1.56it/s, Train Loss=2.5, validation loss=2.35] 16%|â–ˆâ–Œ        | 81/500 [00:52<04:27,  1.56it/s, Train Loss=2.27, validation loss=2.33] 16%|â–ˆâ–‹        | 82/500 [00:52<04:23,  1.59it/s, Train Loss=2.27, validation loss=2.33] 16%|â–ˆâ–‹        | 82/500 [00:53<04:23,  1.59it/s, Train Loss=3.25, validation loss=2.37] 17%|â–ˆâ–‹        | 83/500 [00:53<04:26,  1.57it/s, Train Loss=3.25, validation loss=2.37] 17%|â–ˆâ–‹        | 83/500 [00:54<04:26,  1.57it/s, Train Loss=1.93, validation loss=2.35] 17%|â–ˆâ–‹        | 84/500 [00:54<04:41,  1.48it/s, Train Loss=1.93, validation loss=2.35] 17%|â–ˆâ–‹        | 84/500 [00:54<04:41,  1.48it/s, Train Loss=1.87, validation loss=2.36] 17%|â–ˆâ–‹        | 85/500 [00:54<04:30,  1.53it/s, Train Loss=1.87, validation loss=2.36] 17%|â–ˆâ–‹        | 85/500 [00:55<04:30,  1.53it/s, Train Loss=3.15, validation loss=2.31] 17%|â–ˆâ–‹        | 86/500 [00:55<04:23,  1.57it/s, Train Loss=3.15, validation loss=2.31] 17%|â–ˆâ–‹        | 86/500 [00:56<04:23,  1.57it/s, Train Loss=1.77, validation loss=2.32] 17%|â–ˆâ–‹        | 87/500 [00:56<04:20,  1.58it/s, Train Loss=1.77, validation loss=2.32] 17%|â–ˆâ–‹        | 87/500 [00:56<04:20,  1.58it/s, Train Loss=2.22, validation loss=2.32] 18%|â–ˆâ–Š        | 88/500 [00:56<04:16,  1.61it/s, Train Loss=2.22, validation loss=2.32] 18%|â–ˆâ–Š        | 88/500 [00:57<04:16,  1.61it/s, Train Loss=2.16, validation loss=2.37] 18%|â–ˆâ–Š        | 89/500 [00:57<04:16,  1.60it/s, Train Loss=2.16, validation loss=2.37] 18%|â–ˆâ–Š        | 89/500 [00:58<04:16,  1.60it/s, Train Loss=2.2, validation loss=2.34]  18%|â–ˆâ–Š        | 90/500 [00:58<04:26,  1.54it/s, Train Loss=2.2, validation loss=2.34] 18%|â–ˆâ–Š        | 90/500 [00:58<04:26,  1.54it/s, Train Loss=3.37, validation loss=2.33] 18%|â–ˆâ–Š        | 91/500 [00:58<04:22,  1.56it/s, Train Loss=3.37, validation loss=2.33] 18%|â–ˆâ–Š        | 91/500 [00:59<04:22,  1.56it/s, Train Loss=1.87, validation loss=2.32] 18%|â–ˆâ–Š        | 92/500 [00:59<04:19,  1.57it/s, Train Loss=1.87, validation loss=2.32] 18%|â–ˆâ–Š        | 92/500 [00:59<04:19,  1.57it/s, Train Loss=2.19, validation loss=2.34] 19%|â–ˆâ–Š        | 93/500 [00:59<04:19,  1.57it/s, Train Loss=2.19, validation loss=2.34] 19%|â–ˆâ–Š        | 93/500 [01:00<04:19,  1.57it/s, Train Loss=1.64, validation loss=2.32] 19%|â–ˆâ–‰        | 94/500 [01:00<04:15,  1.59it/s, Train Loss=1.64, validation loss=2.32] 19%|â–ˆâ–‰        | 94/500 [01:01<04:15,  1.59it/s, Train Loss=2.08, validation loss=2.34] 19%|â–ˆâ–‰        | 95/500 [01:01<04:17,  1.57it/s, Train Loss=2.08, validation loss=2.34] 19%|â–ˆâ–‰        | 95/500 [01:01<04:17,  1.57it/s, Train Loss=1.95, validation loss=2.33] 19%|â–ˆâ–‰        | 96/500 [01:01<04:28,  1.50it/s, Train Loss=1.95, validation loss=2.33] 19%|â–ˆâ–‰        | 96/500 [01:02<04:28,  1.50it/s, Train Loss=1.8, validation loss=2.32]  19%|â–ˆâ–‰        | 97/500 [01:02<04:19,  1.55it/s, Train Loss=1.8, validation loss=2.32] 19%|â–ˆâ–‰        | 97/500 [01:03<04:19,  1.55it/s, Train Loss=2.11, validation loss=2.34] 20%|â–ˆâ–‰        | 98/500 [01:03<04:17,  1.56it/s, Train Loss=2.11, validation loss=2.34] 20%|â–ˆâ–‰        | 98/500 [01:03<04:17,  1.56it/s, Train Loss=2.22, validation loss=2.32] 20%|â–ˆâ–‰        | 99/500 [01:03<04:12,  1.59it/s, Train Loss=2.22, validation loss=2.32]####################################################################################################
--------------------------------------------- Epoch:100 ---------------------------------------------
-- Training set:
Loss: 2.482362747192383, Lr: 0.0005
Average AUC ROC: 0.52                Average AUC PR: 0.28
 20%|â–ˆâ–‰        | 99/500 [01:04<04:12,  1.59it/s, Train Loss=2.48, validation loss=2.3]  20%|â–ˆâ–ˆ        | 100/500 [01:04<04:10,  1.59it/s, Train Loss=2.48, validation loss=2.3]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.296182230114937
Average AUC ROC: 0.55                    Average AUC PR: 0.31
 20%|â–ˆâ–ˆ        | 100/500 [01:04<04:10,  1.59it/s, Train Loss=2.92, validation loss=2.29] 20%|â–ˆâ–ˆ        | 101/500 [01:04<04:09,  1.60it/s, Train Loss=2.92, validation loss=2.29] 20%|â–ˆâ–ˆ        | 101/500 [01:05<04:09,  1.60it/s, Train Loss=2.44, validation loss=2.32] 20%|â–ˆâ–ˆ        | 102/500 [01:05<04:05,  1.62it/s, Train Loss=2.44, validation loss=2.32] 20%|â–ˆâ–ˆ        | 102/500 [01:06<04:05,  1.62it/s, Train Loss=2.12, validation loss=2.31] 21%|â–ˆâ–ˆ        | 103/500 [01:06<04:19,  1.53it/s, Train Loss=2.12, validation loss=2.31] 21%|â–ˆâ–ˆ        | 103/500 [01:06<04:19,  1.53it/s, Train Loss=2.77, validation loss=2.3]  21%|â–ˆâ–ˆ        | 104/500 [01:06<04:18,  1.53it/s, Train Loss=2.77, validation loss=2.3] 21%|â–ˆâ–ˆ        | 104/500 [01:07<04:18,  1.53it/s, Train Loss=2.44, validation loss=2.29] 21%|â–ˆâ–ˆ        | 105/500 [01:07<04:12,  1.56it/s, Train Loss=2.44, validation loss=2.29] 21%|â–ˆâ–ˆ        | 105/500 [01:08<04:12,  1.56it/s, Train Loss=2.11, validation loss=2.32] 21%|â–ˆâ–ˆ        | 106/500 [01:08<04:08,  1.58it/s, Train Loss=2.11, validation loss=2.32] 21%|â–ˆâ–ˆ        | 106/500 [01:08<04:08,  1.58it/s, Train Loss=2.38, validation loss=2.33] 21%|â–ˆâ–ˆâ–       | 107/500 [01:08<04:08,  1.58it/s, Train Loss=2.38, validation loss=2.33] 21%|â–ˆâ–ˆâ–       | 107/500 [01:09<04:08,  1.58it/s, Train Loss=3.06, validation loss=2.32] 22%|â–ˆâ–ˆâ–       | 108/500 [01:09<04:19,  1.51it/s, Train Loss=3.06, validation loss=2.32] 22%|â–ˆâ–ˆâ–       | 108/500 [01:10<04:19,  1.51it/s, Train Loss=2.93, validation loss=2.31] 22%|â–ˆâ–ˆâ–       | 109/500 [01:10<04:15,  1.53it/s, Train Loss=2.93, validation loss=2.31] 22%|â–ˆâ–ˆâ–       | 109/500 [01:10<04:15,  1.53it/s, Train Loss=3.06, validation loss=2.32] 22%|â–ˆâ–ˆâ–       | 110/500 [01:10<04:10,  1.56it/s, Train Loss=3.06, validation loss=2.32] 22%|â–ˆâ–ˆâ–       | 110/500 [01:11<04:10,  1.56it/s, Train Loss=3.35, validation loss=2.3]  22%|â–ˆâ–ˆâ–       | 111/500 [01:11<04:10,  1.55it/s, Train Loss=3.35, validation loss=2.3] 22%|â–ˆâ–ˆâ–       | 111/500 [01:12<04:10,  1.55it/s, Train Loss=1.91, validation loss=2.29] 22%|â–ˆâ–ˆâ–       | 112/500 [01:12<04:10,  1.55it/s, Train Loss=1.91, validation loss=2.29] 22%|â–ˆâ–ˆâ–       | 112/500 [01:12<04:10,  1.55it/s, Train Loss=2.24, validation loss=2.32] 23%|â–ˆâ–ˆâ–       | 113/500 [01:12<04:06,  1.57it/s, Train Loss=2.24, validation loss=2.32] 23%|â–ˆâ–ˆâ–       | 113/500 [01:13<04:06,  1.57it/s, Train Loss=2.64, validation loss=2.3]  23%|â–ˆâ–ˆâ–       | 114/500 [01:13<04:04,  1.58it/s, Train Loss=2.64, validation loss=2.3] 23%|â–ˆâ–ˆâ–       | 114/500 [01:14<04:04,  1.58it/s, Train Loss=1.42, validation loss=2.31] 23%|â–ˆâ–ˆâ–       | 115/500 [01:14<04:16,  1.50it/s, Train Loss=1.42, validation loss=2.31] 23%|â–ˆâ–ˆâ–       | 115/500 [01:14<04:16,  1.50it/s, Train Loss=2.1, validation loss=2.32]  23%|â–ˆâ–ˆâ–       | 116/500 [01:14<04:08,  1.55it/s, Train Loss=2.1, validation loss=2.32] 23%|â–ˆâ–ˆâ–       | 116/500 [01:15<04:08,  1.55it/s, Train Loss=2.21, validation loss=2.32] 23%|â–ˆâ–ˆâ–       | 117/500 [01:15<04:02,  1.58it/s, Train Loss=2.21, validation loss=2.32] 23%|â–ˆâ–ˆâ–       | 117/500 [01:15<04:02,  1.58it/s, Train Loss=3.54, validation loss=2.33] 24%|â–ˆâ–ˆâ–       | 118/500 [01:15<04:01,  1.58it/s, Train Loss=3.54, validation loss=2.33] 24%|â–ˆâ–ˆâ–       | 118/500 [01:16<04:01,  1.58it/s, Train Loss=1.75, validation loss=2.32] 24%|â–ˆâ–ˆâ–       | 119/500 [01:16<03:58,  1.60it/s, Train Loss=1.75, validation loss=2.32] 24%|â–ˆâ–ˆâ–       | 119/500 [01:17<03:58,  1.60it/s, Train Loss=2.07, validation loss=2.32] 24%|â–ˆâ–ˆâ–       | 120/500 [01:17<04:05,  1.55it/s, Train Loss=2.07, validation loss=2.32] 24%|â–ˆâ–ˆâ–       | 120/500 [01:17<04:05,  1.55it/s, Train Loss=2.04, validation loss=2.31] 24%|â–ˆâ–ˆâ–       | 121/500 [01:17<04:05,  1.55it/s, Train Loss=2.04, validation loss=2.31] 24%|â–ˆâ–ˆâ–       | 121/500 [01:18<04:05,  1.55it/s, Train Loss=2.57, validation loss=2.3]  24%|â–ˆâ–ˆâ–       | 122/500 [01:18<04:02,  1.56it/s, Train Loss=2.57, validation loss=2.3] 24%|â–ˆâ–ˆâ–       | 122/500 [01:19<04:02,  1.56it/s, Train Loss=1.73, validation loss=2.31] 25%|â–ˆâ–ˆâ–       | 123/500 [01:19<04:01,  1.56it/s, Train Loss=1.73, validation loss=2.31] 25%|â–ˆâ–ˆâ–       | 123/500 [01:19<04:01,  1.56it/s, Train Loss=1.77, validation loss=2.3]  25%|â–ˆâ–ˆâ–       | 124/500 [01:19<04:01,  1.55it/s, Train Loss=1.77, validation loss=2.3] 25%|â–ˆâ–ˆâ–       | 124/500 [01:20<04:01,  1.55it/s, Train Loss=2.9, validation loss=2.32] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:20<04:02,  1.55it/s, Train Loss=2.9, validation loss=2.32] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:21<04:02,  1.55it/s, Train Loss=2.58, validation loss=2.32] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:21<04:00,  1.56it/s, Train Loss=2.58, validation loss=2.32] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:21<04:00,  1.56it/s, Train Loss=2.4, validation loss=2.32]  25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:21<04:13,  1.47it/s, Train Loss=2.4, validation loss=2.32] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:22<04:13,  1.47it/s, Train Loss=2.79, validation loss=2.3] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:22<04:07,  1.50it/s, Train Loss=2.79, validation loss=2.3] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:23<04:07,  1.50it/s, Train Loss=1.9, validation loss=2.31] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:23<03:58,  1.55it/s, Train Loss=1.9, validation loss=2.31] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:23<03:58,  1.55it/s, Train Loss=3.62, validation loss=2.29] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:23<03:59,  1.54it/s, Train Loss=3.62, validation loss=2.29] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:24<03:59,  1.54it/s, Train Loss=2.06, validation loss=2.3]  26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:24<04:11,  1.47it/s, Train Loss=2.06, validation loss=2.3] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:25<04:11,  1.47it/s, Train Loss=1.54, validation loss=2.3] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:25<04:00,  1.53it/s, Train Loss=1.54, validation loss=2.3] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:25<04:00,  1.53it/s, Train Loss=2.62, validation loss=2.31] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:25<03:55,  1.56it/s, Train Loss=2.62, validation loss=2.31] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:26<03:55,  1.56it/s, Train Loss=1.7, validation loss=2.31]  27%|â–ˆâ–ˆâ–‹       | 134/500 [01:26<03:52,  1.57it/s, Train Loss=1.7, validation loss=2.31] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:26<03:52,  1.57it/s, Train Loss=3.08, validation loss=2.32] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:26<03:50,  1.58it/s, Train Loss=3.08, validation loss=2.32] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:27<03:50,  1.58it/s, Train Loss=2.21, validation loss=2.32] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:27<03:51,  1.57it/s, Train Loss=2.21, validation loss=2.32] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:28<03:51,  1.57it/s, Train Loss=5.4, validation loss=2.3]   27%|â–ˆâ–ˆâ–‹       | 137/500 [01:28<03:47,  1.60it/s, Train Loss=5.4, validation loss=2.3] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:28<03:47,  1.60it/s, Train Loss=1.53, validation loss=2.32] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:28<04:00,  1.50it/s, Train Loss=1.53, validation loss=2.32] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:29<04:00,  1.50it/s, Train Loss=2.78, validation loss=2.31] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:29<03:55,  1.53it/s, Train Loss=2.78, validation loss=2.31] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:30<03:55,  1.53it/s, Train Loss=2.66, validation loss=2.3]  28%|â–ˆâ–ˆâ–Š       | 140/500 [01:30<03:51,  1.56it/s, Train Loss=2.66, validation loss=2.3] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:30<03:51,  1.56it/s, Train Loss=1.7, validation loss=2.31] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:30<03:46,  1.58it/s, Train Loss=1.7, validation loss=2.31] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:31<03:46,  1.58it/s, Train Loss=2.57, validation loss=2.29] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:31<03:47,  1.58it/s, Train Loss=2.57, validation loss=2.29] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:32<03:47,  1.58it/s, Train Loss=2.96, validation loss=2.29] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:32<03:54,  1.52it/s, Train Loss=2.96, validation loss=2.29] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:32<03:54,  1.52it/s, Train Loss=3.14, validation loss=2.29] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:32<03:49,  1.55it/s, Train Loss=3.14, validation loss=2.29] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:33<03:49,  1.55it/s, Train Loss=1.89, validation loss=2.3]  29%|â–ˆâ–ˆâ–‰       | 145/500 [01:33<03:51,  1.54it/s, Train Loss=1.89, validation loss=2.3] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:34<03:51,  1.54it/s, Train Loss=2.7, validation loss=2.29] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:34<03:48,  1.55it/s, Train Loss=2.7, validation loss=2.29] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:34<03:48,  1.55it/s, Train Loss=1.54, validation loss=2.31] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:34<03:45,  1.57it/s, Train Loss=1.54, validation loss=2.31] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:35<03:45,  1.57it/s, Train Loss=2.33, validation loss=2.31] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:35<03:43,  1.57it/s, Train Loss=2.33, validation loss=2.31] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:35<03:43,  1.57it/s, Train Loss=2.51, validation loss=2.28] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:35<03:44,  1.57it/s, Train Loss=2.51, validation loss=2.28] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:36<03:44,  1.57it/s, Train Loss=2.17, validation loss=2.29] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:36<03:50,  1.52it/s, Train Loss=2.17, validation loss=2.29] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:37<03:50,  1.52it/s, Train Loss=2.99, validation loss=2.29] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:37<03:46,  1.54it/s, Train Loss=2.99, validation loss=2.29] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:37<03:46,  1.54it/s, Train Loss=2.85, validation loss=2.28] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:37<03:42,  1.56it/s, Train Loss=2.85, validation loss=2.28] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:38<03:42,  1.56it/s, Train Loss=2.52, validation loss=2.28] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:38<03:37,  1.60it/s, Train Loss=2.52, validation loss=2.28] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:39<03:37,  1.60it/s, Train Loss=2.19, validation loss=2.28] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:39<03:46,  1.53it/s, Train Loss=2.19, validation loss=2.28] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:39<03:46,  1.53it/s, Train Loss=2.13, validation loss=2.31] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:39<03:40,  1.56it/s, Train Loss=2.13, validation loss=2.31] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:40<03:40,  1.56it/s, Train Loss=1.74, validation loss=2.3]  31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:40<03:36,  1.59it/s, Train Loss=1.74, validation loss=2.3] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:41<03:36,  1.59it/s, Train Loss=2.13, validation loss=2.29] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:41<03:33,  1.61it/s, Train Loss=2.13, validation loss=2.29] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:41<03:33,  1.61it/s, Train Loss=2.17, validation loss=2.3]  32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:41<03:35,  1.58it/s, Train Loss=2.17, validation loss=2.3] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:42<03:35,  1.58it/s, Train Loss=2.89, validation loss=2.28] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:42<03:34,  1.59it/s, Train Loss=2.89, validation loss=2.28] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:42<03:34,  1.59it/s, Train Loss=2.91, validation loss=2.29] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:42<03:38,  1.56it/s, Train Loss=2.91, validation loss=2.29] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:43<03:38,  1.56it/s, Train Loss=5.52, validation loss=2.28] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:43<03:38,  1.55it/s, Train Loss=5.52, validation loss=2.28] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:44<03:38,  1.55it/s, Train Loss=1.26, validation loss=2.28] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:44<03:44,  1.51it/s, Train Loss=1.26, validation loss=2.28] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:44<03:44,  1.51it/s, Train Loss=2.39, validation loss=2.28] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:44<03:36,  1.56it/s, Train Loss=2.39, validation loss=2.28] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:45<03:36,  1.56it/s, Train Loss=4.07, validation loss=2.29] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:45<03:33,  1.57it/s, Train Loss=4.07, validation loss=2.29] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:46<03:33,  1.57it/s, Train Loss=1.78, validation loss=2.3]  33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:46<03:29,  1.60it/s, Train Loss=1.78, validation loss=2.3] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:46<03:29,  1.60it/s, Train Loss=2.16, validation loss=2.29] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:46<03:33,  1.56it/s, Train Loss=2.16, validation loss=2.29] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:47<03:33,  1.56it/s, Train Loss=1.45, validation loss=2.3]  33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:47<03:33,  1.56it/s, Train Loss=1.45, validation loss=2.3] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:48<03:33,  1.56it/s, Train Loss=2.08, validation loss=2.3] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:48<03:30,  1.58it/s, Train Loss=2.08, validation loss=2.3] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:48<03:30,  1.58it/s, Train Loss=2.22, validation loss=2.3] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:48<03:27,  1.59it/s, Train Loss=2.22, validation loss=2.3] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:49<03:27,  1.59it/s, Train Loss=1.52, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:49<03:27,  1.59it/s, Train Loss=1.52, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:49<03:27,  1.59it/s, Train Loss=1.72, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:49<03:26,  1.59it/s, Train Loss=1.72, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:50<03:26,  1.59it/s, Train Loss=2.5, validation loss=2.3]   34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:50<03:25,  1.60it/s, Train Loss=2.5, validation loss=2.3] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:51<03:25,  1.60it/s, Train Loss=2.04, validation loss=2.3] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:51<03:22,  1.61it/s, Train Loss=2.04, validation loss=2.3] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:51<03:22,  1.61it/s, Train Loss=2.34, validation loss=2.31] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:51<03:35,  1.51it/s, Train Loss=2.34, validation loss=2.31] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:52<03:35,  1.51it/s, Train Loss=2.28, validation loss=2.28] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:52<03:32,  1.53it/s, Train Loss=2.28, validation loss=2.28] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:53<03:32,  1.53it/s, Train Loss=2.62, validation loss=2.28] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:53<03:27,  1.56it/s, Train Loss=2.62, validation loss=2.28] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:53<03:27,  1.56it/s, Train Loss=2.64, validation loss=2.29] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:53<03:28,  1.55it/s, Train Loss=2.64, validation loss=2.29] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:54<03:28,  1.55it/s, Train Loss=1.56, validation loss=2.31] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:54<03:34,  1.50it/s, Train Loss=1.56, validation loss=2.31] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:55<03:34,  1.50it/s, Train Loss=5.08, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:55<03:31,  1.52it/s, Train Loss=5.08, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:55<03:31,  1.52it/s, Train Loss=2.05, validation loss=2.28] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:55<03:29,  1.53it/s, Train Loss=2.05, validation loss=2.28] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:56<03:29,  1.53it/s, Train Loss=1.86, validation loss=2.3]  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:56<03:27,  1.54it/s, Train Loss=1.86, validation loss=2.3] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:57<03:27,  1.54it/s, Train Loss=2.18, validation loss=2.3] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:57<03:24,  1.56it/s, Train Loss=2.18, validation loss=2.3] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:57<03:24,  1.56it/s, Train Loss=2.14, validation loss=2.29] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:57<03:25,  1.54it/s, Train Loss=2.14, validation loss=2.29] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:58<03:25,  1.54it/s, Train Loss=2.47, validation loss=2.28] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:58<03:20,  1.57it/s, Train Loss=2.47, validation loss=2.28] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:59<03:20,  1.57it/s, Train Loss=1.57, validation loss=2.28] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:59<03:26,  1.52it/s, Train Loss=1.57, validation loss=2.28] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:59<03:26,  1.52it/s, Train Loss=2.66, validation loss=2.28] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [01:59<03:20,  1.57it/s, Train Loss=2.66, validation loss=2.28] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:00<03:20,  1.57it/s, Train Loss=1.77, validation loss=2.29] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:00<03:18,  1.58it/s, Train Loss=1.77, validation loss=2.29] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:00<03:18,  1.58it/s, Train Loss=1.55, validation loss=2.3]  38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:00<03:18,  1.57it/s, Train Loss=1.55, validation loss=2.3] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:01<03:18,  1.57it/s, Train Loss=2.37, validation loss=2.3] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:01<03:22,  1.54it/s, Train Loss=2.37, validation loss=2.3] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:02<03:22,  1.54it/s, Train Loss=1.68, validation loss=2.29] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:02<03:20,  1.55it/s, Train Loss=1.68, validation loss=2.29] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:02<03:20,  1.55it/s, Train Loss=1.52, validation loss=2.28] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:02<03:15,  1.58it/s, Train Loss=1.52, validation loss=2.28] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:03<03:15,  1.58it/s, Train Loss=1.88, validation loss=2.29] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:03<03:21,  1.53it/s, Train Loss=1.88, validation loss=2.29] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:04<03:21,  1.53it/s, Train Loss=2.29, validation loss=2.29] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:04<03:15,  1.57it/s, Train Loss=2.29, validation loss=2.29] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:04<03:15,  1.57it/s, Train Loss=1.58, validation loss=2.28] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:04<03:10,  1.61it/s, Train Loss=1.58, validation loss=2.28] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:05<03:10,  1.61it/s, Train Loss=1.6, validation loss=2.28]  39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:05<03:10,  1.60it/s, Train Loss=1.6, validation loss=2.28] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:06<03:10,  1.60it/s, Train Loss=1.4, validation loss=2.31] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:06<03:17,  1.54it/s, Train Loss=1.4, validation loss=2.31] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:06<03:17,  1.54it/s, Train Loss=2.56, validation loss=2.3] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:06<03:14,  1.56it/s, Train Loss=2.56, validation loss=2.3] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:07<03:14,  1.56it/s, Train Loss=1.63, validation loss=2.32] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:07<03:14,  1.55it/s, Train Loss=1.63, validation loss=2.32] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:07<03:14,  1.55it/s, Train Loss=2.86, validation loss=2.3]  40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:07<03:13,  1.56it/s, Train Loss=2.86, validation loss=2.3]####################################################################################################
--------------------------------------------- Epoch:200 ---------------------------------------------
-- Training set:
Loss: 2.6791329383850098, Lr: 0.00025
Average AUC ROC: 0.52                Average AUC PR: 0.28
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:08<03:13,  1.56it/s, Train Loss=2.68, validation loss=2.28] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:08<03:18,  1.51it/s, Train Loss=2.68, validation loss=2.28]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.280949153006077
Average AUC ROC: 0.55                    Average AUC PR: 0.31
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:09<03:18,  1.51it/s, Train Loss=3.07, validation loss=2.3]  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:09<03:15,  1.53it/s, Train Loss=3.07, validation loss=2.3] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:09<03:15,  1.53it/s, Train Loss=2.09, validation loss=2.29] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:09<03:13,  1.54it/s, Train Loss=2.09, validation loss=2.29] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:10<03:13,  1.54it/s, Train Loss=1.96, validation loss=2.28] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:10<03:08,  1.57it/s, Train Loss=1.96, validation loss=2.28] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:11<03:08,  1.57it/s, Train Loss=2.21, validation loss=2.3]  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:11<03:09,  1.56it/s, Train Loss=2.21, validation loss=2.3] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:11<03:09,  1.56it/s, Train Loss=2.13, validation loss=2.29] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:11<03:04,  1.60it/s, Train Loss=2.13, validation loss=2.29] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:12<03:04,  1.60it/s, Train Loss=1.4, validation loss=2.28]  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:12<03:09,  1.56it/s, Train Loss=1.4, validation loss=2.28] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:13<03:09,  1.56it/s, Train Loss=1.61, validation loss=2.28] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:13<03:09,  1.54it/s, Train Loss=1.61, validation loss=2.28] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:13<03:09,  1.54it/s, Train Loss=2.3, validation loss=2.28]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:13<03:08,  1.55it/s, Train Loss=2.3, validation loss=2.28] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:14<03:08,  1.55it/s, Train Loss=1.61, validation loss=2.28] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:14<03:05,  1.57it/s, Train Loss=1.61, validation loss=2.28] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:15<03:05,  1.57it/s, Train Loss=2.56, validation loss=2.28] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:15<03:05,  1.56it/s, Train Loss=2.56, validation loss=2.28] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:15<03:05,  1.56it/s, Train Loss=2.3, validation loss=2.28]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:15<03:03,  1.58it/s, Train Loss=2.3, validation loss=2.28] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:16<03:03,  1.58it/s, Train Loss=2.99, validation loss=2.29] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:16<03:09,  1.52it/s, Train Loss=2.99, validation loss=2.29] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:17<03:09,  1.52it/s, Train Loss=2.27, validation loss=2.3]  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:17<03:05,  1.54it/s, Train Loss=2.27, validation loss=2.3] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:17<03:05,  1.54it/s, Train Loss=3.02, validation loss=2.3] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:17<03:02,  1.57it/s, Train Loss=3.02, validation loss=2.3] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:18<03:02,  1.57it/s, Train Loss=1.87, validation loss=2.28] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:18<02:56,  1.61it/s, Train Loss=1.87, validation loss=2.28] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:18<02:56,  1.61it/s, Train Loss=3.03, validation loss=2.29] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:18<03:04,  1.54it/s, Train Loss=3.03, validation loss=2.29] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:19<03:04,  1.54it/s, Train Loss=2.38, validation loss=2.3]  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:19<03:10,  1.49it/s, Train Loss=2.38, validation loss=2.3] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:20<03:10,  1.49it/s, Train Loss=1.6, validation loss=2.31] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:20<03:06,  1.51it/s, Train Loss=1.6, validation loss=2.31] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:20<03:06,  1.51it/s, Train Loss=2.42, validation loss=2.3] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:20<03:00,  1.55it/s, Train Loss=2.42, validation loss=2.3] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:21<03:00,  1.55it/s, Train Loss=3.23, validation loss=2.27] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:21<02:58,  1.57it/s, Train Loss=3.23, validation loss=2.27] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:22<02:58,  1.57it/s, Train Loss=3.1, validation loss=2.29]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:22<02:55,  1.59it/s, Train Loss=3.1, validation loss=2.29] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:22<02:55,  1.59it/s, Train Loss=2.57, validation loss=2.3] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:22<02:54,  1.59it/s, Train Loss=2.57, validation loss=2.3] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:23<02:54,  1.59it/s, Train Loss=2.39, validation loss=2.27] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:23<03:02,  1.52it/s, Train Loss=2.39, validation loss=2.27] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:24<03:02,  1.52it/s, Train Loss=1.99, validation loss=2.3]  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:24<02:58,  1.55it/s, Train Loss=1.99, validation loss=2.3] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:24<02:58,  1.55it/s, Train Loss=1.72, validation loss=2.3] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:24<02:58,  1.54it/s, Train Loss=1.72, validation loss=2.3] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:25<02:58,  1.54it/s, Train Loss=1.32, validation loss=2.28] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:25<02:52,  1.58it/s, Train Loss=1.32, validation loss=2.28] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:26<02:52,  1.58it/s, Train Loss=2.34, validation loss=2.27] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:26<02:58,  1.53it/s, Train Loss=2.34, validation loss=2.27] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:26<02:58,  1.53it/s, Train Loss=2.74, validation loss=2.28] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:26<02:55,  1.55it/s, Train Loss=2.74, validation loss=2.28] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:27<02:55,  1.55it/s, Train Loss=2.92, validation loss=2.29] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:27<02:53,  1.56it/s, Train Loss=2.92, validation loss=2.29] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:27<02:53,  1.56it/s, Train Loss=1.84, validation loss=2.28] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:27<02:51,  1.58it/s, Train Loss=1.84, validation loss=2.28] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:28<02:51,  1.58it/s, Train Loss=1.8, validation loss=2.27]  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:28<02:47,  1.60it/s, Train Loss=1.8, validation loss=2.27] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:29<02:47,  1.60it/s, Train Loss=3.7, validation loss=2.27] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:29<02:48,  1.59it/s, Train Loss=3.7, validation loss=2.27] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:29<02:48,  1.59it/s, Train Loss=2.4, validation loss=2.27] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:29<02:47,  1.59it/s, Train Loss=2.4, validation loss=2.27] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:30<02:47,  1.59it/s, Train Loss=2.57, validation loss=2.27] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:30<02:56,  1.51it/s, Train Loss=2.57, validation loss=2.27] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:31<02:56,  1.51it/s, Train Loss=2.69, validation loss=2.28] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:31<02:52,  1.53it/s, Train Loss=2.69, validation loss=2.28] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:31<02:52,  1.53it/s, Train Loss=1.91, validation loss=2.27] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:31<02:47,  1.57it/s, Train Loss=1.91, validation loss=2.27] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:32<02:47,  1.57it/s, Train Loss=1.98, validation loss=2.28] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:32<02:47,  1.57it/s, Train Loss=1.98, validation loss=2.28] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:33<02:47,  1.57it/s, Train Loss=2.72, validation loss=2.27] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:33<02:52,  1.52it/s, Train Loss=2.72, validation loss=2.27] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:33<02:52,  1.52it/s, Train Loss=1.69, validation loss=2.31] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:33<02:56,  1.48it/s, Train Loss=1.69, validation loss=2.31] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:34<02:56,  1.48it/s, Train Loss=2.22, validation loss=2.3]  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:34<02:53,  1.50it/s, Train Loss=2.22, validation loss=2.3] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:35<02:53,  1.50it/s, Train Loss=2.5, validation loss=2.27] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:35<02:50,  1.52it/s, Train Loss=2.5, validation loss=2.27] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:35<02:50,  1.52it/s, Train Loss=1.92, validation loss=2.29] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:35<02:49,  1.52it/s, Train Loss=1.92, validation loss=2.29] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:36<02:49,  1.52it/s, Train Loss=5.04, validation loss=2.27] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:36<02:48,  1.53it/s, Train Loss=5.04, validation loss=2.27] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:37<02:48,  1.53it/s, Train Loss=1.98, validation loss=2.3]  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:37<02:45,  1.55it/s, Train Loss=1.98, validation loss=2.3] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:37<02:45,  1.55it/s, Train Loss=1.42, validation loss=2.3] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:37<02:46,  1.53it/s, Train Loss=1.42, validation loss=2.3] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:38<02:46,  1.53it/s, Train Loss=1.98, validation loss=2.29] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:38<02:45,  1.54it/s, Train Loss=1.98, validation loss=2.29] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:39<02:45,  1.54it/s, Train Loss=2.02, validation loss=2.29] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:39<02:44,  1.54it/s, Train Loss=2.02, validation loss=2.29] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:39<02:44,  1.54it/s, Train Loss=2.18, validation loss=2.31] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:39<02:44,  1.53it/s, Train Loss=2.18, validation loss=2.31] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:40<02:44,  1.53it/s, Train Loss=2.99, validation loss=2.28] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:40<02:45,  1.51it/s, Train Loss=2.99, validation loss=2.28] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:40<02:45,  1.51it/s, Train Loss=2.67, validation loss=2.26] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:40<02:42,  1.54it/s, Train Loss=2.67, validation loss=2.26] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:41<02:42,  1.54it/s, Train Loss=2.2, validation loss=2.27]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:41<02:40,  1.55it/s, Train Loss=2.2, validation loss=2.27] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:42<02:40,  1.55it/s, Train Loss=3.28, validation loss=2.29] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:42<02:38,  1.56it/s, Train Loss=3.28, validation loss=2.29] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:42<02:38,  1.56it/s, Train Loss=1.49, validation loss=2.28] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:42<02:37,  1.57it/s, Train Loss=1.49, validation loss=2.28] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:43<02:37,  1.57it/s, Train Loss=1.68, validation loss=2.3]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:43<02:35,  1.58it/s, Train Loss=1.68, validation loss=2.3] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:44<02:35,  1.58it/s, Train Loss=3.92, validation loss=2.28] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:44<02:34,  1.59it/s, Train Loss=3.92, validation loss=2.28] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:44<02:34,  1.59it/s, Train Loss=2.19, validation loss=2.3]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:44<02:32,  1.60it/s, Train Loss=2.19, validation loss=2.3] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:45<02:32,  1.60it/s, Train Loss=3.78, validation loss=2.27] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:45<02:38,  1.53it/s, Train Loss=3.78, validation loss=2.27] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:46<02:38,  1.53it/s, Train Loss=2.57, validation loss=2.28] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:46<02:35,  1.55it/s, Train Loss=2.57, validation loss=2.28] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:46<02:35,  1.55it/s, Train Loss=2.67, validation loss=2.27] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:46<02:32,  1.58it/s, Train Loss=2.67, validation loss=2.27] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:47<02:32,  1.58it/s, Train Loss=3.86, validation loss=2.28] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:47<02:40,  1.49it/s, Train Loss=3.86, validation loss=2.28] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:48<02:40,  1.49it/s, Train Loss=1.44, validation loss=2.3]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:48<02:43,  1.46it/s, Train Loss=1.44, validation loss=2.3] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:48<02:43,  1.46it/s, Train Loss=2.9, validation loss=2.28] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:48<02:41,  1.47it/s, Train Loss=2.9, validation loss=2.28] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:49<02:41,  1.47it/s, Train Loss=1.74, validation loss=2.29] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:49<02:41,  1.47it/s, Train Loss=1.74, validation loss=2.29] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:50<02:41,  1.47it/s, Train Loss=1.39, validation loss=2.29] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:50<02:36,  1.51it/s, Train Loss=1.39, validation loss=2.29] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:50<02:36,  1.51it/s, Train Loss=3.1, validation loss=2.27]  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:50<02:31,  1.55it/s, Train Loss=3.1, validation loss=2.27] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:51<02:31,  1.55it/s, Train Loss=1.81, validation loss=2.28] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:51<02:29,  1.57it/s, Train Loss=1.81, validation loss=2.28] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:52<02:29,  1.57it/s, Train Loss=1.13, validation loss=2.32] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:52<02:29,  1.56it/s, Train Loss=1.13, validation loss=2.32] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:52<02:29,  1.56it/s, Train Loss=2, validation loss=2.29]    54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:52<02:28,  1.56it/s, Train Loss=2, validation loss=2.29] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:53<02:28,  1.56it/s, Train Loss=1.5, validation loss=2.27] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:53<02:27,  1.57it/s, Train Loss=1.5, validation loss=2.27] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:53<02:27,  1.57it/s, Train Loss=3.95, validation loss=2.28] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:53<02:29,  1.54it/s, Train Loss=3.95, validation loss=2.28] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:54<02:29,  1.54it/s, Train Loss=1.19, validation loss=2.28] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:54<02:34,  1.49it/s, Train Loss=1.19, validation loss=2.28] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:55<02:34,  1.49it/s, Train Loss=1.65, validation loss=2.28] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:55<02:48,  1.35it/s, Train Loss=1.65, validation loss=2.28] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:56<02:48,  1.35it/s, Train Loss=2.4, validation loss=2.29]  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:56<02:54,  1.30it/s, Train Loss=2.4, validation loss=2.29] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:57<02:54,  1.30it/s, Train Loss=2.66, validation loss=2.26] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:57<03:04,  1.22it/s, Train Loss=2.66, validation loss=2.26] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:58<03:04,  1.22it/s, Train Loss=1.7, validation loss=2.31]  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:58<03:09,  1.19it/s, Train Loss=1.7, validation loss=2.31] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:59<03:09,  1.19it/s, Train Loss=2.27, validation loss=2.29] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:59<03:13,  1.16it/s, Train Loss=2.27, validation loss=2.29] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [03:00<03:13,  1.16it/s, Train Loss=2.4, validation loss=2.29]  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [03:00<03:12,  1.16it/s, Train Loss=2.4, validation loss=2.29] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [03:00<03:12,  1.16it/s, Train Loss=1.58, validation loss=2.27] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [03:00<02:55,  1.27it/s, Train Loss=1.58, validation loss=2.27] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [03:01<02:55,  1.27it/s, Train Loss=3.62, validation loss=2.28] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:01<02:45,  1.33it/s, Train Loss=3.62, validation loss=2.28] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:01<02:45,  1.33it/s, Train Loss=2.24, validation loss=2.32] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:01<02:36,  1.40it/s, Train Loss=2.24, validation loss=2.32] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:02<02:36,  1.40it/s, Train Loss=3.07, validation loss=2.27] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:02<02:31,  1.44it/s, Train Loss=3.07, validation loss=2.27] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:03<02:31,  1.44it/s, Train Loss=1.82, validation loss=2.26] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:03<02:25,  1.50it/s, Train Loss=1.82, validation loss=2.26] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:03<02:25,  1.50it/s, Train Loss=1.68, validation loss=2.28] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:03<02:19,  1.55it/s, Train Loss=1.68, validation loss=2.28] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:04<02:19,  1.55it/s, Train Loss=2.14, validation loss=2.29] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:04<02:16,  1.58it/s, Train Loss=2.14, validation loss=2.29] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:04<02:16,  1.58it/s, Train Loss=1.73, validation loss=2.27] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:04<02:14,  1.60it/s, Train Loss=1.73, validation loss=2.27] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:05<02:14,  1.60it/s, Train Loss=1.76, validation loss=2.28] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:05<02:13,  1.60it/s, Train Loss=1.76, validation loss=2.28] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:06<02:13,  1.60it/s, Train Loss=1.14, validation loss=2.28] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:06<02:12,  1.61it/s, Train Loss=1.14, validation loss=2.28] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:06<02:12,  1.61it/s, Train Loss=1.44, validation loss=2.28] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:06<02:13,  1.59it/s, Train Loss=1.44, validation loss=2.28] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:07<02:13,  1.59it/s, Train Loss=3.13, validation loss=2.26] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:07<02:10,  1.61it/s, Train Loss=3.13, validation loss=2.26] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:08<02:10,  1.61it/s, Train Loss=1.43, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:08<02:10,  1.61it/s, Train Loss=1.43, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:08<02:10,  1.61it/s, Train Loss=1.56, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:08<02:09,  1.61it/s, Train Loss=1.56, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:09<02:09,  1.61it/s, Train Loss=1.61, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:09<02:08,  1.62it/s, Train Loss=1.61, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:09<02:08,  1.62it/s, Train Loss=1.6, validation loss=2.27]  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:09<02:09,  1.59it/s, Train Loss=1.6, validation loss=2.27] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:10<02:09,  1.59it/s, Train Loss=1.56, validation loss=2.27] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:10<02:09,  1.59it/s, Train Loss=1.56, validation loss=2.27] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:11<02:09,  1.59it/s, Train Loss=1.88, validation loss=2.28] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:11<02:08,  1.60it/s, Train Loss=1.88, validation loss=2.28] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:11<02:08,  1.60it/s, Train Loss=1.78, validation loss=2.27] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:11<02:07,  1.60it/s, Train Loss=1.78, validation loss=2.27] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:12<02:07,  1.60it/s, Train Loss=2.62, validation loss=2.28] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:12<02:06,  1.60it/s, Train Loss=2.62, validation loss=2.28] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:13<02:06,  1.60it/s, Train Loss=2.11, validation loss=2.29] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:13<02:07,  1.58it/s, Train Loss=2.11, validation loss=2.29] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:13<02:07,  1.58it/s, Train Loss=2.07, validation loss=2.27] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:13<02:07,  1.58it/s, Train Loss=2.07, validation loss=2.27]####################################################################################################
--------------------------------------------- Epoch:300 ---------------------------------------------
-- Training set:
Loss: 2.2731306552886963, Lr: 0.000125
Average AUC ROC: 0.53                Average AUC PR: 0.28
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:14<02:07,  1.58it/s, Train Loss=2.27, validation loss=2.28] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:14<02:05,  1.60it/s, Train Loss=2.27, validation loss=2.28]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.2782560661435127
Average AUC ROC: 0.55                    Average AUC PR: 0.31
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:14<02:05,  1.60it/s, Train Loss=1.52, validation loss=2.27] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:14<02:05,  1.59it/s, Train Loss=1.52, validation loss=2.27] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:15<02:05,  1.59it/s, Train Loss=1.36, validation loss=2.27] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:15<02:01,  1.63it/s, Train Loss=1.36, validation loss=2.27] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:16<02:01,  1.63it/s, Train Loss=1.75, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:16<02:01,  1.63it/s, Train Loss=1.75, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:16<02:01,  1.63it/s, Train Loss=1.65, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:16<02:03,  1.59it/s, Train Loss=1.65, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:17<02:03,  1.59it/s, Train Loss=1.98, validation loss=2.29] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:17<02:02,  1.59it/s, Train Loss=1.98, validation loss=2.29] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:18<02:02,  1.59it/s, Train Loss=1.88, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:18<02:00,  1.61it/s, Train Loss=1.88, validation loss=2.27] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:18<02:00,  1.61it/s, Train Loss=1.88, validation loss=2.28] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:18<01:59,  1.61it/s, Train Loss=1.88, validation loss=2.28] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:19<01:59,  1.61it/s, Train Loss=1.9, validation loss=2.27]  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:19<02:02,  1.56it/s, Train Loss=1.9, validation loss=2.27] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:19<02:02,  1.56it/s, Train Loss=2.77, validation loss=2.27] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:19<02:00,  1.58it/s, Train Loss=2.77, validation loss=2.27] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:20<02:00,  1.58it/s, Train Loss=2.31, validation loss=2.28] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:20<01:58,  1.61it/s, Train Loss=2.31, validation loss=2.28] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:21<01:58,  1.61it/s, Train Loss=1.44, validation loss=2.27] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:21<01:58,  1.59it/s, Train Loss=1.44, validation loss=2.27] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:21<01:58,  1.59it/s, Train Loss=1.9, validation loss=2.28]  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:21<01:57,  1.60it/s, Train Loss=1.9, validation loss=2.28] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:22<01:57,  1.60it/s, Train Loss=2.27, validation loss=2.27] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:22<01:55,  1.61it/s, Train Loss=2.27, validation loss=2.27] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:23<01:55,  1.61it/s, Train Loss=2.98, validation loss=2.28] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:23<01:55,  1.61it/s, Train Loss=2.98, validation loss=2.28] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:23<01:55,  1.61it/s, Train Loss=3.37, validation loss=2.27] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:23<01:54,  1.61it/s, Train Loss=3.37, validation loss=2.27] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:24<01:54,  1.61it/s, Train Loss=1.32, validation loss=2.29] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:24<01:56,  1.58it/s, Train Loss=1.32, validation loss=2.29] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:25<01:56,  1.58it/s, Train Loss=3.74, validation loss=2.27] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:25<01:56,  1.57it/s, Train Loss=3.74, validation loss=2.27] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:25<01:56,  1.57it/s, Train Loss=2.43, validation loss=2.28] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:25<01:55,  1.58it/s, Train Loss=2.43, validation loss=2.28] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:26<01:55,  1.58it/s, Train Loss=1.6, validation loss=2.27]  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:26<01:53,  1.60it/s, Train Loss=1.6, validation loss=2.27] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:26<01:53,  1.60it/s, Train Loss=4.37, validation loss=2.27] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:26<01:52,  1.59it/s, Train Loss=4.37, validation loss=2.27] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:27<01:52,  1.59it/s, Train Loss=1.48, validation loss=2.27] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:27<01:53,  1.58it/s, Train Loss=1.48, validation loss=2.27] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:28<01:53,  1.58it/s, Train Loss=3.28, validation loss=2.26] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:28<01:51,  1.60it/s, Train Loss=3.28, validation loss=2.26] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:28<01:51,  1.60it/s, Train Loss=1.61, validation loss=2.28] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:28<01:50,  1.60it/s, Train Loss=1.61, validation loss=2.28] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:29<01:50,  1.60it/s, Train Loss=1.52, validation loss=2.27] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:29<01:53,  1.56it/s, Train Loss=1.52, validation loss=2.27] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:30<01:53,  1.56it/s, Train Loss=2.89, validation loss=2.27] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:30<01:56,  1.51it/s, Train Loss=2.89, validation loss=2.27] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:30<01:56,  1.51it/s, Train Loss=2.07, validation loss=2.27] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:30<01:52,  1.55it/s, Train Loss=2.07, validation loss=2.27] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:31<01:52,  1.55it/s, Train Loss=4.11, validation loss=2.27] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:31<01:50,  1.56it/s, Train Loss=4.11, validation loss=2.27] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:31<01:50,  1.56it/s, Train Loss=2.69, validation loss=2.28] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:31<01:48,  1.59it/s, Train Loss=2.69, validation loss=2.28] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:32<01:48,  1.59it/s, Train Loss=2.11, validation loss=2.29] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:32<01:47,  1.59it/s, Train Loss=2.11, validation loss=2.29] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:33<01:47,  1.59it/s, Train Loss=1.51, validation loss=2.28] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:33<01:45,  1.60it/s, Train Loss=1.51, validation loss=2.28] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:33<01:45,  1.60it/s, Train Loss=3.34, validation loss=2.29] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:33<01:45,  1.60it/s, Train Loss=3.34, validation loss=2.29] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:34<01:45,  1.60it/s, Train Loss=2, validation loss=2.28]    66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:34<01:44,  1.61it/s, Train Loss=2, validation loss=2.28] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:35<01:44,  1.61it/s, Train Loss=1.93, validation loss=2.28] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:35<01:44,  1.59it/s, Train Loss=1.93, validation loss=2.28] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:35<01:44,  1.59it/s, Train Loss=1.93, validation loss=2.28] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:35<01:44,  1.58it/s, Train Loss=1.93, validation loss=2.28] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:36<01:44,  1.58it/s, Train Loss=1.7, validation loss=2.28]  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:36<01:43,  1.59it/s, Train Loss=1.7, validation loss=2.28] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:36<01:43,  1.59it/s, Train Loss=2.66, validation loss=2.28] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:36<01:42,  1.60it/s, Train Loss=2.66, validation loss=2.28] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:37<01:42,  1.60it/s, Train Loss=3.07, validation loss=2.26] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:37<01:41,  1.61it/s, Train Loss=3.07, validation loss=2.26] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:38<01:41,  1.61it/s, Train Loss=2.24, validation loss=2.28] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:38<01:40,  1.62it/s, Train Loss=2.24, validation loss=2.28] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:38<01:40,  1.62it/s, Train Loss=1.19, validation loss=2.28] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:38<01:39,  1.62it/s, Train Loss=1.19, validation loss=2.28] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:39<01:39,  1.62it/s, Train Loss=1.38, validation loss=2.29] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:39<01:38,  1.63it/s, Train Loss=1.38, validation loss=2.29] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:40<01:38,  1.63it/s, Train Loss=1.44, validation loss=2.28] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:40<01:38,  1.62it/s, Train Loss=1.44, validation loss=2.28] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:40<01:38,  1.62it/s, Train Loss=2.56, validation loss=2.27] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:40<01:37,  1.61it/s, Train Loss=2.56, validation loss=2.27] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:41<01:37,  1.61it/s, Train Loss=1.28, validation loss=2.27] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:41<01:40,  1.57it/s, Train Loss=1.28, validation loss=2.27] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:41<01:40,  1.57it/s, Train Loss=2.06, validation loss=2.27] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:41<01:38,  1.58it/s, Train Loss=2.06, validation loss=2.27] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:42<01:38,  1.58it/s, Train Loss=2.19, validation loss=2.27] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:42<01:37,  1.58it/s, Train Loss=2.19, validation loss=2.27] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:43<01:37,  1.58it/s, Train Loss=1.69, validation loss=2.3]  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:43<01:35,  1.61it/s, Train Loss=1.69, validation loss=2.3] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:43<01:35,  1.61it/s, Train Loss=2.2, validation loss=2.29] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:43<01:35,  1.61it/s, Train Loss=2.2, validation loss=2.29] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:44<01:35,  1.61it/s, Train Loss=1.94, validation loss=2.29] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:44<01:34,  1.60it/s, Train Loss=1.94, validation loss=2.29] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:45<01:34,  1.60it/s, Train Loss=2.03, validation loss=2.27] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:45<01:33,  1.62it/s, Train Loss=2.03, validation loss=2.27] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:45<01:33,  1.62it/s, Train Loss=1.76, validation loss=2.29] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:45<01:37,  1.53it/s, Train Loss=1.76, validation loss=2.29] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:46<01:37,  1.53it/s, Train Loss=3.77, validation loss=2.27] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:46<01:36,  1.55it/s, Train Loss=3.77, validation loss=2.27] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:47<01:36,  1.55it/s, Train Loss=2.14, validation loss=2.29] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:47<01:33,  1.58it/s, Train Loss=2.14, validation loss=2.29] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:47<01:33,  1.58it/s, Train Loss=1.33, validation loss=2.28] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:47<01:33,  1.57it/s, Train Loss=1.33, validation loss=2.28] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:48<01:33,  1.57it/s, Train Loss=1.48, validation loss=2.28] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:48<01:32,  1.58it/s, Train Loss=1.48, validation loss=2.28] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:48<01:32,  1.58it/s, Train Loss=2.14, validation loss=2.27] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:48<01:31,  1.59it/s, Train Loss=2.14, validation loss=2.27] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:49<01:31,  1.59it/s, Train Loss=1.94, validation loss=2.28] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:49<01:29,  1.60it/s, Train Loss=1.94, validation loss=2.28] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:50<01:29,  1.60it/s, Train Loss=2.85, validation loss=2.27] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:50<01:28,  1.61it/s, Train Loss=2.85, validation loss=2.27] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:50<01:28,  1.61it/s, Train Loss=1.57, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:50<01:29,  1.59it/s, Train Loss=1.57, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:51<01:29,  1.59it/s, Train Loss=3.31, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:51<01:29,  1.57it/s, Train Loss=3.31, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:52<01:29,  1.57it/s, Train Loss=2.64, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:52<01:30,  1.55it/s, Train Loss=2.64, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:52<01:30,  1.55it/s, Train Loss=2.91, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:52<01:28,  1.57it/s, Train Loss=2.91, validation loss=2.27] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:53<01:28,  1.57it/s, Train Loss=2.02, validation loss=2.29] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:53<01:26,  1.59it/s, Train Loss=2.02, validation loss=2.29] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:53<01:26,  1.59it/s, Train Loss=1.16, validation loss=2.27] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:53<01:26,  1.58it/s, Train Loss=1.16, validation loss=2.27] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:54<01:26,  1.58it/s, Train Loss=2.75, validation loss=2.28] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:54<01:25,  1.59it/s, Train Loss=2.75, validation loss=2.28] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:55<01:25,  1.59it/s, Train Loss=2.45, validation loss=2.27] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:55<01:25,  1.58it/s, Train Loss=2.45, validation loss=2.27] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:55<01:25,  1.58it/s, Train Loss=1.33, validation loss=2.29] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:55<01:24,  1.59it/s, Train Loss=1.33, validation loss=2.29] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:56<01:24,  1.59it/s, Train Loss=1.69, validation loss=2.27] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:56<01:23,  1.59it/s, Train Loss=1.69, validation loss=2.27] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:57<01:23,  1.59it/s, Train Loss=1.49, validation loss=2.28] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:57<01:21,  1.61it/s, Train Loss=1.49, validation loss=2.28] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:57<01:21,  1.61it/s, Train Loss=4.14, validation loss=2.27] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:57<01:26,  1.51it/s, Train Loss=4.14, validation loss=2.27] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:58<01:26,  1.51it/s, Train Loss=1.49, validation loss=2.27] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:58<01:27,  1.49it/s, Train Loss=1.49, validation loss=2.27] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:59<01:27,  1.49it/s, Train Loss=1.66, validation loss=2.29] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:59<01:26,  1.49it/s, Train Loss=1.66, validation loss=2.29] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:59<01:26,  1.49it/s, Train Loss=3.21, validation loss=2.27] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [03:59<01:23,  1.53it/s, Train Loss=3.21, validation loss=2.27] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [04:00<01:23,  1.53it/s, Train Loss=1.62, validation loss=2.29] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:00<01:22,  1.55it/s, Train Loss=1.62, validation loss=2.29] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:01<01:22,  1.55it/s, Train Loss=2.41, validation loss=2.31] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:01<01:20,  1.56it/s, Train Loss=2.41, validation loss=2.31] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:01<01:20,  1.56it/s, Train Loss=1.39, validation loss=2.28] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:01<01:19,  1.57it/s, Train Loss=1.39, validation loss=2.28] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:02<01:19,  1.57it/s, Train Loss=3.11, validation loss=2.28] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:02<01:21,  1.52it/s, Train Loss=3.11, validation loss=2.28] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:03<01:21,  1.52it/s, Train Loss=2.41, validation loss=2.27] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:03<01:19,  1.54it/s, Train Loss=2.41, validation loss=2.27] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:03<01:19,  1.54it/s, Train Loss=1.52, validation loss=2.27] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:03<01:18,  1.55it/s, Train Loss=1.52, validation loss=2.27] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:04<01:18,  1.55it/s, Train Loss=2.92, validation loss=2.26] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:04<01:17,  1.57it/s, Train Loss=2.92, validation loss=2.26] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:04<01:17,  1.57it/s, Train Loss=3.47, validation loss=2.27] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:04<01:15,  1.58it/s, Train Loss=3.47, validation loss=2.27] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:05<01:15,  1.58it/s, Train Loss=2.97, validation loss=2.28] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:05<01:14,  1.59it/s, Train Loss=2.97, validation loss=2.28] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:06<01:14,  1.59it/s, Train Loss=1.87, validation loss=2.3]  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:06<01:13,  1.60it/s, Train Loss=1.87, validation loss=2.3] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:06<01:13,  1.60it/s, Train Loss=1.53, validation loss=2.29] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:06<01:11,  1.63it/s, Train Loss=1.53, validation loss=2.29] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:07<01:11,  1.63it/s, Train Loss=1.4, validation loss=2.28]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:07<01:12,  1.61it/s, Train Loss=1.4, validation loss=2.28] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:08<01:12,  1.61it/s, Train Loss=2.57, validation loss=2.27] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:08<01:14,  1.54it/s, Train Loss=2.57, validation loss=2.27] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:08<01:14,  1.54it/s, Train Loss=1.48, validation loss=2.27] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:08<01:12,  1.58it/s, Train Loss=1.48, validation loss=2.27] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:09<01:12,  1.58it/s, Train Loss=2.58, validation loss=2.26] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:09<01:12,  1.57it/s, Train Loss=2.58, validation loss=2.26] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:09<01:12,  1.57it/s, Train Loss=2.41, validation loss=2.3]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:09<01:12,  1.56it/s, Train Loss=2.41, validation loss=2.3] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:10<01:12,  1.56it/s, Train Loss=2.07, validation loss=2.26] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:10<01:10,  1.58it/s, Train Loss=2.07, validation loss=2.26] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:11<01:10,  1.58it/s, Train Loss=3.22, validation loss=2.3]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:11<01:09,  1.59it/s, Train Loss=3.22, validation loss=2.3] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:11<01:09,  1.59it/s, Train Loss=2.33, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:11<01:07,  1.61it/s, Train Loss=2.33, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:12<01:07,  1.61it/s, Train Loss=2.57, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:12<01:07,  1.59it/s, Train Loss=2.57, validation loss=2.27] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:13<01:07,  1.59it/s, Train Loss=1.41, validation loss=2.28] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:13<01:10,  1.51it/s, Train Loss=1.41, validation loss=2.28] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:13<01:10,  1.51it/s, Train Loss=1.94, validation loss=2.3]  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:13<01:08,  1.55it/s, Train Loss=1.94, validation loss=2.3] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:14<01:08,  1.55it/s, Train Loss=1.4, validation loss=2.28] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:14<01:06,  1.58it/s, Train Loss=1.4, validation loss=2.28] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:15<01:06,  1.58it/s, Train Loss=1.64, validation loss=2.28] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:15<01:05,  1.59it/s, Train Loss=1.64, validation loss=2.28] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:15<01:05,  1.59it/s, Train Loss=2.94, validation loss=2.27] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:15<01:03,  1.61it/s, Train Loss=2.94, validation loss=2.27] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:16<01:03,  1.61it/s, Train Loss=1.81, validation loss=2.29] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:16<01:03,  1.60it/s, Train Loss=1.81, validation loss=2.29] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:16<01:03,  1.60it/s, Train Loss=2.21, validation loss=2.28] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:16<01:03,  1.59it/s, Train Loss=2.21, validation loss=2.28]####################################################################################################
--------------------------------------------- Epoch:400 ---------------------------------------------
-- Training set:
Loss: 3.143275022506714, Lr: 6.25e-05
Average AUC ROC: 0.52                Average AUC PR: 0.29
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:17<01:03,  1.59it/s, Train Loss=3.14, validation loss=2.28] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:17<01:06,  1.49it/s, Train Loss=3.14, validation loss=2.28]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.2820815593004227
Average AUC ROC: 0.55                    Average AUC PR: 0.31
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:18<01:06,  1.49it/s, Train Loss=2.07, validation loss=2.28] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:18<01:05,  1.52it/s, Train Loss=2.07, validation loss=2.28] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:18<01:05,  1.52it/s, Train Loss=1.94, validation loss=2.28] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:18<01:03,  1.55it/s, Train Loss=1.94, validation loss=2.28] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:19<01:03,  1.55it/s, Train Loss=1.94, validation loss=2.27] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:19<01:01,  1.57it/s, Train Loss=1.94, validation loss=2.27] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:20<01:01,  1.57it/s, Train Loss=1.63, validation loss=2.29] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:20<01:01,  1.57it/s, Train Loss=1.63, validation loss=2.29] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:20<01:01,  1.57it/s, Train Loss=1.1, validation loss=2.27]  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:20<00:59,  1.59it/s, Train Loss=1.1, validation loss=2.27] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:21<00:59,  1.59it/s, Train Loss=1.65, validation loss=2.29] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:21<00:58,  1.60it/s, Train Loss=1.65, validation loss=2.29] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:22<00:58,  1.60it/s, Train Loss=1.98, validation loss=2.28] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:22<00:58,  1.59it/s, Train Loss=1.98, validation loss=2.28] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:22<00:58,  1.59it/s, Train Loss=3.27, validation loss=2.26] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:22<00:58,  1.57it/s, Train Loss=3.27, validation loss=2.26] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:23<00:58,  1.57it/s, Train Loss=2.49, validation loss=2.27] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:23<00:59,  1.54it/s, Train Loss=2.49, validation loss=2.27] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:24<00:59,  1.54it/s, Train Loss=1.87, validation loss=2.29] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:24<00:58,  1.54it/s, Train Loss=1.87, validation loss=2.29] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:24<00:58,  1.54it/s, Train Loss=2.8, validation loss=2.26]  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:24<00:57,  1.55it/s, Train Loss=2.8, validation loss=2.26] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:25<00:57,  1.55it/s, Train Loss=1.43, validation loss=2.28] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:25<00:56,  1.57it/s, Train Loss=1.43, validation loss=2.28] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:25<00:56,  1.57it/s, Train Loss=1.19, validation loss=2.26] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:25<00:55,  1.58it/s, Train Loss=1.19, validation loss=2.26] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:26<00:55,  1.58it/s, Train Loss=2.64, validation loss=2.26] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:26<00:54,  1.59it/s, Train Loss=2.64, validation loss=2.26] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:27<00:54,  1.59it/s, Train Loss=2.86, validation loss=2.27] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:27<00:53,  1.60it/s, Train Loss=2.86, validation loss=2.27] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:27<00:53,  1.60it/s, Train Loss=2.75, validation loss=2.27] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:27<00:52,  1.61it/s, Train Loss=2.75, validation loss=2.27] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:28<00:52,  1.61it/s, Train Loss=2.83, validation loss=2.27] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:28<00:51,  1.61it/s, Train Loss=2.83, validation loss=2.27] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:28<00:51,  1.61it/s, Train Loss=2.17, validation loss=2.27] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:28<00:50,  1.62it/s, Train Loss=2.17, validation loss=2.27] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:29<00:50,  1.62it/s, Train Loss=5.53, validation loss=2.26] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:29<00:53,  1.51it/s, Train Loss=5.53, validation loss=2.26] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:30<00:53,  1.51it/s, Train Loss=1.11, validation loss=2.26] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:30<00:51,  1.56it/s, Train Loss=1.11, validation loss=2.26] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:30<00:51,  1.56it/s, Train Loss=1.75, validation loss=2.29] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:30<00:50,  1.57it/s, Train Loss=1.75, validation loss=2.29] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:31<00:50,  1.57it/s, Train Loss=1.59, validation loss=2.27] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:31<00:49,  1.56it/s, Train Loss=1.59, validation loss=2.27] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:32<00:49,  1.56it/s, Train Loss=2.16, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:32<00:48,  1.58it/s, Train Loss=2.16, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:32<00:48,  1.58it/s, Train Loss=1.64, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:32<00:47,  1.61it/s, Train Loss=1.64, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:33<00:47,  1.61it/s, Train Loss=2.2, validation loss=2.28]  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:33<00:49,  1.51it/s, Train Loss=2.2, validation loss=2.28] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:34<00:49,  1.51it/s, Train Loss=2.17, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:34<00:47,  1.56it/s, Train Loss=2.17, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:34<00:47,  1.56it/s, Train Loss=1.4, validation loss=2.27]  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:34<00:46,  1.58it/s, Train Loss=1.4, validation loss=2.27] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:35<00:46,  1.58it/s, Train Loss=1.95, validation loss=2.28] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:35<00:45,  1.58it/s, Train Loss=1.95, validation loss=2.28] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:36<00:45,  1.58it/s, Train Loss=2.34, validation loss=2.27] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:36<00:44,  1.58it/s, Train Loss=2.34, validation loss=2.27] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:36<00:44,  1.58it/s, Train Loss=1.89, validation loss=2.28] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:36<00:44,  1.58it/s, Train Loss=1.89, validation loss=2.28] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:37<00:44,  1.58it/s, Train Loss=2.04, validation loss=2.28] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:37<00:43,  1.60it/s, Train Loss=2.04, validation loss=2.28] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:37<00:43,  1.60it/s, Train Loss=2.14, validation loss=2.29] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:37<00:42,  1.61it/s, Train Loss=2.14, validation loss=2.29] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:38<00:42,  1.61it/s, Train Loss=2.69, validation loss=2.27] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:38<00:41,  1.60it/s, Train Loss=2.69, validation loss=2.27] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:39<00:41,  1.60it/s, Train Loss=2.28, validation loss=2.28] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:39<00:40,  1.63it/s, Train Loss=2.28, validation loss=2.28] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:39<00:40,  1.63it/s, Train Loss=2.43, validation loss=2.28] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:39<00:42,  1.54it/s, Train Loss=2.43, validation loss=2.28] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:40<00:42,  1.54it/s, Train Loss=2.49, validation loss=2.28] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:40<00:40,  1.57it/s, Train Loss=2.49, validation loss=2.28] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:41<00:40,  1.57it/s, Train Loss=1.47, validation loss=2.28] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:41<00:40,  1.57it/s, Train Loss=1.47, validation loss=2.28] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:41<00:40,  1.57it/s, Train Loss=1.5, validation loss=2.28]  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:41<00:38,  1.59it/s, Train Loss=1.5, validation loss=2.28] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:42<00:38,  1.59it/s, Train Loss=1.37, validation loss=2.28] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:42<00:38,  1.60it/s, Train Loss=1.37, validation loss=2.28] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:42<00:38,  1.60it/s, Train Loss=1.94, validation loss=2.29] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:42<00:36,  1.63it/s, Train Loss=1.94, validation loss=2.29] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:43<00:36,  1.63it/s, Train Loss=2.55, validation loss=2.29] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:43<00:35,  1.64it/s, Train Loss=2.55, validation loss=2.29] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:44<00:35,  1.64it/s, Train Loss=1.72, validation loss=2.27] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:44<00:35,  1.62it/s, Train Loss=1.72, validation loss=2.27] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:44<00:35,  1.62it/s, Train Loss=2.05, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:44<00:34,  1.63it/s, Train Loss=2.05, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:45<00:34,  1.63it/s, Train Loss=1.45, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:45<00:36,  1.52it/s, Train Loss=1.45, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:46<00:36,  1.52it/s, Train Loss=1.37, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:46<00:35,  1.55it/s, Train Loss=1.37, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:46<00:35,  1.55it/s, Train Loss=2.07, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:46<00:34,  1.57it/s, Train Loss=2.07, validation loss=2.28] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:47<00:34,  1.57it/s, Train Loss=1.75, validation loss=2.27] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:47<00:35,  1.51it/s, Train Loss=1.75, validation loss=2.27] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:48<00:35,  1.51it/s, Train Loss=1.62, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:48<00:33,  1.55it/s, Train Loss=1.62, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:48<00:33,  1.55it/s, Train Loss=1.98, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:48<00:32,  1.58it/s, Train Loss=1.98, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:49<00:32,  1.58it/s, Train Loss=2.04, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:49<00:32,  1.52it/s, Train Loss=2.04, validation loss=2.27] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:50<00:32,  1.52it/s, Train Loss=3.28, validation loss=2.28] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:50<00:32,  1.52it/s, Train Loss=3.28, validation loss=2.28] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:50<00:32,  1.52it/s, Train Loss=2.99, validation loss=2.26] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:50<00:30,  1.57it/s, Train Loss=2.99, validation loss=2.26] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:51<00:30,  1.57it/s, Train Loss=4.34, validation loss=2.27] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:51<00:29,  1.58it/s, Train Loss=4.34, validation loss=2.27] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:51<00:29,  1.58it/s, Train Loss=3.31, validation loss=2.26] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:51<00:28,  1.61it/s, Train Loss=3.31, validation loss=2.26] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:52<00:28,  1.61it/s, Train Loss=1.76, validation loss=2.28] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:52<00:28,  1.61it/s, Train Loss=1.76, validation loss=2.28] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:53<00:28,  1.61it/s, Train Loss=4.38, validation loss=2.27] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:53<00:27,  1.61it/s, Train Loss=4.38, validation loss=2.27] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:53<00:27,  1.61it/s, Train Loss=2.02, validation loss=2.27] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:53<00:26,  1.62it/s, Train Loss=2.02, validation loss=2.27] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:54<00:26,  1.62it/s, Train Loss=2.8, validation loss=2.26]  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:54<00:25,  1.62it/s, Train Loss=2.8, validation loss=2.26] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:54<00:25,  1.62it/s, Train Loss=2.98, validation loss=2.29] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:54<00:25,  1.60it/s, Train Loss=2.98, validation loss=2.29] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:55<00:25,  1.60it/s, Train Loss=2.97, validation loss=2.28] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:55<00:26,  1.48it/s, Train Loss=2.97, validation loss=2.28] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:56<00:26,  1.48it/s, Train Loss=2.4, validation loss=2.25]  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:56<00:25,  1.52it/s, Train Loss=2.4, validation loss=2.25] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:57<00:25,  1.52it/s, Train Loss=2.11, validation loss=2.27] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:57<00:24,  1.54it/s, Train Loss=2.11, validation loss=2.27] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:57<00:24,  1.54it/s, Train Loss=2.64, validation loss=2.26] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:57<00:23,  1.56it/s, Train Loss=2.64, validation loss=2.26] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:58<00:23,  1.56it/s, Train Loss=1.71, validation loss=2.26] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:58<00:22,  1.58it/s, Train Loss=1.71, validation loss=2.26] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:58<00:22,  1.58it/s, Train Loss=1.95, validation loss=2.28] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:58<00:22,  1.58it/s, Train Loss=1.95, validation loss=2.28] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:59<00:22,  1.58it/s, Train Loss=1.5, validation loss=2.28]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:59<00:21,  1.60it/s, Train Loss=1.5, validation loss=2.28] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [05:00<00:21,  1.60it/s, Train Loss=2.39, validation loss=2.27] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:00<00:22,  1.50it/s, Train Loss=2.39, validation loss=2.27] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:00<00:22,  1.50it/s, Train Loss=2.14, validation loss=2.28] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:00<00:20,  1.53it/s, Train Loss=2.14, validation loss=2.28] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:01<00:20,  1.53it/s, Train Loss=2.19, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:01<00:19,  1.56it/s, Train Loss=2.19, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:02<00:19,  1.56it/s, Train Loss=2.7, validation loss=2.27]  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:02<00:18,  1.59it/s, Train Loss=2.7, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:02<00:18,  1.59it/s, Train Loss=2.41, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:02<00:18,  1.54it/s, Train Loss=2.41, validation loss=2.27] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:03<00:18,  1.54it/s, Train Loss=2.71, validation loss=2.28] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:03<00:17,  1.57it/s, Train Loss=2.71, validation loss=2.28] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:04<00:17,  1.57it/s, Train Loss=2.54, validation loss=2.26] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:04<00:17,  1.57it/s, Train Loss=2.54, validation loss=2.26] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:04<00:17,  1.57it/s, Train Loss=3.2, validation loss=2.26]  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:04<00:16,  1.59it/s, Train Loss=3.2, validation loss=2.26] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:05<00:16,  1.59it/s, Train Loss=1.67, validation loss=2.26] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:05<00:16,  1.50it/s, Train Loss=1.67, validation loss=2.26] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:06<00:16,  1.50it/s, Train Loss=1.79, validation loss=2.27] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:06<00:15,  1.54it/s, Train Loss=1.79, validation loss=2.27] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:06<00:15,  1.54it/s, Train Loss=1.66, validation loss=2.27] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:06<00:14,  1.58it/s, Train Loss=1.66, validation loss=2.27] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:07<00:14,  1.58it/s, Train Loss=2.49, validation loss=2.26] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:07<00:13,  1.58it/s, Train Loss=2.49, validation loss=2.26] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:07<00:13,  1.58it/s, Train Loss=2.13, validation loss=2.27] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:07<00:13,  1.60it/s, Train Loss=2.13, validation loss=2.27] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:08<00:13,  1.60it/s, Train Loss=1.9, validation loss=2.27]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:08<00:12,  1.60it/s, Train Loss=1.9, validation loss=2.27] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:09<00:12,  1.60it/s, Train Loss=4.18, validation loss=2.26] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:09<00:11,  1.59it/s, Train Loss=4.18, validation loss=2.26] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:09<00:11,  1.59it/s, Train Loss=2.16, validation loss=2.26] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:09<00:11,  1.61it/s, Train Loss=2.16, validation loss=2.26] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:10<00:11,  1.61it/s, Train Loss=1.38, validation loss=2.28] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:10<00:10,  1.63it/s, Train Loss=1.38, validation loss=2.28] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:10<00:10,  1.63it/s, Train Loss=2.75, validation loss=2.3]  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:10<00:09,  1.63it/s, Train Loss=2.75, validation loss=2.3] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:11<00:09,  1.63it/s, Train Loss=1.57, validation loss=2.28] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:11<00:09,  1.50it/s, Train Loss=1.57, validation loss=2.28] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:12<00:09,  1.50it/s, Train Loss=2.37, validation loss=2.27] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:12<00:09,  1.54it/s, Train Loss=2.37, validation loss=2.27] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:12<00:09,  1.54it/s, Train Loss=2.19, validation loss=2.27] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:12<00:08,  1.54it/s, Train Loss=2.19, validation loss=2.27] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:13<00:08,  1.54it/s, Train Loss=1.81, validation loss=2.27] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:13<00:07,  1.55it/s, Train Loss=1.81, validation loss=2.27] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:14<00:07,  1.55it/s, Train Loss=1.59, validation loss=2.28] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:14<00:07,  1.55it/s, Train Loss=1.59, validation loss=2.28] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:14<00:07,  1.55it/s, Train Loss=1.83, validation loss=2.28] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:14<00:06,  1.58it/s, Train Loss=1.83, validation loss=2.28] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:15<00:06,  1.58it/s, Train Loss=1.9, validation loss=2.29]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:15<00:06,  1.46it/s, Train Loss=1.9, validation loss=2.29] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:16<00:06,  1.46it/s, Train Loss=2.01, validation loss=2.28] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:16<00:05,  1.51it/s, Train Loss=2.01, validation loss=2.28] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:16<00:05,  1.51it/s, Train Loss=1.68, validation loss=2.27] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:16<00:04,  1.52it/s, Train Loss=1.68, validation loss=2.27] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:17<00:04,  1.52it/s, Train Loss=1.85, validation loss=2.28] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:17<00:04,  1.49it/s, Train Loss=1.85, validation loss=2.28] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:18<00:04,  1.49it/s, Train Loss=1.45, validation loss=2.28] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:18<00:03,  1.51it/s, Train Loss=1.45, validation loss=2.28] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:18<00:03,  1.51it/s, Train Loss=1.61, validation loss=2.28] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:18<00:02,  1.54it/s, Train Loss=1.61, validation loss=2.28] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:19<00:02,  1.54it/s, Train Loss=1.81, validation loss=2.27] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:19<00:01,  1.57it/s, Train Loss=1.81, validation loss=2.27] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:20<00:01,  1.57it/s, Train Loss=2.11, validation loss=2.26]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:20<00:01,  1.56it/s, Train Loss=2.11, validation loss=2.26]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:20<00:01,  1.56it/s, Train Loss=1.68, validation loss=2.28]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:20<00:00,  1.59it/s, Train Loss=1.68, validation loss=2.28]####################################################################################################
--------------------------------------------- Epoch:500 ---------------------------------------------
-- Training set:
Loss: 1.8087366819381714, Lr: 3.125e-05
Average AUC ROC: 0.51                Average AUC PR: 0.28
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:21<00:00,  1.59it/s, Train Loss=1.81, validation loss=2.27]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:21<00:00,  1.49it/s, Train Loss=1.81, validation loss=2.27]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:21<00:00,  1.56it/s, Train Loss=1.81, validation loss=2.27]
----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.267849639058113
Average AUC ROC: 0.54                    Average AUC PR: 0.31

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 204
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=0, validation loss=0]  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=3.9, validation loss=3.34]  0%|          | 1/500 [00:00<04:52,  1.71it/s, Train Loss=3.9, validation loss=3.34]  0%|          | 1/500 [00:01<04:52,  1.71it/s, Train Loss=3.12, validation loss=2.95]  0%|          | 2/500 [00:01<04:57,  1.67it/s, Train Loss=3.12, validation loss=2.95]  0%|          | 2/500 [00:01<04:57,  1.67it/s, Train Loss=2.2, validation loss=2.86]   1%|          | 3/500 [00:01<05:04,  1.63it/s, Train Loss=2.2, validation loss=2.86]  1%|          | 3/500 [00:02<05:04,  1.63it/s, Train Loss=6.26, validation loss=2.74]  1%|          | 4/500 [00:02<05:06,  1.62it/s, Train Loss=6.26, validation loss=2.74]  1%|          | 4/500 [00:03<05:06,  1.62it/s, Train Loss=5.23, validation loss=2.67]  1%|          | 5/500 [00:03<05:04,  1.62it/s, Train Loss=5.23, validation loss=2.67]  1%|          | 5/500 [00:03<05:04,  1.62it/s, Train Loss=3.51, validation loss=2.66]  1%|          | 6/500 [00:03<05:03,  1.63it/s, Train Loss=3.51, validation loss=2.66]  1%|          | 6/500 [00:04<05:03,  1.63it/s, Train Loss=4.27, validation loss=2.66]  1%|â–         | 7/500 [00:04<05:19,  1.54it/s, Train Loss=4.27, validation loss=2.66]  1%|â–         | 7/500 [00:05<05:19,  1.54it/s, Train Loss=2.67, validation loss=2.66]  2%|â–         | 8/500 [00:05<05:15,  1.56it/s, Train Loss=2.67, validation loss=2.66]  2%|â–         | 8/500 [00:05<05:15,  1.56it/s, Train Loss=2.67, validation loss=2.62]  2%|â–         | 9/500 [00:05<05:08,  1.59it/s, Train Loss=2.67, validation loss=2.62]  2%|â–         | 9/500 [00:06<05:08,  1.59it/s, Train Loss=3.27, validation loss=2.59]  2%|â–         | 10/500 [00:06<05:04,  1.61it/s, Train Loss=3.27, validation loss=2.59]  2%|â–         | 10/500 [00:06<05:04,  1.61it/s, Train Loss=2.2, validation loss=2.6]    2%|â–         | 11/500 [00:06<05:07,  1.59it/s, Train Loss=2.2, validation loss=2.6]  2%|â–         | 11/500 [00:07<05:07,  1.59it/s, Train Loss=4.02, validation loss=2.59]  2%|â–         | 12/500 [00:07<05:02,  1.61it/s, Train Loss=4.02, validation loss=2.59]  2%|â–         | 12/500 [00:08<05:02,  1.61it/s, Train Loss=6.38, validation loss=2.53]  3%|â–         | 13/500 [00:08<05:14,  1.55it/s, Train Loss=6.38, validation loss=2.53]  3%|â–         | 13/500 [00:08<05:14,  1.55it/s, Train Loss=2.55, validation loss=2.57]  3%|â–         | 14/500 [00:08<05:13,  1.55it/s, Train Loss=2.55, validation loss=2.57]  3%|â–         | 14/500 [00:09<05:13,  1.55it/s, Train Loss=2.33, validation loss=2.57]  3%|â–         | 15/500 [00:09<05:10,  1.56it/s, Train Loss=2.33, validation loss=2.57]  3%|â–         | 15/500 [00:10<05:10,  1.56it/s, Train Loss=2.37, validation loss=2.53]  3%|â–         | 16/500 [00:10<05:07,  1.57it/s, Train Loss=2.37, validation loss=2.53]  3%|â–         | 16/500 [00:10<05:07,  1.57it/s, Train Loss=4.15, validation loss=2.55]  3%|â–         | 17/500 [00:10<05:06,  1.57it/s, Train Loss=4.15, validation loss=2.55]  3%|â–         | 17/500 [00:11<05:06,  1.57it/s, Train Loss=2.33, validation loss=2.56]  4%|â–         | 18/500 [00:11<05:04,  1.58it/s, Train Loss=2.33, validation loss=2.56]  4%|â–         | 18/500 [00:11<05:04,  1.58it/s, Train Loss=2.89, validation loss=2.54]  4%|â–         | 19/500 [00:11<05:03,  1.59it/s, Train Loss=2.89, validation loss=2.54]  4%|â–         | 19/500 [00:12<05:03,  1.59it/s, Train Loss=2.64, validation loss=2.52]  4%|â–         | 20/500 [00:12<05:00,  1.60it/s, Train Loss=2.64, validation loss=2.52]  4%|â–         | 20/500 [00:13<05:00,  1.60it/s, Train Loss=1.91, validation loss=2.51]  4%|â–         | 21/500 [00:13<04:57,  1.61it/s, Train Loss=1.91, validation loss=2.51]  4%|â–         | 21/500 [00:13<04:57,  1.61it/s, Train Loss=2.14, validation loss=2.51]  4%|â–         | 22/500 [00:13<04:56,  1.61it/s, Train Loss=2.14, validation loss=2.51]  4%|â–         | 22/500 [00:14<04:56,  1.61it/s, Train Loss=2.93, validation loss=2.47]  5%|â–         | 23/500 [00:14<05:15,  1.51it/s, Train Loss=2.93, validation loss=2.47]  5%|â–         | 23/500 [00:15<05:15,  1.51it/s, Train Loss=2.94, validation loss=2.49]  5%|â–         | 24/500 [00:15<05:06,  1.55it/s, Train Loss=2.94, validation loss=2.49]  5%|â–         | 24/500 [00:15<05:06,  1.55it/s, Train Loss=3.39, validation loss=2.47]  5%|â–Œ         | 25/500 [00:15<05:08,  1.54it/s, Train Loss=3.39, validation loss=2.47]  5%|â–Œ         | 25/500 [00:16<05:08,  1.54it/s, Train Loss=3.1, validation loss=2.47]   5%|â–Œ         | 26/500 [00:16<05:09,  1.53it/s, Train Loss=3.1, validation loss=2.47]  5%|â–Œ         | 26/500 [00:17<05:09,  1.53it/s, Train Loss=2.19, validation loss=2.49]  5%|â–Œ         | 27/500 [00:17<05:06,  1.54it/s, Train Loss=2.19, validation loss=2.49]  5%|â–Œ         | 27/500 [00:17<05:06,  1.54it/s, Train Loss=3.14, validation loss=2.5]   6%|â–Œ         | 28/500 [00:17<05:02,  1.56it/s, Train Loss=3.14, validation loss=2.5]  6%|â–Œ         | 28/500 [00:18<05:02,  1.56it/s, Train Loss=3.12, validation loss=2.46]  6%|â–Œ         | 29/500 [00:18<05:02,  1.56it/s, Train Loss=3.12, validation loss=2.46]  6%|â–Œ         | 29/500 [00:19<05:02,  1.56it/s, Train Loss=2.71, validation loss=2.48]  6%|â–Œ         | 30/500 [00:19<05:17,  1.48it/s, Train Loss=2.71, validation loss=2.48]  6%|â–Œ         | 30/500 [00:19<05:17,  1.48it/s, Train Loss=3.33, validation loss=2.45]  6%|â–Œ         | 31/500 [00:19<05:12,  1.50it/s, Train Loss=3.33, validation loss=2.45]  6%|â–Œ         | 31/500 [00:20<05:12,  1.50it/s, Train Loss=4.84, validation loss=2.46]  6%|â–‹         | 32/500 [00:20<05:08,  1.52it/s, Train Loss=4.84, validation loss=2.46]  6%|â–‹         | 32/500 [00:21<05:08,  1.52it/s, Train Loss=2.22, validation loss=2.45]  7%|â–‹         | 33/500 [00:21<05:03,  1.54it/s, Train Loss=2.22, validation loss=2.45]  7%|â–‹         | 33/500 [00:21<05:03,  1.54it/s, Train Loss=2.11, validation loss=2.46]  7%|â–‹         | 34/500 [00:21<04:59,  1.56it/s, Train Loss=2.11, validation loss=2.46]  7%|â–‹         | 34/500 [00:22<04:59,  1.56it/s, Train Loss=3.06, validation loss=2.45]  7%|â–‹         | 35/500 [00:22<04:56,  1.57it/s, Train Loss=3.06, validation loss=2.45]  7%|â–‹         | 35/500 [00:22<04:56,  1.57it/s, Train Loss=2.88, validation loss=2.44]  7%|â–‹         | 36/500 [00:22<04:53,  1.58it/s, Train Loss=2.88, validation loss=2.44]  7%|â–‹         | 36/500 [00:23<04:53,  1.58it/s, Train Loss=3.54, validation loss=2.41]  7%|â–‹         | 37/500 [00:23<04:47,  1.61it/s, Train Loss=3.54, validation loss=2.41]  7%|â–‹         | 37/500 [00:24<04:47,  1.61it/s, Train Loss=2.05, validation loss=2.43]  8%|â–Š         | 38/500 [00:24<05:04,  1.52it/s, Train Loss=2.05, validation loss=2.43]  8%|â–Š         | 38/500 [00:24<05:04,  1.52it/s, Train Loss=2.45, validation loss=2.42]  8%|â–Š         | 39/500 [00:24<04:59,  1.54it/s, Train Loss=2.45, validation loss=2.42]  8%|â–Š         | 39/500 [00:25<04:59,  1.54it/s, Train Loss=2.57, validation loss=2.41]  8%|â–Š         | 40/500 [00:25<04:55,  1.56it/s, Train Loss=2.57, validation loss=2.41]  8%|â–Š         | 40/500 [00:26<04:55,  1.56it/s, Train Loss=2.13, validation loss=2.42]  8%|â–Š         | 41/500 [00:26<04:49,  1.59it/s, Train Loss=2.13, validation loss=2.42]  8%|â–Š         | 41/500 [00:26<04:49,  1.59it/s, Train Loss=3.64, validation loss=2.44]  8%|â–Š         | 42/500 [00:26<04:47,  1.59it/s, Train Loss=3.64, validation loss=2.44]  8%|â–Š         | 42/500 [00:27<04:47,  1.59it/s, Train Loss=3.33, validation loss=2.42]  9%|â–Š         | 43/500 [00:27<04:44,  1.61it/s, Train Loss=3.33, validation loss=2.42]  9%|â–Š         | 43/500 [00:27<04:44,  1.61it/s, Train Loss=2.02, validation loss=2.39]  9%|â–‰         | 44/500 [00:27<04:43,  1.61it/s, Train Loss=2.02, validation loss=2.39]  9%|â–‰         | 44/500 [00:28<04:43,  1.61it/s, Train Loss=1.9, validation loss=2.38]   9%|â–‰         | 45/500 [00:28<04:44,  1.60it/s, Train Loss=1.9, validation loss=2.38]  9%|â–‰         | 45/500 [00:29<04:44,  1.60it/s, Train Loss=2.82, validation loss=2.38]  9%|â–‰         | 46/500 [00:29<04:44,  1.60it/s, Train Loss=2.82, validation loss=2.38]  9%|â–‰         | 46/500 [00:29<04:44,  1.60it/s, Train Loss=2.01, validation loss=2.37]  9%|â–‰         | 47/500 [00:29<04:53,  1.54it/s, Train Loss=2.01, validation loss=2.37]  9%|â–‰         | 47/500 [00:30<04:53,  1.54it/s, Train Loss=2.99, validation loss=2.38] 10%|â–‰         | 48/500 [00:30<04:49,  1.56it/s, Train Loss=2.99, validation loss=2.38] 10%|â–‰         | 48/500 [00:31<04:49,  1.56it/s, Train Loss=2.61, validation loss=2.42] 10%|â–‰         | 49/500 [00:31<04:45,  1.58it/s, Train Loss=2.61, validation loss=2.42] 10%|â–‰         | 49/500 [00:31<04:45,  1.58it/s, Train Loss=2.14, validation loss=2.38] 10%|â–ˆ         | 50/500 [00:31<04:48,  1.56it/s, Train Loss=2.14, validation loss=2.38] 10%|â–ˆ         | 50/500 [00:32<04:48,  1.56it/s, Train Loss=2.12, validation loss=2.39] 10%|â–ˆ         | 51/500 [00:32<04:53,  1.53it/s, Train Loss=2.12, validation loss=2.39] 10%|â–ˆ         | 51/500 [00:33<04:53,  1.53it/s, Train Loss=1.91, validation loss=2.38] 10%|â–ˆ         | 52/500 [00:33<04:49,  1.55it/s, Train Loss=1.91, validation loss=2.38] 10%|â–ˆ         | 52/500 [00:33<04:49,  1.55it/s, Train Loss=3.38, validation loss=2.35] 11%|â–ˆ         | 53/500 [00:33<05:05,  1.46it/s, Train Loss=3.38, validation loss=2.35] 11%|â–ˆ         | 53/500 [00:34<05:05,  1.46it/s, Train Loss=3.14, validation loss=2.36] 11%|â–ˆ         | 54/500 [00:34<05:01,  1.48it/s, Train Loss=3.14, validation loss=2.36] 11%|â–ˆ         | 54/500 [00:35<05:01,  1.48it/s, Train Loss=4.07, validation loss=2.37] 11%|â–ˆ         | 55/500 [00:35<04:53,  1.52it/s, Train Loss=4.07, validation loss=2.37] 11%|â–ˆ         | 55/500 [00:35<04:53,  1.52it/s, Train Loss=2.68, validation loss=2.37] 11%|â–ˆ         | 56/500 [00:35<04:49,  1.54it/s, Train Loss=2.68, validation loss=2.37] 11%|â–ˆ         | 56/500 [00:36<04:49,  1.54it/s, Train Loss=2.23, validation loss=2.37] 11%|â–ˆâ–        | 57/500 [00:36<04:50,  1.52it/s, Train Loss=2.23, validation loss=2.37] 11%|â–ˆâ–        | 57/500 [00:37<04:50,  1.52it/s, Train Loss=2.13, validation loss=2.35] 12%|â–ˆâ–        | 58/500 [00:37<04:49,  1.53it/s, Train Loss=2.13, validation loss=2.35] 12%|â–ˆâ–        | 58/500 [00:37<04:49,  1.53it/s, Train Loss=2.21, validation loss=2.39] 12%|â–ˆâ–        | 59/500 [00:37<04:42,  1.56it/s, Train Loss=2.21, validation loss=2.39] 12%|â–ˆâ–        | 59/500 [00:38<04:42,  1.56it/s, Train Loss=1.22, validation loss=2.36] 12%|â–ˆâ–        | 60/500 [00:38<04:40,  1.57it/s, Train Loss=1.22, validation loss=2.36] 12%|â–ˆâ–        | 60/500 [00:38<04:40,  1.57it/s, Train Loss=2.17, validation loss=2.37] 12%|â–ˆâ–        | 61/500 [00:38<04:35,  1.59it/s, Train Loss=2.17, validation loss=2.37] 12%|â–ˆâ–        | 61/500 [00:39<04:35,  1.59it/s, Train Loss=2.71, validation loss=2.37] 12%|â–ˆâ–        | 62/500 [00:39<04:51,  1.50it/s, Train Loss=2.71, validation loss=2.37] 12%|â–ˆâ–        | 62/500 [00:40<04:51,  1.50it/s, Train Loss=3.25, validation loss=2.35] 13%|â–ˆâ–        | 63/500 [00:40<04:47,  1.52it/s, Train Loss=3.25, validation loss=2.35] 13%|â–ˆâ–        | 63/500 [00:41<04:47,  1.52it/s, Train Loss=3.28, validation loss=2.37] 13%|â–ˆâ–        | 64/500 [00:41<04:45,  1.53it/s, Train Loss=3.28, validation loss=2.37] 13%|â–ˆâ–        | 64/500 [00:41<04:45,  1.53it/s, Train Loss=3.69, validation loss=2.34] 13%|â–ˆâ–        | 65/500 [00:41<04:38,  1.56it/s, Train Loss=3.69, validation loss=2.34] 13%|â–ˆâ–        | 65/500 [00:42<04:38,  1.56it/s, Train Loss=2.83, validation loss=2.34] 13%|â–ˆâ–        | 66/500 [00:42<04:36,  1.57it/s, Train Loss=2.83, validation loss=2.34] 13%|â–ˆâ–        | 66/500 [00:42<04:36,  1.57it/s, Train Loss=2.33, validation loss=2.34] 13%|â–ˆâ–        | 67/500 [00:42<04:31,  1.59it/s, Train Loss=2.33, validation loss=2.34] 13%|â–ˆâ–        | 67/500 [00:43<04:31,  1.59it/s, Train Loss=3.95, validation loss=2.33] 14%|â–ˆâ–        | 68/500 [00:43<04:30,  1.60it/s, Train Loss=3.95, validation loss=2.33] 14%|â–ˆâ–        | 68/500 [00:44<04:30,  1.60it/s, Train Loss=3.74, validation loss=2.36] 14%|â–ˆâ–        | 69/500 [00:44<04:41,  1.53it/s, Train Loss=3.74, validation loss=2.36] 14%|â–ˆâ–        | 69/500 [00:44<04:41,  1.53it/s, Train Loss=2.11, validation loss=2.32] 14%|â–ˆâ–        | 70/500 [00:44<04:38,  1.54it/s, Train Loss=2.11, validation loss=2.32] 14%|â–ˆâ–        | 70/500 [00:45<04:38,  1.54it/s, Train Loss=1.66, validation loss=2.34] 14%|â–ˆâ–        | 71/500 [00:45<04:37,  1.54it/s, Train Loss=1.66, validation loss=2.34] 14%|â–ˆâ–        | 71/500 [00:46<04:37,  1.54it/s, Train Loss=3.57, validation loss=2.32] 14%|â–ˆâ–        | 72/500 [00:46<04:31,  1.58it/s, Train Loss=3.57, validation loss=2.32] 14%|â–ˆâ–        | 72/500 [00:46<04:31,  1.58it/s, Train Loss=2.28, validation loss=2.33] 15%|â–ˆâ–        | 73/500 [00:46<04:33,  1.56it/s, Train Loss=2.28, validation loss=2.33] 15%|â–ˆâ–        | 73/500 [00:47<04:33,  1.56it/s, Train Loss=2.57, validation loss=2.3]  15%|â–ˆâ–        | 74/500 [00:47<04:29,  1.58it/s, Train Loss=2.57, validation loss=2.3] 15%|â–ˆâ–        | 74/500 [00:48<04:29,  1.58it/s, Train Loss=3.53, validation loss=2.32] 15%|â–ˆâ–Œ        | 75/500 [00:48<04:34,  1.55it/s, Train Loss=3.53, validation loss=2.32] 15%|â–ˆâ–Œ        | 75/500 [00:48<04:34,  1.55it/s, Train Loss=1.79, validation loss=2.33] 15%|â–ˆâ–Œ        | 76/500 [00:48<04:33,  1.55it/s, Train Loss=1.79, validation loss=2.33] 15%|â–ˆâ–Œ        | 76/500 [00:49<04:33,  1.55it/s, Train Loss=2.18, validation loss=2.33] 15%|â–ˆâ–Œ        | 77/500 [00:49<04:44,  1.48it/s, Train Loss=2.18, validation loss=2.33] 15%|â–ˆâ–Œ        | 77/500 [00:50<04:44,  1.48it/s, Train Loss=2.23, validation loss=2.31] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:38,  1.51it/s, Train Loss=2.23, validation loss=2.31] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:38,  1.51it/s, Train Loss=2.36, validation loss=2.33] 16%|â–ˆâ–Œ        | 79/500 [00:50<04:32,  1.55it/s, Train Loss=2.36, validation loss=2.33] 16%|â–ˆâ–Œ        | 79/500 [00:51<04:32,  1.55it/s, Train Loss=2.2, validation loss=2.32]  16%|â–ˆâ–Œ        | 80/500 [00:51<04:30,  1.55it/s, Train Loss=2.2, validation loss=2.32] 16%|â–ˆâ–Œ        | 80/500 [00:51<04:30,  1.55it/s, Train Loss=2.05, validation loss=2.32] 16%|â–ˆâ–Œ        | 81/500 [00:51<04:27,  1.57it/s, Train Loss=2.05, validation loss=2.32] 16%|â–ˆâ–Œ        | 81/500 [00:52<04:27,  1.57it/s, Train Loss=2.73, validation loss=2.32] 16%|â–ˆâ–‹        | 82/500 [00:52<04:23,  1.58it/s, Train Loss=2.73, validation loss=2.32] 16%|â–ˆâ–‹        | 82/500 [00:53<04:23,  1.58it/s, Train Loss=3.37, validation loss=2.31] 17%|â–ˆâ–‹        | 83/500 [00:53<04:22,  1.59it/s, Train Loss=3.37, validation loss=2.31] 17%|â–ˆâ–‹        | 83/500 [00:53<04:22,  1.59it/s, Train Loss=2.27, validation loss=2.3]  17%|â–ˆâ–‹        | 84/500 [00:53<04:21,  1.59it/s, Train Loss=2.27, validation loss=2.3] 17%|â–ˆâ–‹        | 84/500 [00:54<04:21,  1.59it/s, Train Loss=2.05, validation loss=2.32] 17%|â–ˆâ–‹        | 85/500 [00:54<04:22,  1.58it/s, Train Loss=2.05, validation loss=2.32] 17%|â–ˆâ–‹        | 85/500 [00:55<04:22,  1.58it/s, Train Loss=2.05, validation loss=2.31] 17%|â–ˆâ–‹        | 86/500 [00:55<04:33,  1.51it/s, Train Loss=2.05, validation loss=2.31] 17%|â–ˆâ–‹        | 86/500 [00:55<04:33,  1.51it/s, Train Loss=2.53, validation loss=2.31] 17%|â–ˆâ–‹        | 87/500 [00:55<04:25,  1.56it/s, Train Loss=2.53, validation loss=2.31] 17%|â–ˆâ–‹        | 87/500 [00:56<04:25,  1.56it/s, Train Loss=2.13, validation loss=2.3]  18%|â–ˆâ–Š        | 88/500 [00:56<04:20,  1.58it/s, Train Loss=2.13, validation loss=2.3] 18%|â–ˆâ–Š        | 88/500 [00:57<04:20,  1.58it/s, Train Loss=3.31, validation loss=2.3] 18%|â–ˆâ–Š        | 89/500 [00:57<04:18,  1.59it/s, Train Loss=3.31, validation loss=2.3] 18%|â–ˆâ–Š        | 89/500 [00:57<04:18,  1.59it/s, Train Loss=3.1, validation loss=2.3]  18%|â–ˆâ–Š        | 90/500 [00:57<04:17,  1.59it/s, Train Loss=3.1, validation loss=2.3] 18%|â–ˆâ–Š        | 90/500 [00:58<04:17,  1.59it/s, Train Loss=1.49, validation loss=2.31] 18%|â–ˆâ–Š        | 91/500 [00:58<04:14,  1.61it/s, Train Loss=1.49, validation loss=2.31] 18%|â–ˆâ–Š        | 91/500 [00:58<04:14,  1.61it/s, Train Loss=1.78, validation loss=2.31] 18%|â–ˆâ–Š        | 92/500 [00:58<04:27,  1.53it/s, Train Loss=1.78, validation loss=2.31] 18%|â–ˆâ–Š        | 92/500 [00:59<04:27,  1.53it/s, Train Loss=2.5, validation loss=2.31]  19%|â–ˆâ–Š        | 93/500 [00:59<04:22,  1.55it/s, Train Loss=2.5, validation loss=2.31] 19%|â–ˆâ–Š        | 93/500 [01:00<04:22,  1.55it/s, Train Loss=2.51, validation loss=2.29] 19%|â–ˆâ–‰        | 94/500 [01:00<04:19,  1.56it/s, Train Loss=2.51, validation loss=2.29] 19%|â–ˆâ–‰        | 94/500 [01:00<04:19,  1.56it/s, Train Loss=1.85, validation loss=2.33] 19%|â–ˆâ–‰        | 95/500 [01:00<04:17,  1.57it/s, Train Loss=1.85, validation loss=2.33] 19%|â–ˆâ–‰        | 95/500 [01:01<04:17,  1.57it/s, Train Loss=1.84, validation loss=2.29] 19%|â–ˆâ–‰        | 96/500 [01:01<04:14,  1.59it/s, Train Loss=1.84, validation loss=2.29] 19%|â–ˆâ–‰        | 96/500 [01:02<04:14,  1.59it/s, Train Loss=2.78, validation loss=2.29] 19%|â–ˆâ–‰        | 97/500 [01:02<04:12,  1.60it/s, Train Loss=2.78, validation loss=2.29] 19%|â–ˆâ–‰        | 97/500 [01:02<04:12,  1.60it/s, Train Loss=1.76, validation loss=2.31] 20%|â–ˆâ–‰        | 98/500 [01:02<04:13,  1.59it/s, Train Loss=1.76, validation loss=2.31] 20%|â–ˆâ–‰        | 98/500 [01:03<04:13,  1.59it/s, Train Loss=2.36, validation loss=2.31] 20%|â–ˆâ–‰        | 99/500 [01:03<04:13,  1.58it/s, Train Loss=2.36, validation loss=2.31]####################################################################################################
--------------------------------------------- Epoch:100 ---------------------------------------------
-- Training set:
Loss: 2.35286808013916, Lr: 0.0005
Average AUC ROC: 0.53                Average AUC PR: 0.29
 20%|â–ˆâ–‰        | 99/500 [01:03<04:13,  1.58it/s, Train Loss=2.35, validation loss=2.29] 20%|â–ˆâ–ˆ        | 100/500 [01:03<04:12,  1.58it/s, Train Loss=2.35, validation loss=2.29]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.288631170988083
Average AUC ROC: 0.57                    Average AUC PR: 0.31
 20%|â–ˆâ–ˆ        | 100/500 [01:04<04:12,  1.58it/s, Train Loss=2.01, validation loss=2.3]  20%|â–ˆâ–ˆ        | 101/500 [01:04<04:08,  1.61it/s, Train Loss=2.01, validation loss=2.3] 20%|â–ˆâ–ˆ        | 101/500 [01:05<04:08,  1.61it/s, Train Loss=2.46, validation loss=2.3] 20%|â–ˆâ–ˆ        | 102/500 [01:05<04:29,  1.48it/s, Train Loss=2.46, validation loss=2.3] 20%|â–ˆâ–ˆ        | 102/500 [01:06<04:29,  1.48it/s, Train Loss=2.23, validation loss=2.3] 21%|â–ˆâ–ˆ        | 103/500 [01:06<04:21,  1.52it/s, Train Loss=2.23, validation loss=2.3] 21%|â–ˆâ–ˆ        | 103/500 [01:06<04:21,  1.52it/s, Train Loss=1.94, validation loss=2.29] 21%|â–ˆâ–ˆ        | 104/500 [01:06<04:15,  1.55it/s, Train Loss=1.94, validation loss=2.29] 21%|â–ˆâ–ˆ        | 104/500 [01:07<04:15,  1.55it/s, Train Loss=2.05, validation loss=2.28] 21%|â–ˆâ–ˆ        | 105/500 [01:07<04:10,  1.58it/s, Train Loss=2.05, validation loss=2.28] 21%|â–ˆâ–ˆ        | 105/500 [01:07<04:10,  1.58it/s, Train Loss=2.92, validation loss=2.3]  21%|â–ˆâ–ˆ        | 106/500 [01:07<04:07,  1.59it/s, Train Loss=2.92, validation loss=2.3] 21%|â–ˆâ–ˆ        | 106/500 [01:08<04:07,  1.59it/s, Train Loss=2.17, validation loss=2.29] 21%|â–ˆâ–ˆâ–       | 107/500 [01:08<04:04,  1.61it/s, Train Loss=2.17, validation loss=2.29] 21%|â–ˆâ–ˆâ–       | 107/500 [01:09<04:04,  1.61it/s, Train Loss=2.81, validation loss=2.27] 22%|â–ˆâ–ˆâ–       | 108/500 [01:09<04:15,  1.53it/s, Train Loss=2.81, validation loss=2.27] 22%|â–ˆâ–ˆâ–       | 108/500 [01:09<04:15,  1.53it/s, Train Loss=2.21, validation loss=2.29] 22%|â–ˆâ–ˆâ–       | 109/500 [01:09<04:11,  1.56it/s, Train Loss=2.21, validation loss=2.29] 22%|â–ˆâ–ˆâ–       | 109/500 [01:10<04:11,  1.56it/s, Train Loss=2.78, validation loss=2.3]  22%|â–ˆâ–ˆâ–       | 110/500 [01:10<04:06,  1.58it/s, Train Loss=2.78, validation loss=2.3] 22%|â–ˆâ–ˆâ–       | 110/500 [01:10<04:06,  1.58it/s, Train Loss=2, validation loss=2.28]   22%|â–ˆâ–ˆâ–       | 111/500 [01:10<03:59,  1.62it/s, Train Loss=2, validation loss=2.28] 22%|â–ˆâ–ˆâ–       | 111/500 [01:11<03:59,  1.62it/s, Train Loss=3.93, validation loss=2.28] 22%|â–ˆâ–ˆâ–       | 112/500 [01:11<03:59,  1.62it/s, Train Loss=3.93, validation loss=2.28] 22%|â–ˆâ–ˆâ–       | 112/500 [01:12<03:59,  1.62it/s, Train Loss=3.34, validation loss=2.28] 23%|â–ˆâ–ˆâ–       | 113/500 [01:12<03:56,  1.63it/s, Train Loss=3.34, validation loss=2.28] 23%|â–ˆâ–ˆâ–       | 113/500 [01:12<03:56,  1.63it/s, Train Loss=3.76, validation loss=2.29] 23%|â–ˆâ–ˆâ–       | 114/500 [01:12<04:00,  1.60it/s, Train Loss=3.76, validation loss=2.29] 23%|â–ˆâ–ˆâ–       | 114/500 [01:13<04:00,  1.60it/s, Train Loss=1.53, validation loss=2.3]  23%|â–ˆâ–ˆâ–       | 115/500 [01:13<03:58,  1.61it/s, Train Loss=1.53, validation loss=2.3] 23%|â–ˆâ–ˆâ–       | 115/500 [01:14<03:58,  1.61it/s, Train Loss=2.31, validation loss=2.29] 23%|â–ˆâ–ˆâ–       | 116/500 [01:14<03:56,  1.62it/s, Train Loss=2.31, validation loss=2.29] 23%|â–ˆâ–ˆâ–       | 116/500 [01:14<03:56,  1.62it/s, Train Loss=2.84, validation loss=2.27] 23%|â–ˆâ–ˆâ–       | 117/500 [01:14<04:11,  1.52it/s, Train Loss=2.84, validation loss=2.27] 23%|â–ˆâ–ˆâ–       | 117/500 [01:15<04:11,  1.52it/s, Train Loss=2.17, validation loss=2.3]  24%|â–ˆâ–ˆâ–       | 118/500 [01:15<04:05,  1.55it/s, Train Loss=2.17, validation loss=2.3] 24%|â–ˆâ–ˆâ–       | 118/500 [01:16<04:05,  1.55it/s, Train Loss=1.24, validation loss=2.28] 24%|â–ˆâ–ˆâ–       | 119/500 [01:16<04:03,  1.56it/s, Train Loss=1.24, validation loss=2.28] 24%|â–ˆâ–ˆâ–       | 119/500 [01:16<04:03,  1.56it/s, Train Loss=2.43, validation loss=2.28] 24%|â–ˆâ–ˆâ–       | 120/500 [01:16<04:02,  1.56it/s, Train Loss=2.43, validation loss=2.28] 24%|â–ˆâ–ˆâ–       | 120/500 [01:17<04:02,  1.56it/s, Train Loss=2.56, validation loss=2.31] 24%|â–ˆâ–ˆâ–       | 121/500 [01:17<04:09,  1.52it/s, Train Loss=2.56, validation loss=2.31] 24%|â–ˆâ–ˆâ–       | 121/500 [01:18<04:09,  1.52it/s, Train Loss=2.39, validation loss=2.28] 24%|â–ˆâ–ˆâ–       | 122/500 [01:18<04:01,  1.56it/s, Train Loss=2.39, validation loss=2.28] 24%|â–ˆâ–ˆâ–       | 122/500 [01:18<04:01,  1.56it/s, Train Loss=2.33, validation loss=2.3]  25%|â–ˆâ–ˆâ–       | 123/500 [01:18<04:00,  1.57it/s, Train Loss=2.33, validation loss=2.3] 25%|â–ˆâ–ˆâ–       | 123/500 [01:19<04:00,  1.57it/s, Train Loss=2.4, validation loss=2.27] 25%|â–ˆâ–ˆâ–       | 124/500 [01:19<03:59,  1.57it/s, Train Loss=2.4, validation loss=2.27] 25%|â–ˆâ–ˆâ–       | 124/500 [01:19<03:59,  1.57it/s, Train Loss=2.24, validation loss=2.28] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:19<04:07,  1.51it/s, Train Loss=2.24, validation loss=2.28] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:20<04:07,  1.51it/s, Train Loss=2.75, validation loss=2.28] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:20<04:03,  1.54it/s, Train Loss=2.75, validation loss=2.28] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:21<04:03,  1.54it/s, Train Loss=3.2, validation loss=2.26]  25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:21<03:59,  1.56it/s, Train Loss=3.2, validation loss=2.26] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:21<03:59,  1.56it/s, Train Loss=2.66, validation loss=2.27] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:21<03:58,  1.56it/s, Train Loss=2.66, validation loss=2.27] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:22<03:58,  1.56it/s, Train Loss=2.51, validation loss=2.28] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:22<03:56,  1.57it/s, Train Loss=2.51, validation loss=2.28] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:23<03:56,  1.57it/s, Train Loss=1.77, validation loss=2.3]  26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:23<03:57,  1.56it/s, Train Loss=1.77, validation loss=2.3] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:23<03:57,  1.56it/s, Train Loss=2.11, validation loss=2.29] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:23<04:05,  1.50it/s, Train Loss=2.11, validation loss=2.29] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:24<04:05,  1.50it/s, Train Loss=2.06, validation loss=2.28] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:24<04:00,  1.53it/s, Train Loss=2.06, validation loss=2.28] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:25<04:00,  1.53it/s, Train Loss=2.28, validation loss=2.29] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:25<03:54,  1.56it/s, Train Loss=2.28, validation loss=2.29] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:25<03:54,  1.56it/s, Train Loss=2.65, validation loss=2.27] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:25<03:57,  1.54it/s, Train Loss=2.65, validation loss=2.27] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:26<03:57,  1.54it/s, Train Loss=1.72, validation loss=2.27] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:26<03:52,  1.57it/s, Train Loss=1.72, validation loss=2.27] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:26<03:52,  1.57it/s, Train Loss=1.74, validation loss=2.29] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:26<03:48,  1.60it/s, Train Loss=1.74, validation loss=2.29] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:27<03:48,  1.60it/s, Train Loss=2.57, validation loss=2.28] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:27<03:46,  1.61it/s, Train Loss=2.57, validation loss=2.28] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:28<03:46,  1.61it/s, Train Loss=3.07, validation loss=2.27] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:28<03:45,  1.61it/s, Train Loss=3.07, validation loss=2.27] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:28<03:45,  1.61it/s, Train Loss=2.15, validation loss=2.28] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:28<03:44,  1.61it/s, Train Loss=2.15, validation loss=2.28] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:29<03:44,  1.61it/s, Train Loss=3.03, validation loss=2.28] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:29<03:47,  1.58it/s, Train Loss=3.03, validation loss=2.28] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:30<03:47,  1.58it/s, Train Loss=2.9, validation loss=2.25]  28%|â–ˆâ–ˆâ–Š       | 141/500 [01:30<03:59,  1.50it/s, Train Loss=2.9, validation loss=2.25] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:30<03:59,  1.50it/s, Train Loss=2.86, validation loss=2.27] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:30<03:53,  1.53it/s, Train Loss=2.86, validation loss=2.27] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:31<03:53,  1.53it/s, Train Loss=2.27, validation loss=2.28] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:31<03:48,  1.56it/s, Train Loss=2.27, validation loss=2.28] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:32<03:48,  1.56it/s, Train Loss=2.3, validation loss=2.28]  29%|â–ˆâ–ˆâ–‰       | 144/500 [01:32<03:43,  1.59it/s, Train Loss=2.3, validation loss=2.28] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:32<03:43,  1.59it/s, Train Loss=1.81, validation loss=2.26] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:32<03:42,  1.60it/s, Train Loss=1.81, validation loss=2.26] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:33<03:42,  1.60it/s, Train Loss=1.03, validation loss=2.28] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:33<03:56,  1.50it/s, Train Loss=1.03, validation loss=2.28] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:34<03:56,  1.50it/s, Train Loss=3.54, validation loss=2.27] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:34<03:54,  1.51it/s, Train Loss=3.54, validation loss=2.27] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:34<03:54,  1.51it/s, Train Loss=1.59, validation loss=2.28] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:34<03:51,  1.52it/s, Train Loss=1.59, validation loss=2.28] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:35<03:51,  1.52it/s, Train Loss=1.98, validation loss=2.29] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:35<03:44,  1.56it/s, Train Loss=1.98, validation loss=2.29] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:35<03:44,  1.56it/s, Train Loss=2.97, validation loss=2.29] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:35<03:42,  1.57it/s, Train Loss=2.97, validation loss=2.29] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:36<03:42,  1.57it/s, Train Loss=2.52, validation loss=2.27] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:36<03:47,  1.53it/s, Train Loss=2.52, validation loss=2.27] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:37<03:47,  1.53it/s, Train Loss=1.57, validation loss=2.26] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:37<03:42,  1.56it/s, Train Loss=1.57, validation loss=2.26] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:37<03:42,  1.56it/s, Train Loss=1.69, validation loss=2.27] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:37<03:42,  1.56it/s, Train Loss=1.69, validation loss=2.27] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:38<03:42,  1.56it/s, Train Loss=2.01, validation loss=2.28] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:38<03:38,  1.58it/s, Train Loss=2.01, validation loss=2.28] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:39<03:38,  1.58it/s, Train Loss=4.72, validation loss=2.26] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:39<03:36,  1.59it/s, Train Loss=4.72, validation loss=2.26] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:39<03:36,  1.59it/s, Train Loss=4.38, validation loss=2.26] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:39<03:47,  1.51it/s, Train Loss=4.38, validation loss=2.26] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:40<03:47,  1.51it/s, Train Loss=4.81, validation loss=2.26] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:40<03:44,  1.53it/s, Train Loss=4.81, validation loss=2.26] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:41<03:44,  1.53it/s, Train Loss=1.6, validation loss=2.26]  32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:41<03:43,  1.53it/s, Train Loss=1.6, validation loss=2.26] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:41<03:43,  1.53it/s, Train Loss=1.4, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:41<03:43,  1.53it/s, Train Loss=1.4, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:42<03:43,  1.53it/s, Train Loss=2.07, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:42<03:39,  1.55it/s, Train Loss=2.07, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:43<03:39,  1.55it/s, Train Loss=1.82, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:43<03:45,  1.50it/s, Train Loss=1.82, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:43<03:45,  1.50it/s, Train Loss=4.2, validation loss=2.25]  32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:43<03:42,  1.52it/s, Train Loss=4.2, validation loss=2.25] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:44<03:42,  1.52it/s, Train Loss=2.81, validation loss=2.26] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:44<03:37,  1.55it/s, Train Loss=2.81, validation loss=2.26] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:45<03:37,  1.55it/s, Train Loss=1.95, validation loss=2.27] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:45<03:32,  1.58it/s, Train Loss=1.95, validation loss=2.27] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:45<03:32,  1.58it/s, Train Loss=1.82, validation loss=2.26] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:45<03:30,  1.59it/s, Train Loss=1.82, validation loss=2.26] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:46<03:30,  1.59it/s, Train Loss=3.29, validation loss=2.28] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:46<03:27,  1.61it/s, Train Loss=3.29, validation loss=2.28] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:46<03:27,  1.61it/s, Train Loss=1.37, validation loss=2.26] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:46<03:28,  1.60it/s, Train Loss=1.37, validation loss=2.26] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:47<03:28,  1.60it/s, Train Loss=2.78, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:47<03:26,  1.61it/s, Train Loss=2.78, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:48<03:26,  1.61it/s, Train Loss=1.75, validation loss=2.26] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:48<03:27,  1.60it/s, Train Loss=1.75, validation loss=2.26] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:48<03:27,  1.60it/s, Train Loss=3.51, validation loss=2.26] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:48<03:36,  1.52it/s, Train Loss=3.51, validation loss=2.26] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:49<03:36,  1.52it/s, Train Loss=2.26, validation loss=2.26] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:49<03:31,  1.56it/s, Train Loss=2.26, validation loss=2.26] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:50<03:31,  1.56it/s, Train Loss=2.91, validation loss=2.25] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:50<03:27,  1.58it/s, Train Loss=2.91, validation loss=2.25] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:50<03:27,  1.58it/s, Train Loss=2.65, validation loss=2.25] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:50<03:28,  1.57it/s, Train Loss=2.65, validation loss=2.25] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:51<03:28,  1.57it/s, Train Loss=2.1, validation loss=2.26]  35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:51<03:26,  1.58it/s, Train Loss=2.1, validation loss=2.26] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:52<03:26,  1.58it/s, Train Loss=1.89, validation loss=2.25] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:52<03:25,  1.58it/s, Train Loss=1.89, validation loss=2.25] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:52<03:25,  1.58it/s, Train Loss=2.44, validation loss=2.26] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:52<03:24,  1.58it/s, Train Loss=2.44, validation loss=2.26] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:53<03:24,  1.58it/s, Train Loss=2.75, validation loss=2.26] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:53<03:21,  1.61it/s, Train Loss=2.75, validation loss=2.26] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:53<03:21,  1.61it/s, Train Loss=2.95, validation loss=2.26] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:53<03:31,  1.52it/s, Train Loss=2.95, validation loss=2.26] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:54<03:31,  1.52it/s, Train Loss=1.63, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:54<03:26,  1.55it/s, Train Loss=1.63, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:55<03:26,  1.55it/s, Train Loss=2.71, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:55<03:21,  1.59it/s, Train Loss=2.71, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:55<03:21,  1.59it/s, Train Loss=1.85, validation loss=2.26] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:55<03:23,  1.57it/s, Train Loss=1.85, validation loss=2.26] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:56<03:23,  1.57it/s, Train Loss=3.27, validation loss=2.26] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:56<03:19,  1.60it/s, Train Loss=3.27, validation loss=2.26] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:57<03:19,  1.60it/s, Train Loss=2.33, validation loss=2.27] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:57<03:17,  1.61it/s, Train Loss=2.33, validation loss=2.27] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:57<03:17,  1.61it/s, Train Loss=1.58, validation loss=2.26] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:57<03:15,  1.61it/s, Train Loss=1.58, validation loss=2.26] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:58<03:15,  1.61it/s, Train Loss=2.27, validation loss=2.25] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:58<03:26,  1.53it/s, Train Loss=2.27, validation loss=2.25] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:59<03:26,  1.53it/s, Train Loss=1.54, validation loss=2.25] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [01:59<03:25,  1.53it/s, Train Loss=1.54, validation loss=2.25] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [01:59<03:25,  1.53it/s, Train Loss=1.7, validation loss=2.27]  37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [01:59<03:21,  1.55it/s, Train Loss=1.7, validation loss=2.27] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:00<03:21,  1.55it/s, Train Loss=2.38, validation loss=2.27] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:00<03:19,  1.57it/s, Train Loss=2.38, validation loss=2.27] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:00<03:19,  1.57it/s, Train Loss=1.75, validation loss=2.25] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:00<03:16,  1.58it/s, Train Loss=1.75, validation loss=2.25] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:01<03:16,  1.58it/s, Train Loss=1.44, validation loss=2.28] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:01<03:14,  1.60it/s, Train Loss=1.44, validation loss=2.28] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:02<03:14,  1.60it/s, Train Loss=1.63, validation loss=2.28] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:02<03:11,  1.61it/s, Train Loss=1.63, validation loss=2.28] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:02<03:11,  1.61it/s, Train Loss=3.38, validation loss=2.26] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:02<03:14,  1.58it/s, Train Loss=3.38, validation loss=2.26] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:03<03:14,  1.58it/s, Train Loss=2.53, validation loss=2.25] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:03<03:12,  1.60it/s, Train Loss=2.53, validation loss=2.25] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:04<03:12,  1.60it/s, Train Loss=2.34, validation loss=2.25] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:04<03:22,  1.51it/s, Train Loss=2.34, validation loss=2.25] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:04<03:22,  1.51it/s, Train Loss=2.49, validation loss=2.24] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:04<03:16,  1.55it/s, Train Loss=2.49, validation loss=2.24] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:05<03:16,  1.55it/s, Train Loss=1.93, validation loss=2.26] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:05<03:14,  1.56it/s, Train Loss=1.93, validation loss=2.26] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:06<03:14,  1.56it/s, Train Loss=2.96, validation loss=2.24] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:06<03:11,  1.58it/s, Train Loss=2.96, validation loss=2.24] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:06<03:11,  1.58it/s, Train Loss=3.04, validation loss=2.26] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:06<03:08,  1.60it/s, Train Loss=3.04, validation loss=2.26] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:07<03:08,  1.60it/s, Train Loss=2.67, validation loss=2.25] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:07<03:07,  1.60it/s, Train Loss=2.67, validation loss=2.25]####################################################################################################
--------------------------------------------- Epoch:200 ---------------------------------------------
-- Training set:
Loss: 2.916142463684082, Lr: 0.00025
Average AUC ROC: 0.53                Average AUC PR: 0.29
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:07<03:07,  1.60it/s, Train Loss=2.92, validation loss=2.27] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:07<03:18,  1.51it/s, Train Loss=2.92, validation loss=2.27]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.268552377820015
Average AUC ROC: 0.56                    Average AUC PR: 0.3
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:08<03:18,  1.51it/s, Train Loss=1.23, validation loss=2.25] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:08<03:11,  1.56it/s, Train Loss=1.23, validation loss=2.25] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:09<03:11,  1.56it/s, Train Loss=1.55, validation loss=2.26] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:09<03:08,  1.58it/s, Train Loss=1.55, validation loss=2.26] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:09<03:08,  1.58it/s, Train Loss=2.54, validation loss=2.26] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:09<03:05,  1.60it/s, Train Loss=2.54, validation loss=2.26] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:10<03:05,  1.60it/s, Train Loss=2.53, validation loss=2.25] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:10<03:05,  1.60it/s, Train Loss=2.53, validation loss=2.25] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:11<03:05,  1.60it/s, Train Loss=2.1, validation loss=2.27]  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:11<03:03,  1.60it/s, Train Loss=2.1, validation loss=2.27] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:11<03:03,  1.60it/s, Train Loss=1.28, validation loss=2.25] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:11<03:05,  1.58it/s, Train Loss=1.28, validation loss=2.25] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:12<03:05,  1.58it/s, Train Loss=1.67, validation loss=2.26] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:12<03:03,  1.59it/s, Train Loss=1.67, validation loss=2.26] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:12<03:03,  1.59it/s, Train Loss=1.97, validation loss=2.25] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:12<03:03,  1.59it/s, Train Loss=1.97, validation loss=2.25] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:13<03:03,  1.59it/s, Train Loss=2.54, validation loss=2.25] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:13<03:17,  1.48it/s, Train Loss=2.54, validation loss=2.25] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:14<03:17,  1.48it/s, Train Loss=1.87, validation loss=2.26] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:14<03:12,  1.51it/s, Train Loss=1.87, validation loss=2.26] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:14<03:12,  1.51it/s, Train Loss=3.31, validation loss=2.24] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:14<03:09,  1.53it/s, Train Loss=3.31, validation loss=2.24] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:15<03:09,  1.53it/s, Train Loss=2.26, validation loss=2.24] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:15<03:04,  1.56it/s, Train Loss=2.26, validation loss=2.24] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:16<03:04,  1.56it/s, Train Loss=2.23, validation loss=2.25] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:16<03:00,  1.59it/s, Train Loss=2.23, validation loss=2.25] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:16<03:00,  1.59it/s, Train Loss=2.99, validation loss=2.25] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:16<03:07,  1.52it/s, Train Loss=2.99, validation loss=2.25] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:17<03:07,  1.52it/s, Train Loss=1.82, validation loss=2.27] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:17<03:06,  1.53it/s, Train Loss=1.82, validation loss=2.27] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:18<03:06,  1.53it/s, Train Loss=1.95, validation loss=2.26] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:18<03:04,  1.54it/s, Train Loss=1.95, validation loss=2.26] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:18<03:04,  1.54it/s, Train Loss=2.15, validation loss=2.26] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:18<03:00,  1.56it/s, Train Loss=2.15, validation loss=2.26] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:19<03:00,  1.56it/s, Train Loss=1.89, validation loss=2.26] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:19<02:58,  1.58it/s, Train Loss=1.89, validation loss=2.26] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:20<02:58,  1.58it/s, Train Loss=1.68, validation loss=2.26] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:20<02:57,  1.58it/s, Train Loss=1.68, validation loss=2.26] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:20<02:57,  1.58it/s, Train Loss=2.13, validation loss=2.25] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:20<02:57,  1.58it/s, Train Loss=2.13, validation loss=2.25] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:21<02:57,  1.58it/s, Train Loss=1.93, validation loss=2.25] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:21<02:56,  1.58it/s, Train Loss=1.93, validation loss=2.25] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:21<02:56,  1.58it/s, Train Loss=1.43, validation loss=2.25] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:21<02:52,  1.61it/s, Train Loss=1.43, validation loss=2.25] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:22<02:52,  1.61it/s, Train Loss=1.48, validation loss=2.25] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:22<03:02,  1.52it/s, Train Loss=1.48, validation loss=2.25] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:23<03:02,  1.52it/s, Train Loss=2.61, validation loss=2.26] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:23<02:55,  1.57it/s, Train Loss=2.61, validation loss=2.26] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:23<02:55,  1.57it/s, Train Loss=1.99, validation loss=2.25] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:23<02:54,  1.58it/s, Train Loss=1.99, validation loss=2.25] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:24<02:54,  1.58it/s, Train Loss=1.32, validation loss=2.25] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:24<02:53,  1.58it/s, Train Loss=1.32, validation loss=2.25] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:25<02:53,  1.58it/s, Train Loss=1.71, validation loss=2.25] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:25<02:51,  1.59it/s, Train Loss=1.71, validation loss=2.25] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:25<02:51,  1.59it/s, Train Loss=1.29, validation loss=2.24] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:25<02:51,  1.59it/s, Train Loss=1.29, validation loss=2.24] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:26<02:51,  1.59it/s, Train Loss=1.67, validation loss=2.25] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:26<02:59,  1.51it/s, Train Loss=1.67, validation loss=2.25] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:27<02:59,  1.51it/s, Train Loss=2.12, validation loss=2.26] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:27<02:58,  1.51it/s, Train Loss=2.12, validation loss=2.26] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:27<02:58,  1.51it/s, Train Loss=2.22, validation loss=2.26] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:27<02:54,  1.54it/s, Train Loss=2.22, validation loss=2.26] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:28<02:54,  1.54it/s, Train Loss=2.25, validation loss=2.25] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:28<02:53,  1.54it/s, Train Loss=2.25, validation loss=2.25] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:29<02:53,  1.54it/s, Train Loss=1.53, validation loss=2.24] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:29<02:53,  1.54it/s, Train Loss=1.53, validation loss=2.24] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:29<02:53,  1.54it/s, Train Loss=1.86, validation loss=2.24] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:29<02:50,  1.56it/s, Train Loss=1.86, validation loss=2.24] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:30<02:50,  1.56it/s, Train Loss=1.99, validation loss=2.27] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:30<02:50,  1.56it/s, Train Loss=1.99, validation loss=2.27] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:30<02:50,  1.56it/s, Train Loss=2.12, validation loss=2.26] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:30<02:47,  1.58it/s, Train Loss=2.12, validation loss=2.26] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:31<02:47,  1.58it/s, Train Loss=2.69, validation loss=2.25] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:31<02:44,  1.60it/s, Train Loss=2.69, validation loss=2.25] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:32<02:44,  1.60it/s, Train Loss=1.65, validation loss=2.24] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:32<02:50,  1.54it/s, Train Loss=1.65, validation loss=2.24] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:32<02:50,  1.54it/s, Train Loss=2.5, validation loss=2.26]  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:32<02:46,  1.57it/s, Train Loss=2.5, validation loss=2.26] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:33<02:46,  1.57it/s, Train Loss=2.18, validation loss=2.26] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:33<02:43,  1.59it/s, Train Loss=2.18, validation loss=2.26] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:34<02:43,  1.59it/s, Train Loss=3.55, validation loss=2.25] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:34<02:42,  1.60it/s, Train Loss=3.55, validation loss=2.25] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:34<02:42,  1.60it/s, Train Loss=2.47, validation loss=2.26] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:34<02:39,  1.62it/s, Train Loss=2.47, validation loss=2.26] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:35<02:39,  1.62it/s, Train Loss=2.01, validation loss=2.25] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:35<02:38,  1.62it/s, Train Loss=2.01, validation loss=2.25] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:36<02:38,  1.62it/s, Train Loss=2.49, validation loss=2.25] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:36<02:46,  1.54it/s, Train Loss=2.49, validation loss=2.25] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:36<02:46,  1.54it/s, Train Loss=2.27, validation loss=2.25] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:36<02:45,  1.54it/s, Train Loss=2.27, validation loss=2.25] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:37<02:45,  1.54it/s, Train Loss=2.44, validation loss=2.24] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:37<02:42,  1.57it/s, Train Loss=2.44, validation loss=2.24] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:37<02:42,  1.57it/s, Train Loss=1.68, validation loss=2.27] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:37<02:40,  1.57it/s, Train Loss=1.68, validation loss=2.27] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:38<02:40,  1.57it/s, Train Loss=1.49, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:38<02:39,  1.58it/s, Train Loss=1.49, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:39<02:39,  1.58it/s, Train Loss=2.26, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:39<02:37,  1.60it/s, Train Loss=2.26, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:39<02:37,  1.60it/s, Train Loss=3.02, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:39<02:37,  1.59it/s, Train Loss=3.02, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:40<02:37,  1.59it/s, Train Loss=2.68, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:40<02:36,  1.59it/s, Train Loss=2.68, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:41<02:36,  1.59it/s, Train Loss=2, validation loss=2.24]    50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:41<02:34,  1.60it/s, Train Loss=2, validation loss=2.24] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:41<02:34,  1.60it/s, Train Loss=2.45, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:41<02:40,  1.53it/s, Train Loss=2.45, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:42<02:40,  1.53it/s, Train Loss=2.5, validation loss=2.25]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:42<02:38,  1.55it/s, Train Loss=2.5, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:43<02:38,  1.55it/s, Train Loss=3.28, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:43<02:37,  1.56it/s, Train Loss=3.28, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:43<02:37,  1.56it/s, Train Loss=1.95, validation loss=2.24] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:43<02:34,  1.58it/s, Train Loss=1.95, validation loss=2.24] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:44<02:34,  1.58it/s, Train Loss=3.2, validation loss=2.25]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:44<02:35,  1.56it/s, Train Loss=3.2, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:44<02:35,  1.56it/s, Train Loss=4.22, validation loss=2.25] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:44<02:33,  1.58it/s, Train Loss=4.22, validation loss=2.25] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:45<02:33,  1.58it/s, Train Loss=3.16, validation loss=2.25] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:45<02:30,  1.60it/s, Train Loss=3.16, validation loss=2.25] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:46<02:30,  1.60it/s, Train Loss=2.17, validation loss=2.24] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:46<02:42,  1.48it/s, Train Loss=2.17, validation loss=2.24] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:46<02:42,  1.48it/s, Train Loss=2.7, validation loss=2.26]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:46<02:38,  1.51it/s, Train Loss=2.7, validation loss=2.26] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:47<02:38,  1.51it/s, Train Loss=2.35, validation loss=2.26] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:47<02:35,  1.53it/s, Train Loss=2.35, validation loss=2.26] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:48<02:35,  1.53it/s, Train Loss=0.933, validation loss=2.26] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:48<02:33,  1.55it/s, Train Loss=0.933, validation loss=2.26] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:48<02:33,  1.55it/s, Train Loss=1.43, validation loss=2.24]  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:48<02:30,  1.57it/s, Train Loss=1.43, validation loss=2.24] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:49<02:30,  1.57it/s, Train Loss=3.29, validation loss=2.24] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:49<02:30,  1.56it/s, Train Loss=3.29, validation loss=2.24] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:50<02:30,  1.56it/s, Train Loss=2.79, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:50<02:27,  1.58it/s, Train Loss=2.79, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:50<02:27,  1.58it/s, Train Loss=2.21, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:50<02:32,  1.53it/s, Train Loss=2.21, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:51<02:32,  1.53it/s, Train Loss=1.51, validation loss=2.25] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:51<02:32,  1.52it/s, Train Loss=1.51, validation loss=2.25] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:52<02:32,  1.52it/s, Train Loss=1.66, validation loss=2.27] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:52<02:29,  1.55it/s, Train Loss=1.66, validation loss=2.27] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:52<02:29,  1.55it/s, Train Loss=2.73, validation loss=2.26] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:52<02:27,  1.56it/s, Train Loss=2.73, validation loss=2.26] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:53<02:27,  1.56it/s, Train Loss=2.35, validation loss=2.25] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:53<02:23,  1.60it/s, Train Loss=2.35, validation loss=2.25] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:53<02:23,  1.60it/s, Train Loss=1.63, validation loss=2.25] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:53<02:21,  1.61it/s, Train Loss=1.63, validation loss=2.25] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:54<02:21,  1.61it/s, Train Loss=1.83, validation loss=2.25] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:54<02:21,  1.61it/s, Train Loss=1.83, validation loss=2.25] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:55<02:21,  1.61it/s, Train Loss=3.74, validation loss=2.24] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:55<02:23,  1.57it/s, Train Loss=3.74, validation loss=2.24] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:55<02:23,  1.57it/s, Train Loss=2.38, validation loss=2.25] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:55<02:26,  1.54it/s, Train Loss=2.38, validation loss=2.25] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:56<02:26,  1.54it/s, Train Loss=1.81, validation loss=2.24] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:56<02:26,  1.53it/s, Train Loss=1.81, validation loss=2.24] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:57<02:26,  1.53it/s, Train Loss=2.38, validation loss=2.25] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:57<02:22,  1.56it/s, Train Loss=2.38, validation loss=2.25] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:57<02:22,  1.56it/s, Train Loss=2.15, validation loss=2.25] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:57<02:21,  1.57it/s, Train Loss=2.15, validation loss=2.25] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:58<02:21,  1.57it/s, Train Loss=1.96, validation loss=2.25] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [02:58<02:21,  1.56it/s, Train Loss=1.96, validation loss=2.25] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [02:59<02:21,  1.56it/s, Train Loss=1.6, validation loss=2.25]  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [02:59<02:20,  1.57it/s, Train Loss=1.6, validation loss=2.25] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [02:59<02:20,  1.57it/s, Train Loss=2.4, validation loss=2.24] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [02:59<02:23,  1.53it/s, Train Loss=2.4, validation loss=2.24] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:00<02:23,  1.53it/s, Train Loss=2.81, validation loss=2.25] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:00<02:29,  1.46it/s, Train Loss=2.81, validation loss=2.25] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:01<02:29,  1.46it/s, Train Loss=1.25, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:01<02:26,  1.48it/s, Train Loss=1.25, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:01<02:26,  1.48it/s, Train Loss=1.66, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:01<02:23,  1.51it/s, Train Loss=1.66, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:02<02:23,  1.51it/s, Train Loss=1.61, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:02<02:19,  1.54it/s, Train Loss=1.61, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:03<02:19,  1.54it/s, Train Loss=2.66, validation loss=2.24] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:03<02:15,  1.58it/s, Train Loss=2.66, validation loss=2.24] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:03<02:15,  1.58it/s, Train Loss=2.96, validation loss=2.24] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:03<02:12,  1.60it/s, Train Loss=2.96, validation loss=2.24] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:04<02:12,  1.60it/s, Train Loss=1.99, validation loss=2.26] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:04<02:12,  1.60it/s, Train Loss=1.99, validation loss=2.26] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:04<02:12,  1.60it/s, Train Loss=2.64, validation loss=2.25] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:04<02:11,  1.60it/s, Train Loss=2.64, validation loss=2.25] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:05<02:11,  1.60it/s, Train Loss=2.01, validation loss=2.24] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:05<02:15,  1.55it/s, Train Loss=2.01, validation loss=2.24] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:06<02:15,  1.55it/s, Train Loss=1.45, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:06<02:15,  1.54it/s, Train Loss=1.45, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:06<02:15,  1.54it/s, Train Loss=2.01, validation loss=2.24] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:06<02:13,  1.56it/s, Train Loss=2.01, validation loss=2.24] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:07<02:13,  1.56it/s, Train Loss=2.04, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:07<02:10,  1.59it/s, Train Loss=2.04, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:08<02:10,  1.59it/s, Train Loss=1.38, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:08<02:10,  1.57it/s, Train Loss=1.38, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:08<02:10,  1.57it/s, Train Loss=3.25, validation loss=2.24] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:08<02:09,  1.59it/s, Train Loss=3.25, validation loss=2.24] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:09<02:09,  1.59it/s, Train Loss=2.08, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:09<02:16,  1.50it/s, Train Loss=2.08, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:10<02:16,  1.50it/s, Train Loss=1.77, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:10<02:11,  1.54it/s, Train Loss=1.77, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:10<02:11,  1.54it/s, Train Loss=1.55, validation loss=2.25] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:10<02:07,  1.58it/s, Train Loss=1.55, validation loss=2.25] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:11<02:07,  1.58it/s, Train Loss=1.97, validation loss=2.26] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:11<02:05,  1.61it/s, Train Loss=1.97, validation loss=2.26]####################################################################################################
--------------------------------------------- Epoch:300 ---------------------------------------------
-- Training set:
Loss: 1.7723498344421387, Lr: 0.000125
Average AUC ROC: 0.52                Average AUC PR: 0.29
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:11<02:05,  1.61it/s, Train Loss=1.77, validation loss=2.25] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:11<02:03,  1.62it/s, Train Loss=1.77, validation loss=2.25]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.2499504312872887
Average AUC ROC: 0.56                    Average AUC PR: 0.3
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:12<02:03,  1.62it/s, Train Loss=2.2, validation loss=2.23]  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:12<02:03,  1.61it/s, Train Loss=2.2, validation loss=2.23] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:13<02:03,  1.61it/s, Train Loss=1.49, validation loss=2.23] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:13<02:02,  1.62it/s, Train Loss=1.49, validation loss=2.23] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:13<02:02,  1.62it/s, Train Loss=2.41, validation loss=2.24] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:13<02:00,  1.63it/s, Train Loss=2.41, validation loss=2.24] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:14<02:00,  1.63it/s, Train Loss=1.87, validation loss=2.23] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:14<01:57,  1.66it/s, Train Loss=1.87, validation loss=2.23] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:14<01:57,  1.66it/s, Train Loss=3.1, validation loss=2.24]  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:14<02:01,  1.60it/s, Train Loss=3.1, validation loss=2.24] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:15<02:01,  1.60it/s, Train Loss=3.91, validation loss=2.23] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:15<02:03,  1.57it/s, Train Loss=3.91, validation loss=2.23] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:16<02:03,  1.57it/s, Train Loss=2.1, validation loss=2.25]  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:16<02:01,  1.59it/s, Train Loss=2.1, validation loss=2.25] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:16<02:01,  1.59it/s, Train Loss=3.5, validation loss=2.24] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:16<01:59,  1.61it/s, Train Loss=3.5, validation loss=2.24] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:17<01:59,  1.61it/s, Train Loss=3.14, validation loss=2.24] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:17<01:58,  1.62it/s, Train Loss=3.14, validation loss=2.24] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:18<01:58,  1.62it/s, Train Loss=1.58, validation loss=2.25] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:18<01:56,  1.63it/s, Train Loss=1.58, validation loss=2.25] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:18<01:56,  1.63it/s, Train Loss=2.82, validation loss=2.23] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:18<02:02,  1.54it/s, Train Loss=2.82, validation loss=2.23] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:19<02:02,  1.54it/s, Train Loss=1.96, validation loss=2.26] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:19<02:01,  1.54it/s, Train Loss=1.96, validation loss=2.26] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:20<02:01,  1.54it/s, Train Loss=4.01, validation loss=2.23] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:20<01:58,  1.58it/s, Train Loss=4.01, validation loss=2.23] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:20<01:58,  1.58it/s, Train Loss=1.81, validation loss=2.25] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:20<02:00,  1.55it/s, Train Loss=1.81, validation loss=2.25] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:21<02:00,  1.55it/s, Train Loss=1.95, validation loss=2.24] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:21<01:56,  1.58it/s, Train Loss=1.95, validation loss=2.24] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:21<01:56,  1.58it/s, Train Loss=2.71, validation loss=2.24] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:21<01:56,  1.58it/s, Train Loss=2.71, validation loss=2.24] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:22<01:56,  1.58it/s, Train Loss=2.46, validation loss=2.24] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:22<01:56,  1.57it/s, Train Loss=2.46, validation loss=2.24] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:23<01:56,  1.57it/s, Train Loss=1.55, validation loss=2.25] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:23<01:53,  1.61it/s, Train Loss=1.55, validation loss=2.25] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:23<01:53,  1.61it/s, Train Loss=2.31, validation loss=2.24] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:23<01:53,  1.60it/s, Train Loss=2.31, validation loss=2.24] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:24<01:53,  1.60it/s, Train Loss=2.17, validation loss=2.24] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:24<01:57,  1.53it/s, Train Loss=2.17, validation loss=2.24] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:25<01:57,  1.53it/s, Train Loss=3.25, validation loss=2.24] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:25<01:54,  1.57it/s, Train Loss=3.25, validation loss=2.24] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:25<01:54,  1.57it/s, Train Loss=1.73, validation loss=2.25] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:25<01:53,  1.57it/s, Train Loss=1.73, validation loss=2.25] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:26<01:53,  1.57it/s, Train Loss=2.57, validation loss=2.23] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:26<01:51,  1.59it/s, Train Loss=2.57, validation loss=2.23] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:27<01:51,  1.59it/s, Train Loss=2.17, validation loss=2.25] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:27<01:50,  1.60it/s, Train Loss=2.17, validation loss=2.25] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:27<01:50,  1.60it/s, Train Loss=1.75, validation loss=2.25] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:27<01:54,  1.53it/s, Train Loss=1.75, validation loss=2.25] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:28<01:54,  1.53it/s, Train Loss=1.5, validation loss=2.24]  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:28<01:52,  1.55it/s, Train Loss=1.5, validation loss=2.24] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:28<01:52,  1.55it/s, Train Loss=1.65, validation loss=2.23] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:28<01:50,  1.57it/s, Train Loss=1.65, validation loss=2.23] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:29<01:50,  1.57it/s, Train Loss=2.17, validation loss=2.23] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:29<01:48,  1.58it/s, Train Loss=2.17, validation loss=2.23] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:30<01:48,  1.58it/s, Train Loss=1.97, validation loss=2.24] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:30<01:47,  1.60it/s, Train Loss=1.97, validation loss=2.24] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:30<01:47,  1.60it/s, Train Loss=1.83, validation loss=2.24] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:30<01:50,  1.54it/s, Train Loss=1.83, validation loss=2.24] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:31<01:50,  1.54it/s, Train Loss=3.37, validation loss=2.25] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:31<01:47,  1.56it/s, Train Loss=3.37, validation loss=2.25] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:32<01:47,  1.56it/s, Train Loss=1.57, validation loss=2.26] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:32<01:45,  1.59it/s, Train Loss=1.57, validation loss=2.26] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:32<01:45,  1.59it/s, Train Loss=1.57, validation loss=2.23] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:32<01:47,  1.55it/s, Train Loss=1.57, validation loss=2.23] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:33<01:47,  1.55it/s, Train Loss=2.38, validation loss=2.24] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:33<01:50,  1.50it/s, Train Loss=2.38, validation loss=2.24] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:34<01:50,  1.50it/s, Train Loss=2.07, validation loss=2.25] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:34<01:47,  1.53it/s, Train Loss=2.07, validation loss=2.25] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:34<01:47,  1.53it/s, Train Loss=2.2, validation loss=2.24]  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:34<01:43,  1.58it/s, Train Loss=2.2, validation loss=2.24] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:35<01:43,  1.58it/s, Train Loss=1.8, validation loss=2.24] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:35<01:42,  1.58it/s, Train Loss=1.8, validation loss=2.24] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:35<01:42,  1.58it/s, Train Loss=2.28, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:35<01:41,  1.60it/s, Train Loss=2.28, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:36<01:41,  1.60it/s, Train Loss=2.1, validation loss=2.24]  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:36<01:38,  1.63it/s, Train Loss=2.1, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:37<01:38,  1.63it/s, Train Loss=2.71, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:37<01:42,  1.56it/s, Train Loss=2.71, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:37<01:42,  1.56it/s, Train Loss=1.41, validation loss=2.23] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:37<01:41,  1.57it/s, Train Loss=1.41, validation loss=2.23] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:38<01:41,  1.57it/s, Train Loss=2.01, validation loss=2.22] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:38<01:39,  1.58it/s, Train Loss=2.01, validation loss=2.22] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:39<01:39,  1.58it/s, Train Loss=2.63, validation loss=2.25] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:39<01:38,  1.59it/s, Train Loss=2.63, validation loss=2.25] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:39<01:38,  1.59it/s, Train Loss=2.81, validation loss=2.24] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:39<01:36,  1.62it/s, Train Loss=2.81, validation loss=2.24] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:40<01:36,  1.62it/s, Train Loss=1.79, validation loss=2.25] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:40<01:35,  1.62it/s, Train Loss=1.79, validation loss=2.25] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:40<01:35,  1.62it/s, Train Loss=1.34, validation loss=2.24] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:40<01:35,  1.62it/s, Train Loss=1.34, validation loss=2.24] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:41<01:35,  1.62it/s, Train Loss=2.14, validation loss=2.23] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:41<01:35,  1.61it/s, Train Loss=2.14, validation loss=2.23] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:42<01:35,  1.61it/s, Train Loss=2.94, validation loss=2.23] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:42<01:34,  1.60it/s, Train Loss=2.94, validation loss=2.23] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:43<01:34,  1.60it/s, Train Loss=3.43, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:43<01:42,  1.48it/s, Train Loss=3.43, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:43<01:42,  1.48it/s, Train Loss=2.56, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:43<01:38,  1.52it/s, Train Loss=2.56, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:44<01:38,  1.52it/s, Train Loss=2.63, validation loss=2.23] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:44<01:36,  1.55it/s, Train Loss=2.63, validation loss=2.23] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:44<01:36,  1.55it/s, Train Loss=1.33, validation loss=2.23] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:44<01:34,  1.56it/s, Train Loss=1.33, validation loss=2.23] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:45<01:34,  1.56it/s, Train Loss=1.92, validation loss=2.24] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:45<01:33,  1.57it/s, Train Loss=1.92, validation loss=2.24] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:46<01:33,  1.57it/s, Train Loss=1.55, validation loss=2.24] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:46<01:33,  1.56it/s, Train Loss=1.55, validation loss=2.24] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:46<01:33,  1.56it/s, Train Loss=1.86, validation loss=2.24] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:46<01:35,  1.52it/s, Train Loss=1.86, validation loss=2.24] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:47<01:35,  1.52it/s, Train Loss=2.05, validation loss=2.25] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:47<01:32,  1.56it/s, Train Loss=2.05, validation loss=2.25] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:48<01:32,  1.56it/s, Train Loss=1.95, validation loss=2.24] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:48<01:31,  1.57it/s, Train Loss=1.95, validation loss=2.24] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:48<01:31,  1.57it/s, Train Loss=2.24, validation loss=2.23] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:48<01:30,  1.57it/s, Train Loss=2.24, validation loss=2.23] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:49<01:30,  1.57it/s, Train Loss=1.89, validation loss=2.25] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:49<01:29,  1.57it/s, Train Loss=1.89, validation loss=2.25] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:49<01:29,  1.57it/s, Train Loss=3.05, validation loss=2.24] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:49<01:28,  1.59it/s, Train Loss=3.05, validation loss=2.24] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:50<01:28,  1.59it/s, Train Loss=1.91, validation loss=2.25] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:50<01:26,  1.60it/s, Train Loss=1.91, validation loss=2.25] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:51<01:26,  1.60it/s, Train Loss=3.27, validation loss=2.24] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:51<01:24,  1.63it/s, Train Loss=3.27, validation loss=2.24] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:51<01:24,  1.63it/s, Train Loss=2.21, validation loss=2.24] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:51<01:24,  1.61it/s, Train Loss=2.21, validation loss=2.24] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:52<01:24,  1.61it/s, Train Loss=2.97, validation loss=2.24] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:52<01:27,  1.55it/s, Train Loss=2.97, validation loss=2.24] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:53<01:27,  1.55it/s, Train Loss=2.89, validation loss=2.24] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:53<01:26,  1.56it/s, Train Loss=2.89, validation loss=2.24] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:53<01:26,  1.56it/s, Train Loss=2.1, validation loss=2.25]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:53<01:25,  1.58it/s, Train Loss=2.1, validation loss=2.25] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:54<01:25,  1.58it/s, Train Loss=2.13, validation loss=2.24] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:54<01:23,  1.58it/s, Train Loss=2.13, validation loss=2.24] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:55<01:23,  1.58it/s, Train Loss=2.49, validation loss=2.26] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:55<01:22,  1.59it/s, Train Loss=2.49, validation loss=2.26] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:55<01:22,  1.59it/s, Train Loss=1.75, validation loss=2.25] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:55<01:26,  1.52it/s, Train Loss=1.75, validation loss=2.25] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:56<01:26,  1.52it/s, Train Loss=1.83, validation loss=2.24] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:56<01:24,  1.54it/s, Train Loss=1.83, validation loss=2.24] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:56<01:24,  1.54it/s, Train Loss=2.77, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:56<01:22,  1.56it/s, Train Loss=2.77, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:57<01:22,  1.56it/s, Train Loss=1.84, validation loss=2.24] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [03:57<01:22,  1.55it/s, Train Loss=1.84, validation loss=2.24] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [03:58<01:22,  1.55it/s, Train Loss=2.23, validation loss=2.24] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [03:58<01:20,  1.57it/s, Train Loss=2.23, validation loss=2.24] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [03:58<01:20,  1.57it/s, Train Loss=2.48, validation loss=2.24] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [03:58<01:19,  1.58it/s, Train Loss=2.48, validation loss=2.24] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [03:59<01:19,  1.58it/s, Train Loss=1.66, validation loss=2.24] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [03:59<01:19,  1.58it/s, Train Loss=1.66, validation loss=2.24] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:00<01:19,  1.58it/s, Train Loss=2.6, validation loss=2.23]  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:00<01:18,  1.59it/s, Train Loss=2.6, validation loss=2.23] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:00<01:18,  1.59it/s, Train Loss=2.08, validation loss=2.25] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:00<01:16,  1.61it/s, Train Loss=2.08, validation loss=2.25] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:01<01:16,  1.61it/s, Train Loss=1.33, validation loss=2.24] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:01<01:14,  1.64it/s, Train Loss=1.33, validation loss=2.24] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:02<01:14,  1.64it/s, Train Loss=1.47, validation loss=2.23] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:02<01:17,  1.56it/s, Train Loss=1.47, validation loss=2.23] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:02<01:17,  1.56it/s, Train Loss=1.69, validation loss=2.24] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:02<01:15,  1.58it/s, Train Loss=1.69, validation loss=2.24] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:03<01:15,  1.58it/s, Train Loss=1.66, validation loss=2.25] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:03<01:15,  1.57it/s, Train Loss=1.66, validation loss=2.25] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:03<01:15,  1.57it/s, Train Loss=2.11, validation loss=2.26] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:03<01:15,  1.57it/s, Train Loss=2.11, validation loss=2.26] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:04<01:15,  1.57it/s, Train Loss=2.84, validation loss=2.25] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:04<01:14,  1.58it/s, Train Loss=2.84, validation loss=2.25] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:05<01:14,  1.58it/s, Train Loss=1.69, validation loss=2.24] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:05<01:16,  1.52it/s, Train Loss=1.69, validation loss=2.24] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:05<01:16,  1.52it/s, Train Loss=2.97, validation loss=2.24] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:05<01:15,  1.53it/s, Train Loss=2.97, validation loss=2.24] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:06<01:15,  1.53it/s, Train Loss=2.32, validation loss=2.23] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:06<01:13,  1.55it/s, Train Loss=2.32, validation loss=2.23] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:07<01:13,  1.55it/s, Train Loss=1.92, validation loss=2.26] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:07<01:12,  1.56it/s, Train Loss=1.92, validation loss=2.26] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:07<01:12,  1.56it/s, Train Loss=2.19, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:07<01:10,  1.58it/s, Train Loss=2.19, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:08<01:10,  1.58it/s, Train Loss=2.43, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:08<01:09,  1.61it/s, Train Loss=2.43, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:08<01:09,  1.61it/s, Train Loss=2.52, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:08<01:07,  1.62it/s, Train Loss=2.52, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:09<01:07,  1.62it/s, Train Loss=2.83, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:09<01:07,  1.61it/s, Train Loss=2.83, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:10<01:07,  1.61it/s, Train Loss=3.01, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:10<01:07,  1.60it/s, Train Loss=3.01, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:10<01:07,  1.60it/s, Train Loss=3.03, validation loss=2.24] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:10<01:09,  1.53it/s, Train Loss=3.03, validation loss=2.24] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:11<01:09,  1.53it/s, Train Loss=1.49, validation loss=2.26] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:11<01:08,  1.54it/s, Train Loss=1.49, validation loss=2.26] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:12<01:08,  1.54it/s, Train Loss=3.26, validation loss=2.25] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:12<01:06,  1.58it/s, Train Loss=3.26, validation loss=2.25] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:12<01:06,  1.58it/s, Train Loss=1.9, validation loss=2.23]  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:12<01:05,  1.58it/s, Train Loss=1.9, validation loss=2.23] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:13<01:05,  1.58it/s, Train Loss=1.83, validation loss=2.24] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:13<01:04,  1.59it/s, Train Loss=1.83, validation loss=2.24] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:14<01:04,  1.59it/s, Train Loss=3.21, validation loss=2.25] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:14<01:07,  1.51it/s, Train Loss=3.21, validation loss=2.25] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:14<01:07,  1.51it/s, Train Loss=2.29, validation loss=2.25] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:14<01:05,  1.54it/s, Train Loss=2.29, validation loss=2.25]####################################################################################################
--------------------------------------------- Epoch:400 ---------------------------------------------
-- Training set:
Loss: 1.8371412754058838, Lr: 6.25e-05
Average AUC ROC: 0.54                Average AUC PR: 0.29
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:15<01:05,  1.54it/s, Train Loss=1.84, validation loss=2.24] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:15<01:03,  1.58it/s, Train Loss=1.84, validation loss=2.24]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.236734814941883
Average AUC ROC: 0.56                    Average AUC PR: 0.3
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:16<01:03,  1.58it/s, Train Loss=1.34, validation loss=2.25] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:16<01:02,  1.59it/s, Train Loss=1.34, validation loss=2.25] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:16<01:02,  1.59it/s, Train Loss=3.18, validation loss=2.24] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:16<01:01,  1.60it/s, Train Loss=3.18, validation loss=2.24] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:17<01:01,  1.60it/s, Train Loss=2.86, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:17<01:01,  1.59it/s, Train Loss=2.86, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:17<01:01,  1.59it/s, Train Loss=1.72, validation loss=2.23] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:17<01:00,  1.59it/s, Train Loss=1.72, validation loss=2.23] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:18<01:00,  1.59it/s, Train Loss=2.11, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:18<00:59,  1.61it/s, Train Loss=2.11, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:19<00:59,  1.61it/s, Train Loss=1.14, validation loss=2.25] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:19<00:58,  1.62it/s, Train Loss=1.14, validation loss=2.25] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:19<00:58,  1.62it/s, Train Loss=2.76, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:19<01:00,  1.55it/s, Train Loss=2.76, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:20<01:00,  1.55it/s, Train Loss=1.32, validation loss=2.25] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:20<00:58,  1.58it/s, Train Loss=1.32, validation loss=2.25] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:21<00:58,  1.58it/s, Train Loss=1.92, validation loss=2.23] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:21<00:56,  1.61it/s, Train Loss=1.92, validation loss=2.23] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:21<00:56,  1.61it/s, Train Loss=2.34, validation loss=2.24] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:21<00:56,  1.60it/s, Train Loss=2.34, validation loss=2.24] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:22<00:56,  1.60it/s, Train Loss=2.11, validation loss=2.26] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:22<00:55,  1.62it/s, Train Loss=2.11, validation loss=2.26] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:22<00:55,  1.62it/s, Train Loss=2.12, validation loss=2.24] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:22<00:54,  1.62it/s, Train Loss=2.12, validation loss=2.24] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:23<00:54,  1.62it/s, Train Loss=1.79, validation loss=2.24] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:23<00:56,  1.53it/s, Train Loss=1.79, validation loss=2.24] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:24<00:56,  1.53it/s, Train Loss=3.24, validation loss=2.24] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:24<00:55,  1.54it/s, Train Loss=3.24, validation loss=2.24] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:24<00:55,  1.54it/s, Train Loss=1.71, validation loss=2.25] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:24<00:55,  1.54it/s, Train Loss=1.71, validation loss=2.25] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:25<00:55,  1.54it/s, Train Loss=2.34, validation loss=2.25] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:25<00:54,  1.55it/s, Train Loss=2.34, validation loss=2.25] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:26<00:54,  1.55it/s, Train Loss=1.78, validation loss=2.24] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:26<00:53,  1.55it/s, Train Loss=1.78, validation loss=2.24] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:26<00:53,  1.55it/s, Train Loss=1.81, validation loss=2.24] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:26<00:52,  1.57it/s, Train Loss=1.81, validation loss=2.24] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:27<00:52,  1.57it/s, Train Loss=1.71, validation loss=2.25] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:27<00:51,  1.58it/s, Train Loss=1.71, validation loss=2.25] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:28<00:51,  1.58it/s, Train Loss=2.46, validation loss=2.24] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:28<00:50,  1.59it/s, Train Loss=2.46, validation loss=2.24] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:28<00:50,  1.59it/s, Train Loss=1.89, validation loss=2.25] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:28<00:48,  1.62it/s, Train Loss=1.89, validation loss=2.25] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:29<00:48,  1.62it/s, Train Loss=1.91, validation loss=2.24] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:29<00:50,  1.53it/s, Train Loss=1.91, validation loss=2.24] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:30<00:50,  1.53it/s, Train Loss=2.37, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:30<00:49,  1.55it/s, Train Loss=2.37, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:30<00:49,  1.55it/s, Train Loss=2.12, validation loss=2.25] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:30<00:47,  1.58it/s, Train Loss=2.12, validation loss=2.25] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:31<00:47,  1.58it/s, Train Loss=2.69, validation loss=2.24] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:31<00:46,  1.60it/s, Train Loss=2.69, validation loss=2.24] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:31<00:46,  1.60it/s, Train Loss=1.76, validation loss=2.24] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:31<00:47,  1.55it/s, Train Loss=1.76, validation loss=2.24] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:32<00:47,  1.55it/s, Train Loss=2, validation loss=2.24]    85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:32<00:49,  1.47it/s, Train Loss=2, validation loss=2.24] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:33<00:49,  1.47it/s, Train Loss=2.67, validation loss=2.24] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:33<00:47,  1.52it/s, Train Loss=2.67, validation loss=2.24] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:33<00:47,  1.52it/s, Train Loss=2.06, validation loss=2.24] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:33<00:46,  1.53it/s, Train Loss=2.06, validation loss=2.24] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:34<00:46,  1.53it/s, Train Loss=2.63, validation loss=2.23] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:34<00:45,  1.55it/s, Train Loss=2.63, validation loss=2.23] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:35<00:45,  1.55it/s, Train Loss=2.5, validation loss=2.24]  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:35<00:44,  1.56it/s, Train Loss=2.5, validation loss=2.24] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:35<00:44,  1.56it/s, Train Loss=1.39, validation loss=2.25] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:35<00:43,  1.57it/s, Train Loss=1.39, validation loss=2.25] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:36<00:43,  1.57it/s, Train Loss=1.59, validation loss=2.23] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:36<00:42,  1.59it/s, Train Loss=1.59, validation loss=2.23] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:37<00:42,  1.59it/s, Train Loss=2.02, validation loss=2.23] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:37<00:40,  1.61it/s, Train Loss=2.02, validation loss=2.23] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:37<00:40,  1.61it/s, Train Loss=1.36, validation loss=2.24] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:37<00:40,  1.59it/s, Train Loss=1.36, validation loss=2.24] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:38<00:40,  1.59it/s, Train Loss=1.52, validation loss=2.25] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:38<00:42,  1.52it/s, Train Loss=1.52, validation loss=2.25] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:38<00:42,  1.52it/s, Train Loss=2.74, validation loss=2.23] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:38<00:40,  1.56it/s, Train Loss=2.74, validation loss=2.23] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:39<00:40,  1.56it/s, Train Loss=1.99, validation loss=2.24] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:39<00:39,  1.57it/s, Train Loss=1.99, validation loss=2.24] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:40<00:39,  1.57it/s, Train Loss=3.08, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:40<00:38,  1.59it/s, Train Loss=3.08, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:40<00:38,  1.59it/s, Train Loss=1.72, validation loss=2.25] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:40<00:37,  1.61it/s, Train Loss=1.72, validation loss=2.25] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:41<00:37,  1.61it/s, Train Loss=2.81, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:41<00:38,  1.54it/s, Train Loss=2.81, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:42<00:38,  1.54it/s, Train Loss=1.61, validation loss=2.24] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:42<00:37,  1.56it/s, Train Loss=1.61, validation loss=2.24] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:42<00:37,  1.56it/s, Train Loss=1.97, validation loss=2.25] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:42<00:35,  1.59it/s, Train Loss=1.97, validation loss=2.25] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:43<00:35,  1.59it/s, Train Loss=2.17, validation loss=2.23] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:43<00:35,  1.58it/s, Train Loss=2.17, validation loss=2.23] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:44<00:35,  1.58it/s, Train Loss=2.06, validation loss=2.23] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:44<00:35,  1.57it/s, Train Loss=2.06, validation loss=2.23] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:44<00:35,  1.57it/s, Train Loss=1.91, validation loss=2.24] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:44<00:35,  1.53it/s, Train Loss=1.91, validation loss=2.24] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:45<00:35,  1.53it/s, Train Loss=1.81, validation loss=2.25] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:45<00:34,  1.54it/s, Train Loss=1.81, validation loss=2.25] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:45<00:34,  1.54it/s, Train Loss=1.65, validation loss=2.25] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:45<00:33,  1.57it/s, Train Loss=1.65, validation loss=2.25] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:46<00:33,  1.57it/s, Train Loss=1.77, validation loss=2.24] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:46<00:32,  1.58it/s, Train Loss=1.77, validation loss=2.24] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:47<00:32,  1.58it/s, Train Loss=1.63, validation loss=2.25] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:47<00:32,  1.53it/s, Train Loss=1.63, validation loss=2.25] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:47<00:32,  1.53it/s, Train Loss=2.13, validation loss=2.23] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:47<00:31,  1.55it/s, Train Loss=2.13, validation loss=2.23] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:48<00:31,  1.55it/s, Train Loss=1.98, validation loss=2.24] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:48<00:31,  1.55it/s, Train Loss=1.98, validation loss=2.24] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:49<00:31,  1.55it/s, Train Loss=2.87, validation loss=2.25] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:49<00:30,  1.55it/s, Train Loss=2.87, validation loss=2.25] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:49<00:30,  1.55it/s, Train Loss=1.98, validation loss=2.25] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:49<00:29,  1.57it/s, Train Loss=1.98, validation loss=2.25] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:50<00:29,  1.57it/s, Train Loss=2.76, validation loss=2.23] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:50<00:30,  1.49it/s, Train Loss=2.76, validation loss=2.23] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:51<00:30,  1.49it/s, Train Loss=2.48, validation loss=2.25] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:51<00:28,  1.53it/s, Train Loss=2.48, validation loss=2.25] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:51<00:28,  1.53it/s, Train Loss=1.43, validation loss=2.24] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:51<00:27,  1.54it/s, Train Loss=1.43, validation loss=2.24] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:52<00:27,  1.54it/s, Train Loss=1.5, validation loss=2.24]  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:52<00:27,  1.54it/s, Train Loss=1.5, validation loss=2.24] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:53<00:27,  1.54it/s, Train Loss=2.38, validation loss=2.24] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:53<00:26,  1.55it/s, Train Loss=2.38, validation loss=2.24] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:53<00:26,  1.55it/s, Train Loss=1.33, validation loss=2.26] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:53<00:25,  1.59it/s, Train Loss=1.33, validation loss=2.26] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:54<00:25,  1.59it/s, Train Loss=3.02, validation loss=2.24] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:54<00:24,  1.59it/s, Train Loss=3.02, validation loss=2.24] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:54<00:24,  1.59it/s, Train Loss=2.88, validation loss=2.23] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:54<00:23,  1.59it/s, Train Loss=2.88, validation loss=2.23] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:55<00:23,  1.59it/s, Train Loss=3.01, validation loss=2.24] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:55<00:23,  1.56it/s, Train Loss=3.01, validation loss=2.24] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:56<00:23,  1.56it/s, Train Loss=1.64, validation loss=2.25] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:56<00:23,  1.52it/s, Train Loss=1.64, validation loss=2.25] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:56<00:23,  1.52it/s, Train Loss=2.18, validation loss=2.24] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:56<00:22,  1.53it/s, Train Loss=2.18, validation loss=2.24] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:57<00:22,  1.53it/s, Train Loss=1.96, validation loss=2.24] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:57<00:22,  1.54it/s, Train Loss=1.96, validation loss=2.24] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:58<00:22,  1.54it/s, Train Loss=3.91, validation loss=2.23] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [04:58<00:21,  1.54it/s, Train Loss=3.91, validation loss=2.23] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [04:58<00:21,  1.54it/s, Train Loss=3.26, validation loss=2.24] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [04:58<00:20,  1.57it/s, Train Loss=3.26, validation loss=2.24] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [04:59<00:20,  1.57it/s, Train Loss=1.64, validation loss=2.24] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [04:59<00:20,  1.49it/s, Train Loss=1.64, validation loss=2.24] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:00<00:20,  1.49it/s, Train Loss=1.84, validation loss=2.25] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:00<00:19,  1.54it/s, Train Loss=1.84, validation loss=2.25] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:00<00:19,  1.54it/s, Train Loss=1.47, validation loss=2.24] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:00<00:18,  1.58it/s, Train Loss=1.47, validation loss=2.24] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:01<00:18,  1.58it/s, Train Loss=1.93, validation loss=2.24] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:01<00:18,  1.52it/s, Train Loss=1.93, validation loss=2.24] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:02<00:18,  1.52it/s, Train Loss=1.5, validation loss=2.23]  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:02<00:17,  1.52it/s, Train Loss=1.5, validation loss=2.23] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:02<00:17,  1.52it/s, Train Loss=2.22, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:02<00:16,  1.54it/s, Train Loss=2.22, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:03<00:16,  1.54it/s, Train Loss=3.27, validation loss=2.23] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:03<00:16,  1.52it/s, Train Loss=3.27, validation loss=2.23] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:04<00:16,  1.52it/s, Train Loss=1.88, validation loss=2.23] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:04<00:15,  1.50it/s, Train Loss=1.88, validation loss=2.23] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:05<00:15,  1.50it/s, Train Loss=2.2, validation loss=2.24]  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:05<00:16,  1.40it/s, Train Loss=2.2, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:05<00:16,  1.40it/s, Train Loss=2.2, validation loss=2.25] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:05<00:15,  1.46it/s, Train Loss=2.2, validation loss=2.25] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:06<00:15,  1.46it/s, Train Loss=2.36, validation loss=2.23] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:06<00:14,  1.49it/s, Train Loss=2.36, validation loss=2.23] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:06<00:14,  1.49it/s, Train Loss=1.5, validation loss=2.24]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:06<00:13,  1.52it/s, Train Loss=1.5, validation loss=2.24] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:07<00:13,  1.52it/s, Train Loss=1.97, validation loss=2.23] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:07<00:12,  1.51it/s, Train Loss=1.97, validation loss=2.23] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:08<00:12,  1.51it/s, Train Loss=2.1, validation loss=2.24]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:08<00:12,  1.44it/s, Train Loss=2.1, validation loss=2.24] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:09<00:12,  1.44it/s, Train Loss=1.7, validation loss=2.25] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:09<00:11,  1.45it/s, Train Loss=1.7, validation loss=2.25] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:09<00:11,  1.45it/s, Train Loss=1.35, validation loss=2.24] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:09<00:10,  1.47it/s, Train Loss=1.35, validation loss=2.24] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:10<00:10,  1.47it/s, Train Loss=1.6, validation loss=2.22]  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:10<00:10,  1.46it/s, Train Loss=1.6, validation loss=2.22] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:11<00:10,  1.46it/s, Train Loss=2.14, validation loss=2.24] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:11<00:09,  1.46it/s, Train Loss=2.14, validation loss=2.24] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:11<00:09,  1.46it/s, Train Loss=2.08, validation loss=2.23] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:11<00:09,  1.43it/s, Train Loss=2.08, validation loss=2.23] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:12<00:09,  1.43it/s, Train Loss=1.23, validation loss=2.24] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:12<00:08,  1.38it/s, Train Loss=1.23, validation loss=2.24] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:13<00:08,  1.38it/s, Train Loss=1.95, validation loss=2.23] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:13<00:08,  1.28it/s, Train Loss=1.95, validation loss=2.23] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:14<00:08,  1.28it/s, Train Loss=2.12, validation loss=2.23] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:14<00:07,  1.28it/s, Train Loss=2.12, validation loss=2.23] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:15<00:07,  1.28it/s, Train Loss=3.29, validation loss=2.23] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:15<00:07,  1.27it/s, Train Loss=3.29, validation loss=2.23] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:15<00:07,  1.27it/s, Train Loss=1.09, validation loss=2.23] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:15<00:05,  1.36it/s, Train Loss=1.09, validation loss=2.23] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:16<00:05,  1.36it/s, Train Loss=2.06, validation loss=2.24] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:16<00:04,  1.44it/s, Train Loss=2.06, validation loss=2.24] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:16<00:04,  1.44it/s, Train Loss=3.18, validation loss=2.23] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:16<00:04,  1.49it/s, Train Loss=3.18, validation loss=2.23] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:17<00:04,  1.49it/s, Train Loss=2.99, validation loss=2.24] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:17<00:03,  1.48it/s, Train Loss=2.99, validation loss=2.24] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:18<00:03,  1.48it/s, Train Loss=2.57, validation loss=2.23] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:18<00:02,  1.52it/s, Train Loss=2.57, validation loss=2.23] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:18<00:02,  1.52it/s, Train Loss=1.81, validation loss=2.25] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:18<00:01,  1.55it/s, Train Loss=1.81, validation loss=2.25] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:19<00:01,  1.55it/s, Train Loss=1.53, validation loss=2.24]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:19<00:01,  1.55it/s, Train Loss=1.53, validation loss=2.24]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:20<00:01,  1.55it/s, Train Loss=3.49, validation loss=2.24]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:20<00:00,  1.58it/s, Train Loss=3.49, validation loss=2.24]####################################################################################################
--------------------------------------------- Epoch:500 ---------------------------------------------
-- Training set:
Loss: 1.8429903984069824, Lr: 3.125e-05
Average AUC ROC: 0.53                Average AUC PR: 0.29
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:20<00:00,  1.58it/s, Train Loss=1.84, validation loss=2.24]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:20<00:00,  1.58it/s, Train Loss=1.84, validation loss=2.24]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:20<00:00,  1.56it/s, Train Loss=1.84, validation loss=2.24]
----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.241820991039276
Average AUC ROC: 0.56                    Average AUC PR: 0.3

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 281
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=0, validation loss=0]  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=2.57, validation loss=3.28]  0%|          | 1/500 [00:00<05:13,  1.59it/s, Train Loss=2.57, validation loss=3.28]  0%|          | 1/500 [00:01<05:13,  1.59it/s, Train Loss=4.24, validation loss=3.07]  0%|          | 2/500 [00:01<05:10,  1.60it/s, Train Loss=4.24, validation loss=3.07]  0%|          | 2/500 [00:01<05:10,  1.60it/s, Train Loss=5.29, validation loss=2.93]  1%|          | 3/500 [00:01<05:08,  1.61it/s, Train Loss=5.29, validation loss=2.93]  1%|          | 3/500 [00:02<05:08,  1.61it/s, Train Loss=3.27, validation loss=2.81]  1%|          | 4/500 [00:02<05:09,  1.60it/s, Train Loss=3.27, validation loss=2.81]  1%|          | 4/500 [00:03<05:09,  1.60it/s, Train Loss=3.69, validation loss=2.76]  1%|          | 5/500 [00:03<05:09,  1.60it/s, Train Loss=3.69, validation loss=2.76]  1%|          | 5/500 [00:03<05:09,  1.60it/s, Train Loss=3.61, validation loss=2.74]  1%|          | 6/500 [00:03<05:07,  1.61it/s, Train Loss=3.61, validation loss=2.74]  1%|          | 6/500 [00:04<05:07,  1.61it/s, Train Loss=3.97, validation loss=2.72]  1%|â–         | 7/500 [00:04<05:04,  1.62it/s, Train Loss=3.97, validation loss=2.72]  1%|â–         | 7/500 [00:05<05:04,  1.62it/s, Train Loss=5.36, validation loss=2.74]  2%|â–         | 8/500 [00:05<05:18,  1.55it/s, Train Loss=5.36, validation loss=2.74]  2%|â–         | 8/500 [00:05<05:18,  1.55it/s, Train Loss=2.4, validation loss=2.74]   2%|â–         | 9/500 [00:05<05:14,  1.56it/s, Train Loss=2.4, validation loss=2.74]  2%|â–         | 9/500 [00:06<05:14,  1.56it/s, Train Loss=3.8, validation loss=2.72]  2%|â–         | 10/500 [00:06<05:12,  1.57it/s, Train Loss=3.8, validation loss=2.72]  2%|â–         | 10/500 [00:06<05:12,  1.57it/s, Train Loss=3.91, validation loss=2.7]  2%|â–         | 11/500 [00:06<05:12,  1.56it/s, Train Loss=3.91, validation loss=2.7]  2%|â–         | 11/500 [00:07<05:12,  1.56it/s, Train Loss=2.27, validation loss=2.7]  2%|â–         | 12/500 [00:07<05:08,  1.58it/s, Train Loss=2.27, validation loss=2.7]  2%|â–         | 12/500 [00:08<05:08,  1.58it/s, Train Loss=3.03, validation loss=2.71]  3%|â–         | 13/500 [00:08<05:03,  1.61it/s, Train Loss=3.03, validation loss=2.71]  3%|â–         | 13/500 [00:08<05:03,  1.61it/s, Train Loss=2.98, validation loss=2.7]   3%|â–         | 14/500 [00:08<05:24,  1.50it/s, Train Loss=2.98, validation loss=2.7]  3%|â–         | 14/500 [00:09<05:24,  1.50it/s, Train Loss=2.79, validation loss=2.72]  3%|â–         | 15/500 [00:09<05:18,  1.52it/s, Train Loss=2.79, validation loss=2.72]  3%|â–         | 15/500 [00:10<05:18,  1.52it/s, Train Loss=2.37, validation loss=2.72]  3%|â–         | 16/500 [00:10<05:12,  1.55it/s, Train Loss=2.37, validation loss=2.72]  3%|â–         | 16/500 [00:10<05:12,  1.55it/s, Train Loss=2.63, validation loss=2.73]  3%|â–         | 17/500 [00:10<05:10,  1.56it/s, Train Loss=2.63, validation loss=2.73]  3%|â–         | 17/500 [00:11<05:10,  1.56it/s, Train Loss=1.78, validation loss=2.71]  4%|â–         | 18/500 [00:11<05:03,  1.59it/s, Train Loss=1.78, validation loss=2.71]  4%|â–         | 18/500 [00:12<05:03,  1.59it/s, Train Loss=3.93, validation loss=2.71]  4%|â–         | 19/500 [00:12<05:00,  1.60it/s, Train Loss=3.93, validation loss=2.71]  4%|â–         | 19/500 [00:12<05:00,  1.60it/s, Train Loss=2.91, validation loss=2.71]  4%|â–         | 20/500 [00:12<04:58,  1.61it/s, Train Loss=2.91, validation loss=2.71]  4%|â–         | 20/500 [00:13<04:58,  1.61it/s, Train Loss=3.25, validation loss=2.69]  4%|â–         | 21/500 [00:13<05:00,  1.60it/s, Train Loss=3.25, validation loss=2.69]  4%|â–         | 21/500 [00:13<05:00,  1.60it/s, Train Loss=2.64, validation loss=2.7]   4%|â–         | 22/500 [00:13<05:01,  1.58it/s, Train Loss=2.64, validation loss=2.7]  4%|â–         | 22/500 [00:14<05:01,  1.58it/s, Train Loss=1.93, validation loss=2.69]  5%|â–         | 23/500 [00:14<05:08,  1.55it/s, Train Loss=1.93, validation loss=2.69]  5%|â–         | 23/500 [00:15<05:08,  1.55it/s, Train Loss=2.71, validation loss=2.66]  5%|â–         | 24/500 [00:15<05:05,  1.56it/s, Train Loss=2.71, validation loss=2.66]  5%|â–         | 24/500 [00:15<05:05,  1.56it/s, Train Loss=1.92, validation loss=2.65]  5%|â–Œ         | 25/500 [00:15<05:07,  1.55it/s, Train Loss=1.92, validation loss=2.65]  5%|â–Œ         | 25/500 [00:16<05:07,  1.55it/s, Train Loss=2.62, validation loss=2.66]  5%|â–Œ         | 26/500 [00:16<05:08,  1.54it/s, Train Loss=2.62, validation loss=2.66]  5%|â–Œ         | 26/500 [00:17<05:08,  1.54it/s, Train Loss=3.86, validation loss=2.63]  5%|â–Œ         | 27/500 [00:17<05:04,  1.56it/s, Train Loss=3.86, validation loss=2.63]  5%|â–Œ         | 27/500 [00:17<05:04,  1.56it/s, Train Loss=3.26, validation loss=2.65]  6%|â–Œ         | 28/500 [00:17<05:14,  1.50it/s, Train Loss=3.26, validation loss=2.65]  6%|â–Œ         | 28/500 [00:18<05:14,  1.50it/s, Train Loss=2.58, validation loss=2.63]  6%|â–Œ         | 29/500 [00:18<05:08,  1.53it/s, Train Loss=2.58, validation loss=2.63]  6%|â–Œ         | 29/500 [00:19<05:08,  1.53it/s, Train Loss=2.87, validation loss=2.63]  6%|â–Œ         | 30/500 [00:19<05:03,  1.55it/s, Train Loss=2.87, validation loss=2.63]  6%|â–Œ         | 30/500 [00:19<05:03,  1.55it/s, Train Loss=2.39, validation loss=2.63]  6%|â–Œ         | 31/500 [00:19<04:59,  1.57it/s, Train Loss=2.39, validation loss=2.63]  6%|â–Œ         | 31/500 [00:20<04:59,  1.57it/s, Train Loss=3.12, validation loss=2.6]   6%|â–‹         | 32/500 [00:20<04:57,  1.58it/s, Train Loss=3.12, validation loss=2.6]  6%|â–‹         | 32/500 [00:21<04:57,  1.58it/s, Train Loss=2.27, validation loss=2.61]  7%|â–‹         | 33/500 [00:21<04:55,  1.58it/s, Train Loss=2.27, validation loss=2.61]  7%|â–‹         | 33/500 [00:21<04:55,  1.58it/s, Train Loss=2.97, validation loss=2.6]   7%|â–‹         | 34/500 [00:21<04:51,  1.60it/s, Train Loss=2.97, validation loss=2.6]  7%|â–‹         | 34/500 [00:22<04:51,  1.60it/s, Train Loss=2.55, validation loss=2.6]  7%|â–‹         | 35/500 [00:22<04:50,  1.60it/s, Train Loss=2.55, validation loss=2.6]  7%|â–‹         | 35/500 [00:22<04:50,  1.60it/s, Train Loss=3.29, validation loss=2.6]  7%|â–‹         | 36/500 [00:22<05:01,  1.54it/s, Train Loss=3.29, validation loss=2.6]  7%|â–‹         | 36/500 [00:23<05:01,  1.54it/s, Train Loss=2.67, validation loss=2.62]  7%|â–‹         | 37/500 [00:23<05:02,  1.53it/s, Train Loss=2.67, validation loss=2.62]  7%|â–‹         | 37/500 [00:24<05:02,  1.53it/s, Train Loss=2.13, validation loss=2.6]   8%|â–Š         | 38/500 [00:24<04:58,  1.55it/s, Train Loss=2.13, validation loss=2.6]  8%|â–Š         | 38/500 [00:24<04:58,  1.55it/s, Train Loss=1.99, validation loss=2.6]  8%|â–Š         | 39/500 [00:24<04:56,  1.55it/s, Train Loss=1.99, validation loss=2.6]  8%|â–Š         | 39/500 [00:25<04:56,  1.55it/s, Train Loss=2.26, validation loss=2.62]  8%|â–Š         | 40/500 [00:25<04:51,  1.58it/s, Train Loss=2.26, validation loss=2.62]  8%|â–Š         | 40/500 [00:26<04:51,  1.58it/s, Train Loss=2, validation loss=2.61]     8%|â–Š         | 41/500 [00:26<05:00,  1.53it/s, Train Loss=2, validation loss=2.61]  8%|â–Š         | 41/500 [00:26<05:00,  1.53it/s, Train Loss=2.82, validation loss=2.58]  8%|â–Š         | 42/500 [00:26<04:56,  1.55it/s, Train Loss=2.82, validation loss=2.58]  8%|â–Š         | 42/500 [00:27<04:56,  1.55it/s, Train Loss=2.1, validation loss=2.58]   9%|â–Š         | 43/500 [00:27<04:50,  1.58it/s, Train Loss=2.1, validation loss=2.58]  9%|â–Š         | 43/500 [00:28<04:50,  1.58it/s, Train Loss=3.12, validation loss=2.59]  9%|â–‰         | 44/500 [00:28<04:48,  1.58it/s, Train Loss=3.12, validation loss=2.59]  9%|â–‰         | 44/500 [00:28<04:48,  1.58it/s, Train Loss=1.76, validation loss=2.58]  9%|â–‰         | 45/500 [00:28<04:48,  1.58it/s, Train Loss=1.76, validation loss=2.58]  9%|â–‰         | 45/500 [00:29<04:48,  1.58it/s, Train Loss=1.51, validation loss=2.57]  9%|â–‰         | 46/500 [00:29<04:46,  1.59it/s, Train Loss=1.51, validation loss=2.57]  9%|â–‰         | 46/500 [00:29<04:46,  1.59it/s, Train Loss=1.88, validation loss=2.53]  9%|â–‰         | 47/500 [00:29<04:41,  1.61it/s, Train Loss=1.88, validation loss=2.53]  9%|â–‰         | 47/500 [00:30<04:41,  1.61it/s, Train Loss=2.89, validation loss=2.55] 10%|â–‰         | 48/500 [00:30<04:44,  1.59it/s, Train Loss=2.89, validation loss=2.55] 10%|â–‰         | 48/500 [00:31<04:44,  1.59it/s, Train Loss=2.5, validation loss=2.57]  10%|â–‰         | 49/500 [00:31<04:44,  1.59it/s, Train Loss=2.5, validation loss=2.57] 10%|â–‰         | 49/500 [00:31<04:44,  1.59it/s, Train Loss=3.02, validation loss=2.56] 10%|â–ˆ         | 50/500 [00:31<04:49,  1.55it/s, Train Loss=3.02, validation loss=2.56] 10%|â–ˆ         | 50/500 [00:32<04:49,  1.55it/s, Train Loss=2.79, validation loss=2.54] 10%|â–ˆ         | 51/500 [00:32<04:53,  1.53it/s, Train Loss=2.79, validation loss=2.54] 10%|â–ˆ         | 51/500 [00:33<04:53,  1.53it/s, Train Loss=3.14, validation loss=2.54] 10%|â–ˆ         | 52/500 [00:33<04:51,  1.54it/s, Train Loss=3.14, validation loss=2.54] 10%|â–ˆ         | 52/500 [00:33<04:51,  1.54it/s, Train Loss=2.16, validation loss=2.55] 11%|â–ˆ         | 53/500 [00:33<04:53,  1.52it/s, Train Loss=2.16, validation loss=2.55] 11%|â–ˆ         | 53/500 [00:34<04:53,  1.52it/s, Train Loss=1.47, validation loss=2.55] 11%|â–ˆ         | 54/500 [00:34<04:50,  1.53it/s, Train Loss=1.47, validation loss=2.55] 11%|â–ˆ         | 54/500 [00:35<04:50,  1.53it/s, Train Loss=1.96, validation loss=2.55] 11%|â–ˆ         | 55/500 [00:35<05:04,  1.46it/s, Train Loss=1.96, validation loss=2.55] 11%|â–ˆ         | 55/500 [00:35<05:04,  1.46it/s, Train Loss=3.15, validation loss=2.54] 11%|â–ˆ         | 56/500 [00:35<04:57,  1.49it/s, Train Loss=3.15, validation loss=2.54] 11%|â–ˆ         | 56/500 [00:36<04:57,  1.49it/s, Train Loss=2.58, validation loss=2.52] 11%|â–ˆâ–        | 57/500 [00:36<04:47,  1.54it/s, Train Loss=2.58, validation loss=2.52] 11%|â–ˆâ–        | 57/500 [00:37<04:47,  1.54it/s, Train Loss=2.13, validation loss=2.5]  12%|â–ˆâ–        | 58/500 [00:37<04:42,  1.56it/s, Train Loss=2.13, validation loss=2.5] 12%|â–ˆâ–        | 58/500 [00:37<04:42,  1.56it/s, Train Loss=2.21, validation loss=2.51] 12%|â–ˆâ–        | 59/500 [00:37<04:42,  1.56it/s, Train Loss=2.21, validation loss=2.51] 12%|â–ˆâ–        | 59/500 [00:38<04:42,  1.56it/s, Train Loss=1.67, validation loss=2.49] 12%|â–ˆâ–        | 60/500 [00:38<04:39,  1.57it/s, Train Loss=1.67, validation loss=2.49] 12%|â–ˆâ–        | 60/500 [00:39<04:39,  1.57it/s, Train Loss=2.88, validation loss=2.49] 12%|â–ˆâ–        | 61/500 [00:39<04:33,  1.60it/s, Train Loss=2.88, validation loss=2.49] 12%|â–ˆâ–        | 61/500 [00:39<04:33,  1.60it/s, Train Loss=1.87, validation loss=2.5]  12%|â–ˆâ–        | 62/500 [00:39<04:34,  1.60it/s, Train Loss=1.87, validation loss=2.5] 12%|â–ˆâ–        | 62/500 [00:40<04:34,  1.60it/s, Train Loss=1.69, validation loss=2.49] 13%|â–ˆâ–        | 63/500 [00:40<04:31,  1.61it/s, Train Loss=1.69, validation loss=2.49] 13%|â–ˆâ–        | 63/500 [00:41<04:31,  1.61it/s, Train Loss=1.66, validation loss=2.49] 13%|â–ˆâ–        | 64/500 [00:41<04:48,  1.51it/s, Train Loss=1.66, validation loss=2.49] 13%|â–ˆâ–        | 64/500 [00:41<04:48,  1.51it/s, Train Loss=2.33, validation loss=2.49] 13%|â–ˆâ–        | 65/500 [00:41<04:48,  1.51it/s, Train Loss=2.33, validation loss=2.49] 13%|â–ˆâ–        | 65/500 [00:42<04:48,  1.51it/s, Train Loss=2.73, validation loss=2.48] 13%|â–ˆâ–        | 66/500 [00:42<04:41,  1.54it/s, Train Loss=2.73, validation loss=2.48] 13%|â–ˆâ–        | 66/500 [00:42<04:41,  1.54it/s, Train Loss=3.14, validation loss=2.49] 13%|â–ˆâ–        | 67/500 [00:42<04:35,  1.57it/s, Train Loss=3.14, validation loss=2.49] 13%|â–ˆâ–        | 67/500 [00:43<04:35,  1.57it/s, Train Loss=2.22, validation loss=2.5]  14%|â–ˆâ–        | 68/500 [00:43<04:32,  1.58it/s, Train Loss=2.22, validation loss=2.5] 14%|â–ˆâ–        | 68/500 [00:44<04:32,  1.58it/s, Train Loss=2.98, validation loss=2.47] 14%|â–ˆâ–        | 69/500 [00:44<04:37,  1.55it/s, Train Loss=2.98, validation loss=2.47] 14%|â–ˆâ–        | 69/500 [00:44<04:37,  1.55it/s, Train Loss=2.01, validation loss=2.47] 14%|â–ˆâ–        | 70/500 [00:44<04:37,  1.55it/s, Train Loss=2.01, validation loss=2.47] 14%|â–ˆâ–        | 70/500 [00:45<04:37,  1.55it/s, Train Loss=2.27, validation loss=2.46] 14%|â–ˆâ–        | 71/500 [00:45<04:32,  1.58it/s, Train Loss=2.27, validation loss=2.46] 14%|â–ˆâ–        | 71/500 [00:46<04:32,  1.58it/s, Train Loss=4.12, validation loss=2.46] 14%|â–ˆâ–        | 72/500 [00:46<04:30,  1.58it/s, Train Loss=4.12, validation loss=2.46] 14%|â–ˆâ–        | 72/500 [00:46<04:30,  1.58it/s, Train Loss=3.32, validation loss=2.46] 15%|â–ˆâ–        | 73/500 [00:46<04:26,  1.60it/s, Train Loss=3.32, validation loss=2.46] 15%|â–ˆâ–        | 73/500 [00:47<04:26,  1.60it/s, Train Loss=2.49, validation loss=2.44] 15%|â–ˆâ–        | 74/500 [00:47<04:22,  1.62it/s, Train Loss=2.49, validation loss=2.44] 15%|â–ˆâ–        | 74/500 [00:47<04:22,  1.62it/s, Train Loss=2.44, validation loss=2.44] 15%|â–ˆâ–Œ        | 75/500 [00:47<04:22,  1.62it/s, Train Loss=2.44, validation loss=2.44] 15%|â–ˆâ–Œ        | 75/500 [00:48<04:22,  1.62it/s, Train Loss=1.85, validation loss=2.45] 15%|â–ˆâ–Œ        | 76/500 [00:48<04:28,  1.58it/s, Train Loss=1.85, validation loss=2.45] 15%|â–ˆâ–Œ        | 76/500 [00:49<04:28,  1.58it/s, Train Loss=3.12, validation loss=2.44] 15%|â–ˆâ–Œ        | 77/500 [00:49<04:33,  1.55it/s, Train Loss=3.12, validation loss=2.44] 15%|â–ˆâ–Œ        | 77/500 [00:49<04:33,  1.55it/s, Train Loss=2.56, validation loss=2.43] 16%|â–ˆâ–Œ        | 78/500 [00:49<04:28,  1.57it/s, Train Loss=2.56, validation loss=2.43] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:28,  1.57it/s, Train Loss=3.09, validation loss=2.44] 16%|â–ˆâ–Œ        | 79/500 [00:50<04:27,  1.57it/s, Train Loss=3.09, validation loss=2.44] 16%|â–ˆâ–Œ        | 79/500 [00:51<04:27,  1.57it/s, Train Loss=3.16, validation loss=2.43] 16%|â–ˆâ–Œ        | 80/500 [00:51<04:26,  1.58it/s, Train Loss=3.16, validation loss=2.43] 16%|â–ˆâ–Œ        | 80/500 [00:51<04:26,  1.58it/s, Train Loss=1.83, validation loss=2.44] 16%|â–ˆâ–Œ        | 81/500 [00:51<04:26,  1.57it/s, Train Loss=1.83, validation loss=2.44] 16%|â–ˆâ–Œ        | 81/500 [00:52<04:26,  1.57it/s, Train Loss=1.99, validation loss=2.44] 16%|â–ˆâ–‹        | 82/500 [00:52<04:21,  1.60it/s, Train Loss=1.99, validation loss=2.44] 16%|â–ˆâ–‹        | 82/500 [00:52<04:21,  1.60it/s, Train Loss=1.95, validation loss=2.43] 17%|â–ˆâ–‹        | 83/500 [00:52<04:21,  1.60it/s, Train Loss=1.95, validation loss=2.43] 17%|â–ˆâ–‹        | 83/500 [00:53<04:21,  1.60it/s, Train Loss=1.6, validation loss=2.44]  17%|â–ˆâ–‹        | 84/500 [00:53<04:33,  1.52it/s, Train Loss=1.6, validation loss=2.44] 17%|â–ˆâ–‹        | 84/500 [00:54<04:33,  1.52it/s, Train Loss=2.34, validation loss=2.44] 17%|â–ˆâ–‹        | 85/500 [00:54<04:28,  1.54it/s, Train Loss=2.34, validation loss=2.44] 17%|â–ˆâ–‹        | 85/500 [00:54<04:28,  1.54it/s, Train Loss=3.35, validation loss=2.42] 17%|â–ˆâ–‹        | 86/500 [00:54<04:27,  1.55it/s, Train Loss=3.35, validation loss=2.42] 17%|â–ˆâ–‹        | 86/500 [00:55<04:27,  1.55it/s, Train Loss=2.94, validation loss=2.43] 17%|â–ˆâ–‹        | 87/500 [00:55<04:20,  1.58it/s, Train Loss=2.94, validation loss=2.43] 17%|â–ˆâ–‹        | 87/500 [00:56<04:20,  1.58it/s, Train Loss=2.73, validation loss=2.43] 18%|â–ˆâ–Š        | 88/500 [00:56<04:21,  1.58it/s, Train Loss=2.73, validation loss=2.43] 18%|â–ˆâ–Š        | 88/500 [00:56<04:21,  1.58it/s, Train Loss=2.34, validation loss=2.43] 18%|â–ˆâ–Š        | 89/500 [00:56<04:28,  1.53it/s, Train Loss=2.34, validation loss=2.43] 18%|â–ˆâ–Š        | 89/500 [00:57<04:28,  1.53it/s, Train Loss=1.68, validation loss=2.43] 18%|â–ˆâ–Š        | 90/500 [00:57<04:24,  1.55it/s, Train Loss=1.68, validation loss=2.43] 18%|â–ˆâ–Š        | 90/500 [00:58<04:24,  1.55it/s, Train Loss=2.95, validation loss=2.41] 18%|â–ˆâ–Š        | 91/500 [00:58<04:26,  1.54it/s, Train Loss=2.95, validation loss=2.41] 18%|â–ˆâ–Š        | 91/500 [00:58<04:26,  1.54it/s, Train Loss=2.64, validation loss=2.42] 18%|â–ˆâ–Š        | 92/500 [00:58<04:21,  1.56it/s, Train Loss=2.64, validation loss=2.42] 18%|â–ˆâ–Š        | 92/500 [00:59<04:21,  1.56it/s, Train Loss=1.97, validation loss=2.4]  19%|â–ˆâ–Š        | 93/500 [00:59<04:16,  1.59it/s, Train Loss=1.97, validation loss=2.4] 19%|â–ˆâ–Š        | 93/500 [01:00<04:16,  1.59it/s, Train Loss=2.37, validation loss=2.4] 19%|â–ˆâ–‰        | 94/500 [01:00<04:16,  1.58it/s, Train Loss=2.37, validation loss=2.4] 19%|â–ˆâ–‰        | 94/500 [01:00<04:16,  1.58it/s, Train Loss=1.94, validation loss=2.4] 19%|â–ˆâ–‰        | 95/500 [01:00<04:17,  1.57it/s, Train Loss=1.94, validation loss=2.4] 19%|â–ˆâ–‰        | 95/500 [01:01<04:17,  1.57it/s, Train Loss=1.81, validation loss=2.4] 19%|â–ˆâ–‰        | 96/500 [01:01<04:15,  1.58it/s, Train Loss=1.81, validation loss=2.4] 19%|â–ˆâ–‰        | 96/500 [01:01<04:15,  1.58it/s, Train Loss=3.08, validation loss=2.41] 19%|â–ˆâ–‰        | 97/500 [01:01<04:14,  1.58it/s, Train Loss=3.08, validation loss=2.41] 19%|â–ˆâ–‰        | 97/500 [01:02<04:14,  1.58it/s, Train Loss=2.35, validation loss=2.41] 20%|â–ˆâ–‰        | 98/500 [01:02<04:27,  1.50it/s, Train Loss=2.35, validation loss=2.41] 20%|â–ˆâ–‰        | 98/500 [01:03<04:27,  1.50it/s, Train Loss=2.02, validation loss=2.39] 20%|â–ˆâ–‰        | 99/500 [01:03<04:20,  1.54it/s, Train Loss=2.02, validation loss=2.39]####################################################################################################
--------------------------------------------- Epoch:100 ---------------------------------------------
-- Training set:
Loss: 2.1972670555114746, Lr: 0.0005
Average AUC ROC: 0.53                Average AUC PR: 0.3
 20%|â–ˆâ–‰        | 99/500 [01:03<04:20,  1.54it/s, Train Loss=2.2, validation loss=2.4]   20%|â–ˆâ–ˆ        | 100/500 [01:03<04:16,  1.56it/s, Train Loss=2.2, validation loss=2.4]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.4049706161022186
Average AUC ROC: 0.57                    Average AUC PR: 0.32
 20%|â–ˆâ–ˆ        | 100/500 [01:04<04:16,  1.56it/s, Train Loss=3.13, validation loss=2.4] 20%|â–ˆâ–ˆ        | 101/500 [01:04<04:12,  1.58it/s, Train Loss=3.13, validation loss=2.4] 20%|â–ˆâ–ˆ        | 101/500 [01:05<04:12,  1.58it/s, Train Loss=1.9, validation loss=2.4]  20%|â–ˆâ–ˆ        | 102/500 [01:05<04:13,  1.57it/s, Train Loss=1.9, validation loss=2.4] 20%|â–ˆâ–ˆ        | 102/500 [01:05<04:13,  1.57it/s, Train Loss=3.13, validation loss=2.41] 21%|â–ˆâ–ˆ        | 103/500 [01:05<04:23,  1.50it/s, Train Loss=3.13, validation loss=2.41] 21%|â–ˆâ–ˆ        | 103/500 [01:06<04:23,  1.50it/s, Train Loss=2.56, validation loss=2.4]  21%|â–ˆâ–ˆ        | 104/500 [01:06<04:18,  1.53it/s, Train Loss=2.56, validation loss=2.4] 21%|â–ˆâ–ˆ        | 104/500 [01:07<04:18,  1.53it/s, Train Loss=3.54, validation loss=2.43] 21%|â–ˆâ–ˆ        | 105/500 [01:07<04:12,  1.57it/s, Train Loss=3.54, validation loss=2.43] 21%|â–ˆâ–ˆ        | 105/500 [01:07<04:12,  1.57it/s, Train Loss=3.1, validation loss=2.39]  21%|â–ˆâ–ˆ        | 106/500 [01:07<04:09,  1.58it/s, Train Loss=3.1, validation loss=2.39] 21%|â–ˆâ–ˆ        | 106/500 [01:08<04:09,  1.58it/s, Train Loss=3.56, validation loss=2.39] 21%|â–ˆâ–ˆâ–       | 107/500 [01:08<04:08,  1.58it/s, Train Loss=3.56, validation loss=2.39] 21%|â–ˆâ–ˆâ–       | 107/500 [01:09<04:08,  1.58it/s, Train Loss=2.16, validation loss=2.39] 22%|â–ˆâ–ˆâ–       | 108/500 [01:09<04:06,  1.59it/s, Train Loss=2.16, validation loss=2.39] 22%|â–ˆâ–ˆâ–       | 108/500 [01:09<04:06,  1.59it/s, Train Loss=1.78, validation loss=2.38] 22%|â–ˆâ–ˆâ–       | 109/500 [01:09<04:05,  1.59it/s, Train Loss=1.78, validation loss=2.38] 22%|â–ˆâ–ˆâ–       | 109/500 [01:10<04:05,  1.59it/s, Train Loss=2.57, validation loss=2.39] 22%|â–ˆâ–ˆâ–       | 110/500 [01:10<04:01,  1.62it/s, Train Loss=2.57, validation loss=2.39] 22%|â–ˆâ–ˆâ–       | 110/500 [01:10<04:01,  1.62it/s, Train Loss=3.82, validation loss=2.38] 22%|â–ˆâ–ˆâ–       | 111/500 [01:10<04:06,  1.58it/s, Train Loss=3.82, validation loss=2.38] 22%|â–ˆâ–ˆâ–       | 111/500 [01:11<04:06,  1.58it/s, Train Loss=1.92, validation loss=2.39] 22%|â–ˆâ–ˆâ–       | 112/500 [01:11<04:02,  1.60it/s, Train Loss=1.92, validation loss=2.39] 22%|â–ˆâ–ˆâ–       | 112/500 [01:12<04:02,  1.60it/s, Train Loss=2.4, validation loss=2.38]  23%|â–ˆâ–ˆâ–       | 113/500 [01:12<04:02,  1.60it/s, Train Loss=2.4, validation loss=2.38] 23%|â–ˆâ–ˆâ–       | 113/500 [01:12<04:02,  1.60it/s, Train Loss=2.74, validation loss=2.38] 23%|â–ˆâ–ˆâ–       | 114/500 [01:12<04:00,  1.61it/s, Train Loss=2.74, validation loss=2.38] 23%|â–ˆâ–ˆâ–       | 114/500 [01:13<04:00,  1.61it/s, Train Loss=1.75, validation loss=2.39] 23%|â–ˆâ–ˆâ–       | 115/500 [01:13<04:02,  1.59it/s, Train Loss=1.75, validation loss=2.39] 23%|â–ˆâ–ˆâ–       | 115/500 [01:14<04:02,  1.59it/s, Train Loss=2.18, validation loss=2.4]  23%|â–ˆâ–ˆâ–       | 116/500 [01:14<04:14,  1.51it/s, Train Loss=2.18, validation loss=2.4] 23%|â–ˆâ–ˆâ–       | 116/500 [01:14<04:14,  1.51it/s, Train Loss=1.91, validation loss=2.4] 23%|â–ˆâ–ˆâ–       | 117/500 [01:14<04:10,  1.53it/s, Train Loss=1.91, validation loss=2.4] 23%|â–ˆâ–ˆâ–       | 117/500 [01:15<04:10,  1.53it/s, Train Loss=3.05, validation loss=2.38] 24%|â–ˆâ–ˆâ–       | 118/500 [01:15<04:07,  1.54it/s, Train Loss=3.05, validation loss=2.38] 24%|â–ˆâ–ˆâ–       | 118/500 [01:16<04:07,  1.54it/s, Train Loss=5.07, validation loss=2.38] 24%|â–ˆâ–ˆâ–       | 119/500 [01:16<04:04,  1.56it/s, Train Loss=5.07, validation loss=2.38] 24%|â–ˆâ–ˆâ–       | 119/500 [01:16<04:04,  1.56it/s, Train Loss=2.57, validation loss=2.38] 24%|â–ˆâ–ˆâ–       | 120/500 [01:16<03:59,  1.58it/s, Train Loss=2.57, validation loss=2.38] 24%|â–ˆâ–ˆâ–       | 120/500 [01:17<03:59,  1.58it/s, Train Loss=2.38, validation loss=2.39] 24%|â–ˆâ–ˆâ–       | 121/500 [01:17<03:58,  1.59it/s, Train Loss=2.38, validation loss=2.39] 24%|â–ˆâ–ˆâ–       | 121/500 [01:17<03:58,  1.59it/s, Train Loss=1.8, validation loss=2.39]  24%|â–ˆâ–ˆâ–       | 122/500 [01:17<03:57,  1.59it/s, Train Loss=1.8, validation loss=2.39] 24%|â–ˆâ–ˆâ–       | 122/500 [01:18<03:57,  1.59it/s, Train Loss=1.99, validation loss=2.38] 25%|â–ˆâ–ˆâ–       | 123/500 [01:18<03:55,  1.60it/s, Train Loss=1.99, validation loss=2.38] 25%|â–ˆâ–ˆâ–       | 123/500 [01:19<03:55,  1.60it/s, Train Loss=2.89, validation loss=2.37] 25%|â–ˆâ–ˆâ–       | 124/500 [01:19<03:57,  1.58it/s, Train Loss=2.89, validation loss=2.37] 25%|â–ˆâ–ˆâ–       | 124/500 [01:19<03:57,  1.58it/s, Train Loss=2.02, validation loss=2.38] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:19<04:09,  1.50it/s, Train Loss=2.02, validation loss=2.38] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:20<04:09,  1.50it/s, Train Loss=2.69, validation loss=2.38] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:20<04:05,  1.52it/s, Train Loss=2.69, validation loss=2.38] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:21<04:05,  1.52it/s, Train Loss=2.1, validation loss=2.35]  25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:21<04:00,  1.55it/s, Train Loss=2.1, validation loss=2.35] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:21<04:00,  1.55it/s, Train Loss=1.97, validation loss=2.36] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:21<03:54,  1.58it/s, Train Loss=1.97, validation loss=2.36] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:22<03:54,  1.58it/s, Train Loss=2.15, validation loss=2.37] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:22<03:52,  1.60it/s, Train Loss=2.15, validation loss=2.37] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:23<03:52,  1.60it/s, Train Loss=1.58, validation loss=2.38] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:23<03:59,  1.54it/s, Train Loss=1.58, validation loss=2.38] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:23<03:59,  1.54it/s, Train Loss=1.68, validation loss=2.37] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:23<03:54,  1.57it/s, Train Loss=1.68, validation loss=2.37] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:24<03:54,  1.57it/s, Train Loss=2.99, validation loss=2.38] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:24<03:50,  1.60it/s, Train Loss=2.99, validation loss=2.38] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:24<03:50,  1.60it/s, Train Loss=5.49, validation loss=2.36] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:24<03:53,  1.57it/s, Train Loss=5.49, validation loss=2.36] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:25<03:53,  1.57it/s, Train Loss=2.81, validation loss=2.36] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:25<03:48,  1.60it/s, Train Loss=2.81, validation loss=2.36] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:26<03:48,  1.60it/s, Train Loss=1.87, validation loss=2.38] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:26<03:49,  1.59it/s, Train Loss=1.87, validation loss=2.38] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:26<03:49,  1.59it/s, Train Loss=3.27, validation loss=2.36] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:26<03:45,  1.62it/s, Train Loss=3.27, validation loss=2.36] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:27<03:45,  1.62it/s, Train Loss=2.79, validation loss=2.37] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:27<03:54,  1.55it/s, Train Loss=2.79, validation loss=2.37] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:28<03:54,  1.55it/s, Train Loss=2.25, validation loss=2.38] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:28<03:51,  1.56it/s, Train Loss=2.25, validation loss=2.38] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:28<03:51,  1.56it/s, Train Loss=2.18, validation loss=2.37] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:28<03:52,  1.55it/s, Train Loss=2.18, validation loss=2.37] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:29<03:52,  1.55it/s, Train Loss=2.17, validation loss=2.39] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:29<03:51,  1.55it/s, Train Loss=2.17, validation loss=2.39] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:30<03:51,  1.55it/s, Train Loss=2.54, validation loss=2.39] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:30<03:50,  1.56it/s, Train Loss=2.54, validation loss=2.39] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:30<03:50,  1.56it/s, Train Loss=2.19, validation loss=2.39] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:30<03:48,  1.57it/s, Train Loss=2.19, validation loss=2.39] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:31<03:48,  1.57it/s, Train Loss=1.91, validation loss=2.39] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:31<03:45,  1.59it/s, Train Loss=1.91, validation loss=2.39] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:31<03:45,  1.59it/s, Train Loss=2.82, validation loss=2.38] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:31<03:43,  1.60it/s, Train Loss=2.82, validation loss=2.38] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:32<03:43,  1.60it/s, Train Loss=2.55, validation loss=2.36] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:32<03:51,  1.53it/s, Train Loss=2.55, validation loss=2.36] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:33<03:51,  1.53it/s, Train Loss=2.22, validation loss=2.39] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:33<03:47,  1.56it/s, Train Loss=2.22, validation loss=2.39] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:33<03:47,  1.56it/s, Train Loss=2.87, validation loss=2.37] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:33<03:46,  1.56it/s, Train Loss=2.87, validation loss=2.37] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:34<03:46,  1.56it/s, Train Loss=2.33, validation loss=2.37] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:34<03:42,  1.58it/s, Train Loss=2.33, validation loss=2.37] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:35<03:42,  1.58it/s, Train Loss=2.94, validation loss=2.37] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:35<03:49,  1.53it/s, Train Loss=2.94, validation loss=2.37] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:35<03:49,  1.53it/s, Train Loss=2.45, validation loss=2.37] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:35<03:49,  1.53it/s, Train Loss=2.45, validation loss=2.37] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:36<03:49,  1.53it/s, Train Loss=1.87, validation loss=2.35] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:36<03:47,  1.54it/s, Train Loss=1.87, validation loss=2.35] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:37<03:47,  1.54it/s, Train Loss=2.09, validation loss=2.38] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:37<03:42,  1.56it/s, Train Loss=2.09, validation loss=2.38] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:37<03:42,  1.56it/s, Train Loss=1.73, validation loss=2.37] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:37<03:38,  1.59it/s, Train Loss=1.73, validation loss=2.37] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:38<03:38,  1.59it/s, Train Loss=2.11, validation loss=2.36] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:38<03:39,  1.58it/s, Train Loss=2.11, validation loss=2.36] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:38<03:39,  1.58it/s, Train Loss=2.2, validation loss=2.35]  31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:38<03:33,  1.61it/s, Train Loss=2.2, validation loss=2.35] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:39<03:33,  1.61it/s, Train Loss=2.54, validation loss=2.36] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:39<03:34,  1.60it/s, Train Loss=2.54, validation loss=2.36] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:40<03:34,  1.60it/s, Train Loss=2.54, validation loss=2.37] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:40<03:35,  1.60it/s, Train Loss=2.54, validation loss=2.37] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:40<03:35,  1.60it/s, Train Loss=1.92, validation loss=2.36] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:40<03:43,  1.53it/s, Train Loss=1.92, validation loss=2.36] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:41<03:43,  1.53it/s, Train Loss=1.48, validation loss=2.37] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:41<03:39,  1.55it/s, Train Loss=1.48, validation loss=2.37] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:42<03:39,  1.55it/s, Train Loss=2.27, validation loss=2.37] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:42<03:34,  1.59it/s, Train Loss=2.27, validation loss=2.37] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:42<03:34,  1.59it/s, Train Loss=1.81, validation loss=2.35] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:42<03:29,  1.62it/s, Train Loss=1.81, validation loss=2.35] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:43<03:29,  1.62it/s, Train Loss=2.47, validation loss=2.36] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:43<03:28,  1.62it/s, Train Loss=2.47, validation loss=2.36] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:44<03:28,  1.62it/s, Train Loss=2.46, validation loss=2.36] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:44<03:39,  1.53it/s, Train Loss=2.46, validation loss=2.36] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:44<03:39,  1.53it/s, Train Loss=1.62, validation loss=2.37] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:44<03:35,  1.56it/s, Train Loss=1.62, validation loss=2.37] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:45<03:35,  1.56it/s, Train Loss=3.62, validation loss=2.36] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:45<03:32,  1.58it/s, Train Loss=3.62, validation loss=2.36] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:45<03:32,  1.58it/s, Train Loss=2.53, validation loss=2.36] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:45<03:31,  1.58it/s, Train Loss=2.53, validation loss=2.36] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:46<03:31,  1.58it/s, Train Loss=3.43, validation loss=2.36] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:46<03:29,  1.59it/s, Train Loss=3.43, validation loss=2.36] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:47<03:29,  1.59it/s, Train Loss=2.55, validation loss=2.36] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:47<03:27,  1.60it/s, Train Loss=2.55, validation loss=2.36] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:47<03:27,  1.60it/s, Train Loss=2.81, validation loss=2.36] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:47<03:28,  1.59it/s, Train Loss=2.81, validation loss=2.36] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:48<03:28,  1.59it/s, Train Loss=2.17, validation loss=2.35] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:48<03:27,  1.59it/s, Train Loss=2.17, validation loss=2.35] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:49<03:27,  1.59it/s, Train Loss=2.39, validation loss=2.37] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:49<03:26,  1.60it/s, Train Loss=2.39, validation loss=2.37] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:49<03:26,  1.60it/s, Train Loss=2.13, validation loss=2.36] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:49<03:35,  1.52it/s, Train Loss=2.13, validation loss=2.36] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:50<03:35,  1.52it/s, Train Loss=2.6, validation loss=2.37]  35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:50<03:28,  1.57it/s, Train Loss=2.6, validation loss=2.37] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:51<03:28,  1.57it/s, Train Loss=1.89, validation loss=2.36] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:51<03:25,  1.58it/s, Train Loss=1.89, validation loss=2.36] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:51<03:25,  1.58it/s, Train Loss=2.02, validation loss=2.36] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:51<03:27,  1.57it/s, Train Loss=2.02, validation loss=2.36] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:52<03:27,  1.57it/s, Train Loss=2.69, validation loss=2.36] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:52<03:27,  1.56it/s, Train Loss=2.69, validation loss=2.36] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:53<03:27,  1.56it/s, Train Loss=2, validation loss=2.36]    35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:53<03:36,  1.49it/s, Train Loss=2, validation loss=2.36] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:53<03:36,  1.49it/s, Train Loss=1.71, validation loss=2.37] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:53<03:32,  1.52it/s, Train Loss=1.71, validation loss=2.37] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:54<03:32,  1.52it/s, Train Loss=1.54, validation loss=2.36] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:54<03:26,  1.55it/s, Train Loss=1.54, validation loss=2.36] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:54<03:26,  1.55it/s, Train Loss=2.45, validation loss=2.37] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:54<03:23,  1.57it/s, Train Loss=2.45, validation loss=2.37] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:55<03:23,  1.57it/s, Train Loss=2.97, validation loss=2.36] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:55<03:21,  1.59it/s, Train Loss=2.97, validation loss=2.36] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:56<03:21,  1.59it/s, Train Loss=2.69, validation loss=2.37] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:56<03:18,  1.60it/s, Train Loss=2.69, validation loss=2.37] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:56<03:18,  1.60it/s, Train Loss=3.3, validation loss=2.36]  37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:56<03:18,  1.60it/s, Train Loss=3.3, validation loss=2.36] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:57<03:18,  1.60it/s, Train Loss=2.7, validation loss=2.37] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:57<03:25,  1.54it/s, Train Loss=2.7, validation loss=2.37] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:58<03:25,  1.54it/s, Train Loss=2.22, validation loss=2.36] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:58<03:22,  1.56it/s, Train Loss=2.22, validation loss=2.36] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:58<03:22,  1.56it/s, Train Loss=3.05, validation loss=2.35] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [01:58<03:20,  1.57it/s, Train Loss=3.05, validation loss=2.35] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [01:59<03:20,  1.57it/s, Train Loss=1.66, validation loss=2.36] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [01:59<03:18,  1.58it/s, Train Loss=1.66, validation loss=2.36] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [01:59<03:18,  1.58it/s, Train Loss=1.95, validation loss=2.36] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [01:59<03:17,  1.58it/s, Train Loss=1.95, validation loss=2.36] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:00<03:17,  1.58it/s, Train Loss=2.27, validation loss=2.37] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:00<03:15,  1.59it/s, Train Loss=2.27, validation loss=2.37] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:01<03:15,  1.59it/s, Train Loss=1.55, validation loss=2.37] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:01<03:12,  1.61it/s, Train Loss=1.55, validation loss=2.37] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:01<03:12,  1.61it/s, Train Loss=2.6, validation loss=2.36]  38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:01<03:23,  1.52it/s, Train Loss=2.6, validation loss=2.36] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:02<03:23,  1.52it/s, Train Loss=2.83, validation loss=2.37] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:02<03:22,  1.52it/s, Train Loss=2.83, validation loss=2.37] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:03<03:22,  1.52it/s, Train Loss=2.51, validation loss=2.36] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:03<03:17,  1.56it/s, Train Loss=2.51, validation loss=2.36] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:03<03:17,  1.56it/s, Train Loss=2.3, validation loss=2.36]  39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:03<03:15,  1.56it/s, Train Loss=2.3, validation loss=2.36] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:04<03:15,  1.56it/s, Train Loss=1.61, validation loss=2.38] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:04<03:14,  1.56it/s, Train Loss=1.61, validation loss=2.38] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:05<03:14,  1.56it/s, Train Loss=3.29, validation loss=2.37] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:05<03:26,  1.47it/s, Train Loss=3.29, validation loss=2.37] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:05<03:26,  1.47it/s, Train Loss=3.48, validation loss=2.37] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:05<03:20,  1.51it/s, Train Loss=3.48, validation loss=2.37] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:06<03:20,  1.51it/s, Train Loss=2.74, validation loss=2.38] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:06<03:15,  1.54it/s, Train Loss=2.74, validation loss=2.38] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:07<03:15,  1.54it/s, Train Loss=1.5, validation loss=2.37]  40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:07<03:09,  1.59it/s, Train Loss=1.5, validation loss=2.37]####################################################################################################
--------------------------------------------- Epoch:200 ---------------------------------------------
-- Training set:
Loss: 2.2685647010803223, Lr: 0.00025
Average AUC ROC: 0.52                Average AUC PR: 0.28
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:07<03:09,  1.59it/s, Train Loss=2.27, validation loss=2.38] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:07<03:09,  1.58it/s, Train Loss=2.27, validation loss=2.38]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.3766267746686935
Average AUC ROC: 0.56                    Average AUC PR: 0.31
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:08<03:09,  1.58it/s, Train Loss=3.24, validation loss=2.36] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:08<03:07,  1.59it/s, Train Loss=3.24, validation loss=2.36] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:08<03:07,  1.59it/s, Train Loss=1.73, validation loss=2.37] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:08<03:05,  1.61it/s, Train Loss=1.73, validation loss=2.37] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:09<03:05,  1.61it/s, Train Loss=2.96, validation loss=2.38] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:09<03:06,  1.59it/s, Train Loss=2.96, validation loss=2.38] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:10<03:06,  1.59it/s, Train Loss=2.37, validation loss=2.36] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:10<03:05,  1.59it/s, Train Loss=2.37, validation loss=2.36] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:10<03:05,  1.59it/s, Train Loss=2.29, validation loss=2.37] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:10<03:15,  1.51it/s, Train Loss=2.29, validation loss=2.37] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:11<03:15,  1.51it/s, Train Loss=2.12, validation loss=2.38] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:11<03:10,  1.55it/s, Train Loss=2.12, validation loss=2.38] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:12<03:10,  1.55it/s, Train Loss=2.17, validation loss=2.37] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:12<03:07,  1.57it/s, Train Loss=2.17, validation loss=2.37] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:12<03:07,  1.57it/s, Train Loss=2.4, validation loss=2.37]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:12<03:03,  1.60it/s, Train Loss=2.4, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:13<03:03,  1.60it/s, Train Loss=2.6, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:13<03:05,  1.57it/s, Train Loss=2.6, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:14<03:05,  1.57it/s, Train Loss=2.56, validation loss=2.36] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:14<03:11,  1.51it/s, Train Loss=2.56, validation loss=2.36] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:14<03:11,  1.51it/s, Train Loss=1.69, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:14<03:08,  1.54it/s, Train Loss=1.69, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:15<03:08,  1.54it/s, Train Loss=2.7, validation loss=2.37]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:15<03:06,  1.55it/s, Train Loss=2.7, validation loss=2.37] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:16<03:06,  1.55it/s, Train Loss=2.07, validation loss=2.36] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:16<03:02,  1.57it/s, Train Loss=2.07, validation loss=2.36] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:16<03:02,  1.57it/s, Train Loss=2.58, validation loss=2.37] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:16<03:00,  1.58it/s, Train Loss=2.58, validation loss=2.37] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:17<03:00,  1.58it/s, Train Loss=3.19, validation loss=2.36] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:17<02:58,  1.60it/s, Train Loss=3.19, validation loss=2.36] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:17<02:58,  1.60it/s, Train Loss=2.08, validation loss=2.36] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:17<02:59,  1.58it/s, Train Loss=2.08, validation loss=2.36] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:18<02:59,  1.58it/s, Train Loss=1.84, validation loss=2.36] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:18<02:59,  1.58it/s, Train Loss=1.84, validation loss=2.36] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:19<02:59,  1.58it/s, Train Loss=3.35, validation loss=2.36] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:19<03:06,  1.51it/s, Train Loss=3.35, validation loss=2.36] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:19<03:06,  1.51it/s, Train Loss=2.9, validation loss=2.38]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:19<03:00,  1.55it/s, Train Loss=2.9, validation loss=2.38] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:20<03:00,  1.55it/s, Train Loss=3.17, validation loss=2.38] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:20<03:00,  1.55it/s, Train Loss=3.17, validation loss=2.38] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:21<03:00,  1.55it/s, Train Loss=2.76, validation loss=2.36] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:21<03:00,  1.55it/s, Train Loss=2.76, validation loss=2.36] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:21<03:00,  1.55it/s, Train Loss=1.3, validation loss=2.35]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:21<02:57,  1.56it/s, Train Loss=1.3, validation loss=2.35] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:22<02:57,  1.56it/s, Train Loss=2.26, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:22<03:00,  1.53it/s, Train Loss=2.26, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:23<03:00,  1.53it/s, Train Loss=2.54, validation loss=2.35] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:23<02:59,  1.54it/s, Train Loss=2.54, validation loss=2.35] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:23<02:59,  1.54it/s, Train Loss=1.79, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:23<02:58,  1.54it/s, Train Loss=1.79, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:24<02:58,  1.54it/s, Train Loss=3.72, validation loss=2.36] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:24<02:54,  1.57it/s, Train Loss=3.72, validation loss=2.36] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:25<02:54,  1.57it/s, Train Loss=1.97, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:25<02:52,  1.58it/s, Train Loss=1.97, validation loss=2.37] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:25<02:52,  1.58it/s, Train Loss=2.13, validation loss=2.36] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:25<02:51,  1.58it/s, Train Loss=2.13, validation loss=2.36] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:26<02:51,  1.58it/s, Train Loss=2.04, validation loss=2.36] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:26<02:56,  1.54it/s, Train Loss=2.04, validation loss=2.36] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:27<02:56,  1.54it/s, Train Loss=2.52, validation loss=2.37] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:27<02:55,  1.53it/s, Train Loss=2.52, validation loss=2.37] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:27<02:55,  1.53it/s, Train Loss=1.54, validation loss=2.35] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:27<02:51,  1.57it/s, Train Loss=1.54, validation loss=2.35] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:28<02:51,  1.57it/s, Train Loss=2.64, validation loss=2.36] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:28<02:50,  1.57it/s, Train Loss=2.64, validation loss=2.36] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:28<02:50,  1.57it/s, Train Loss=2.02, validation loss=2.37] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:28<02:48,  1.59it/s, Train Loss=2.02, validation loss=2.37] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:29<02:48,  1.59it/s, Train Loss=1.99, validation loss=2.36] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:29<02:46,  1.60it/s, Train Loss=1.99, validation loss=2.36] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:30<02:46,  1.60it/s, Train Loss=1.87, validation loss=2.36] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:30<02:46,  1.59it/s, Train Loss=1.87, validation loss=2.36] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:30<02:46,  1.59it/s, Train Loss=2.28, validation loss=2.35] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:30<02:44,  1.60it/s, Train Loss=2.28, validation loss=2.35] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:31<02:44,  1.60it/s, Train Loss=2.65, validation loss=2.36] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:31<02:50,  1.54it/s, Train Loss=2.65, validation loss=2.36] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:32<02:50,  1.54it/s, Train Loss=1.75, validation loss=2.34] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:32<02:46,  1.57it/s, Train Loss=1.75, validation loss=2.34] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:32<02:46,  1.57it/s, Train Loss=1.81, validation loss=2.36] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:32<02:43,  1.59it/s, Train Loss=1.81, validation loss=2.36] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:33<02:43,  1.59it/s, Train Loss=2.75, validation loss=2.36] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:33<02:40,  1.62it/s, Train Loss=2.75, validation loss=2.36] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:33<02:40,  1.62it/s, Train Loss=2.33, validation loss=2.37] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:33<02:41,  1.61it/s, Train Loss=2.33, validation loss=2.37] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:34<02:41,  1.61it/s, Train Loss=1.88, validation loss=2.36] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:34<02:45,  1.56it/s, Train Loss=1.88, validation loss=2.36] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:35<02:45,  1.56it/s, Train Loss=1.53, validation loss=2.36] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:35<02:42,  1.58it/s, Train Loss=1.53, validation loss=2.36] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:35<02:42,  1.58it/s, Train Loss=3.98, validation loss=2.38] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:35<02:45,  1.55it/s, Train Loss=3.98, validation loss=2.38] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:36<02:45,  1.55it/s, Train Loss=2.13, validation loss=2.38] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:36<02:41,  1.58it/s, Train Loss=2.13, validation loss=2.38] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:37<02:41,  1.58it/s, Train Loss=1.4, validation loss=2.36]  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:37<02:36,  1.62it/s, Train Loss=1.4, validation loss=2.36] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:37<02:36,  1.62it/s, Train Loss=2.27, validation loss=2.36] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:37<02:35,  1.63it/s, Train Loss=2.27, validation loss=2.36] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:38<02:35,  1.63it/s, Train Loss=3.56, validation loss=2.36] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:38<02:32,  1.65it/s, Train Loss=3.56, validation loss=2.36] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:38<02:32,  1.65it/s, Train Loss=2.81, validation loss=2.36] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:38<02:30,  1.66it/s, Train Loss=2.81, validation loss=2.36] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:39<02:30,  1.66it/s, Train Loss=2.57, validation loss=2.37] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:39<02:30,  1.66it/s, Train Loss=2.57, validation loss=2.37] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:39<02:30,  1.66it/s, Train Loss=2.38, validation loss=2.35] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:39<02:27,  1.69it/s, Train Loss=2.38, validation loss=2.35] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:40<02:27,  1.69it/s, Train Loss=2.14, validation loss=2.37] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:40<02:25,  1.71it/s, Train Loss=2.14, validation loss=2.37] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:41<02:25,  1.71it/s, Train Loss=2.26, validation loss=2.36] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:41<02:26,  1.69it/s, Train Loss=2.26, validation loss=2.36] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:41<02:26,  1.69it/s, Train Loss=3.41, validation loss=2.37] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:41<02:26,  1.68it/s, Train Loss=3.41, validation loss=2.37] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:42<02:26,  1.68it/s, Train Loss=2.24, validation loss=2.36] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:42<02:28,  1.65it/s, Train Loss=2.24, validation loss=2.36] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:43<02:28,  1.65it/s, Train Loss=4.09, validation loss=2.36] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:43<02:28,  1.64it/s, Train Loss=4.09, validation loss=2.36] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:43<02:28,  1.64it/s, Train Loss=1.55, validation loss=2.36] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:43<02:29,  1.62it/s, Train Loss=1.55, validation loss=2.36] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:44<02:29,  1.62it/s, Train Loss=1.9, validation loss=2.36]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:44<02:28,  1.63it/s, Train Loss=1.9, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:44<02:28,  1.63it/s, Train Loss=3.59, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:44<02:26,  1.65it/s, Train Loss=3.59, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:45<02:26,  1.65it/s, Train Loss=1.94, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:45<02:26,  1.64it/s, Train Loss=1.94, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:46<02:26,  1.64it/s, Train Loss=2.1, validation loss=2.37]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:46<02:25,  1.64it/s, Train Loss=2.1, validation loss=2.37] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:46<02:25,  1.64it/s, Train Loss=2.3, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:46<02:24,  1.65it/s, Train Loss=2.3, validation loss=2.36] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:47<02:24,  1.65it/s, Train Loss=2.08, validation loss=2.37] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:47<02:33,  1.54it/s, Train Loss=2.08, validation loss=2.37] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:48<02:33,  1.54it/s, Train Loss=2.99, validation loss=2.34] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:48<02:31,  1.56it/s, Train Loss=2.99, validation loss=2.34] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:48<02:31,  1.56it/s, Train Loss=3.44, validation loss=2.36] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:48<02:29,  1.57it/s, Train Loss=3.44, validation loss=2.36] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:49<02:29,  1.57it/s, Train Loss=2.51, validation loss=2.36] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:49<02:28,  1.57it/s, Train Loss=2.51, validation loss=2.36] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:49<02:28,  1.57it/s, Train Loss=1.38, validation loss=2.37] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:49<02:27,  1.58it/s, Train Loss=1.38, validation loss=2.37] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:50<02:27,  1.58it/s, Train Loss=2.43, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:50<02:31,  1.54it/s, Train Loss=2.43, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:51<02:31,  1.54it/s, Train Loss=2.8, validation loss=2.36]  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:51<02:43,  1.41it/s, Train Loss=2.8, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:52<02:43,  1.41it/s, Train Loss=1.98, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:52<02:36,  1.47it/s, Train Loss=1.98, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:52<02:36,  1.47it/s, Train Loss=2.51, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:52<02:30,  1.52it/s, Train Loss=2.51, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:53<02:30,  1.52it/s, Train Loss=1.53, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:53<02:27,  1.55it/s, Train Loss=1.53, validation loss=2.36] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:53<02:27,  1.55it/s, Train Loss=2.37, validation loss=2.35] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:53<02:22,  1.59it/s, Train Loss=2.37, validation loss=2.35] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:54<02:22,  1.59it/s, Train Loss=3.37, validation loss=2.38] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:54<02:22,  1.58it/s, Train Loss=3.37, validation loss=2.38] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:55<02:22,  1.58it/s, Train Loss=1.71, validation loss=2.37] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:55<02:20,  1.60it/s, Train Loss=1.71, validation loss=2.37] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:55<02:20,  1.60it/s, Train Loss=2.12, validation loss=2.35] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:55<02:25,  1.54it/s, Train Loss=2.12, validation loss=2.35] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:56<02:25,  1.54it/s, Train Loss=1.1, validation loss=2.36]  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:56<02:36,  1.42it/s, Train Loss=1.1, validation loss=2.36] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:57<02:36,  1.42it/s, Train Loss=2.42, validation loss=2.35] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:57<02:40,  1.38it/s, Train Loss=2.42, validation loss=2.35] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:58<02:40,  1.38it/s, Train Loss=2.12, validation loss=2.37] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [02:58<02:31,  1.46it/s, Train Loss=2.12, validation loss=2.37] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [02:58<02:31,  1.46it/s, Train Loss=2.51, validation loss=2.35] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [02:58<02:25,  1.51it/s, Train Loss=2.51, validation loss=2.35] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [02:59<02:25,  1.51it/s, Train Loss=2.52, validation loss=2.36] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [02:59<02:23,  1.53it/s, Train Loss=2.52, validation loss=2.36] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [02:59<02:23,  1.53it/s, Train Loss=2.55, validation loss=2.36] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [02:59<02:21,  1.54it/s, Train Loss=2.55, validation loss=2.36] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:00<02:21,  1.54it/s, Train Loss=1.8, validation loss=2.36]  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:00<02:18,  1.57it/s, Train Loss=1.8, validation loss=2.36] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:01<02:18,  1.57it/s, Train Loss=2.38, validation loss=2.35] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:01<02:16,  1.59it/s, Train Loss=2.38, validation loss=2.35] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:01<02:16,  1.59it/s, Train Loss=2.94, validation loss=2.36] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:01<02:15,  1.59it/s, Train Loss=2.94, validation loss=2.36] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:02<02:15,  1.59it/s, Train Loss=1.81, validation loss=2.35] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:02<02:13,  1.60it/s, Train Loss=1.81, validation loss=2.35] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:03<02:13,  1.60it/s, Train Loss=2.54, validation loss=2.36] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:03<02:13,  1.60it/s, Train Loss=2.54, validation loss=2.36] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:03<02:13,  1.60it/s, Train Loss=2.73, validation loss=2.36] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:03<02:11,  1.62it/s, Train Loss=2.73, validation loss=2.36] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:04<02:11,  1.62it/s, Train Loss=2.19, validation loss=2.35] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:04<02:08,  1.64it/s, Train Loss=2.19, validation loss=2.35] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:04<02:08,  1.64it/s, Train Loss=4.02, validation loss=2.35] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:04<02:08,  1.64it/s, Train Loss=4.02, validation loss=2.35] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:05<02:08,  1.64it/s, Train Loss=3.72, validation loss=2.35] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:05<02:09,  1.61it/s, Train Loss=3.72, validation loss=2.35] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:06<02:09,  1.61it/s, Train Loss=2.06, validation loss=2.36] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:06<02:08,  1.62it/s, Train Loss=2.06, validation loss=2.36] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:06<02:08,  1.62it/s, Train Loss=1.72, validation loss=2.36] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:06<02:07,  1.62it/s, Train Loss=1.72, validation loss=2.36] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:07<02:07,  1.62it/s, Train Loss=2.82, validation loss=2.35] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:07<02:16,  1.51it/s, Train Loss=2.82, validation loss=2.35] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:08<02:16,  1.51it/s, Train Loss=2.31, validation loss=2.35] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:08<02:12,  1.55it/s, Train Loss=2.31, validation loss=2.35] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:08<02:12,  1.55it/s, Train Loss=2.7, validation loss=2.36]  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:08<02:10,  1.56it/s, Train Loss=2.7, validation loss=2.36] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:09<02:10,  1.56it/s, Train Loss=1.76, validation loss=2.35] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:09<02:08,  1.58it/s, Train Loss=1.76, validation loss=2.35] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:09<02:08,  1.58it/s, Train Loss=2.1, validation loss=2.35]  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:09<02:07,  1.59it/s, Train Loss=2.1, validation loss=2.35] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:10<02:07,  1.59it/s, Train Loss=1.51, validation loss=2.36] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:10<02:04,  1.62it/s, Train Loss=1.51, validation loss=2.36]####################################################################################################
--------------------------------------------- Epoch:300 ---------------------------------------------
-- Training set:
Loss: 1.568169116973877, Lr: 0.000125
Average AUC ROC: 0.52                Average AUC PR: 0.3
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:11<02:04,  1.62it/s, Train Loss=1.57, validation loss=2.35] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:11<02:04,  1.61it/s, Train Loss=1.57, validation loss=2.35]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.35203218460083
Average AUC ROC: 0.56                    Average AUC PR: 0.31
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:11<02:04,  1.61it/s, Train Loss=2.03, validation loss=2.35] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:11<02:05,  1.59it/s, Train Loss=2.03, validation loss=2.35] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:12<02:05,  1.59it/s, Train Loss=2.5, validation loss=2.35]  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:12<02:03,  1.60it/s, Train Loss=2.5, validation loss=2.35] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:13<02:03,  1.60it/s, Train Loss=2.74, validation loss=2.34] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:13<02:01,  1.62it/s, Train Loss=2.74, validation loss=2.34] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:13<02:01,  1.62it/s, Train Loss=2.19, validation loss=2.36] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:13<02:00,  1.63it/s, Train Loss=2.19, validation loss=2.36] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:14<02:00,  1.63it/s, Train Loss=3.38, validation loss=2.35] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:14<01:58,  1.65it/s, Train Loss=3.38, validation loss=2.35] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:14<01:58,  1.65it/s, Train Loss=2.38, validation loss=2.34] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:14<01:57,  1.66it/s, Train Loss=2.38, validation loss=2.34] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:15<01:57,  1.66it/s, Train Loss=2.19, validation loss=2.35] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:15<01:58,  1.63it/s, Train Loss=2.19, validation loss=2.35] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:16<01:58,  1.63it/s, Train Loss=2.81, validation loss=2.36] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:16<01:58,  1.62it/s, Train Loss=2.81, validation loss=2.36] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:16<01:58,  1.62it/s, Train Loss=2.35, validation loss=2.34] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:16<02:05,  1.52it/s, Train Loss=2.35, validation loss=2.34] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:17<02:05,  1.52it/s, Train Loss=1.72, validation loss=2.34] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:17<02:00,  1.57it/s, Train Loss=1.72, validation loss=2.34] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:18<02:00,  1.57it/s, Train Loss=1.74, validation loss=2.34] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:18<01:59,  1.59it/s, Train Loss=1.74, validation loss=2.34] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:18<01:59,  1.59it/s, Train Loss=1.75, validation loss=2.35] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:18<01:57,  1.60it/s, Train Loss=1.75, validation loss=2.35] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:19<01:57,  1.60it/s, Train Loss=1.74, validation loss=2.35] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:19<01:55,  1.62it/s, Train Loss=1.74, validation loss=2.35] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:19<01:55,  1.62it/s, Train Loss=1.91, validation loss=2.35] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:19<01:54,  1.63it/s, Train Loss=1.91, validation loss=2.35] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:20<01:54,  1.63it/s, Train Loss=3.9, validation loss=2.36]  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:20<01:52,  1.64it/s, Train Loss=3.9, validation loss=2.36] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:21<01:52,  1.64it/s, Train Loss=3.08, validation loss=2.36] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:21<01:52,  1.64it/s, Train Loss=3.08, validation loss=2.36] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:21<01:52,  1.64it/s, Train Loss=2.95, validation loss=2.35] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:21<02:00,  1.51it/s, Train Loss=2.95, validation loss=2.35] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:22<02:00,  1.51it/s, Train Loss=1.6, validation loss=2.34]  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:22<02:10,  1.39it/s, Train Loss=1.6, validation loss=2.34] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:23<02:10,  1.39it/s, Train Loss=3.47, validation loss=2.37] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:23<02:04,  1.46it/s, Train Loss=3.47, validation loss=2.37] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:23<02:04,  1.46it/s, Train Loss=3.42, validation loss=2.36] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:23<01:58,  1.52it/s, Train Loss=3.42, validation loss=2.36] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:24<01:58,  1.52it/s, Train Loss=1.58, validation loss=2.34] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:24<01:57,  1.53it/s, Train Loss=1.58, validation loss=2.34] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:25<01:57,  1.53it/s, Train Loss=2.06, validation loss=2.35] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:25<01:54,  1.55it/s, Train Loss=2.06, validation loss=2.35] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:25<01:54,  1.55it/s, Train Loss=2.45, validation loss=2.35] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:25<01:53,  1.57it/s, Train Loss=2.45, validation loss=2.35] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:26<01:53,  1.57it/s, Train Loss=1.41, validation loss=2.34] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:26<01:50,  1.59it/s, Train Loss=1.41, validation loss=2.34] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:26<01:50,  1.59it/s, Train Loss=1.88, validation loss=2.34] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:26<01:49,  1.60it/s, Train Loss=1.88, validation loss=2.34] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:27<01:49,  1.60it/s, Train Loss=1.41, validation loss=2.35] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:27<01:48,  1.60it/s, Train Loss=1.41, validation loss=2.35] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:28<01:48,  1.60it/s, Train Loss=2.17, validation loss=2.35] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:28<01:48,  1.59it/s, Train Loss=2.17, validation loss=2.35] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:28<01:48,  1.59it/s, Train Loss=2.05, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:28<01:46,  1.61it/s, Train Loss=2.05, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:29<01:46,  1.61it/s, Train Loss=2.82, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:29<01:44,  1.63it/s, Train Loss=2.82, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:30<01:44,  1.63it/s, Train Loss=2.26, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:30<01:44,  1.63it/s, Train Loss=2.26, validation loss=2.35] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:30<01:44,  1.63it/s, Train Loss=2.67, validation loss=2.34] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:30<01:44,  1.62it/s, Train Loss=2.67, validation loss=2.34] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:31<01:44,  1.62it/s, Train Loss=1.71, validation loss=2.34] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:31<01:43,  1.62it/s, Train Loss=1.71, validation loss=2.34] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:32<01:43,  1.62it/s, Train Loss=2.11, validation loss=2.34] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:32<01:48,  1.54it/s, Train Loss=2.11, validation loss=2.34] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:32<01:48,  1.54it/s, Train Loss=2.65, validation loss=2.36] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:32<01:49,  1.51it/s, Train Loss=2.65, validation loss=2.36] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:33<01:49,  1.51it/s, Train Loss=1.62, validation loss=2.36] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:33<01:52,  1.46it/s, Train Loss=1.62, validation loss=2.36] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:34<01:52,  1.46it/s, Train Loss=1.87, validation loss=2.35] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:34<01:51,  1.46it/s, Train Loss=1.87, validation loss=2.35] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:34<01:51,  1.46it/s, Train Loss=2.19, validation loss=2.35] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:34<01:53,  1.43it/s, Train Loss=2.19, validation loss=2.35] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:35<01:53,  1.43it/s, Train Loss=1.87, validation loss=2.34] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:35<01:54,  1.41it/s, Train Loss=1.87, validation loss=2.34] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:36<01:54,  1.41it/s, Train Loss=2.42, validation loss=2.36] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:36<01:52,  1.44it/s, Train Loss=2.42, validation loss=2.36] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:36<01:52,  1.44it/s, Train Loss=2.27, validation loss=2.36] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:36<01:49,  1.47it/s, Train Loss=2.27, validation loss=2.36] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:37<01:49,  1.47it/s, Train Loss=2.34, validation loss=2.35] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:37<01:45,  1.51it/s, Train Loss=2.34, validation loss=2.35] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:38<01:45,  1.51it/s, Train Loss=2.17, validation loss=2.36] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:38<01:44,  1.51it/s, Train Loss=2.17, validation loss=2.36] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:38<01:44,  1.51it/s, Train Loss=2.15, validation loss=2.34] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:38<01:42,  1.53it/s, Train Loss=2.15, validation loss=2.34] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:39<01:42,  1.53it/s, Train Loss=1.89, validation loss=2.34] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:39<01:39,  1.56it/s, Train Loss=1.89, validation loss=2.34] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:40<01:39,  1.56it/s, Train Loss=1.53, validation loss=2.34] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:40<01:38,  1.58it/s, Train Loss=1.53, validation loss=2.34] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:40<01:38,  1.58it/s, Train Loss=2.35, validation loss=2.34] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:40<01:36,  1.60it/s, Train Loss=2.35, validation loss=2.34] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:41<01:36,  1.60it/s, Train Loss=1.89, validation loss=2.35] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:41<01:35,  1.60it/s, Train Loss=1.89, validation loss=2.35] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:41<01:35,  1.60it/s, Train Loss=2.38, validation loss=2.36] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:41<01:36,  1.58it/s, Train Loss=2.38, validation loss=2.36] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:42<01:36,  1.58it/s, Train Loss=2.01, validation loss=2.36] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:42<01:39,  1.51it/s, Train Loss=2.01, validation loss=2.36] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:43<01:39,  1.51it/s, Train Loss=1.88, validation loss=2.35] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:43<01:42,  1.47it/s, Train Loss=1.88, validation loss=2.35] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:44<01:42,  1.47it/s, Train Loss=3.3, validation loss=2.34]  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:44<01:38,  1.51it/s, Train Loss=3.3, validation loss=2.34] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:44<01:38,  1.51it/s, Train Loss=2.69, validation loss=2.34] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:44<01:35,  1.55it/s, Train Loss=2.69, validation loss=2.34] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:45<01:35,  1.55it/s, Train Loss=2.02, validation loss=2.37] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:45<01:33,  1.58it/s, Train Loss=2.02, validation loss=2.37] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:45<01:33,  1.58it/s, Train Loss=1.77, validation loss=2.33] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:45<01:32,  1.58it/s, Train Loss=1.77, validation loss=2.33] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:46<01:32,  1.58it/s, Train Loss=1.7, validation loss=2.34]  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:46<01:30,  1.60it/s, Train Loss=1.7, validation loss=2.34] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:47<01:30,  1.60it/s, Train Loss=2.89, validation loss=2.34] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:47<01:33,  1.54it/s, Train Loss=2.89, validation loss=2.34] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:47<01:33,  1.54it/s, Train Loss=1.73, validation loss=2.34] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:47<01:37,  1.47it/s, Train Loss=1.73, validation loss=2.34] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:48<01:37,  1.47it/s, Train Loss=1.78, validation loss=2.35] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:48<01:34,  1.51it/s, Train Loss=1.78, validation loss=2.35] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:49<01:34,  1.51it/s, Train Loss=1.19, validation loss=2.36] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:49<01:32,  1.53it/s, Train Loss=1.19, validation loss=2.36] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:49<01:32,  1.53it/s, Train Loss=4.64, validation loss=2.35] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:49<01:29,  1.56it/s, Train Loss=4.64, validation loss=2.35] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:50<01:29,  1.56it/s, Train Loss=2.13, validation loss=2.36] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:50<01:29,  1.56it/s, Train Loss=2.13, validation loss=2.36] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:51<01:29,  1.56it/s, Train Loss=3.79, validation loss=2.34] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:51<01:27,  1.58it/s, Train Loss=3.79, validation loss=2.34] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:51<01:27,  1.58it/s, Train Loss=1.43, validation loss=2.35] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:51<01:26,  1.58it/s, Train Loss=1.43, validation loss=2.35] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:52<01:26,  1.58it/s, Train Loss=2.07, validation loss=2.34] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:52<01:30,  1.51it/s, Train Loss=2.07, validation loss=2.34] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:53<01:30,  1.51it/s, Train Loss=3.92, validation loss=2.34] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:53<01:33,  1.44it/s, Train Loss=3.92, validation loss=2.34] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:53<01:33,  1.44it/s, Train Loss=2.08, validation loss=2.34] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:53<01:35,  1.40it/s, Train Loss=2.08, validation loss=2.34] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:54<01:35,  1.40it/s, Train Loss=2.17, validation loss=2.36] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:54<01:36,  1.38it/s, Train Loss=2.17, validation loss=2.36] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:55<01:36,  1.38it/s, Train Loss=1.54, validation loss=2.34] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:55<01:35,  1.38it/s, Train Loss=1.54, validation loss=2.34] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:56<01:35,  1.38it/s, Train Loss=2.36, validation loss=2.34] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:56<01:33,  1.40it/s, Train Loss=2.36, validation loss=2.34] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:56<01:33,  1.40it/s, Train Loss=1.68, validation loss=2.33] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:56<01:32,  1.40it/s, Train Loss=1.68, validation loss=2.33] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:57<01:32,  1.40it/s, Train Loss=1.26, validation loss=2.35] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:57<01:29,  1.45it/s, Train Loss=1.26, validation loss=2.35] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:58<01:29,  1.45it/s, Train Loss=2.23, validation loss=2.35] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [03:58<01:25,  1.49it/s, Train Loss=2.23, validation loss=2.35] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [03:58<01:25,  1.49it/s, Train Loss=1.54, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [03:58<01:23,  1.53it/s, Train Loss=1.54, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [03:59<01:23,  1.53it/s, Train Loss=2.24, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [03:59<01:20,  1.57it/s, Train Loss=2.24, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [03:59<01:20,  1.57it/s, Train Loss=1.71, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [03:59<01:18,  1.59it/s, Train Loss=1.71, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:00<01:18,  1.59it/s, Train Loss=2.17, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:00<01:18,  1.58it/s, Train Loss=2.17, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:01<01:18,  1.58it/s, Train Loss=2.57, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:01<01:18,  1.57it/s, Train Loss=2.57, validation loss=2.35] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:01<01:18,  1.57it/s, Train Loss=1.91, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:01<01:16,  1.60it/s, Train Loss=1.91, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:02<01:16,  1.60it/s, Train Loss=2.6, validation loss=2.34]  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:02<01:17,  1.56it/s, Train Loss=2.6, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:03<01:17,  1.56it/s, Train Loss=1.89, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:03<01:16,  1.57it/s, Train Loss=1.89, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:03<01:16,  1.57it/s, Train Loss=2.23, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:03<01:17,  1.54it/s, Train Loss=2.23, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:04<01:17,  1.54it/s, Train Loss=1.71, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:04<01:15,  1.57it/s, Train Loss=1.71, validation loss=2.34] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:05<01:15,  1.57it/s, Train Loss=2.23, validation loss=2.35] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:05<01:14,  1.56it/s, Train Loss=2.23, validation loss=2.35] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:05<01:14,  1.56it/s, Train Loss=2.28, validation loss=2.33] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:05<01:12,  1.59it/s, Train Loss=2.28, validation loss=2.33] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:06<01:12,  1.59it/s, Train Loss=2.72, validation loss=2.36] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:06<01:10,  1.62it/s, Train Loss=2.72, validation loss=2.36] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:06<01:10,  1.62it/s, Train Loss=1.99, validation loss=2.35] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:06<01:09,  1.64it/s, Train Loss=1.99, validation loss=2.35] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:07<01:09,  1.64it/s, Train Loss=4.23, validation loss=2.34] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:07<01:08,  1.64it/s, Train Loss=4.23, validation loss=2.34] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:08<01:08,  1.64it/s, Train Loss=2.45, validation loss=2.33] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:08<01:07,  1.65it/s, Train Loss=2.45, validation loss=2.33] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:08<01:07,  1.65it/s, Train Loss=1.86, validation loss=2.36] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:08<01:07,  1.66it/s, Train Loss=1.86, validation loss=2.36] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:09<01:07,  1.66it/s, Train Loss=2.99, validation loss=2.35] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:09<01:06,  1.66it/s, Train Loss=2.99, validation loss=2.35] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:09<01:06,  1.66it/s, Train Loss=2.44, validation loss=2.35] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:09<01:06,  1.64it/s, Train Loss=2.44, validation loss=2.35] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:10<01:06,  1.64it/s, Train Loss=2.96, validation loss=2.34] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:10<01:05,  1.65it/s, Train Loss=2.96, validation loss=2.34] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:11<01:05,  1.65it/s, Train Loss=1.84, validation loss=2.36] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:11<01:04,  1.65it/s, Train Loss=1.84, validation loss=2.36] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:11<01:04,  1.65it/s, Train Loss=2.57, validation loss=2.34] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:11<01:04,  1.65it/s, Train Loss=2.57, validation loss=2.34] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:12<01:04,  1.65it/s, Train Loss=1.71, validation loss=2.34] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:12<01:03,  1.65it/s, Train Loss=1.71, validation loss=2.34] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:13<01:03,  1.65it/s, Train Loss=2.37, validation loss=2.33] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:13<01:08,  1.51it/s, Train Loss=2.37, validation loss=2.33] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:13<01:08,  1.51it/s, Train Loss=2.44, validation loss=2.33] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:13<01:09,  1.48it/s, Train Loss=2.44, validation loss=2.33] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:14<01:09,  1.48it/s, Train Loss=3.04, validation loss=2.34] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:14<01:08,  1.49it/s, Train Loss=3.04, validation loss=2.34] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:15<01:08,  1.49it/s, Train Loss=2.28, validation loss=2.34] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:15<01:06,  1.52it/s, Train Loss=2.28, validation loss=2.34]####################################################################################################
--------------------------------------------- Epoch:400 ---------------------------------------------
-- Training set:
Loss: 1.920228362083435, Lr: 6.25e-05
Average AUC ROC: 0.51                Average AUC PR: 0.29
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:15<01:06,  1.52it/s, Train Loss=1.92, validation loss=2.35] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:15<01:04,  1.56it/s, Train Loss=1.92, validation loss=2.35]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.3468620777130127
Average AUC ROC: 0.56                    Average AUC PR: 0.31
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:16<01:04,  1.56it/s, Train Loss=2.75, validation loss=2.35] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:16<01:02,  1.58it/s, Train Loss=2.75, validation loss=2.35] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:16<01:02,  1.58it/s, Train Loss=2.08, validation loss=2.34] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:16<01:01,  1.59it/s, Train Loss=2.08, validation loss=2.34] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:17<01:01,  1.59it/s, Train Loss=1.84, validation loss=2.35] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:17<01:00,  1.59it/s, Train Loss=1.84, validation loss=2.35] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:18<01:00,  1.59it/s, Train Loss=1.59, validation loss=2.34] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:18<00:58,  1.63it/s, Train Loss=1.59, validation loss=2.34] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:18<00:58,  1.63it/s, Train Loss=2.49, validation loss=2.33] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:18<00:58,  1.62it/s, Train Loss=2.49, validation loss=2.33] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:19<00:58,  1.62it/s, Train Loss=2.13, validation loss=2.33] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:19<00:57,  1.64it/s, Train Loss=2.13, validation loss=2.33] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:19<00:57,  1.64it/s, Train Loss=2.35, validation loss=2.34] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:19<00:56,  1.64it/s, Train Loss=2.35, validation loss=2.34] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:20<00:56,  1.64it/s, Train Loss=1.82, validation loss=2.34] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:20<00:56,  1.64it/s, Train Loss=1.82, validation loss=2.34] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:21<00:56,  1.64it/s, Train Loss=1.45, validation loss=2.35] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:21<00:56,  1.61it/s, Train Loss=1.45, validation loss=2.35] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:21<00:56,  1.61it/s, Train Loss=2.51, validation loss=2.33] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:21<00:56,  1.58it/s, Train Loss=2.51, validation loss=2.33] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:22<00:56,  1.58it/s, Train Loss=2.31, validation loss=2.33] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:22<00:56,  1.57it/s, Train Loss=2.31, validation loss=2.33] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:23<00:56,  1.57it/s, Train Loss=1.94, validation loss=2.34] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:23<00:54,  1.60it/s, Train Loss=1.94, validation loss=2.34] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:23<00:54,  1.60it/s, Train Loss=2.03, validation loss=2.35] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:23<00:53,  1.62it/s, Train Loss=2.03, validation loss=2.35] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:24<00:53,  1.62it/s, Train Loss=1.82, validation loss=2.33] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:24<00:53,  1.59it/s, Train Loss=1.82, validation loss=2.33] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:24<00:53,  1.59it/s, Train Loss=3.44, validation loss=2.34] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:24<00:52,  1.61it/s, Train Loss=3.44, validation loss=2.34] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:25<00:52,  1.61it/s, Train Loss=1.68, validation loss=2.35] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:25<00:51,  1.62it/s, Train Loss=1.68, validation loss=2.35] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:26<00:51,  1.62it/s, Train Loss=1.74, validation loss=2.35] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:26<00:51,  1.61it/s, Train Loss=1.74, validation loss=2.35] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:26<00:51,  1.61it/s, Train Loss=2.18, validation loss=2.34] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:26<00:51,  1.59it/s, Train Loss=2.18, validation loss=2.34] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:27<00:51,  1.59it/s, Train Loss=2.16, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:27<00:50,  1.60it/s, Train Loss=2.16, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:28<00:50,  1.60it/s, Train Loss=1.96, validation loss=2.33] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:28<00:49,  1.62it/s, Train Loss=1.96, validation loss=2.33] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:28<00:49,  1.62it/s, Train Loss=2.18, validation loss=2.34] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:28<00:48,  1.63it/s, Train Loss=2.18, validation loss=2.34] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:29<00:48,  1.63it/s, Train Loss=3.22, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:29<00:48,  1.62it/s, Train Loss=3.22, validation loss=2.35] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:29<00:48,  1.62it/s, Train Loss=1.97, validation loss=2.33] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:29<00:48,  1.58it/s, Train Loss=1.97, validation loss=2.33] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:30<00:48,  1.58it/s, Train Loss=1.57, validation loss=2.34] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:30<00:47,  1.59it/s, Train Loss=1.57, validation loss=2.34] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:31<00:47,  1.59it/s, Train Loss=1.74, validation loss=2.35] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:31<00:46,  1.60it/s, Train Loss=1.74, validation loss=2.35] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:31<00:46,  1.60it/s, Train Loss=2.44, validation loss=2.34] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:31<00:46,  1.60it/s, Train Loss=2.44, validation loss=2.34] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:32<00:46,  1.60it/s, Train Loss=2, validation loss=2.37]    85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:32<00:44,  1.63it/s, Train Loss=2, validation loss=2.37] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:33<00:44,  1.63it/s, Train Loss=2.5, validation loss=2.34] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:33<00:44,  1.61it/s, Train Loss=2.5, validation loss=2.34] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:33<00:44,  1.61it/s, Train Loss=2.31, validation loss=2.34] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:33<00:44,  1.60it/s, Train Loss=2.31, validation loss=2.34] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:34<00:44,  1.60it/s, Train Loss=2.18, validation loss=2.33] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:34<00:43,  1.62it/s, Train Loss=2.18, validation loss=2.33] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:34<00:43,  1.62it/s, Train Loss=1.94, validation loss=2.34] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:34<00:42,  1.62it/s, Train Loss=1.94, validation loss=2.34] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:35<00:42,  1.62it/s, Train Loss=1.91, validation loss=2.35] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:35<00:41,  1.64it/s, Train Loss=1.91, validation loss=2.35] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:36<00:41,  1.64it/s, Train Loss=1.79, validation loss=2.34] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:36<00:41,  1.62it/s, Train Loss=1.79, validation loss=2.34] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:36<00:41,  1.62it/s, Train Loss=2.63, validation loss=2.34] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:36<00:41,  1.59it/s, Train Loss=2.63, validation loss=2.34] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:37<00:41,  1.59it/s, Train Loss=3.12, validation loss=2.33] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:37<00:40,  1.59it/s, Train Loss=3.12, validation loss=2.33] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:38<00:40,  1.59it/s, Train Loss=1.98, validation loss=2.35] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:38<00:42,  1.52it/s, Train Loss=1.98, validation loss=2.35] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:38<00:42,  1.52it/s, Train Loss=2.11, validation loss=2.35] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:38<00:45,  1.37it/s, Train Loss=2.11, validation loss=2.35] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:39<00:45,  1.37it/s, Train Loss=1.86, validation loss=2.34] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:39<00:43,  1.43it/s, Train Loss=1.86, validation loss=2.34] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:40<00:43,  1.43it/s, Train Loss=1.91, validation loss=2.35] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:40<00:40,  1.50it/s, Train Loss=1.91, validation loss=2.35] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:40<00:40,  1.50it/s, Train Loss=1.96, validation loss=2.35] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:40<00:39,  1.54it/s, Train Loss=1.96, validation loss=2.35] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:41<00:39,  1.54it/s, Train Loss=2.57, validation loss=2.34] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:41<00:38,  1.55it/s, Train Loss=2.57, validation loss=2.34] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:42<00:38,  1.55it/s, Train Loss=2.07, validation loss=2.33] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:42<00:36,  1.58it/s, Train Loss=2.07, validation loss=2.33] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:42<00:36,  1.58it/s, Train Loss=2.21, validation loss=2.36] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:42<00:35,  1.59it/s, Train Loss=2.21, validation loss=2.36] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:43<00:35,  1.59it/s, Train Loss=1.95, validation loss=2.34] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:43<00:35,  1.58it/s, Train Loss=1.95, validation loss=2.34] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:43<00:35,  1.58it/s, Train Loss=2.87, validation loss=2.36] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:43<00:34,  1.59it/s, Train Loss=2.87, validation loss=2.36] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:44<00:34,  1.59it/s, Train Loss=2.41, validation loss=2.34] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:44<00:33,  1.62it/s, Train Loss=2.41, validation loss=2.34] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:45<00:33,  1.62it/s, Train Loss=1.11, validation loss=2.34] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:45<00:33,  1.60it/s, Train Loss=1.11, validation loss=2.34] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:45<00:33,  1.60it/s, Train Loss=2.34, validation loss=2.35] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:45<00:34,  1.53it/s, Train Loss=2.34, validation loss=2.35] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:46<00:34,  1.53it/s, Train Loss=2.37, validation loss=2.34] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:46<00:32,  1.56it/s, Train Loss=2.37, validation loss=2.34] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:47<00:32,  1.56it/s, Train Loss=2.02, validation loss=2.36] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:47<00:31,  1.58it/s, Train Loss=2.02, validation loss=2.36] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:47<00:31,  1.58it/s, Train Loss=1.74, validation loss=2.35] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:47<00:31,  1.58it/s, Train Loss=1.74, validation loss=2.35] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:48<00:31,  1.58it/s, Train Loss=2.63, validation loss=2.34] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:48<00:30,  1.60it/s, Train Loss=2.63, validation loss=2.34] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:48<00:30,  1.60it/s, Train Loss=2.4, validation loss=2.35]  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:48<00:29,  1.61it/s, Train Loss=2.4, validation loss=2.35] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:49<00:29,  1.61it/s, Train Loss=1.71, validation loss=2.33] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:49<00:28,  1.61it/s, Train Loss=1.71, validation loss=2.33] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:50<00:28,  1.61it/s, Train Loss=1.26, validation loss=2.34] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:50<00:27,  1.61it/s, Train Loss=1.26, validation loss=2.34] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:50<00:27,  1.61it/s, Train Loss=2.48, validation loss=2.34] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:50<00:27,  1.62it/s, Train Loss=2.48, validation loss=2.34] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:51<00:27,  1.62it/s, Train Loss=1.39, validation loss=2.34] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:51<00:26,  1.62it/s, Train Loss=1.39, validation loss=2.34] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:52<00:26,  1.62it/s, Train Loss=1.47, validation loss=2.34] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:52<00:25,  1.63it/s, Train Loss=1.47, validation loss=2.34] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:52<00:25,  1.63it/s, Train Loss=2.27, validation loss=2.33] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:52<00:24,  1.64it/s, Train Loss=2.27, validation loss=2.33] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:53<00:24,  1.64it/s, Train Loss=3.07, validation loss=2.34] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:53<00:25,  1.56it/s, Train Loss=3.07, validation loss=2.34] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:53<00:25,  1.56it/s, Train Loss=2.41, validation loss=2.34] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:53<00:24,  1.58it/s, Train Loss=2.41, validation loss=2.34] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:54<00:24,  1.58it/s, Train Loss=2.23, validation loss=2.34] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:54<00:24,  1.58it/s, Train Loss=2.23, validation loss=2.34] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:55<00:24,  1.58it/s, Train Loss=2.89, validation loss=2.34] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:55<00:23,  1.59it/s, Train Loss=2.89, validation loss=2.34] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:55<00:23,  1.59it/s, Train Loss=2.09, validation loss=2.34] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:55<00:22,  1.61it/s, Train Loss=2.09, validation loss=2.34] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:56<00:22,  1.61it/s, Train Loss=2.23, validation loss=2.34] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:56<00:21,  1.61it/s, Train Loss=2.23, validation loss=2.34] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [04:57<00:21,  1.61it/s, Train Loss=1.29, validation loss=2.34] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:57<00:21,  1.62it/s, Train Loss=1.29, validation loss=2.34] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [04:57<00:21,  1.62it/s, Train Loss=2.45, validation loss=2.33] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [04:57<00:20,  1.62it/s, Train Loss=2.45, validation loss=2.33] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [04:58<00:20,  1.62it/s, Train Loss=2.98, validation loss=2.34] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [04:58<00:19,  1.64it/s, Train Loss=2.98, validation loss=2.34] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [04:58<00:19,  1.64it/s, Train Loss=1.63, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [04:58<00:19,  1.62it/s, Train Loss=1.63, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [04:59<00:19,  1.62it/s, Train Loss=2.57, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [04:59<00:18,  1.61it/s, Train Loss=2.57, validation loss=2.35] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:00<00:18,  1.61it/s, Train Loss=2.02, validation loss=2.34] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:00<00:18,  1.54it/s, Train Loss=2.02, validation loss=2.34] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:00<00:18,  1.54it/s, Train Loss=2.12, validation loss=2.33] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:00<00:17,  1.56it/s, Train Loss=2.12, validation loss=2.33] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:01<00:17,  1.56it/s, Train Loss=1.9, validation loss=2.33]  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:01<00:17,  1.54it/s, Train Loss=1.9, validation loss=2.33] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:02<00:17,  1.54it/s, Train Loss=2.94, validation loss=2.33] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:02<00:16,  1.54it/s, Train Loss=2.94, validation loss=2.33] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:02<00:16,  1.54it/s, Train Loss=2.28, validation loss=2.35] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:02<00:16,  1.54it/s, Train Loss=2.28, validation loss=2.35] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:03<00:16,  1.54it/s, Train Loss=1.96, validation loss=2.34] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:03<00:15,  1.55it/s, Train Loss=1.96, validation loss=2.34] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:04<00:15,  1.55it/s, Train Loss=1.93, validation loss=2.34] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:04<00:16,  1.43it/s, Train Loss=1.93, validation loss=2.34] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:04<00:16,  1.43it/s, Train Loss=4.01, validation loss=2.36] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:04<00:14,  1.48it/s, Train Loss=4.01, validation loss=2.36] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:05<00:14,  1.48it/s, Train Loss=2.07, validation loss=2.33] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:05<00:13,  1.53it/s, Train Loss=2.07, validation loss=2.33] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:06<00:13,  1.53it/s, Train Loss=1.67, validation loss=2.33] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:06<00:12,  1.57it/s, Train Loss=1.67, validation loss=2.33] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:06<00:12,  1.57it/s, Train Loss=2.05, validation loss=2.34] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:06<00:11,  1.60it/s, Train Loss=2.05, validation loss=2.34] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:07<00:11,  1.60it/s, Train Loss=2.54, validation loss=2.34] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:07<00:11,  1.53it/s, Train Loss=2.54, validation loss=2.34] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:08<00:11,  1.53it/s, Train Loss=1.68, validation loss=2.33] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:08<00:10,  1.56it/s, Train Loss=1.68, validation loss=2.33] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:08<00:10,  1.56it/s, Train Loss=2.07, validation loss=2.34] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:08<00:10,  1.60it/s, Train Loss=2.07, validation loss=2.34] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:09<00:10,  1.60it/s, Train Loss=2.95, validation loss=2.34] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:09<00:09,  1.59it/s, Train Loss=2.95, validation loss=2.34] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:09<00:09,  1.59it/s, Train Loss=2.6, validation loss=2.34]  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:09<00:08,  1.64it/s, Train Loss=2.6, validation loss=2.34] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:10<00:08,  1.64it/s, Train Loss=3.29, validation loss=2.34] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:10<00:07,  1.64it/s, Train Loss=3.29, validation loss=2.34] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:11<00:07,  1.64it/s, Train Loss=2.07, validation loss=2.33] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:11<00:07,  1.63it/s, Train Loss=2.07, validation loss=2.33] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:11<00:07,  1.63it/s, Train Loss=2.29, validation loss=2.35] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:11<00:06,  1.64it/s, Train Loss=2.29, validation loss=2.35] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:12<00:06,  1.64it/s, Train Loss=1.97, validation loss=2.35] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:12<00:06,  1.61it/s, Train Loss=1.97, validation loss=2.35] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:12<00:06,  1.61it/s, Train Loss=2.19, validation loss=2.35] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:12<00:05,  1.59it/s, Train Loss=2.19, validation loss=2.35] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:13<00:05,  1.59it/s, Train Loss=1.97, validation loss=2.34] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:13<00:04,  1.61it/s, Train Loss=1.97, validation loss=2.34] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:14<00:04,  1.61it/s, Train Loss=3.48, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:14<00:04,  1.53it/s, Train Loss=3.48, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:14<00:04,  1.53it/s, Train Loss=2.71, validation loss=2.33] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:14<00:03,  1.54it/s, Train Loss=2.71, validation loss=2.33] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:15<00:03,  1.54it/s, Train Loss=1.61, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:15<00:03,  1.56it/s, Train Loss=1.61, validation loss=2.35] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:16<00:03,  1.56it/s, Train Loss=2.03, validation loss=2.34] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:16<00:02,  1.59it/s, Train Loss=2.03, validation loss=2.34] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:16<00:02,  1.59it/s, Train Loss=1.81, validation loss=2.34] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:16<00:01,  1.59it/s, Train Loss=1.81, validation loss=2.34] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:17<00:01,  1.59it/s, Train Loss=2.12, validation loss=2.35]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:17<00:01,  1.59it/s, Train Loss=2.12, validation loss=2.35]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:18<00:01,  1.59it/s, Train Loss=1.84, validation loss=2.35]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:18<00:00,  1.59it/s, Train Loss=1.84, validation loss=2.35]####################################################################################################
--------------------------------------------- Epoch:500 ---------------------------------------------
-- Training set:
Loss: 2.8254826068878174, Lr: 3.125e-05
Average AUC ROC: 0.53                Average AUC PR: 0.3
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:18<00:00,  1.59it/s, Train Loss=2.83, validation loss=2.35]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:18<00:00,  1.60it/s, Train Loss=2.83, validation loss=2.35]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:18<00:00,  1.57it/s, Train Loss=2.83, validation loss=2.35]
----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.348147213459015
Average AUC ROC: 0.56                    Average AUC PR: 0.31

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 841
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=0, validation loss=0]  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=3.88, validation loss=3.18]  0%|          | 1/500 [00:00<05:07,  1.62it/s, Train Loss=3.88, validation loss=3.18]  0%|          | 1/500 [00:01<05:07,  1.62it/s, Train Loss=2.31, validation loss=2.93]  0%|          | 2/500 [00:01<04:59,  1.66it/s, Train Loss=2.31, validation loss=2.93]  0%|          | 2/500 [00:01<04:59,  1.66it/s, Train Loss=3.55, validation loss=2.8]   1%|          | 3/500 [00:01<05:31,  1.50it/s, Train Loss=3.55, validation loss=2.8]  1%|          | 3/500 [00:02<05:31,  1.50it/s, Train Loss=4.32, validation loss=2.71]  1%|          | 4/500 [00:02<05:21,  1.54it/s, Train Loss=4.32, validation loss=2.71]  1%|          | 4/500 [00:03<05:21,  1.54it/s, Train Loss=2.59, validation loss=2.7]   1%|          | 5/500 [00:03<05:07,  1.61it/s, Train Loss=2.59, validation loss=2.7]  1%|          | 5/500 [00:03<05:07,  1.61it/s, Train Loss=3.53, validation loss=2.7]  1%|          | 6/500 [00:03<05:09,  1.60it/s, Train Loss=3.53, validation loss=2.7]  1%|          | 6/500 [00:04<05:09,  1.60it/s, Train Loss=2.65, validation loss=2.68]  1%|â–         | 7/500 [00:04<05:05,  1.61it/s, Train Loss=2.65, validation loss=2.68]  1%|â–         | 7/500 [00:05<05:05,  1.61it/s, Train Loss=3.62, validation loss=2.73]  2%|â–         | 8/500 [00:05<05:15,  1.56it/s, Train Loss=3.62, validation loss=2.73]  2%|â–         | 8/500 [00:05<05:15,  1.56it/s, Train Loss=3.8, validation loss=2.69]   2%|â–         | 9/500 [00:05<05:30,  1.49it/s, Train Loss=3.8, validation loss=2.69]  2%|â–         | 9/500 [00:06<05:30,  1.49it/s, Train Loss=3.19, validation loss=2.69]  2%|â–         | 10/500 [00:06<05:19,  1.53it/s, Train Loss=3.19, validation loss=2.69]  2%|â–         | 10/500 [00:07<05:19,  1.53it/s, Train Loss=3.49, validation loss=2.65]  2%|â–         | 11/500 [00:07<05:10,  1.57it/s, Train Loss=3.49, validation loss=2.65]  2%|â–         | 11/500 [00:07<05:10,  1.57it/s, Train Loss=2.18, validation loss=2.71]  2%|â–         | 12/500 [00:07<05:13,  1.56it/s, Train Loss=2.18, validation loss=2.71]  2%|â–         | 12/500 [00:08<05:13,  1.56it/s, Train Loss=2.53, validation loss=2.67]  3%|â–         | 13/500 [00:08<05:10,  1.57it/s, Train Loss=2.53, validation loss=2.67]  3%|â–         | 13/500 [00:08<05:10,  1.57it/s, Train Loss=2.27, validation loss=2.66]  3%|â–         | 14/500 [00:08<05:01,  1.61it/s, Train Loss=2.27, validation loss=2.66]  3%|â–         | 14/500 [00:09<05:01,  1.61it/s, Train Loss=4.06, validation loss=2.66]  3%|â–         | 15/500 [00:09<05:11,  1.56it/s, Train Loss=4.06, validation loss=2.66]  3%|â–         | 15/500 [00:10<05:11,  1.56it/s, Train Loss=3.45, validation loss=2.63]  3%|â–         | 16/500 [00:10<05:05,  1.59it/s, Train Loss=3.45, validation loss=2.63]  3%|â–         | 16/500 [00:10<05:05,  1.59it/s, Train Loss=3.13, validation loss=2.69]  3%|â–         | 17/500 [00:10<05:04,  1.58it/s, Train Loss=3.13, validation loss=2.69]  3%|â–         | 17/500 [00:11<05:04,  1.58it/s, Train Loss=2.45, validation loss=2.64]  4%|â–         | 18/500 [00:11<05:01,  1.60it/s, Train Loss=2.45, validation loss=2.64]  4%|â–         | 18/500 [00:12<05:01,  1.60it/s, Train Loss=1.66, validation loss=2.62]  4%|â–         | 19/500 [00:12<05:01,  1.60it/s, Train Loss=1.66, validation loss=2.62]  4%|â–         | 19/500 [00:12<05:01,  1.60it/s, Train Loss=1.78, validation loss=2.63]  4%|â–         | 20/500 [00:12<04:54,  1.63it/s, Train Loss=1.78, validation loss=2.63]  4%|â–         | 20/500 [00:13<04:54,  1.63it/s, Train Loss=2.72, validation loss=2.62]  4%|â–         | 21/500 [00:13<04:51,  1.64it/s, Train Loss=2.72, validation loss=2.62]  4%|â–         | 21/500 [00:13<04:51,  1.64it/s, Train Loss=3.15, validation loss=2.59]  4%|â–         | 22/500 [00:13<04:57,  1.60it/s, Train Loss=3.15, validation loss=2.59]  4%|â–         | 22/500 [00:14<04:57,  1.60it/s, Train Loss=2.53, validation loss=2.61]  5%|â–         | 23/500 [00:14<04:59,  1.59it/s, Train Loss=2.53, validation loss=2.61]  5%|â–         | 23/500 [00:15<04:59,  1.59it/s, Train Loss=2.32, validation loss=2.58]  5%|â–         | 24/500 [00:15<04:56,  1.60it/s, Train Loss=2.32, validation loss=2.58]  5%|â–         | 24/500 [00:15<04:56,  1.60it/s, Train Loss=2.38, validation loss=2.6]   5%|â–Œ         | 25/500 [00:15<05:17,  1.50it/s, Train Loss=2.38, validation loss=2.6]  5%|â–Œ         | 25/500 [00:16<05:17,  1.50it/s, Train Loss=2.87, validation loss=2.56]  5%|â–Œ         | 26/500 [00:16<05:10,  1.53it/s, Train Loss=2.87, validation loss=2.56]  5%|â–Œ         | 26/500 [00:17<05:10,  1.53it/s, Train Loss=2.17, validation loss=2.56]  5%|â–Œ         | 27/500 [00:17<05:06,  1.54it/s, Train Loss=2.17, validation loss=2.56]  5%|â–Œ         | 27/500 [00:17<05:06,  1.54it/s, Train Loss=1.79, validation loss=2.54]  6%|â–Œ         | 28/500 [00:17<05:02,  1.56it/s, Train Loss=1.79, validation loss=2.54]  6%|â–Œ         | 28/500 [00:18<05:02,  1.56it/s, Train Loss=3.14, validation loss=2.55]  6%|â–Œ         | 29/500 [00:18<05:00,  1.56it/s, Train Loss=3.14, validation loss=2.55]  6%|â–Œ         | 29/500 [00:19<05:00,  1.56it/s, Train Loss=2.04, validation loss=2.52]  6%|â–Œ         | 30/500 [00:19<04:57,  1.58it/s, Train Loss=2.04, validation loss=2.52]  6%|â–Œ         | 30/500 [00:19<04:57,  1.58it/s, Train Loss=2.79, validation loss=2.51]  6%|â–Œ         | 31/500 [00:19<04:54,  1.59it/s, Train Loss=2.79, validation loss=2.51]  6%|â–Œ         | 31/500 [00:20<04:54,  1.59it/s, Train Loss=4.04, validation loss=2.51]  6%|â–‹         | 32/500 [00:20<04:53,  1.59it/s, Train Loss=4.04, validation loss=2.51]  6%|â–‹         | 32/500 [00:20<04:53,  1.59it/s, Train Loss=2.28, validation loss=2.55]  7%|â–‹         | 33/500 [00:20<04:54,  1.58it/s, Train Loss=2.28, validation loss=2.55]  7%|â–‹         | 33/500 [00:21<04:54,  1.58it/s, Train Loss=2.2, validation loss=2.52]   7%|â–‹         | 34/500 [00:21<04:52,  1.59it/s, Train Loss=2.2, validation loss=2.52]  7%|â–‹         | 34/500 [00:22<04:52,  1.59it/s, Train Loss=1.81, validation loss=2.56]  7%|â–‹         | 35/500 [00:22<05:05,  1.52it/s, Train Loss=1.81, validation loss=2.56]  7%|â–‹         | 35/500 [00:22<05:05,  1.52it/s, Train Loss=2.74, validation loss=2.51]  7%|â–‹         | 36/500 [00:22<05:01,  1.54it/s, Train Loss=2.74, validation loss=2.51]  7%|â–‹         | 36/500 [00:23<05:01,  1.54it/s, Train Loss=2.56, validation loss=2.53]  7%|â–‹         | 37/500 [00:23<04:58,  1.55it/s, Train Loss=2.56, validation loss=2.53]  7%|â–‹         | 37/500 [00:24<04:58,  1.55it/s, Train Loss=4.11, validation loss=2.53]  8%|â–Š         | 38/500 [00:24<04:53,  1.58it/s, Train Loss=4.11, validation loss=2.53]  8%|â–Š         | 38/500 [00:24<04:53,  1.58it/s, Train Loss=3.81, validation loss=2.5]   8%|â–Š         | 39/500 [00:24<04:49,  1.59it/s, Train Loss=3.81, validation loss=2.5]  8%|â–Š         | 39/500 [00:25<04:49,  1.59it/s, Train Loss=4.06, validation loss=2.51]  8%|â–Š         | 40/500 [00:25<04:57,  1.55it/s, Train Loss=4.06, validation loss=2.51]  8%|â–Š         | 40/500 [00:26<04:57,  1.55it/s, Train Loss=2.1, validation loss=2.5]    8%|â–Š         | 41/500 [00:26<05:02,  1.52it/s, Train Loss=2.1, validation loss=2.5]  8%|â–Š         | 41/500 [00:26<05:02,  1.52it/s, Train Loss=2.48, validation loss=2.51]  8%|â–Š         | 42/500 [00:26<04:54,  1.56it/s, Train Loss=2.48, validation loss=2.51]  8%|â–Š         | 42/500 [00:27<04:54,  1.56it/s, Train Loss=2.66, validation loss=2.52]  9%|â–Š         | 43/500 [00:27<04:46,  1.59it/s, Train Loss=2.66, validation loss=2.52]  9%|â–Š         | 43/500 [00:27<04:46,  1.59it/s, Train Loss=2.13, validation loss=2.52]  9%|â–‰         | 44/500 [00:27<04:44,  1.61it/s, Train Loss=2.13, validation loss=2.52]  9%|â–‰         | 44/500 [00:28<04:44,  1.61it/s, Train Loss=2.43, validation loss=2.49]  9%|â–‰         | 45/500 [00:28<04:55,  1.54it/s, Train Loss=2.43, validation loss=2.49]  9%|â–‰         | 45/500 [00:29<04:55,  1.54it/s, Train Loss=1.87, validation loss=2.49]  9%|â–‰         | 46/500 [00:29<04:49,  1.57it/s, Train Loss=1.87, validation loss=2.49]  9%|â–‰         | 46/500 [00:29<04:49,  1.57it/s, Train Loss=3.54, validation loss=2.48]  9%|â–‰         | 47/500 [00:29<04:44,  1.59it/s, Train Loss=3.54, validation loss=2.48]  9%|â–‰         | 47/500 [00:30<04:44,  1.59it/s, Train Loss=2.64, validation loss=2.48] 10%|â–‰         | 48/500 [00:30<04:43,  1.60it/s, Train Loss=2.64, validation loss=2.48] 10%|â–‰         | 48/500 [00:31<04:43,  1.60it/s, Train Loss=2.8, validation loss=2.45]  10%|â–‰         | 49/500 [00:31<04:44,  1.58it/s, Train Loss=2.8, validation loss=2.45] 10%|â–‰         | 49/500 [00:31<04:44,  1.58it/s, Train Loss=3.86, validation loss=2.48] 10%|â–ˆ         | 50/500 [00:31<04:45,  1.58it/s, Train Loss=3.86, validation loss=2.48] 10%|â–ˆ         | 50/500 [00:32<04:45,  1.58it/s, Train Loss=3.22, validation loss=2.47] 10%|â–ˆ         | 51/500 [00:32<04:41,  1.59it/s, Train Loss=3.22, validation loss=2.47] 10%|â–ˆ         | 51/500 [00:33<04:41,  1.59it/s, Train Loss=1.31, validation loss=2.49] 10%|â–ˆ         | 52/500 [00:33<04:42,  1.59it/s, Train Loss=1.31, validation loss=2.49] 10%|â–ˆ         | 52/500 [00:33<04:42,  1.59it/s, Train Loss=2.65, validation loss=2.48] 11%|â–ˆ         | 53/500 [00:33<04:44,  1.57it/s, Train Loss=2.65, validation loss=2.48] 11%|â–ˆ         | 53/500 [00:34<04:44,  1.57it/s, Train Loss=2.52, validation loss=2.46] 11%|â–ˆ         | 54/500 [00:34<04:40,  1.59it/s, Train Loss=2.52, validation loss=2.46] 11%|â–ˆ         | 54/500 [00:35<04:40,  1.59it/s, Train Loss=1.96, validation loss=2.46] 11%|â–ˆ         | 55/500 [00:35<04:56,  1.50it/s, Train Loss=1.96, validation loss=2.46] 11%|â–ˆ         | 55/500 [00:35<04:56,  1.50it/s, Train Loss=3.49, validation loss=2.45] 11%|â–ˆ         | 56/500 [00:35<04:49,  1.53it/s, Train Loss=3.49, validation loss=2.45] 11%|â–ˆ         | 56/500 [00:36<04:49,  1.53it/s, Train Loss=2.12, validation loss=2.46] 11%|â–ˆâ–        | 57/500 [00:36<04:42,  1.57it/s, Train Loss=2.12, validation loss=2.46] 11%|â–ˆâ–        | 57/500 [00:36<04:42,  1.57it/s, Train Loss=1.94, validation loss=2.46] 12%|â–ˆâ–        | 58/500 [00:36<04:38,  1.58it/s, Train Loss=1.94, validation loss=2.46] 12%|â–ˆâ–        | 58/500 [00:37<04:38,  1.58it/s, Train Loss=3.68, validation loss=2.44] 12%|â–ˆâ–        | 59/500 [00:37<04:38,  1.58it/s, Train Loss=3.68, validation loss=2.44] 12%|â–ˆâ–        | 59/500 [00:38<04:38,  1.58it/s, Train Loss=2.05, validation loss=2.45] 12%|â–ˆâ–        | 60/500 [00:38<04:39,  1.58it/s, Train Loss=2.05, validation loss=2.45] 12%|â–ˆâ–        | 60/500 [00:38<04:39,  1.58it/s, Train Loss=3.24, validation loss=2.45] 12%|â–ˆâ–        | 61/500 [00:38<04:37,  1.58it/s, Train Loss=3.24, validation loss=2.45] 12%|â–ˆâ–        | 61/500 [00:39<04:37,  1.58it/s, Train Loss=1.83, validation loss=2.44] 12%|â–ˆâ–        | 62/500 [00:39<04:38,  1.57it/s, Train Loss=1.83, validation loss=2.44] 12%|â–ˆâ–        | 62/500 [00:40<04:38,  1.57it/s, Train Loss=2.66, validation loss=2.41] 13%|â–ˆâ–        | 63/500 [00:40<04:35,  1.58it/s, Train Loss=2.66, validation loss=2.41] 13%|â–ˆâ–        | 63/500 [00:40<04:35,  1.58it/s, Train Loss=2.04, validation loss=2.42] 13%|â–ˆâ–        | 64/500 [00:40<04:33,  1.59it/s, Train Loss=2.04, validation loss=2.42] 13%|â–ˆâ–        | 64/500 [00:41<04:33,  1.59it/s, Train Loss=1.89, validation loss=2.38] 13%|â–ˆâ–        | 65/500 [00:41<04:47,  1.51it/s, Train Loss=1.89, validation loss=2.38] 13%|â–ˆâ–        | 65/500 [00:42<04:47,  1.51it/s, Train Loss=1.47, validation loss=2.4]  13%|â–ˆâ–        | 66/500 [00:42<04:43,  1.53it/s, Train Loss=1.47, validation loss=2.4] 13%|â–ˆâ–        | 66/500 [00:42<04:43,  1.53it/s, Train Loss=3.18, validation loss=2.4] 13%|â–ˆâ–        | 67/500 [00:42<04:42,  1.53it/s, Train Loss=3.18, validation loss=2.4] 13%|â–ˆâ–        | 67/500 [00:43<04:42,  1.53it/s, Train Loss=4.05, validation loss=2.39] 14%|â–ˆâ–        | 68/500 [00:43<04:38,  1.55it/s, Train Loss=4.05, validation loss=2.39] 14%|â–ˆâ–        | 68/500 [00:43<04:38,  1.55it/s, Train Loss=1.97, validation loss=2.41] 14%|â–ˆâ–        | 69/500 [00:43<04:32,  1.58it/s, Train Loss=1.97, validation loss=2.41] 14%|â–ˆâ–        | 69/500 [00:44<04:32,  1.58it/s, Train Loss=3.15, validation loss=2.42] 14%|â–ˆâ–        | 70/500 [00:44<04:30,  1.59it/s, Train Loss=3.15, validation loss=2.42] 14%|â–ˆâ–        | 70/500 [00:45<04:30,  1.59it/s, Train Loss=2.4, validation loss=2.39]  14%|â–ˆâ–        | 71/500 [00:45<04:27,  1.60it/s, Train Loss=2.4, validation loss=2.39] 14%|â–ˆâ–        | 71/500 [00:45<04:27,  1.60it/s, Train Loss=2.14, validation loss=2.42] 14%|â–ˆâ–        | 72/500 [00:45<04:38,  1.54it/s, Train Loss=2.14, validation loss=2.42] 14%|â–ˆâ–        | 72/500 [00:46<04:38,  1.54it/s, Train Loss=1.71, validation loss=2.4]  15%|â–ˆâ–        | 73/500 [00:46<04:43,  1.51it/s, Train Loss=1.71, validation loss=2.4] 15%|â–ˆâ–        | 73/500 [00:47<04:43,  1.51it/s, Train Loss=1.58, validation loss=2.4] 15%|â–ˆâ–        | 74/500 [00:47<04:38,  1.53it/s, Train Loss=1.58, validation loss=2.4] 15%|â–ˆâ–        | 74/500 [00:47<04:38,  1.53it/s, Train Loss=2.57, validation loss=2.38] 15%|â–ˆâ–Œ        | 75/500 [00:47<04:52,  1.45it/s, Train Loss=2.57, validation loss=2.38] 15%|â–ˆâ–Œ        | 75/500 [00:48<04:52,  1.45it/s, Train Loss=2.85, validation loss=2.41] 15%|â–ˆâ–Œ        | 76/500 [00:48<04:42,  1.50it/s, Train Loss=2.85, validation loss=2.41] 15%|â–ˆâ–Œ        | 76/500 [00:49<04:42,  1.50it/s, Train Loss=4.78, validation loss=2.38] 15%|â–ˆâ–Œ        | 77/500 [00:49<04:34,  1.54it/s, Train Loss=4.78, validation loss=2.38] 15%|â–ˆâ–Œ        | 77/500 [00:49<04:34,  1.54it/s, Train Loss=4.28, validation loss=2.36] 16%|â–ˆâ–Œ        | 78/500 [00:49<04:30,  1.56it/s, Train Loss=4.28, validation loss=2.36] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:30,  1.56it/s, Train Loss=2.14, validation loss=2.38] 16%|â–ˆâ–Œ        | 79/500 [00:50<04:28,  1.57it/s, Train Loss=2.14, validation loss=2.38] 16%|â–ˆâ–Œ        | 79/500 [00:51<04:28,  1.57it/s, Train Loss=2, validation loss=2.41]    16%|â–ˆâ–Œ        | 80/500 [00:51<04:25,  1.58it/s, Train Loss=2, validation loss=2.41] 16%|â–ˆâ–Œ        | 80/500 [00:51<04:25,  1.58it/s, Train Loss=1.81, validation loss=2.39] 16%|â–ˆâ–Œ        | 81/500 [00:51<04:21,  1.60it/s, Train Loss=1.81, validation loss=2.39] 16%|â–ˆâ–Œ        | 81/500 [00:52<04:21,  1.60it/s, Train Loss=1.74, validation loss=2.39] 16%|â–ˆâ–‹        | 82/500 [00:52<04:22,  1.59it/s, Train Loss=1.74, validation loss=2.39] 16%|â–ˆâ–‹        | 82/500 [00:52<04:22,  1.59it/s, Train Loss=2.13, validation loss=2.37] 17%|â–ˆâ–‹        | 83/500 [00:52<04:22,  1.59it/s, Train Loss=2.13, validation loss=2.37] 17%|â–ˆâ–‹        | 83/500 [00:53<04:22,  1.59it/s, Train Loss=2.9, validation loss=2.35]  17%|â–ˆâ–‹        | 84/500 [00:53<04:38,  1.50it/s, Train Loss=2.9, validation loss=2.35] 17%|â–ˆâ–‹        | 84/500 [00:54<04:38,  1.50it/s, Train Loss=2.22, validation loss=2.35] 17%|â–ˆâ–‹        | 85/500 [00:54<04:33,  1.52it/s, Train Loss=2.22, validation loss=2.35] 17%|â–ˆâ–‹        | 85/500 [00:54<04:33,  1.52it/s, Train Loss=2.63, validation loss=2.34] 17%|â–ˆâ–‹        | 86/500 [00:54<04:28,  1.54it/s, Train Loss=2.63, validation loss=2.34] 17%|â–ˆâ–‹        | 86/500 [00:55<04:28,  1.54it/s, Train Loss=2.19, validation loss=2.35] 17%|â–ˆâ–‹        | 87/500 [00:55<04:23,  1.56it/s, Train Loss=2.19, validation loss=2.35] 17%|â–ˆâ–‹        | 87/500 [00:56<04:23,  1.56it/s, Train Loss=1.77, validation loss=2.34] 18%|â–ˆâ–Š        | 88/500 [00:56<04:19,  1.59it/s, Train Loss=1.77, validation loss=2.34] 18%|â–ˆâ–Š        | 88/500 [00:56<04:19,  1.59it/s, Train Loss=1.9, validation loss=2.35]  18%|â–ˆâ–Š        | 89/500 [00:56<04:19,  1.58it/s, Train Loss=1.9, validation loss=2.35] 18%|â–ˆâ–Š        | 89/500 [00:57<04:19,  1.58it/s, Train Loss=2.63, validation loss=2.35] 18%|â–ˆâ–Š        | 90/500 [00:57<04:17,  1.59it/s, Train Loss=2.63, validation loss=2.35] 18%|â–ˆâ–Š        | 90/500 [00:58<04:17,  1.59it/s, Train Loss=1.37, validation loss=2.34] 18%|â–ˆâ–Š        | 91/500 [00:58<04:14,  1.61it/s, Train Loss=1.37, validation loss=2.34] 18%|â–ˆâ–Š        | 91/500 [00:58<04:14,  1.61it/s, Train Loss=1.55, validation loss=2.37] 18%|â–ˆâ–Š        | 92/500 [00:58<04:11,  1.62it/s, Train Loss=1.55, validation loss=2.37] 18%|â–ˆâ–Š        | 92/500 [00:59<04:11,  1.62it/s, Train Loss=2.17, validation loss=2.35] 19%|â–ˆâ–Š        | 93/500 [00:59<04:18,  1.58it/s, Train Loss=2.17, validation loss=2.35] 19%|â–ˆâ–Š        | 93/500 [00:59<04:18,  1.58it/s, Train Loss=2.09, validation loss=2.37] 19%|â–ˆâ–‰        | 94/500 [00:59<04:15,  1.59it/s, Train Loss=2.09, validation loss=2.37] 19%|â–ˆâ–‰        | 94/500 [01:00<04:15,  1.59it/s, Train Loss=2.47, validation loss=2.33] 19%|â–ˆâ–‰        | 95/500 [01:00<04:16,  1.58it/s, Train Loss=2.47, validation loss=2.33] 19%|â–ˆâ–‰        | 95/500 [01:01<04:16,  1.58it/s, Train Loss=2.26, validation loss=2.32] 19%|â–ˆâ–‰        | 96/500 [01:01<04:17,  1.57it/s, Train Loss=2.26, validation loss=2.32] 19%|â–ˆâ–‰        | 96/500 [01:01<04:17,  1.57it/s, Train Loss=2.49, validation loss=2.33] 19%|â–ˆâ–‰        | 97/500 [01:01<04:16,  1.57it/s, Train Loss=2.49, validation loss=2.33] 19%|â–ˆâ–‰        | 97/500 [01:02<04:16,  1.57it/s, Train Loss=2.24, validation loss=2.32] 20%|â–ˆâ–‰        | 98/500 [01:02<04:11,  1.60it/s, Train Loss=2.24, validation loss=2.32] 20%|â–ˆâ–‰        | 98/500 [01:03<04:11,  1.60it/s, Train Loss=2.56, validation loss=2.34] 20%|â–ˆâ–‰        | 99/500 [01:03<04:12,  1.59it/s, Train Loss=2.56, validation loss=2.34]####################################################################################################
--------------------------------------------- Epoch:100 ---------------------------------------------
-- Training set:
Loss: 2.2457685470581055, Lr: 0.0005
Average AUC ROC: 0.52                Average AUC PR: 0.28
 20%|â–ˆâ–‰        | 99/500 [01:03<04:12,  1.59it/s, Train Loss=2.25, validation loss=2.32] 20%|â–ˆâ–ˆ        | 100/500 [01:03<04:08,  1.61it/s, Train Loss=2.25, validation loss=2.32]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.322991631925106
Average AUC ROC: 0.58                    Average AUC PR: 0.31
 20%|â–ˆâ–ˆ        | 100/500 [01:04<04:08,  1.61it/s, Train Loss=2.28, validation loss=2.33] 20%|â–ˆâ–ˆ        | 101/500 [01:04<04:08,  1.60it/s, Train Loss=2.28, validation loss=2.33] 20%|â–ˆâ–ˆ        | 101/500 [01:05<04:08,  1.60it/s, Train Loss=3.49, validation loss=2.32] 20%|â–ˆâ–ˆ        | 102/500 [01:05<04:18,  1.54it/s, Train Loss=3.49, validation loss=2.32] 20%|â–ˆâ–ˆ        | 102/500 [01:05<04:18,  1.54it/s, Train Loss=2.42, validation loss=2.32] 21%|â–ˆâ–ˆ        | 103/500 [01:05<04:18,  1.54it/s, Train Loss=2.42, validation loss=2.32] 21%|â–ˆâ–ˆ        | 103/500 [01:06<04:18,  1.54it/s, Train Loss=1.59, validation loss=2.31] 21%|â–ˆâ–ˆ        | 104/500 [01:06<04:11,  1.57it/s, Train Loss=1.59, validation loss=2.31] 21%|â–ˆâ–ˆ        | 104/500 [01:06<04:11,  1.57it/s, Train Loss=1.8, validation loss=2.33]  21%|â–ˆâ–ˆ        | 105/500 [01:06<04:11,  1.57it/s, Train Loss=1.8, validation loss=2.33] 21%|â–ˆâ–ˆ        | 105/500 [01:07<04:11,  1.57it/s, Train Loss=2.39, validation loss=2.32] 21%|â–ˆâ–ˆ        | 106/500 [01:07<04:06,  1.60it/s, Train Loss=2.39, validation loss=2.32] 21%|â–ˆâ–ˆ        | 106/500 [01:08<04:06,  1.60it/s, Train Loss=2.43, validation loss=2.33] 21%|â–ˆâ–ˆâ–       | 107/500 [01:08<04:03,  1.61it/s, Train Loss=2.43, validation loss=2.33] 21%|â–ˆâ–ˆâ–       | 107/500 [01:08<04:03,  1.61it/s, Train Loss=1.76, validation loss=2.31] 22%|â–ˆâ–ˆâ–       | 108/500 [01:08<04:00,  1.63it/s, Train Loss=1.76, validation loss=2.31] 22%|â–ˆâ–ˆâ–       | 108/500 [01:09<04:00,  1.63it/s, Train Loss=2.16, validation loss=2.3]  22%|â–ˆâ–ˆâ–       | 109/500 [01:09<04:00,  1.63it/s, Train Loss=2.16, validation loss=2.3] 22%|â–ˆâ–ˆâ–       | 109/500 [01:09<04:00,  1.63it/s, Train Loss=1.61, validation loss=2.32] 22%|â–ˆâ–ˆâ–       | 110/500 [01:09<04:00,  1.62it/s, Train Loss=1.61, validation loss=2.32] 22%|â–ˆâ–ˆâ–       | 110/500 [01:10<04:00,  1.62it/s, Train Loss=2.94, validation loss=2.3]  22%|â–ˆâ–ˆâ–       | 111/500 [01:10<04:15,  1.52it/s, Train Loss=2.94, validation loss=2.3] 22%|â–ˆâ–ˆâ–       | 111/500 [01:11<04:15,  1.52it/s, Train Loss=3.01, validation loss=2.29] 22%|â–ˆâ–ˆâ–       | 112/500 [01:11<04:22,  1.48it/s, Train Loss=3.01, validation loss=2.29] 22%|â–ˆâ–ˆâ–       | 112/500 [01:12<04:22,  1.48it/s, Train Loss=2.26, validation loss=2.31] 23%|â–ˆâ–ˆâ–       | 113/500 [01:12<04:34,  1.41it/s, Train Loss=2.26, validation loss=2.31] 23%|â–ˆâ–ˆâ–       | 113/500 [01:12<04:34,  1.41it/s, Train Loss=1.87, validation loss=2.29] 23%|â–ˆâ–ˆâ–       | 114/500 [01:12<04:26,  1.45it/s, Train Loss=1.87, validation loss=2.29] 23%|â–ˆâ–ˆâ–       | 114/500 [01:13<04:26,  1.45it/s, Train Loss=2.67, validation loss=2.3]  23%|â–ˆâ–ˆâ–       | 115/500 [01:13<04:17,  1.50it/s, Train Loss=2.67, validation loss=2.3] 23%|â–ˆâ–ˆâ–       | 115/500 [01:14<04:17,  1.50it/s, Train Loss=1.8, validation loss=2.34] 23%|â–ˆâ–ˆâ–       | 116/500 [01:14<04:13,  1.51it/s, Train Loss=1.8, validation loss=2.34] 23%|â–ˆâ–ˆâ–       | 116/500 [01:14<04:13,  1.51it/s, Train Loss=1.69, validation loss=2.31] 23%|â–ˆâ–ˆâ–       | 117/500 [01:14<04:07,  1.55it/s, Train Loss=1.69, validation loss=2.31] 23%|â–ˆâ–ˆâ–       | 117/500 [01:15<04:07,  1.55it/s, Train Loss=2.32, validation loss=2.3]  24%|â–ˆâ–ˆâ–       | 118/500 [01:15<04:02,  1.57it/s, Train Loss=2.32, validation loss=2.3] 24%|â–ˆâ–ˆâ–       | 118/500 [01:16<04:02,  1.57it/s, Train Loss=3.12, validation loss=2.3] 24%|â–ˆâ–ˆâ–       | 119/500 [01:16<04:03,  1.57it/s, Train Loss=3.12, validation loss=2.3] 24%|â–ˆâ–ˆâ–       | 119/500 [01:16<04:03,  1.57it/s, Train Loss=1.46, validation loss=2.29] 24%|â–ˆâ–ˆâ–       | 120/500 [01:16<04:15,  1.49it/s, Train Loss=1.46, validation loss=2.29] 24%|â–ˆâ–ˆâ–       | 120/500 [01:17<04:15,  1.49it/s, Train Loss=2.79, validation loss=2.32] 24%|â–ˆâ–ˆâ–       | 121/500 [01:17<04:06,  1.53it/s, Train Loss=2.79, validation loss=2.32] 24%|â–ˆâ–ˆâ–       | 121/500 [01:18<04:06,  1.53it/s, Train Loss=1.8, validation loss=2.3]   24%|â–ˆâ–ˆâ–       | 122/500 [01:18<04:13,  1.49it/s, Train Loss=1.8, validation loss=2.3] 24%|â–ˆâ–ˆâ–       | 122/500 [01:18<04:13,  1.49it/s, Train Loss=2.21, validation loss=2.31] 25%|â–ˆâ–ˆâ–       | 123/500 [01:18<04:11,  1.50it/s, Train Loss=2.21, validation loss=2.31] 25%|â–ˆâ–ˆâ–       | 123/500 [01:19<04:11,  1.50it/s, Train Loss=1.9, validation loss=2.3]   25%|â–ˆâ–ˆâ–       | 124/500 [01:19<04:03,  1.54it/s, Train Loss=1.9, validation loss=2.3] 25%|â–ˆâ–ˆâ–       | 124/500 [01:19<04:03,  1.54it/s, Train Loss=1.82, validation loss=2.31] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:19<03:58,  1.57it/s, Train Loss=1.82, validation loss=2.31] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:20<03:58,  1.57it/s, Train Loss=1.98, validation loss=2.32] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:20<03:54,  1.60it/s, Train Loss=1.98, validation loss=2.32] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:21<03:54,  1.60it/s, Train Loss=2.04, validation loss=2.29] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:21<03:55,  1.59it/s, Train Loss=2.04, validation loss=2.29] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:21<03:55,  1.59it/s, Train Loss=1.93, validation loss=2.28] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:21<04:05,  1.52it/s, Train Loss=1.93, validation loss=2.28] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:22<04:05,  1.52it/s, Train Loss=3.32, validation loss=2.29] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:22<03:58,  1.56it/s, Train Loss=3.32, validation loss=2.29] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:23<03:58,  1.56it/s, Train Loss=1.44, validation loss=2.3]  26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:23<04:05,  1.51it/s, Train Loss=1.44, validation loss=2.3] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:23<04:05,  1.51it/s, Train Loss=2.14, validation loss=2.29] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:23<04:05,  1.51it/s, Train Loss=2.14, validation loss=2.29] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:24<04:05,  1.51it/s, Train Loss=1.81, validation loss=2.29] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:24<04:06,  1.49it/s, Train Loss=1.81, validation loss=2.29] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:25<04:06,  1.49it/s, Train Loss=1.77, validation loss=2.28] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:25<04:07,  1.48it/s, Train Loss=1.77, validation loss=2.28] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:25<04:07,  1.48it/s, Train Loss=2.76, validation loss=2.28] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:25<04:05,  1.49it/s, Train Loss=2.76, validation loss=2.28] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:26<04:05,  1.49it/s, Train Loss=3.36, validation loss=2.29] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:26<04:09,  1.46it/s, Train Loss=3.36, validation loss=2.29] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:27<04:09,  1.46it/s, Train Loss=2.77, validation loss=2.28] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:27<04:15,  1.42it/s, Train Loss=2.77, validation loss=2.28] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:27<04:15,  1.42it/s, Train Loss=2.76, validation loss=2.29] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:27<04:03,  1.49it/s, Train Loss=2.76, validation loss=2.29] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:28<04:03,  1.49it/s, Train Loss=2.59, validation loss=2.32] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:28<03:57,  1.53it/s, Train Loss=2.59, validation loss=2.32] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:29<03:57,  1.53it/s, Train Loss=2.17, validation loss=2.3]  28%|â–ˆâ–ˆâ–Š       | 139/500 [01:29<03:53,  1.55it/s, Train Loss=2.17, validation loss=2.3] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:29<03:53,  1.55it/s, Train Loss=3.21, validation loss=2.29] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:29<03:48,  1.57it/s, Train Loss=3.21, validation loss=2.29] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:30<03:48,  1.57it/s, Train Loss=1.76, validation loss=2.29] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:30<03:47,  1.58it/s, Train Loss=1.76, validation loss=2.29] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:31<03:47,  1.58it/s, Train Loss=1.71, validation loss=2.29] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:31<03:47,  1.58it/s, Train Loss=1.71, validation loss=2.29] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:31<03:47,  1.58it/s, Train Loss=2.51, validation loss=2.28] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:31<03:56,  1.51it/s, Train Loss=2.51, validation loss=2.28] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:32<03:56,  1.51it/s, Train Loss=3.64, validation loss=2.27] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:32<04:19,  1.37it/s, Train Loss=3.64, validation loss=2.27] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:33<04:19,  1.37it/s, Train Loss=2.28, validation loss=2.29] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:33<04:20,  1.36it/s, Train Loss=2.28, validation loss=2.29] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:34<04:20,  1.36it/s, Train Loss=2.7, validation loss=2.35]  29%|â–ˆâ–ˆâ–‰       | 146/500 [01:34<04:16,  1.38it/s, Train Loss=2.7, validation loss=2.35] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:34<04:16,  1.38it/s, Train Loss=3.92, validation loss=2.28] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:34<04:19,  1.36it/s, Train Loss=3.92, validation loss=2.28] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:35<04:19,  1.36it/s, Train Loss=1.85, validation loss=2.3]  30%|â–ˆâ–ˆâ–‰       | 148/500 [01:35<04:21,  1.35it/s, Train Loss=1.85, validation loss=2.3] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:36<04:21,  1.35it/s, Train Loss=2.08, validation loss=2.31] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:36<04:22,  1.33it/s, Train Loss=2.08, validation loss=2.31] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:37<04:22,  1.33it/s, Train Loss=1.85, validation loss=2.31] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:37<04:22,  1.33it/s, Train Loss=1.85, validation loss=2.31] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:37<04:22,  1.33it/s, Train Loss=2.55, validation loss=2.31] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:37<04:14,  1.37it/s, Train Loss=2.55, validation loss=2.31] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:38<04:14,  1.37it/s, Train Loss=3.12, validation loss=2.31] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:38<04:07,  1.40it/s, Train Loss=3.12, validation loss=2.31] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:39<04:07,  1.40it/s, Train Loss=3.01, validation loss=2.3]  31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:39<04:00,  1.44it/s, Train Loss=3.01, validation loss=2.3] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:39<04:00,  1.44it/s, Train Loss=2.51, validation loss=2.3] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:39<03:54,  1.47it/s, Train Loss=2.51, validation loss=2.3] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:40<03:54,  1.47it/s, Train Loss=2.76, validation loss=2.3] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:40<03:46,  1.52it/s, Train Loss=2.76, validation loss=2.3] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:41<03:46,  1.52it/s, Train Loss=2.77, validation loss=2.28] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:41<03:42,  1.55it/s, Train Loss=2.77, validation loss=2.28] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:41<03:42,  1.55it/s, Train Loss=2.51, validation loss=2.27] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:41<03:38,  1.57it/s, Train Loss=2.51, validation loss=2.27] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:42<03:38,  1.57it/s, Train Loss=2.08, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:42<03:35,  1.59it/s, Train Loss=2.08, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:42<03:35,  1.59it/s, Train Loss=2.48, validation loss=2.28] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:42<03:33,  1.60it/s, Train Loss=2.48, validation loss=2.28] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:43<03:33,  1.60it/s, Train Loss=2.67, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:43<03:47,  1.50it/s, Train Loss=2.67, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:44<03:47,  1.50it/s, Train Loss=1.91, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:44<03:39,  1.54it/s, Train Loss=1.91, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:44<03:39,  1.54it/s, Train Loss=2.64, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:44<03:35,  1.57it/s, Train Loss=2.64, validation loss=2.27] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:45<03:35,  1.57it/s, Train Loss=2.66, validation loss=2.28] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:45<03:33,  1.58it/s, Train Loss=2.66, validation loss=2.28] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:46<03:33,  1.58it/s, Train Loss=1.62, validation loss=2.29] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:46<03:29,  1.60it/s, Train Loss=1.62, validation loss=2.29] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:46<03:29,  1.60it/s, Train Loss=2.43, validation loss=2.29] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:46<03:26,  1.62it/s, Train Loss=2.43, validation loss=2.29] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:47<03:26,  1.62it/s, Train Loss=2.56, validation loss=2.28] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:47<03:25,  1.62it/s, Train Loss=2.56, validation loss=2.28] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:47<03:25,  1.62it/s, Train Loss=1.53, validation loss=2.3]  33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:47<03:26,  1.61it/s, Train Loss=1.53, validation loss=2.3] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:48<03:26,  1.61it/s, Train Loss=2.37, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:48<03:36,  1.53it/s, Train Loss=2.37, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:49<03:36,  1.53it/s, Train Loss=1.53, validation loss=2.29] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:49<03:32,  1.56it/s, Train Loss=1.53, validation loss=2.29] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:49<03:32,  1.56it/s, Train Loss=1.71, validation loss=2.3]  34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:49<03:31,  1.56it/s, Train Loss=1.71, validation loss=2.3] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:50<03:31,  1.56it/s, Train Loss=1.15, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:50<03:28,  1.58it/s, Train Loss=1.15, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:51<03:28,  1.58it/s, Train Loss=2.44, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:51<03:23,  1.61it/s, Train Loss=2.44, validation loss=2.28] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:51<03:23,  1.61it/s, Train Loss=2.39, validation loss=2.27] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:51<03:22,  1.62it/s, Train Loss=2.39, validation loss=2.27] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:52<03:22,  1.62it/s, Train Loss=1.9, validation loss=2.28]  35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:52<03:30,  1.55it/s, Train Loss=1.9, validation loss=2.28] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:53<03:30,  1.55it/s, Train Loss=2.19, validation loss=2.28] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:53<03:38,  1.49it/s, Train Loss=2.19, validation loss=2.28] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:53<03:38,  1.49it/s, Train Loss=2.98, validation loss=2.27] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:53<03:44,  1.45it/s, Train Loss=2.98, validation loss=2.27] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:54<03:44,  1.45it/s, Train Loss=1.68, validation loss=2.28] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:54<03:37,  1.49it/s, Train Loss=1.68, validation loss=2.28] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:55<03:37,  1.49it/s, Train Loss=2, validation loss=2.28]    36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:55<03:29,  1.54it/s, Train Loss=2, validation loss=2.28] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:55<03:29,  1.54it/s, Train Loss=1.67, validation loss=2.26] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:55<03:25,  1.56it/s, Train Loss=1.67, validation loss=2.26] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:56<03:25,  1.56it/s, Train Loss=2.35, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:56<03:22,  1.58it/s, Train Loss=2.35, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:57<03:22,  1.58it/s, Train Loss=3.55, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:57<03:20,  1.59it/s, Train Loss=3.55, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:57<03:20,  1.59it/s, Train Loss=1.73, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:57<03:17,  1.61it/s, Train Loss=1.73, validation loss=2.27] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:58<03:17,  1.61it/s, Train Loss=1.53, validation loss=2.27] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:58<03:16,  1.62it/s, Train Loss=1.53, validation loss=2.27] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:58<03:16,  1.62it/s, Train Loss=2.87, validation loss=2.26] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:58<03:25,  1.54it/s, Train Loss=2.87, validation loss=2.26] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:59<03:25,  1.54it/s, Train Loss=1.69, validation loss=2.27] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:59<03:22,  1.56it/s, Train Loss=1.69, validation loss=2.27] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [02:00<03:22,  1.56it/s, Train Loss=2.2, validation loss=2.26]  37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:00<03:19,  1.57it/s, Train Loss=2.2, validation loss=2.26] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:00<03:19,  1.57it/s, Train Loss=2.37, validation loss=2.25] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:00<03:17,  1.58it/s, Train Loss=2.37, validation loss=2.25] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:01<03:17,  1.58it/s, Train Loss=1.58, validation loss=2.31] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:01<03:13,  1.62it/s, Train Loss=1.58, validation loss=2.31] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:02<03:13,  1.62it/s, Train Loss=1.79, validation loss=2.26] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:02<03:13,  1.61it/s, Train Loss=1.79, validation loss=2.26] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:02<03:13,  1.61it/s, Train Loss=1.41, validation loss=2.28] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:02<03:10,  1.63it/s, Train Loss=1.41, validation loss=2.28] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:03<03:10,  1.63it/s, Train Loss=1.72, validation loss=2.25] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:03<03:11,  1.62it/s, Train Loss=1.72, validation loss=2.25] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:03<03:11,  1.62it/s, Train Loss=2.46, validation loss=2.27] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:03<03:17,  1.56it/s, Train Loss=2.46, validation loss=2.27] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:04<03:17,  1.56it/s, Train Loss=2.03, validation loss=2.25] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:04<03:16,  1.56it/s, Train Loss=2.03, validation loss=2.25] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:05<03:16,  1.56it/s, Train Loss=2.85, validation loss=2.26] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:05<03:16,  1.55it/s, Train Loss=2.85, validation loss=2.26] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:05<03:16,  1.55it/s, Train Loss=4.07, validation loss=2.26] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:05<03:12,  1.59it/s, Train Loss=4.07, validation loss=2.26] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:06<03:12,  1.59it/s, Train Loss=1.28, validation loss=2.25] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:06<03:07,  1.63it/s, Train Loss=1.28, validation loss=2.25] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:07<03:07,  1.63it/s, Train Loss=3.12, validation loss=2.24] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:07<03:05,  1.63it/s, Train Loss=3.12, validation loss=2.24] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:07<03:05,  1.63it/s, Train Loss=2.35, validation loss=2.29] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:07<03:07,  1.61it/s, Train Loss=2.35, validation loss=2.29] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:08<03:07,  1.61it/s, Train Loss=3.19, validation loss=2.26] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:08<03:07,  1.60it/s, Train Loss=3.19, validation loss=2.26]####################################################################################################
--------------------------------------------- Epoch:200 ---------------------------------------------
-- Training set:
Loss: 2.0730934143066406, Lr: 0.00025
Average AUC ROC: 0.53                Average AUC PR: 0.29
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:09<03:07,  1.60it/s, Train Loss=2.07, validation loss=2.27] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:09<03:15,  1.53it/s, Train Loss=2.07, validation loss=2.27]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.2665021643042564
Average AUC ROC: 0.58                    Average AUC PR: 0.32
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:09<03:15,  1.53it/s, Train Loss=3.05, validation loss=2.26] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:09<03:11,  1.56it/s, Train Loss=3.05, validation loss=2.26] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:10<03:11,  1.56it/s, Train Loss=2.11, validation loss=2.24] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:10<03:08,  1.58it/s, Train Loss=2.11, validation loss=2.24] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:10<03:08,  1.58it/s, Train Loss=2.82, validation loss=2.25] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:10<03:08,  1.58it/s, Train Loss=2.82, validation loss=2.25] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:11<03:08,  1.58it/s, Train Loss=2.05, validation loss=2.27] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:11<03:07,  1.58it/s, Train Loss=2.05, validation loss=2.27] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:12<03:07,  1.58it/s, Train Loss=1.3, validation loss=2.28]  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:12<03:06,  1.58it/s, Train Loss=1.3, validation loss=2.28] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:12<03:06,  1.58it/s, Train Loss=2.03, validation loss=2.27] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:12<03:13,  1.52it/s, Train Loss=2.03, validation loss=2.27] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:13<03:13,  1.52it/s, Train Loss=2.65, validation loss=2.26] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:13<03:19,  1.47it/s, Train Loss=2.65, validation loss=2.26] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:14<03:19,  1.47it/s, Train Loss=2.63, validation loss=2.29] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:14<03:24,  1.43it/s, Train Loss=2.63, validation loss=2.29] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:15<03:24,  1.43it/s, Train Loss=1.38, validation loss=2.28] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:15<03:18,  1.46it/s, Train Loss=1.38, validation loss=2.28] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:15<03:18,  1.46it/s, Train Loss=2.11, validation loss=2.25] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:15<03:12,  1.50it/s, Train Loss=2.11, validation loss=2.25] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:16<03:12,  1.50it/s, Train Loss=1.92, validation loss=2.26] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:16<03:10,  1.52it/s, Train Loss=1.92, validation loss=2.26] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:16<03:10,  1.52it/s, Train Loss=1.91, validation loss=2.26] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:16<03:05,  1.55it/s, Train Loss=1.91, validation loss=2.26] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:17<03:05,  1.55it/s, Train Loss=1.95, validation loss=2.25] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:17<03:02,  1.57it/s, Train Loss=1.95, validation loss=2.25] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:18<03:02,  1.57it/s, Train Loss=1.93, validation loss=2.26] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:18<02:58,  1.60it/s, Train Loss=1.93, validation loss=2.26] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:18<02:58,  1.60it/s, Train Loss=1.32, validation loss=2.25] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:18<03:09,  1.50it/s, Train Loss=1.32, validation loss=2.25] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:19<03:09,  1.50it/s, Train Loss=2.17, validation loss=2.26] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:19<03:07,  1.51it/s, Train Loss=2.17, validation loss=2.26] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:20<03:07,  1.51it/s, Train Loss=1.69, validation loss=2.29] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:20<03:03,  1.54it/s, Train Loss=1.69, validation loss=2.29] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:20<03:03,  1.54it/s, Train Loss=1.63, validation loss=2.28] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:20<02:58,  1.58it/s, Train Loss=1.63, validation loss=2.28] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:21<02:58,  1.58it/s, Train Loss=2.18, validation loss=2.26] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:21<02:58,  1.57it/s, Train Loss=2.18, validation loss=2.26] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:22<02:58,  1.57it/s, Train Loss=1.99, validation loss=2.26] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:22<02:58,  1.57it/s, Train Loss=1.99, validation loss=2.26] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:22<02:58,  1.57it/s, Train Loss=1.87, validation loss=2.29] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:22<02:55,  1.59it/s, Train Loss=1.87, validation loss=2.29] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:23<02:55,  1.59it/s, Train Loss=3.55, validation loss=2.25] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:23<02:55,  1.58it/s, Train Loss=3.55, validation loss=2.25] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:24<02:55,  1.58it/s, Train Loss=1.49, validation loss=2.27] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:24<03:03,  1.51it/s, Train Loss=1.49, validation loss=2.27] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:24<03:03,  1.51it/s, Train Loss=2.31, validation loss=2.27] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:24<02:57,  1.56it/s, Train Loss=2.31, validation loss=2.27] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:25<02:57,  1.56it/s, Train Loss=3.05, validation loss=2.25] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:25<02:52,  1.59it/s, Train Loss=3.05, validation loss=2.25] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:25<02:52,  1.59it/s, Train Loss=1.85, validation loss=2.24] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:25<02:51,  1.60it/s, Train Loss=1.85, validation loss=2.24] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:26<02:51,  1.60it/s, Train Loss=2.08, validation loss=2.27] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:26<02:50,  1.60it/s, Train Loss=2.08, validation loss=2.27] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:27<02:50,  1.60it/s, Train Loss=3.09, validation loss=2.26] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:27<02:49,  1.60it/s, Train Loss=3.09, validation loss=2.26] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:27<02:49,  1.60it/s, Train Loss=1.31, validation loss=2.27] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:27<02:47,  1.62it/s, Train Loss=1.31, validation loss=2.27] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:28<02:47,  1.62it/s, Train Loss=4.34, validation loss=2.26] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:28<02:58,  1.51it/s, Train Loss=4.34, validation loss=2.26] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:29<02:58,  1.51it/s, Train Loss=2.39, validation loss=2.26] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:29<02:56,  1.53it/s, Train Loss=2.39, validation loss=2.26] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:29<02:56,  1.53it/s, Train Loss=2.52, validation loss=2.25] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:29<02:52,  1.55it/s, Train Loss=2.52, validation loss=2.25] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:30<02:52,  1.55it/s, Train Loss=1.69, validation loss=2.25] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:30<02:51,  1.55it/s, Train Loss=1.69, validation loss=2.25] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:30<02:51,  1.55it/s, Train Loss=1.74, validation loss=2.26] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:30<02:49,  1.57it/s, Train Loss=1.74, validation loss=2.26] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:31<02:49,  1.57it/s, Train Loss=2.15, validation loss=2.24] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:31<02:47,  1.59it/s, Train Loss=2.15, validation loss=2.24] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:32<02:47,  1.59it/s, Train Loss=2.13, validation loss=2.23] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:32<02:44,  1.60it/s, Train Loss=2.13, validation loss=2.23] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:32<02:44,  1.60it/s, Train Loss=2.17, validation loss=2.26] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:32<02:52,  1.52it/s, Train Loss=2.17, validation loss=2.26] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:33<02:52,  1.52it/s, Train Loss=1.87, validation loss=2.25] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:33<02:50,  1.54it/s, Train Loss=1.87, validation loss=2.25] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:34<02:50,  1.54it/s, Train Loss=2.35, validation loss=2.25] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:34<02:49,  1.54it/s, Train Loss=2.35, validation loss=2.25] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:34<02:49,  1.54it/s, Train Loss=2.47, validation loss=2.25] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:34<02:48,  1.54it/s, Train Loss=2.47, validation loss=2.25] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:35<02:48,  1.54it/s, Train Loss=1.55, validation loss=2.24] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:35<02:46,  1.56it/s, Train Loss=1.55, validation loss=2.24] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:36<02:46,  1.56it/s, Train Loss=1.51, validation loss=2.25] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:36<02:44,  1.57it/s, Train Loss=1.51, validation loss=2.25] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:36<02:44,  1.57it/s, Train Loss=2.23, validation loss=2.24] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:36<02:42,  1.58it/s, Train Loss=2.23, validation loss=2.24] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:37<02:42,  1.58it/s, Train Loss=3.27, validation loss=2.24] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:37<02:42,  1.58it/s, Train Loss=3.27, validation loss=2.24] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:38<02:42,  1.58it/s, Train Loss=1.65, validation loss=2.25] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:38<02:47,  1.52it/s, Train Loss=1.65, validation loss=2.25] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:38<02:47,  1.52it/s, Train Loss=1.54, validation loss=2.25] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:38<02:54,  1.46it/s, Train Loss=1.54, validation loss=2.25] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:39<02:54,  1.46it/s, Train Loss=2.14, validation loss=2.26] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:39<02:49,  1.49it/s, Train Loss=2.14, validation loss=2.26] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:40<02:49,  1.49it/s, Train Loss=3.01, validation loss=2.28] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:40<02:45,  1.52it/s, Train Loss=3.01, validation loss=2.28] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:40<02:45,  1.52it/s, Train Loss=3.11, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:40<02:42,  1.54it/s, Train Loss=3.11, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:41<02:42,  1.54it/s, Train Loss=2.37, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:41<02:40,  1.56it/s, Train Loss=2.37, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:41<02:40,  1.56it/s, Train Loss=1.54, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:41<02:39,  1.56it/s, Train Loss=1.54, validation loss=2.25] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:42<02:39,  1.56it/s, Train Loss=2.58, validation loss=2.24] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:42<02:44,  1.51it/s, Train Loss=2.58, validation loss=2.24] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:43<02:44,  1.51it/s, Train Loss=2.08, validation loss=2.26] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:43<02:41,  1.53it/s, Train Loss=2.08, validation loss=2.26] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:43<02:41,  1.53it/s, Train Loss=2.11, validation loss=2.26] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:43<02:37,  1.57it/s, Train Loss=2.11, validation loss=2.26] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:44<02:37,  1.57it/s, Train Loss=2.19, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:44<02:36,  1.57it/s, Train Loss=2.19, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:45<02:36,  1.57it/s, Train Loss=1.79, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:45<02:35,  1.56it/s, Train Loss=1.79, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:45<02:35,  1.56it/s, Train Loss=1.7, validation loss=2.25]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:45<02:37,  1.55it/s, Train Loss=1.7, validation loss=2.25] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:46<02:37,  1.55it/s, Train Loss=2.44, validation loss=2.25] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:46<02:34,  1.56it/s, Train Loss=2.44, validation loss=2.25] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:47<02:34,  1.56it/s, Train Loss=3.7, validation loss=2.24]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:47<02:38,  1.52it/s, Train Loss=3.7, validation loss=2.24] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:47<02:38,  1.52it/s, Train Loss=1.62, validation loss=2.26] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:47<02:36,  1.54it/s, Train Loss=1.62, validation loss=2.26] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:48<02:36,  1.54it/s, Train Loss=3.02, validation loss=2.25] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:48<02:34,  1.55it/s, Train Loss=3.02, validation loss=2.25] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:49<02:34,  1.55it/s, Train Loss=2.51, validation loss=2.25] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:49<02:30,  1.58it/s, Train Loss=2.51, validation loss=2.25] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:49<02:30,  1.58it/s, Train Loss=1.56, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:49<02:30,  1.58it/s, Train Loss=1.56, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:50<02:30,  1.58it/s, Train Loss=2.08, validation loss=2.24] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:50<02:27,  1.60it/s, Train Loss=2.08, validation loss=2.24] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:50<02:27,  1.60it/s, Train Loss=2.35, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:50<02:27,  1.59it/s, Train Loss=2.35, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:51<02:27,  1.59it/s, Train Loss=1.15, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:51<02:36,  1.49it/s, Train Loss=1.15, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:52<02:36,  1.49it/s, Train Loss=1.54, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:52<02:33,  1.52it/s, Train Loss=1.54, validation loss=2.25] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:52<02:33,  1.52it/s, Train Loss=3.49, validation loss=2.24] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:52<02:29,  1.55it/s, Train Loss=3.49, validation loss=2.24] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:53<02:29,  1.55it/s, Train Loss=2.55, validation loss=2.23] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:53<02:28,  1.56it/s, Train Loss=2.55, validation loss=2.23] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:54<02:28,  1.56it/s, Train Loss=2.28, validation loss=2.24] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:54<02:26,  1.57it/s, Train Loss=2.28, validation loss=2.24] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:54<02:26,  1.57it/s, Train Loss=3.34, validation loss=2.24] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:54<02:25,  1.57it/s, Train Loss=3.34, validation loss=2.24] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:55<02:25,  1.57it/s, Train Loss=1.67, validation loss=2.24] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:55<02:22,  1.60it/s, Train Loss=1.67, validation loss=2.24] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:56<02:22,  1.60it/s, Train Loss=2.02, validation loss=2.23] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:56<02:31,  1.50it/s, Train Loss=2.02, validation loss=2.23] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:56<02:31,  1.50it/s, Train Loss=1.86, validation loss=2.25] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:56<02:28,  1.52it/s, Train Loss=1.86, validation loss=2.25] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:57<02:28,  1.52it/s, Train Loss=1.29, validation loss=2.25] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:57<02:26,  1.54it/s, Train Loss=1.29, validation loss=2.25] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:58<02:26,  1.54it/s, Train Loss=2.83, validation loss=2.24] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:58<02:23,  1.56it/s, Train Loss=2.83, validation loss=2.24] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:58<02:23,  1.56it/s, Train Loss=1.19, validation loss=2.24] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:58<02:26,  1.52it/s, Train Loss=1.19, validation loss=2.24] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:59<02:26,  1.52it/s, Train Loss=3.48, validation loss=2.24] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:59<02:31,  1.47it/s, Train Loss=3.48, validation loss=2.24] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [03:00<02:31,  1.47it/s, Train Loss=1.42, validation loss=2.23] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:00<02:27,  1.50it/s, Train Loss=1.42, validation loss=2.23] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:00<02:27,  1.50it/s, Train Loss=2.75, validation loss=2.26] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:00<02:29,  1.47it/s, Train Loss=2.75, validation loss=2.26] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:01<02:29,  1.47it/s, Train Loss=1.38, validation loss=2.26] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:01<02:25,  1.50it/s, Train Loss=1.38, validation loss=2.26] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:02<02:25,  1.50it/s, Train Loss=1.35, validation loss=2.24] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:02<02:22,  1.53it/s, Train Loss=1.35, validation loss=2.24] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:02<02:22,  1.53it/s, Train Loss=1.61, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:02<02:18,  1.56it/s, Train Loss=1.61, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:03<02:18,  1.56it/s, Train Loss=2.76, validation loss=2.24] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:03<02:17,  1.57it/s, Train Loss=2.76, validation loss=2.24] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:04<02:17,  1.57it/s, Train Loss=2.26, validation loss=2.24] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:04<02:18,  1.56it/s, Train Loss=2.26, validation loss=2.24] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:04<02:18,  1.56it/s, Train Loss=1.53, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:04<02:15,  1.58it/s, Train Loss=1.53, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:05<02:15,  1.58it/s, Train Loss=1.92, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:05<02:13,  1.59it/s, Train Loss=1.92, validation loss=2.25] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:05<02:13,  1.59it/s, Train Loss=2.12, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:05<02:20,  1.51it/s, Train Loss=2.12, validation loss=2.27] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:06<02:20,  1.51it/s, Train Loss=2.03, validation loss=2.24] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:06<02:18,  1.53it/s, Train Loss=2.03, validation loss=2.24] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:07<02:18,  1.53it/s, Train Loss=2.64, validation loss=2.25] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:07<02:15,  1.54it/s, Train Loss=2.64, validation loss=2.25] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:07<02:15,  1.54it/s, Train Loss=1.77, validation loss=2.24] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:07<02:13,  1.56it/s, Train Loss=1.77, validation loss=2.24] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:08<02:13,  1.56it/s, Train Loss=1.8, validation loss=2.25]  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:08<02:11,  1.58it/s, Train Loss=1.8, validation loss=2.25] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:09<02:11,  1.58it/s, Train Loss=2.83, validation loss=2.24] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:09<02:08,  1.61it/s, Train Loss=2.83, validation loss=2.24] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:09<02:08,  1.61it/s, Train Loss=2.18, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:09<02:13,  1.54it/s, Train Loss=2.18, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:10<02:13,  1.54it/s, Train Loss=2.22, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:10<02:12,  1.55it/s, Train Loss=2.22, validation loss=2.25] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:11<02:12,  1.55it/s, Train Loss=1.73, validation loss=2.26] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:11<02:08,  1.59it/s, Train Loss=1.73, validation loss=2.26] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:11<02:08,  1.59it/s, Train Loss=3.87, validation loss=2.23] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:11<02:08,  1.58it/s, Train Loss=3.87, validation loss=2.23] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:12<02:08,  1.58it/s, Train Loss=1.52, validation loss=2.25] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:12<02:07,  1.59it/s, Train Loss=1.52, validation loss=2.25] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:12<02:07,  1.59it/s, Train Loss=2.42, validation loss=2.24] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:12<02:05,  1.61it/s, Train Loss=2.42, validation loss=2.24]####################################################################################################
--------------------------------------------- Epoch:300 ---------------------------------------------
-- Training set:
Loss: 3.373635768890381, Lr: 0.000125
Average AUC ROC: 0.52                Average AUC PR: 0.28
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:13<02:05,  1.61it/s, Train Loss=3.37, validation loss=2.23] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:13<02:04,  1.61it/s, Train Loss=3.37, validation loss=2.23]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.227813795208931
Average AUC ROC: 0.58                    Average AUC PR: 0.32
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:14<02:04,  1.61it/s, Train Loss=2.05, validation loss=2.24] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:14<02:13,  1.49it/s, Train Loss=2.05, validation loss=2.24] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:14<02:13,  1.49it/s, Train Loss=1.79, validation loss=2.26] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:14<02:09,  1.53it/s, Train Loss=1.79, validation loss=2.26] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:15<02:09,  1.53it/s, Train Loss=1.73, validation loss=2.24] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:15<02:09,  1.52it/s, Train Loss=1.73, validation loss=2.24] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:16<02:09,  1.52it/s, Train Loss=2.29, validation loss=2.25] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:16<02:07,  1.54it/s, Train Loss=2.29, validation loss=2.25] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:16<02:07,  1.54it/s, Train Loss=1.72, validation loss=2.24] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:16<02:05,  1.56it/s, Train Loss=1.72, validation loss=2.24] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:17<02:05,  1.56it/s, Train Loss=1.75, validation loss=2.23] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:17<02:03,  1.57it/s, Train Loss=1.75, validation loss=2.23] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:18<02:03,  1.57it/s, Train Loss=1.76, validation loss=2.22] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:18<02:08,  1.50it/s, Train Loss=1.76, validation loss=2.22] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:18<02:08,  1.50it/s, Train Loss=2.17, validation loss=2.24] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:18<02:06,  1.52it/s, Train Loss=2.17, validation loss=2.24] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:19<02:06,  1.52it/s, Train Loss=2.35, validation loss=2.24] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:19<02:16,  1.40it/s, Train Loss=2.35, validation loss=2.24] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:20<02:16,  1.40it/s, Train Loss=2.45, validation loss=2.25] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:20<02:11,  1.44it/s, Train Loss=2.45, validation loss=2.25] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:20<02:11,  1.44it/s, Train Loss=2.12, validation loss=2.25] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:20<02:06,  1.49it/s, Train Loss=2.12, validation loss=2.25] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:21<02:06,  1.49it/s, Train Loss=1.8, validation loss=2.24]  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:21<02:02,  1.54it/s, Train Loss=1.8, validation loss=2.24] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:22<02:02,  1.54it/s, Train Loss=4.91, validation loss=2.22] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:22<02:00,  1.55it/s, Train Loss=4.91, validation loss=2.22] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:22<02:00,  1.55it/s, Train Loss=1.65, validation loss=2.26] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:22<02:05,  1.48it/s, Train Loss=1.65, validation loss=2.26] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:23<02:05,  1.48it/s, Train Loss=1.07, validation loss=2.25] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:23<02:01,  1.52it/s, Train Loss=1.07, validation loss=2.25] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:24<02:01,  1.52it/s, Train Loss=2.15, validation loss=2.26] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:24<01:58,  1.56it/s, Train Loss=2.15, validation loss=2.26] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:24<01:58,  1.56it/s, Train Loss=2.57, validation loss=2.25] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:24<01:55,  1.58it/s, Train Loss=2.57, validation loss=2.25] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:25<01:55,  1.58it/s, Train Loss=1.64, validation loss=2.24] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:25<01:56,  1.56it/s, Train Loss=1.64, validation loss=2.24] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:26<01:56,  1.56it/s, Train Loss=1.99, validation loss=2.25] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:26<01:53,  1.59it/s, Train Loss=1.99, validation loss=2.25] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:26<01:53,  1.59it/s, Train Loss=3.29, validation loss=2.23] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:26<01:59,  1.51it/s, Train Loss=3.29, validation loss=2.23] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:27<01:59,  1.51it/s, Train Loss=2.5, validation loss=2.26]  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:27<01:56,  1.53it/s, Train Loss=2.5, validation loss=2.26] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:28<01:56,  1.53it/s, Train Loss=2.26, validation loss=2.24] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:28<01:55,  1.54it/s, Train Loss=2.26, validation loss=2.24] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:28<01:55,  1.54it/s, Train Loss=2.15, validation loss=2.23] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:28<01:53,  1.56it/s, Train Loss=2.15, validation loss=2.23] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:29<01:53,  1.56it/s, Train Loss=1.43, validation loss=2.23] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:29<01:50,  1.59it/s, Train Loss=1.43, validation loss=2.23] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:29<01:50,  1.59it/s, Train Loss=2.45, validation loss=2.24] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:29<01:49,  1.60it/s, Train Loss=2.45, validation loss=2.24] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:30<01:49,  1.60it/s, Train Loss=1.58, validation loss=2.23] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:30<01:48,  1.60it/s, Train Loss=1.58, validation loss=2.23] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:31<01:48,  1.60it/s, Train Loss=2.47, validation loss=2.26] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:31<01:52,  1.53it/s, Train Loss=2.47, validation loss=2.26] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:31<01:52,  1.53it/s, Train Loss=1.85, validation loss=2.25] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:31<01:50,  1.56it/s, Train Loss=1.85, validation loss=2.25] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:32<01:50,  1.56it/s, Train Loss=2.21, validation loss=2.24] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:32<01:48,  1.57it/s, Train Loss=2.21, validation loss=2.24] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:33<01:48,  1.57it/s, Train Loss=1.33, validation loss=2.24] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:33<01:47,  1.58it/s, Train Loss=1.33, validation loss=2.24] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:33<01:47,  1.58it/s, Train Loss=1.75, validation loss=2.25] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:33<01:47,  1.58it/s, Train Loss=1.75, validation loss=2.25] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:34<01:47,  1.58it/s, Train Loss=1.63, validation loss=2.24] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:34<01:44,  1.60it/s, Train Loss=1.63, validation loss=2.24] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:35<01:44,  1.60it/s, Train Loss=3.48, validation loss=2.23] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:35<01:49,  1.53it/s, Train Loss=3.48, validation loss=2.23] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:35<01:49,  1.53it/s, Train Loss=1.35, validation loss=2.25] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:35<01:49,  1.52it/s, Train Loss=1.35, validation loss=2.25] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:36<01:49,  1.52it/s, Train Loss=1.74, validation loss=2.24] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:36<01:47,  1.54it/s, Train Loss=1.74, validation loss=2.24] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:36<01:47,  1.54it/s, Train Loss=3.07, validation loss=2.23] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:36<01:43,  1.58it/s, Train Loss=3.07, validation loss=2.23] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:37<01:43,  1.58it/s, Train Loss=2.25, validation loss=2.23] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:37<01:42,  1.59it/s, Train Loss=2.25, validation loss=2.23] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:38<01:42,  1.59it/s, Train Loss=2.33, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:38<01:42,  1.58it/s, Train Loss=2.33, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:38<01:42,  1.58it/s, Train Loss=1.49, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:38<01:40,  1.61it/s, Train Loss=1.49, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:39<01:40,  1.61it/s, Train Loss=2.53, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:39<01:46,  1.50it/s, Train Loss=2.53, validation loss=2.24] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:40<01:46,  1.50it/s, Train Loss=6.04, validation loss=2.21] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:40<01:48,  1.47it/s, Train Loss=6.04, validation loss=2.21] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:40<01:48,  1.47it/s, Train Loss=2.23, validation loss=2.22] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:40<01:45,  1.50it/s, Train Loss=2.23, validation loss=2.22] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:41<01:45,  1.50it/s, Train Loss=1.69, validation loss=2.24] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:41<01:40,  1.56it/s, Train Loss=1.69, validation loss=2.24] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:42<01:40,  1.56it/s, Train Loss=2.13, validation loss=2.25] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:42<01:39,  1.57it/s, Train Loss=2.13, validation loss=2.25] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:42<01:39,  1.57it/s, Train Loss=2.1, validation loss=2.24]  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:42<01:38,  1.58it/s, Train Loss=2.1, validation loss=2.24] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:43<01:38,  1.58it/s, Train Loss=1.15, validation loss=2.25] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:43<01:41,  1.52it/s, Train Loss=1.15, validation loss=2.25] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:44<01:41,  1.52it/s, Train Loss=2.21, validation loss=2.22] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:44<01:39,  1.53it/s, Train Loss=2.21, validation loss=2.22] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:44<01:39,  1.53it/s, Train Loss=1.84, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:44<01:38,  1.54it/s, Train Loss=1.84, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:45<01:38,  1.54it/s, Train Loss=1.47, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:45<01:36,  1.57it/s, Train Loss=1.47, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:45<01:36,  1.57it/s, Train Loss=1.92, validation loss=2.25] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:45<01:35,  1.57it/s, Train Loss=1.92, validation loss=2.25] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:46<01:35,  1.57it/s, Train Loss=2.32, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:46<01:33,  1.59it/s, Train Loss=2.32, validation loss=2.24] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:47<01:33,  1.59it/s, Train Loss=2.57, validation loss=2.23] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:47<01:32,  1.61it/s, Train Loss=2.57, validation loss=2.23] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:47<01:32,  1.61it/s, Train Loss=2.1, validation loss=2.25]  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:47<01:37,  1.51it/s, Train Loss=2.1, validation loss=2.25] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:48<01:37,  1.51it/s, Train Loss=1.81, validation loss=2.24] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:48<01:34,  1.55it/s, Train Loss=1.81, validation loss=2.24] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:49<01:34,  1.55it/s, Train Loss=2.32, validation loss=2.26] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:49<01:32,  1.58it/s, Train Loss=2.32, validation loss=2.26] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:49<01:32,  1.58it/s, Train Loss=1.76, validation loss=2.23] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:49<01:30,  1.59it/s, Train Loss=1.76, validation loss=2.23] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:50<01:30,  1.59it/s, Train Loss=1.76, validation loss=2.23] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:50<01:29,  1.60it/s, Train Loss=1.76, validation loss=2.23] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:51<01:29,  1.60it/s, Train Loss=2.87, validation loss=2.24] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:51<01:28,  1.60it/s, Train Loss=2.87, validation loss=2.24] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:51<01:28,  1.60it/s, Train Loss=2.94, validation loss=2.23] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:51<01:32,  1.53it/s, Train Loss=2.94, validation loss=2.23] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:52<01:32,  1.53it/s, Train Loss=1.76, validation loss=2.24] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:52<01:29,  1.56it/s, Train Loss=1.76, validation loss=2.24] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:53<01:29,  1.56it/s, Train Loss=3.13, validation loss=2.22] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:53<01:28,  1.57it/s, Train Loss=3.13, validation loss=2.22] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:53<01:28,  1.57it/s, Train Loss=2.84, validation loss=2.22] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:53<01:28,  1.57it/s, Train Loss=2.84, validation loss=2.22] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:54<01:28,  1.57it/s, Train Loss=1.86, validation loss=2.25] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:54<01:27,  1.56it/s, Train Loss=1.86, validation loss=2.25] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:54<01:27,  1.56it/s, Train Loss=1.52, validation loss=2.23] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:54<01:26,  1.58it/s, Train Loss=1.52, validation loss=2.23] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:55<01:26,  1.58it/s, Train Loss=1.57, validation loss=2.25] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:55<01:29,  1.51it/s, Train Loss=1.57, validation loss=2.25] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:56<01:29,  1.51it/s, Train Loss=1.67, validation loss=2.25] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:56<01:27,  1.53it/s, Train Loss=1.67, validation loss=2.25] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:56<01:27,  1.53it/s, Train Loss=2.74, validation loss=2.23] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:56<01:24,  1.57it/s, Train Loss=2.74, validation loss=2.23] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:57<01:24,  1.57it/s, Train Loss=2.48, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:57<01:23,  1.59it/s, Train Loss=2.48, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:58<01:23,  1.59it/s, Train Loss=2.29, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:58<01:23,  1.57it/s, Train Loss=2.29, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:58<01:23,  1.57it/s, Train Loss=3.19, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:58<01:22,  1.58it/s, Train Loss=3.19, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [03:59<01:22,  1.58it/s, Train Loss=1.91, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [03:59<01:26,  1.49it/s, Train Loss=1.91, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [04:00<01:26,  1.49it/s, Train Loss=1.74, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [04:00<01:22,  1.56it/s, Train Loss=1.74, validation loss=2.23] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [04:00<01:22,  1.56it/s, Train Loss=2.12, validation loss=2.23] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:00<01:20,  1.58it/s, Train Loss=2.12, validation loss=2.23] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:01<01:20,  1.58it/s, Train Loss=2.42, validation loss=2.23] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:01<01:20,  1.56it/s, Train Loss=2.42, validation loss=2.23] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:02<01:20,  1.56it/s, Train Loss=1.72, validation loss=2.23] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:02<01:20,  1.54it/s, Train Loss=1.72, validation loss=2.23] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:02<01:20,  1.54it/s, Train Loss=1.41, validation loss=2.22] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:02<01:20,  1.55it/s, Train Loss=1.41, validation loss=2.22] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:03<01:20,  1.55it/s, Train Loss=1.93, validation loss=2.24] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:03<01:22,  1.49it/s, Train Loss=1.93, validation loss=2.24] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:04<01:22,  1.49it/s, Train Loss=1.91, validation loss=2.23] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:04<01:20,  1.51it/s, Train Loss=1.91, validation loss=2.23] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:04<01:20,  1.51it/s, Train Loss=2.54, validation loss=2.23] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:04<01:19,  1.52it/s, Train Loss=2.54, validation loss=2.23] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:05<01:19,  1.52it/s, Train Loss=1.35, validation loss=2.24] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:05<01:20,  1.49it/s, Train Loss=1.35, validation loss=2.24] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:06<01:20,  1.49it/s, Train Loss=1.39, validation loss=2.24] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:06<01:21,  1.47it/s, Train Loss=1.39, validation loss=2.24] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:06<01:21,  1.47it/s, Train Loss=1.75, validation loss=2.23] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:06<01:18,  1.51it/s, Train Loss=1.75, validation loss=2.23] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:07<01:18,  1.51it/s, Train Loss=2.44, validation loss=2.22] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:07<01:19,  1.48it/s, Train Loss=2.44, validation loss=2.22] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:08<01:19,  1.48it/s, Train Loss=1.91, validation loss=2.23] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:08<01:17,  1.50it/s, Train Loss=1.91, validation loss=2.23] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:08<01:17,  1.50it/s, Train Loss=1.57, validation loss=2.25] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:08<01:14,  1.53it/s, Train Loss=1.57, validation loss=2.25] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:09<01:14,  1.53it/s, Train Loss=1.67, validation loss=2.23] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:09<01:13,  1.56it/s, Train Loss=1.67, validation loss=2.23] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:09<01:13,  1.56it/s, Train Loss=2.51, validation loss=2.24] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:09<01:11,  1.59it/s, Train Loss=2.51, validation loss=2.24] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:10<01:11,  1.59it/s, Train Loss=3.09, validation loss=2.23] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:10<01:10,  1.59it/s, Train Loss=3.09, validation loss=2.23] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:11<01:10,  1.59it/s, Train Loss=1.7, validation loss=2.24]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:11<01:14,  1.50it/s, Train Loss=1.7, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:11<01:14,  1.50it/s, Train Loss=2.43, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:11<01:11,  1.53it/s, Train Loss=2.43, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:12<01:11,  1.53it/s, Train Loss=1.48, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:12<01:10,  1.55it/s, Train Loss=1.48, validation loss=2.24] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:13<01:10,  1.55it/s, Train Loss=1.82, validation loss=2.23] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:13<01:08,  1.57it/s, Train Loss=1.82, validation loss=2.23] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:13<01:08,  1.57it/s, Train Loss=1.61, validation loss=2.25] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:13<01:07,  1.59it/s, Train Loss=1.61, validation loss=2.25] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:14<01:07,  1.59it/s, Train Loss=1.61, validation loss=2.24] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:14<01:06,  1.60it/s, Train Loss=1.61, validation loss=2.24] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:15<01:06,  1.60it/s, Train Loss=1.96, validation loss=2.24] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:15<01:07,  1.56it/s, Train Loss=1.96, validation loss=2.24] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:15<01:07,  1.56it/s, Train Loss=3.55, validation loss=2.23] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:15<01:07,  1.55it/s, Train Loss=3.55, validation loss=2.23] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:16<01:07,  1.55it/s, Train Loss=2.57, validation loss=2.23] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:16<01:05,  1.58it/s, Train Loss=2.57, validation loss=2.23] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:16<01:05,  1.58it/s, Train Loss=2.31, validation loss=2.24] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:16<01:04,  1.59it/s, Train Loss=2.31, validation loss=2.24] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:17<01:04,  1.59it/s, Train Loss=1.74, validation loss=2.25] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:17<01:02,  1.62it/s, Train Loss=1.74, validation loss=2.25]####################################################################################################
--------------------------------------------- Epoch:400 ---------------------------------------------
-- Training set:
Loss: 1.9178228378295898, Lr: 6.25e-05
Average AUC ROC: 0.53                Average AUC PR: 0.29
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:18<01:02,  1.62it/s, Train Loss=1.92, validation loss=2.24] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:18<01:01,  1.63it/s, Train Loss=1.92, validation loss=2.24]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.2376260086894035
Average AUC ROC: 0.58                    Average AUC PR: 0.32
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:18<01:01,  1.63it/s, Train Loss=1.85, validation loss=2.24] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:18<01:02,  1.59it/s, Train Loss=1.85, validation loss=2.24] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:19<01:02,  1.59it/s, Train Loss=1.45, validation loss=2.25] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:19<01:01,  1.59it/s, Train Loss=1.45, validation loss=2.25] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:20<01:01,  1.59it/s, Train Loss=3.21, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:20<01:01,  1.58it/s, Train Loss=3.21, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:20<01:01,  1.58it/s, Train Loss=2.42, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:20<01:00,  1.59it/s, Train Loss=2.42, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:21<01:00,  1.59it/s, Train Loss=2, validation loss=2.24]    81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:21<00:59,  1.59it/s, Train Loss=2, validation loss=2.24] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:21<00:59,  1.59it/s, Train Loss=1.85, validation loss=2.25] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:21<00:59,  1.57it/s, Train Loss=1.85, validation loss=2.25] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:22<00:59,  1.57it/s, Train Loss=2.87, validation loss=2.23] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:22<00:58,  1.58it/s, Train Loss=2.87, validation loss=2.23] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:23<00:58,  1.58it/s, Train Loss=2.18, validation loss=2.24] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:23<01:01,  1.51it/s, Train Loss=2.18, validation loss=2.24] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:23<01:01,  1.51it/s, Train Loss=1.5, validation loss=2.23]  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:23<00:58,  1.56it/s, Train Loss=1.5, validation loss=2.23] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:24<00:58,  1.56it/s, Train Loss=1.63, validation loss=2.24] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:24<00:56,  1.59it/s, Train Loss=1.63, validation loss=2.24] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:25<00:56,  1.59it/s, Train Loss=1.58, validation loss=2.24] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:25<00:56,  1.57it/s, Train Loss=1.58, validation loss=2.24] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:25<00:56,  1.57it/s, Train Loss=2.21, validation loss=2.22] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:25<00:57,  1.53it/s, Train Loss=2.21, validation loss=2.22] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:26<00:57,  1.53it/s, Train Loss=3.26, validation loss=2.22] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:26<00:58,  1.49it/s, Train Loss=3.26, validation loss=2.22] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:27<00:58,  1.49it/s, Train Loss=1.94, validation loss=2.23] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:27<00:58,  1.47it/s, Train Loss=1.94, validation loss=2.23] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:27<00:58,  1.47it/s, Train Loss=1.61, validation loss=2.23] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:27<00:55,  1.52it/s, Train Loss=1.61, validation loss=2.23] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:28<00:55,  1.52it/s, Train Loss=2.22, validation loss=2.24] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:28<00:54,  1.54it/s, Train Loss=2.22, validation loss=2.24] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:29<00:54,  1.54it/s, Train Loss=2.41, validation loss=2.22] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:29<00:52,  1.57it/s, Train Loss=2.41, validation loss=2.22] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:29<00:52,  1.57it/s, Train Loss=2.11, validation loss=2.23] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:29<00:51,  1.58it/s, Train Loss=2.11, validation loss=2.23] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:30<00:51,  1.58it/s, Train Loss=2.24, validation loss=2.24] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:30<00:51,  1.58it/s, Train Loss=2.24, validation loss=2.24] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:31<00:51,  1.58it/s, Train Loss=1.89, validation loss=2.24] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:31<00:52,  1.51it/s, Train Loss=1.89, validation loss=2.24] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:31<00:52,  1.51it/s, Train Loss=2.35, validation loss=2.23] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:31<00:51,  1.53it/s, Train Loss=2.35, validation loss=2.23] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:32<00:51,  1.53it/s, Train Loss=2.2, validation loss=2.27]  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:32<00:49,  1.56it/s, Train Loss=2.2, validation loss=2.27] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:32<00:49,  1.56it/s, Train Loss=3.09, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:32<00:48,  1.59it/s, Train Loss=3.09, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:33<00:48,  1.59it/s, Train Loss=2.69, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:33<00:47,  1.60it/s, Train Loss=2.69, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:34<00:47,  1.60it/s, Train Loss=3.11, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:34<00:49,  1.51it/s, Train Loss=3.11, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:34<00:49,  1.51it/s, Train Loss=2.17, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:34<00:48,  1.53it/s, Train Loss=2.17, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:35<00:48,  1.53it/s, Train Loss=2.27, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:35<00:46,  1.57it/s, Train Loss=2.27, validation loss=2.23] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:36<00:46,  1.57it/s, Train Loss=2.12, validation loss=2.24] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:36<00:45,  1.58it/s, Train Loss=2.12, validation loss=2.24] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:36<00:45,  1.58it/s, Train Loss=3.07, validation loss=2.24] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:36<00:44,  1.59it/s, Train Loss=3.07, validation loss=2.24] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:37<00:44,  1.59it/s, Train Loss=3.14, validation loss=2.22] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:37<00:46,  1.50it/s, Train Loss=3.14, validation loss=2.22] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:38<00:46,  1.50it/s, Train Loss=1.57, validation loss=2.22] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:38<00:45,  1.52it/s, Train Loss=1.57, validation loss=2.22] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:38<00:45,  1.52it/s, Train Loss=2.13, validation loss=2.21] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:38<00:43,  1.55it/s, Train Loss=2.13, validation loss=2.21] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:39<00:43,  1.55it/s, Train Loss=2.24, validation loss=2.22] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:39<00:42,  1.57it/s, Train Loss=2.24, validation loss=2.22] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:40<00:42,  1.57it/s, Train Loss=1.82, validation loss=2.23] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:40<00:41,  1.59it/s, Train Loss=1.82, validation loss=2.23] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:40<00:41,  1.59it/s, Train Loss=1.49, validation loss=2.22] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:40<00:40,  1.60it/s, Train Loss=1.49, validation loss=2.22] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:41<00:40,  1.60it/s, Train Loss=2.03, validation loss=2.25] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:41<00:42,  1.51it/s, Train Loss=2.03, validation loss=2.25] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:42<00:42,  1.51it/s, Train Loss=1.66, validation loss=2.24] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:42<00:40,  1.55it/s, Train Loss=1.66, validation loss=2.24] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:42<00:40,  1.55it/s, Train Loss=1.92, validation loss=2.24] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:42<00:39,  1.56it/s, Train Loss=1.92, validation loss=2.24] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:43<00:39,  1.56it/s, Train Loss=1.64, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:43<00:38,  1.58it/s, Train Loss=1.64, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:43<00:38,  1.58it/s, Train Loss=2.6, validation loss=2.23]  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:43<00:38,  1.58it/s, Train Loss=2.6, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:44<00:38,  1.58it/s, Train Loss=1.76, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:44<00:37,  1.56it/s, Train Loss=1.76, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:45<00:37,  1.56it/s, Train Loss=2.76, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:45<00:39,  1.47it/s, Train Loss=2.76, validation loss=2.23] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:45<00:39,  1.47it/s, Train Loss=1.83, validation loss=2.23] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:45<00:37,  1.51it/s, Train Loss=1.83, validation loss=2.23] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:46<00:37,  1.51it/s, Train Loss=1.57, validation loss=2.25] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:46<00:37,  1.48it/s, Train Loss=1.57, validation loss=2.25] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:47<00:37,  1.48it/s, Train Loss=2.24, validation loss=2.24] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:47<00:36,  1.51it/s, Train Loss=2.24, validation loss=2.24] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:47<00:36,  1.51it/s, Train Loss=1.52, validation loss=2.26] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:47<00:34,  1.54it/s, Train Loss=1.52, validation loss=2.26] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:48<00:34,  1.54it/s, Train Loss=2.18, validation loss=2.24] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:48<00:33,  1.56it/s, Train Loss=2.18, validation loss=2.24] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:49<00:33,  1.56it/s, Train Loss=2, validation loss=2.23]    90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:49<00:34,  1.50it/s, Train Loss=2, validation loss=2.23] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:49<00:34,  1.50it/s, Train Loss=2.81, validation loss=2.25] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:49<00:33,  1.53it/s, Train Loss=2.81, validation loss=2.25] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:50<00:33,  1.53it/s, Train Loss=2.56, validation loss=2.23] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:50<00:32,  1.56it/s, Train Loss=2.56, validation loss=2.23] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:51<00:32,  1.56it/s, Train Loss=2.27, validation loss=2.22] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:51<00:30,  1.59it/s, Train Loss=2.27, validation loss=2.22] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:51<00:30,  1.59it/s, Train Loss=1.22, validation loss=2.23] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:51<00:30,  1.60it/s, Train Loss=1.22, validation loss=2.23] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:52<00:30,  1.60it/s, Train Loss=1.67, validation loss=2.23] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:52<00:29,  1.59it/s, Train Loss=1.67, validation loss=2.23] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:53<00:29,  1.59it/s, Train Loss=1.74, validation loss=2.22] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:53<00:29,  1.56it/s, Train Loss=1.74, validation loss=2.22] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:53<00:29,  1.56it/s, Train Loss=2.14, validation loss=2.23] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:53<00:28,  1.60it/s, Train Loss=2.14, validation loss=2.23] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:54<00:28,  1.60it/s, Train Loss=1.77, validation loss=2.23] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:54<00:27,  1.58it/s, Train Loss=1.77, validation loss=2.23] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:54<00:27,  1.58it/s, Train Loss=2.25, validation loss=2.21] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:54<00:26,  1.61it/s, Train Loss=2.25, validation loss=2.21] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:55<00:26,  1.61it/s, Train Loss=2.46, validation loss=2.24] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:55<00:27,  1.54it/s, Train Loss=2.46, validation loss=2.24] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:56<00:27,  1.54it/s, Train Loss=2.95, validation loss=2.24] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:56<00:26,  1.56it/s, Train Loss=2.95, validation loss=2.24] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:56<00:26,  1.56it/s, Train Loss=3.51, validation loss=2.23] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:56<00:25,  1.57it/s, Train Loss=3.51, validation loss=2.23] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:57<00:25,  1.57it/s, Train Loss=1.99, validation loss=2.23] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:57<00:24,  1.57it/s, Train Loss=1.99, validation loss=2.23] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:58<00:24,  1.57it/s, Train Loss=2.03, validation loss=2.23] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:58<00:23,  1.59it/s, Train Loss=2.03, validation loss=2.23] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:58<00:23,  1.59it/s, Train Loss=2.22, validation loss=2.23] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:58<00:23,  1.57it/s, Train Loss=2.22, validation loss=2.23] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [04:59<00:23,  1.57it/s, Train Loss=1.82, validation loss=2.24] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [04:59<00:23,  1.52it/s, Train Loss=1.82, validation loss=2.24] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [05:00<00:23,  1.52it/s, Train Loss=3.27, validation loss=2.22] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [05:00<00:22,  1.53it/s, Train Loss=3.27, validation loss=2.22] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [05:00<00:22,  1.53it/s, Train Loss=2.09, validation loss=2.24] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [05:00<00:21,  1.56it/s, Train Loss=2.09, validation loss=2.24] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [05:01<00:21,  1.56it/s, Train Loss=1.63, validation loss=2.23] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:01<00:21,  1.56it/s, Train Loss=1.63, validation loss=2.23] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:01<00:21,  1.56it/s, Train Loss=3.93, validation loss=2.22] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:01<00:20,  1.56it/s, Train Loss=3.93, validation loss=2.22] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:02<00:20,  1.56it/s, Train Loss=1.91, validation loss=2.23] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:02<00:20,  1.50it/s, Train Loss=1.91, validation loss=2.23] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:03<00:20,  1.50it/s, Train Loss=2.61, validation loss=2.22] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:03<00:19,  1.52it/s, Train Loss=2.61, validation loss=2.22] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:03<00:19,  1.52it/s, Train Loss=1.67, validation loss=2.23] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:03<00:18,  1.54it/s, Train Loss=1.67, validation loss=2.23] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:04<00:18,  1.54it/s, Train Loss=3.03, validation loss=2.23] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:04<00:17,  1.57it/s, Train Loss=3.03, validation loss=2.23] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:05<00:17,  1.57it/s, Train Loss=1.64, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:05<00:17,  1.58it/s, Train Loss=1.64, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:05<00:17,  1.58it/s, Train Loss=3.14, validation loss=2.23] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:05<00:16,  1.60it/s, Train Loss=3.14, validation loss=2.23] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:06<00:16,  1.60it/s, Train Loss=1.71, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:06<00:16,  1.56it/s, Train Loss=1.71, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:07<00:16,  1.56it/s, Train Loss=1.36, validation loss=2.25] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:07<00:16,  1.49it/s, Train Loss=1.36, validation loss=2.25] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:07<00:16,  1.49it/s, Train Loss=2.39, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:07<00:15,  1.50it/s, Train Loss=2.39, validation loss=2.24] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:08<00:15,  1.50it/s, Train Loss=2.18, validation loss=2.26] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:08<00:14,  1.54it/s, Train Loss=2.18, validation loss=2.26] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:09<00:14,  1.54it/s, Train Loss=2.21, validation loss=2.24] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:09<00:13,  1.55it/s, Train Loss=2.21, validation loss=2.24] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:09<00:13,  1.55it/s, Train Loss=2.74, validation loss=2.21] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:09<00:13,  1.49it/s, Train Loss=2.74, validation loss=2.21] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:10<00:13,  1.49it/s, Train Loss=1.44, validation loss=2.23] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:10<00:12,  1.52it/s, Train Loss=1.44, validation loss=2.23] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:11<00:12,  1.52it/s, Train Loss=1.72, validation loss=2.24] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:11<00:11,  1.55it/s, Train Loss=1.72, validation loss=2.24] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:11<00:11,  1.55it/s, Train Loss=1.71, validation loss=2.23] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:11<00:10,  1.57it/s, Train Loss=1.71, validation loss=2.23] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:12<00:10,  1.57it/s, Train Loss=1.07, validation loss=2.23] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:12<00:09,  1.61it/s, Train Loss=1.07, validation loss=2.23] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:13<00:09,  1.61it/s, Train Loss=2.21, validation loss=2.22] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:13<00:09,  1.52it/s, Train Loss=2.21, validation loss=2.22] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:13<00:09,  1.52it/s, Train Loss=2.47, validation loss=2.22] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:13<00:09,  1.55it/s, Train Loss=2.47, validation loss=2.22] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:14<00:09,  1.55it/s, Train Loss=1.58, validation loss=2.24] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:14<00:08,  1.58it/s, Train Loss=1.58, validation loss=2.24] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:14<00:08,  1.58it/s, Train Loss=2.75, validation loss=2.22] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:14<00:07,  1.60it/s, Train Loss=2.75, validation loss=2.22] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:15<00:07,  1.60it/s, Train Loss=1.77, validation loss=2.22] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:15<00:06,  1.60it/s, Train Loss=1.77, validation loss=2.22] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:16<00:06,  1.60it/s, Train Loss=1.91, validation loss=2.24] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:16<00:06,  1.59it/s, Train Loss=1.91, validation loss=2.24] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:16<00:06,  1.59it/s, Train Loss=3.17, validation loss=2.24] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:16<00:05,  1.54it/s, Train Loss=3.17, validation loss=2.24] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:17<00:05,  1.54it/s, Train Loss=2.34, validation loss=2.23] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:17<00:05,  1.55it/s, Train Loss=2.34, validation loss=2.23] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:18<00:05,  1.55it/s, Train Loss=2.63, validation loss=2.23] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:18<00:04,  1.57it/s, Train Loss=2.63, validation loss=2.23] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:18<00:04,  1.57it/s, Train Loss=1.79, validation loss=2.23] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:18<00:03,  1.59it/s, Train Loss=1.79, validation loss=2.23] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:19<00:03,  1.59it/s, Train Loss=1.61, validation loss=2.24] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:19<00:03,  1.58it/s, Train Loss=1.61, validation loss=2.24] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:20<00:03,  1.58it/s, Train Loss=1.34, validation loss=2.24] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:20<00:02,  1.53it/s, Train Loss=1.34, validation loss=2.24] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:20<00:02,  1.53it/s, Train Loss=2.33, validation loss=2.25] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:20<00:01,  1.54it/s, Train Loss=2.33, validation loss=2.25] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:21<00:01,  1.54it/s, Train Loss=1.9, validation loss=2.24] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:21<00:01,  1.54it/s, Train Loss=1.9, validation loss=2.24]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:21<00:01,  1.54it/s, Train Loss=1.96, validation loss=2.23]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:21<00:00,  1.56it/s, Train Loss=1.96, validation loss=2.23]####################################################################################################
--------------------------------------------- Epoch:500 ---------------------------------------------
-- Training set:
Loss: 1.8546150922775269, Lr: 3.125e-05
Average AUC ROC: 0.53                Average AUC PR: 0.28
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:22<00:00,  1.56it/s, Train Loss=1.85, validation loss=2.24]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:22<00:00,  1.58it/s, Train Loss=1.85, validation loss=2.24]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:22<00:00,  1.55it/s, Train Loss=1.85, validation loss=2.24]
----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.242256239056587
Average AUC ROC: 0.58                    Average AUC PR: 0.31

        ___  ________ _           _     _          _                     _   _      _   
        |  \/  |_   _| |         | |   | |        (_)                   | \ | |    | |  
        | .  . | | | | |     __ _| |___| |__   ___ _ _ __ ___   ___ _ __|  \| | ___| |_ 
        | |\/| | | | | |    / _` | |_  / '_ \ / _ \ | '_ ` _ \ / _ \ '__| . ` |/ _ \ __|
        | |  | | | | | |___| (_| | |/ /| | | |  __/ | | | | | |  __/ |  | |\  |  __/ |_ 
        \_|  |_/ \_/ \_____/\__,_|_/___|_| |_|\___|_|_| |_| |_|\___|_|  \_| \_/\___|\__|
                                                                                                                                                                                                                        
          
Train the model on 3083 observation with 403 features and test it on 343
cuda

    ###################################################################################
    #   architecture: CombinOptMTL
    #   dataset: ../../data/MRI_rois_20211114//MRI_rois_20211114.csv
    #   target: modified
    #   random state: 31
    #   selected_gender: ['M', 'F']
    #   selected_diagnosis: ['CN', 'AD', 'PD', 'LMCI', 'EMCI', 'MCI', 'FTD']
    #   epochs: 500
    #   training_algortim: FAMO
    #   learning_rate: 0.001
    #   optimizer : Adagrad
    #   batch size: 256
    #   scheduler: StepLR
    #   weight_decay : 0.00025
    #   gamma : 0.5
    #   EarlyStopper
    #   patience: 5
    #   min_delta: 1
    ###################################################################################
    
  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=0, validation loss=0]  0%|          | 0/500 [00:00<?, ?it/s, Train Loss=3.44, validation loss=3.17]  0%|          | 1/500 [00:00<05:06,  1.63it/s, Train Loss=3.44, validation loss=3.17]  0%|          | 1/500 [00:01<05:06,  1.63it/s, Train Loss=2.96, validation loss=2.98]  0%|          | 2/500 [00:01<05:02,  1.64it/s, Train Loss=2.96, validation loss=2.98]  0%|          | 2/500 [00:01<05:02,  1.64it/s, Train Loss=4.68, validation loss=2.87]  1%|          | 3/500 [00:01<05:08,  1.61it/s, Train Loss=4.68, validation loss=2.87]  1%|          | 3/500 [00:02<05:08,  1.61it/s, Train Loss=3.3, validation loss=2.78]   1%|          | 4/500 [00:02<05:24,  1.53it/s, Train Loss=3.3, validation loss=2.78]  1%|          | 4/500 [00:03<05:24,  1.53it/s, Train Loss=1.76, validation loss=2.69]  1%|          | 5/500 [00:03<05:16,  1.56it/s, Train Loss=1.76, validation loss=2.69]  1%|          | 5/500 [00:03<05:16,  1.56it/s, Train Loss=4.2, validation loss=2.69]   1%|          | 6/500 [00:03<05:13,  1.58it/s, Train Loss=4.2, validation loss=2.69]  1%|          | 6/500 [00:04<05:13,  1.58it/s, Train Loss=3.47, validation loss=2.69]  1%|â–         | 7/500 [00:04<05:28,  1.50it/s, Train Loss=3.47, validation loss=2.69]  1%|â–         | 7/500 [00:05<05:28,  1.50it/s, Train Loss=1.96, validation loss=2.66]  2%|â–         | 8/500 [00:05<05:21,  1.53it/s, Train Loss=1.96, validation loss=2.66]  2%|â–         | 8/500 [00:05<05:21,  1.53it/s, Train Loss=3.29, validation loss=2.67]  2%|â–         | 9/500 [00:05<05:20,  1.53it/s, Train Loss=3.29, validation loss=2.67]  2%|â–         | 9/500 [00:06<05:20,  1.53it/s, Train Loss=3.31, validation loss=2.69]  2%|â–         | 10/500 [00:06<05:30,  1.48it/s, Train Loss=3.31, validation loss=2.69]  2%|â–         | 10/500 [00:07<05:30,  1.48it/s, Train Loss=2.65, validation loss=2.65]  2%|â–         | 11/500 [00:07<05:21,  1.52it/s, Train Loss=2.65, validation loss=2.65]  2%|â–         | 11/500 [00:07<05:21,  1.52it/s, Train Loss=2.27, validation loss=2.65]  2%|â–         | 12/500 [00:07<05:10,  1.57it/s, Train Loss=2.27, validation loss=2.65]  2%|â–         | 12/500 [00:08<05:10,  1.57it/s, Train Loss=3.14, validation loss=2.63]  3%|â–         | 13/500 [00:08<05:07,  1.59it/s, Train Loss=3.14, validation loss=2.63]  3%|â–         | 13/500 [00:08<05:07,  1.59it/s, Train Loss=2.41, validation loss=2.64]  3%|â–         | 14/500 [00:08<05:04,  1.60it/s, Train Loss=2.41, validation loss=2.64]  3%|â–         | 14/500 [00:09<05:04,  1.60it/s, Train Loss=1.97, validation loss=2.63]  3%|â–         | 15/500 [00:09<05:05,  1.59it/s, Train Loss=1.97, validation loss=2.63]  3%|â–         | 15/500 [00:10<05:05,  1.59it/s, Train Loss=4.44, validation loss=2.62]  3%|â–         | 16/500 [00:10<05:21,  1.50it/s, Train Loss=4.44, validation loss=2.62]  3%|â–         | 16/500 [00:10<05:21,  1.50it/s, Train Loss=4.07, validation loss=2.63]  3%|â–         | 17/500 [00:10<05:12,  1.55it/s, Train Loss=4.07, validation loss=2.63]  3%|â–         | 17/500 [00:11<05:12,  1.55it/s, Train Loss=2.68, validation loss=2.59]  4%|â–         | 18/500 [00:11<05:11,  1.55it/s, Train Loss=2.68, validation loss=2.59]  4%|â–         | 18/500 [00:12<05:11,  1.55it/s, Train Loss=2.55, validation loss=2.6]   4%|â–         | 19/500 [00:12<05:11,  1.55it/s, Train Loss=2.55, validation loss=2.6]  4%|â–         | 19/500 [00:13<05:11,  1.55it/s, Train Loss=2.62, validation loss=2.62]  4%|â–         | 20/500 [00:13<05:26,  1.47it/s, Train Loss=2.62, validation loss=2.62]  4%|â–         | 20/500 [00:13<05:26,  1.47it/s, Train Loss=3.26, validation loss=2.59]  4%|â–         | 21/500 [00:13<05:21,  1.49it/s, Train Loss=3.26, validation loss=2.59]  4%|â–         | 21/500 [00:14<05:21,  1.49it/s, Train Loss=2.09, validation loss=2.58]  4%|â–         | 22/500 [00:14<05:07,  1.55it/s, Train Loss=2.09, validation loss=2.58]  4%|â–         | 22/500 [00:14<05:07,  1.55it/s, Train Loss=1.74, validation loss=2.61]  5%|â–         | 23/500 [00:14<05:06,  1.56it/s, Train Loss=1.74, validation loss=2.61]  5%|â–         | 23/500 [00:15<05:06,  1.56it/s, Train Loss=1.77, validation loss=2.59]  5%|â–         | 24/500 [00:15<05:00,  1.58it/s, Train Loss=1.77, validation loss=2.59]  5%|â–         | 24/500 [00:16<05:00,  1.58it/s, Train Loss=2.21, validation loss=2.59]  5%|â–Œ         | 25/500 [00:16<05:16,  1.50it/s, Train Loss=2.21, validation loss=2.59]  5%|â–Œ         | 25/500 [00:16<05:16,  1.50it/s, Train Loss=4.24, validation loss=2.6]   5%|â–Œ         | 26/500 [00:16<05:07,  1.54it/s, Train Loss=4.24, validation loss=2.6]  5%|â–Œ         | 26/500 [00:17<05:07,  1.54it/s, Train Loss=2.22, validation loss=2.58]  5%|â–Œ         | 27/500 [00:17<04:58,  1.58it/s, Train Loss=2.22, validation loss=2.58]  5%|â–Œ         | 27/500 [00:18<04:58,  1.58it/s, Train Loss=2.24, validation loss=2.58]  6%|â–Œ         | 28/500 [00:18<04:55,  1.60it/s, Train Loss=2.24, validation loss=2.58]  6%|â–Œ         | 28/500 [00:18<04:55,  1.60it/s, Train Loss=1.83, validation loss=2.58]  6%|â–Œ         | 29/500 [00:18<04:53,  1.61it/s, Train Loss=1.83, validation loss=2.58]  6%|â–Œ         | 29/500 [00:19<04:53,  1.61it/s, Train Loss=2.76, validation loss=2.59]  6%|â–Œ         | 30/500 [00:19<04:49,  1.63it/s, Train Loss=2.76, validation loss=2.59]  6%|â–Œ         | 30/500 [00:19<04:49,  1.63it/s, Train Loss=3.15, validation loss=2.56]  6%|â–Œ         | 31/500 [00:19<05:02,  1.55it/s, Train Loss=3.15, validation loss=2.56]  6%|â–Œ         | 31/500 [00:20<05:02,  1.55it/s, Train Loss=2.92, validation loss=2.55]  6%|â–‹         | 32/500 [00:20<04:55,  1.59it/s, Train Loss=2.92, validation loss=2.55]  6%|â–‹         | 32/500 [00:21<04:55,  1.59it/s, Train Loss=2.97, validation loss=2.56]  7%|â–‹         | 33/500 [00:21<04:51,  1.60it/s, Train Loss=2.97, validation loss=2.56]  7%|â–‹         | 33/500 [00:21<04:51,  1.60it/s, Train Loss=2.14, validation loss=2.58]  7%|â–‹         | 34/500 [00:21<04:51,  1.60it/s, Train Loss=2.14, validation loss=2.58]  7%|â–‹         | 34/500 [00:22<04:51,  1.60it/s, Train Loss=2.1, validation loss=2.56]   7%|â–‹         | 35/500 [00:22<05:00,  1.55it/s, Train Loss=2.1, validation loss=2.56]  7%|â–‹         | 35/500 [00:23<05:00,  1.55it/s, Train Loss=2.55, validation loss=2.56]  7%|â–‹         | 36/500 [00:23<05:00,  1.55it/s, Train Loss=2.55, validation loss=2.56]  7%|â–‹         | 36/500 [00:23<05:00,  1.55it/s, Train Loss=1.79, validation loss=2.54]  7%|â–‹         | 37/500 [00:23<04:57,  1.56it/s, Train Loss=1.79, validation loss=2.54]  7%|â–‹         | 37/500 [00:24<04:57,  1.56it/s, Train Loss=2.37, validation loss=2.51]  8%|â–Š         | 38/500 [00:24<05:08,  1.50it/s, Train Loss=2.37, validation loss=2.51]  8%|â–Š         | 38/500 [00:25<05:08,  1.50it/s, Train Loss=2.12, validation loss=2.54]  8%|â–Š         | 39/500 [00:25<05:15,  1.46it/s, Train Loss=2.12, validation loss=2.54]  8%|â–Š         | 39/500 [00:25<05:15,  1.46it/s, Train Loss=2.26, validation loss=2.51]  8%|â–Š         | 40/500 [00:25<05:20,  1.43it/s, Train Loss=2.26, validation loss=2.51]  8%|â–Š         | 40/500 [00:26<05:20,  1.43it/s, Train Loss=2.55, validation loss=2.53]  8%|â–Š         | 41/500 [00:26<05:08,  1.49it/s, Train Loss=2.55, validation loss=2.53]  8%|â–Š         | 41/500 [00:27<05:08,  1.49it/s, Train Loss=3.28, validation loss=2.53]  8%|â–Š         | 42/500 [00:27<05:01,  1.52it/s, Train Loss=3.28, validation loss=2.53]  8%|â–Š         | 42/500 [00:27<05:01,  1.52it/s, Train Loss=2.36, validation loss=2.54]  9%|â–Š         | 43/500 [00:27<04:50,  1.57it/s, Train Loss=2.36, validation loss=2.54]  9%|â–Š         | 43/500 [00:28<04:50,  1.57it/s, Train Loss=2.94, validation loss=2.52]  9%|â–‰         | 44/500 [00:28<04:49,  1.57it/s, Train Loss=2.94, validation loss=2.52]  9%|â–‰         | 44/500 [00:29<04:49,  1.57it/s, Train Loss=3.02, validation loss=2.54]  9%|â–‰         | 45/500 [00:29<05:01,  1.51it/s, Train Loss=3.02, validation loss=2.54]  9%|â–‰         | 45/500 [00:29<05:01,  1.51it/s, Train Loss=4.81, validation loss=2.53]  9%|â–‰         | 46/500 [00:29<04:57,  1.52it/s, Train Loss=4.81, validation loss=2.53]  9%|â–‰         | 46/500 [00:30<04:57,  1.52it/s, Train Loss=3.1, validation loss=2.53]   9%|â–‰         | 47/500 [00:30<04:58,  1.52it/s, Train Loss=3.1, validation loss=2.53]  9%|â–‰         | 47/500 [00:31<04:58,  1.52it/s, Train Loss=1.69, validation loss=2.53] 10%|â–‰         | 48/500 [00:31<04:52,  1.55it/s, Train Loss=1.69, validation loss=2.53] 10%|â–‰         | 48/500 [00:31<04:52,  1.55it/s, Train Loss=3.25, validation loss=2.52] 10%|â–‰         | 49/500 [00:31<04:47,  1.57it/s, Train Loss=3.25, validation loss=2.52] 10%|â–‰         | 49/500 [00:32<04:47,  1.57it/s, Train Loss=2.92, validation loss=2.5]  10%|â–ˆ         | 50/500 [00:32<04:58,  1.51it/s, Train Loss=2.92, validation loss=2.5] 10%|â–ˆ         | 50/500 [00:33<04:58,  1.51it/s, Train Loss=3.02, validation loss=2.5] 10%|â–ˆ         | 51/500 [00:33<04:52,  1.53it/s, Train Loss=3.02, validation loss=2.5] 10%|â–ˆ         | 51/500 [00:33<04:52,  1.53it/s, Train Loss=2.59, validation loss=2.51] 10%|â–ˆ         | 52/500 [00:33<04:48,  1.55it/s, Train Loss=2.59, validation loss=2.51] 10%|â–ˆ         | 52/500 [00:34<04:48,  1.55it/s, Train Loss=2.75, validation loss=2.46] 11%|â–ˆ         | 53/500 [00:34<04:48,  1.55it/s, Train Loss=2.75, validation loss=2.46] 11%|â–ˆ         | 53/500 [00:34<04:48,  1.55it/s, Train Loss=4.49, validation loss=2.48] 11%|â–ˆ         | 54/500 [00:34<04:49,  1.54it/s, Train Loss=4.49, validation loss=2.48] 11%|â–ˆ         | 54/500 [00:35<04:49,  1.54it/s, Train Loss=2.06, validation loss=2.48] 11%|â–ˆ         | 55/500 [00:35<04:48,  1.54it/s, Train Loss=2.06, validation loss=2.48] 11%|â–ˆ         | 55/500 [00:36<04:48,  1.54it/s, Train Loss=2.37, validation loss=2.47] 11%|â–ˆ         | 56/500 [00:36<04:38,  1.59it/s, Train Loss=2.37, validation loss=2.47] 11%|â–ˆ         | 56/500 [00:36<04:38,  1.59it/s, Train Loss=2.17, validation loss=2.5]  11%|â–ˆâ–        | 57/500 [00:36<04:36,  1.60it/s, Train Loss=2.17, validation loss=2.5] 11%|â–ˆâ–        | 57/500 [00:37<04:36,  1.60it/s, Train Loss=3.25, validation loss=2.48] 12%|â–ˆâ–        | 58/500 [00:37<04:34,  1.61it/s, Train Loss=3.25, validation loss=2.48] 12%|â–ˆâ–        | 58/500 [00:38<04:34,  1.61it/s, Train Loss=3.3, validation loss=2.46]  12%|â–ˆâ–        | 59/500 [00:38<04:33,  1.61it/s, Train Loss=3.3, validation loss=2.46] 12%|â–ˆâ–        | 59/500 [00:38<04:33,  1.61it/s, Train Loss=2.54, validation loss=2.45] 12%|â–ˆâ–        | 60/500 [00:38<04:47,  1.53it/s, Train Loss=2.54, validation loss=2.45] 12%|â–ˆâ–        | 60/500 [00:39<04:47,  1.53it/s, Train Loss=4.17, validation loss=2.46] 12%|â–ˆâ–        | 61/500 [00:39<04:41,  1.56it/s, Train Loss=4.17, validation loss=2.46] 12%|â–ˆâ–        | 61/500 [00:39<04:41,  1.56it/s, Train Loss=3.28, validation loss=2.46] 12%|â–ˆâ–        | 62/500 [00:39<04:36,  1.59it/s, Train Loss=3.28, validation loss=2.46] 12%|â–ˆâ–        | 62/500 [00:40<04:36,  1.59it/s, Train Loss=3.95, validation loss=2.45] 13%|â–ˆâ–        | 63/500 [00:40<04:30,  1.62it/s, Train Loss=3.95, validation loss=2.45] 13%|â–ˆâ–        | 63/500 [00:41<04:30,  1.62it/s, Train Loss=2.06, validation loss=2.47] 13%|â–ˆâ–        | 64/500 [00:41<04:30,  1.61it/s, Train Loss=2.06, validation loss=2.47] 13%|â–ˆâ–        | 64/500 [00:41<04:30,  1.61it/s, Train Loss=4.25, validation loss=2.48] 13%|â–ˆâ–        | 65/500 [00:41<04:35,  1.58it/s, Train Loss=4.25, validation loss=2.48] 13%|â–ˆâ–        | 65/500 [00:42<04:35,  1.58it/s, Train Loss=2.53, validation loss=2.44] 13%|â–ˆâ–        | 66/500 [00:42<04:35,  1.57it/s, Train Loss=2.53, validation loss=2.44] 13%|â–ˆâ–        | 66/500 [00:43<04:35,  1.57it/s, Train Loss=2.34, validation loss=2.45] 13%|â–ˆâ–        | 67/500 [00:43<04:36,  1.57it/s, Train Loss=2.34, validation loss=2.45] 13%|â–ˆâ–        | 67/500 [00:43<04:36,  1.57it/s, Train Loss=2.49, validation loss=2.45] 14%|â–ˆâ–        | 68/500 [00:43<04:33,  1.58it/s, Train Loss=2.49, validation loss=2.45] 14%|â–ˆâ–        | 68/500 [00:44<04:33,  1.58it/s, Train Loss=2.33, validation loss=2.42] 14%|â–ˆâ–        | 69/500 [00:44<04:46,  1.51it/s, Train Loss=2.33, validation loss=2.42] 14%|â–ˆâ–        | 69/500 [00:45<04:46,  1.51it/s, Train Loss=1.89, validation loss=2.43] 14%|â–ˆâ–        | 70/500 [00:45<04:51,  1.47it/s, Train Loss=1.89, validation loss=2.43] 14%|â–ˆâ–        | 70/500 [00:45<04:51,  1.47it/s, Train Loss=2.65, validation loss=2.46] 14%|â–ˆâ–        | 71/500 [00:45<04:47,  1.49it/s, Train Loss=2.65, validation loss=2.46] 14%|â–ˆâ–        | 71/500 [00:46<04:47,  1.49it/s, Train Loss=2.51, validation loss=2.4]  14%|â–ˆâ–        | 72/500 [00:46<04:37,  1.54it/s, Train Loss=2.51, validation loss=2.4] 14%|â–ˆâ–        | 72/500 [00:47<04:37,  1.54it/s, Train Loss=3.22, validation loss=2.41] 15%|â–ˆâ–        | 73/500 [00:47<04:33,  1.56it/s, Train Loss=3.22, validation loss=2.41] 15%|â–ˆâ–        | 73/500 [00:47<04:33,  1.56it/s, Train Loss=2.08, validation loss=2.42] 15%|â–ˆâ–        | 74/500 [00:47<04:29,  1.58it/s, Train Loss=2.08, validation loss=2.42] 15%|â–ˆâ–        | 74/500 [00:48<04:29,  1.58it/s, Train Loss=2.52, validation loss=2.45] 15%|â–ˆâ–Œ        | 75/500 [00:48<04:43,  1.50it/s, Train Loss=2.52, validation loss=2.45] 15%|â–ˆâ–Œ        | 75/500 [00:49<04:43,  1.50it/s, Train Loss=1.54, validation loss=2.43] 15%|â–ˆâ–Œ        | 76/500 [00:49<04:36,  1.53it/s, Train Loss=1.54, validation loss=2.43] 15%|â–ˆâ–Œ        | 76/500 [00:49<04:36,  1.53it/s, Train Loss=2.21, validation loss=2.44] 15%|â–ˆâ–Œ        | 77/500 [00:49<04:30,  1.56it/s, Train Loss=2.21, validation loss=2.44] 15%|â–ˆâ–Œ        | 77/500 [00:50<04:30,  1.56it/s, Train Loss=2.69, validation loss=2.41] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:26,  1.58it/s, Train Loss=2.69, validation loss=2.41] 16%|â–ˆâ–Œ        | 78/500 [00:50<04:26,  1.58it/s, Train Loss=1.99, validation loss=2.41] 16%|â–ˆâ–Œ        | 79/500 [00:50<04:33,  1.54it/s, Train Loss=1.99, validation loss=2.41] 16%|â–ˆâ–Œ        | 79/500 [00:51<04:33,  1.54it/s, Train Loss=2.88, validation loss=2.41] 16%|â–ˆâ–Œ        | 80/500 [00:51<04:31,  1.55it/s, Train Loss=2.88, validation loss=2.41] 16%|â–ˆâ–Œ        | 80/500 [00:52<04:31,  1.55it/s, Train Loss=2.6, validation loss=2.42]  16%|â–ˆâ–Œ        | 81/500 [00:52<04:26,  1.57it/s, Train Loss=2.6, validation loss=2.42] 16%|â–ˆâ–Œ        | 81/500 [00:52<04:26,  1.57it/s, Train Loss=1.8, validation loss=2.41] 16%|â–ˆâ–‹        | 82/500 [00:52<04:26,  1.57it/s, Train Loss=1.8, validation loss=2.41] 16%|â–ˆâ–‹        | 82/500 [00:53<04:26,  1.57it/s, Train Loss=3.45, validation loss=2.39] 17%|â–ˆâ–‹        | 83/500 [00:53<04:23,  1.58it/s, Train Loss=3.45, validation loss=2.39] 17%|â–ˆâ–‹        | 83/500 [00:54<04:23,  1.58it/s, Train Loss=2.33, validation loss=2.41] 17%|â–ˆâ–‹        | 84/500 [00:54<04:34,  1.52it/s, Train Loss=2.33, validation loss=2.41] 17%|â–ˆâ–‹        | 84/500 [00:54<04:34,  1.52it/s, Train Loss=1.87, validation loss=2.38] 17%|â–ˆâ–‹        | 85/500 [00:54<04:28,  1.55it/s, Train Loss=1.87, validation loss=2.38] 17%|â–ˆâ–‹        | 85/500 [00:55<04:28,  1.55it/s, Train Loss=3.22, validation loss=2.38] 17%|â–ˆâ–‹        | 86/500 [00:55<04:23,  1.57it/s, Train Loss=3.22, validation loss=2.38] 17%|â–ˆâ–‹        | 86/500 [00:56<04:23,  1.57it/s, Train Loss=2.69, validation loss=2.39] 17%|â–ˆâ–‹        | 87/500 [00:56<04:21,  1.58it/s, Train Loss=2.69, validation loss=2.39] 17%|â–ˆâ–‹        | 87/500 [00:56<04:21,  1.58it/s, Train Loss=1.99, validation loss=2.44] 18%|â–ˆâ–Š        | 88/500 [00:56<04:17,  1.60it/s, Train Loss=1.99, validation loss=2.44] 18%|â–ˆâ–Š        | 88/500 [00:57<04:17,  1.60it/s, Train Loss=3.34, validation loss=2.39] 18%|â–ˆâ–Š        | 89/500 [00:57<04:37,  1.48it/s, Train Loss=3.34, validation loss=2.39] 18%|â–ˆâ–Š        | 89/500 [00:58<04:37,  1.48it/s, Train Loss=1.83, validation loss=2.4]  18%|â–ˆâ–Š        | 90/500 [00:58<04:28,  1.53it/s, Train Loss=1.83, validation loss=2.4] 18%|â–ˆâ–Š        | 90/500 [00:58<04:28,  1.53it/s, Train Loss=1.56, validation loss=2.42] 18%|â–ˆâ–Š        | 91/500 [00:58<04:25,  1.54it/s, Train Loss=1.56, validation loss=2.42] 18%|â–ˆâ–Š        | 91/500 [00:59<04:25,  1.54it/s, Train Loss=3.82, validation loss=2.38] 18%|â–ˆâ–Š        | 92/500 [00:59<04:37,  1.47it/s, Train Loss=3.82, validation loss=2.38] 18%|â–ˆâ–Š        | 92/500 [01:00<04:37,  1.47it/s, Train Loss=2.74, validation loss=2.4]  19%|â–ˆâ–Š        | 93/500 [01:00<04:26,  1.53it/s, Train Loss=2.74, validation loss=2.4] 19%|â–ˆâ–Š        | 93/500 [01:00<04:26,  1.53it/s, Train Loss=3.44, validation loss=2.41] 19%|â–ˆâ–‰        | 94/500 [01:00<04:21,  1.55it/s, Train Loss=3.44, validation loss=2.41] 19%|â–ˆâ–‰        | 94/500 [01:01<04:21,  1.55it/s, Train Loss=2.06, validation loss=2.37] 19%|â–ˆâ–‰        | 95/500 [01:01<04:18,  1.56it/s, Train Loss=2.06, validation loss=2.37] 19%|â–ˆâ–‰        | 95/500 [01:01<04:18,  1.56it/s, Train Loss=3.91, validation loss=2.38] 19%|â–ˆâ–‰        | 96/500 [01:01<04:18,  1.56it/s, Train Loss=3.91, validation loss=2.38] 19%|â–ˆâ–‰        | 96/500 [01:02<04:18,  1.56it/s, Train Loss=2, validation loss=2.39]    19%|â–ˆâ–‰        | 97/500 [01:02<04:15,  1.57it/s, Train Loss=2, validation loss=2.39] 19%|â–ˆâ–‰        | 97/500 [01:03<04:15,  1.57it/s, Train Loss=2.24, validation loss=2.37] 20%|â–ˆâ–‰        | 98/500 [01:03<04:30,  1.49it/s, Train Loss=2.24, validation loss=2.37] 20%|â–ˆâ–‰        | 98/500 [01:03<04:30,  1.49it/s, Train Loss=1.47, validation loss=2.39] 20%|â–ˆâ–‰        | 99/500 [01:03<04:22,  1.53it/s, Train Loss=1.47, validation loss=2.39]####################################################################################################
--------------------------------------------- Epoch:100 ---------------------------------------------
-- Training set:
Loss: 4.5213141441345215, Lr: 0.0005
Average AUC ROC: 0.53                Average AUC PR: 0.3
 20%|â–ˆâ–‰        | 99/500 [01:04<04:22,  1.53it/s, Train Loss=4.52, validation loss=2.4]  20%|â–ˆâ–ˆ        | 100/500 [01:04<04:22,  1.53it/s, Train Loss=4.52, validation loss=2.4]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.401046320796013
Average AUC ROC: 0.57                    Average AUC PR: 0.32
 20%|â–ˆâ–ˆ        | 100/500 [01:05<04:22,  1.53it/s, Train Loss=3, validation loss=2.4]    20%|â–ˆâ–ˆ        | 101/500 [01:05<04:16,  1.56it/s, Train Loss=3, validation loss=2.4] 20%|â–ˆâ–ˆ        | 101/500 [01:06<04:16,  1.56it/s, Train Loss=3.03, validation loss=2.4] 20%|â–ˆâ–ˆ        | 102/500 [01:06<04:36,  1.44it/s, Train Loss=3.03, validation loss=2.4] 20%|â–ˆâ–ˆ        | 102/500 [01:06<04:36,  1.44it/s, Train Loss=1.4, validation loss=2.4]  21%|â–ˆâ–ˆ        | 103/500 [01:06<04:32,  1.46it/s, Train Loss=1.4, validation loss=2.4] 21%|â–ˆâ–ˆ        | 103/500 [01:07<04:32,  1.46it/s, Train Loss=2.92, validation loss=2.36] 21%|â–ˆâ–ˆ        | 104/500 [01:07<04:26,  1.49it/s, Train Loss=2.92, validation loss=2.36] 21%|â–ˆâ–ˆ        | 104/500 [01:07<04:26,  1.49it/s, Train Loss=2.06, validation loss=2.38] 21%|â–ˆâ–ˆ        | 105/500 [01:07<04:16,  1.54it/s, Train Loss=2.06, validation loss=2.38] 21%|â–ˆâ–ˆ        | 105/500 [01:08<04:16,  1.54it/s, Train Loss=1.75, validation loss=2.39] 21%|â–ˆâ–ˆ        | 106/500 [01:08<04:26,  1.48it/s, Train Loss=1.75, validation loss=2.39] 21%|â–ˆâ–ˆ        | 106/500 [01:09<04:26,  1.48it/s, Train Loss=2.49, validation loss=2.4]  21%|â–ˆâ–ˆâ–       | 107/500 [01:09<04:18,  1.52it/s, Train Loss=2.49, validation loss=2.4] 21%|â–ˆâ–ˆâ–       | 107/500 [01:09<04:18,  1.52it/s, Train Loss=3.21, validation loss=2.36] 22%|â–ˆâ–ˆâ–       | 108/500 [01:09<04:09,  1.57it/s, Train Loss=3.21, validation loss=2.36] 22%|â–ˆâ–ˆâ–       | 108/500 [01:10<04:09,  1.57it/s, Train Loss=1.76, validation loss=2.4]  22%|â–ˆâ–ˆâ–       | 109/500 [01:10<04:08,  1.57it/s, Train Loss=1.76, validation loss=2.4] 22%|â–ˆâ–ˆâ–       | 109/500 [01:11<04:08,  1.57it/s, Train Loss=3.4, validation loss=2.37] 22%|â–ˆâ–ˆâ–       | 110/500 [01:11<04:05,  1.59it/s, Train Loss=3.4, validation loss=2.37] 22%|â–ˆâ–ˆâ–       | 110/500 [01:11<04:05,  1.59it/s, Train Loss=2.12, validation loss=2.36] 22%|â–ˆâ–ˆâ–       | 111/500 [01:11<04:07,  1.57it/s, Train Loss=2.12, validation loss=2.36] 22%|â–ˆâ–ˆâ–       | 111/500 [01:12<04:07,  1.57it/s, Train Loss=2.61, validation loss=2.42] 22%|â–ˆâ–ˆâ–       | 112/500 [01:12<04:04,  1.59it/s, Train Loss=2.61, validation loss=2.42] 22%|â–ˆâ–ˆâ–       | 112/500 [01:13<04:04,  1.59it/s, Train Loss=2.15, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 113/500 [01:13<04:03,  1.59it/s, Train Loss=2.15, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 113/500 [01:13<04:03,  1.59it/s, Train Loss=2.54, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 114/500 [01:13<03:59,  1.61it/s, Train Loss=2.54, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 114/500 [01:14<03:59,  1.61it/s, Train Loss=2.8, validation loss=2.35]  23%|â–ˆâ–ˆâ–       | 115/500 [01:14<04:12,  1.52it/s, Train Loss=2.8, validation loss=2.35] 23%|â–ˆâ–ˆâ–       | 115/500 [01:14<04:12,  1.52it/s, Train Loss=1.86, validation loss=2.37] 23%|â–ˆâ–ˆâ–       | 116/500 [01:14<04:09,  1.54it/s, Train Loss=1.86, validation loss=2.37] 23%|â–ˆâ–ˆâ–       | 116/500 [01:15<04:09,  1.54it/s, Train Loss=2.47, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 117/500 [01:15<04:05,  1.56it/s, Train Loss=2.47, validation loss=2.36] 23%|â–ˆâ–ˆâ–       | 117/500 [01:16<04:05,  1.56it/s, Train Loss=1.63, validation loss=2.37] 24%|â–ˆâ–ˆâ–       | 118/500 [01:16<04:03,  1.57it/s, Train Loss=1.63, validation loss=2.37] 24%|â–ˆâ–ˆâ–       | 118/500 [01:16<04:03,  1.57it/s, Train Loss=2.2, validation loss=2.38]  24%|â–ˆâ–ˆâ–       | 119/500 [01:16<03:59,  1.59it/s, Train Loss=2.2, validation loss=2.38] 24%|â–ˆâ–ˆâ–       | 119/500 [01:17<03:59,  1.59it/s, Train Loss=2.01, validation loss=2.37] 24%|â–ˆâ–ˆâ–       | 120/500 [01:17<04:09,  1.52it/s, Train Loss=2.01, validation loss=2.37] 24%|â–ˆâ–ˆâ–       | 120/500 [01:18<04:09,  1.52it/s, Train Loss=3.21, validation loss=2.37] 24%|â–ˆâ–ˆâ–       | 121/500 [01:18<04:04,  1.55it/s, Train Loss=3.21, validation loss=2.37] 24%|â–ˆâ–ˆâ–       | 121/500 [01:18<04:04,  1.55it/s, Train Loss=3.39, validation loss=2.38] 24%|â–ˆâ–ˆâ–       | 122/500 [01:18<04:08,  1.52it/s, Train Loss=3.39, validation loss=2.38] 24%|â–ˆâ–ˆâ–       | 122/500 [01:19<04:08,  1.52it/s, Train Loss=1.97, validation loss=2.35] 25%|â–ˆâ–ˆâ–       | 123/500 [01:19<04:04,  1.54it/s, Train Loss=1.97, validation loss=2.35] 25%|â–ˆâ–ˆâ–       | 123/500 [01:20<04:04,  1.54it/s, Train Loss=1.56, validation loss=2.37] 25%|â–ˆâ–ˆâ–       | 124/500 [01:20<04:01,  1.56it/s, Train Loss=1.56, validation loss=2.37] 25%|â–ˆâ–ˆâ–       | 124/500 [01:20<04:01,  1.56it/s, Train Loss=1.86, validation loss=2.36] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:20<04:07,  1.51it/s, Train Loss=1.86, validation loss=2.36] 25%|â–ˆâ–ˆâ–Œ       | 125/500 [01:21<04:07,  1.51it/s, Train Loss=2.33, validation loss=2.35] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:21<04:04,  1.53it/s, Train Loss=2.33, validation loss=2.35] 25%|â–ˆâ–ˆâ–Œ       | 126/500 [01:22<04:04,  1.53it/s, Train Loss=3.27, validation loss=2.35] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:22<04:02,  1.54it/s, Train Loss=3.27, validation loss=2.35] 25%|â–ˆâ–ˆâ–Œ       | 127/500 [01:22<04:02,  1.54it/s, Train Loss=2.65, validation loss=2.34] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:22<03:56,  1.57it/s, Train Loss=2.65, validation loss=2.34] 26%|â–ˆâ–ˆâ–Œ       | 128/500 [01:23<03:56,  1.57it/s, Train Loss=2.88, validation loss=2.35] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:23<04:04,  1.52it/s, Train Loss=2.88, validation loss=2.35] 26%|â–ˆâ–ˆâ–Œ       | 129/500 [01:24<04:04,  1.52it/s, Train Loss=3.75, validation loss=2.33] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:24<04:00,  1.54it/s, Train Loss=3.75, validation loss=2.33] 26%|â–ˆâ–ˆâ–Œ       | 130/500 [01:24<04:00,  1.54it/s, Train Loss=2.4, validation loss=2.36]  26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:24<03:55,  1.57it/s, Train Loss=2.4, validation loss=2.36] 26%|â–ˆâ–ˆâ–Œ       | 131/500 [01:25<03:55,  1.57it/s, Train Loss=1.87, validation loss=2.37] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:25<03:53,  1.58it/s, Train Loss=1.87, validation loss=2.37] 26%|â–ˆâ–ˆâ–‹       | 132/500 [01:26<03:53,  1.58it/s, Train Loss=2, validation loss=2.38]    27%|â–ˆâ–ˆâ–‹       | 133/500 [01:26<04:02,  1.51it/s, Train Loss=2, validation loss=2.38] 27%|â–ˆâ–ˆâ–‹       | 133/500 [01:26<04:02,  1.51it/s, Train Loss=2.32, validation loss=2.34] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:26<03:59,  1.53it/s, Train Loss=2.32, validation loss=2.34] 27%|â–ˆâ–ˆâ–‹       | 134/500 [01:27<03:59,  1.53it/s, Train Loss=2.59, validation loss=2.35] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:27<04:04,  1.49it/s, Train Loss=2.59, validation loss=2.35] 27%|â–ˆâ–ˆâ–‹       | 135/500 [01:27<04:04,  1.49it/s, Train Loss=3.12, validation loss=2.33] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:27<03:58,  1.53it/s, Train Loss=3.12, validation loss=2.33] 27%|â–ˆâ–ˆâ–‹       | 136/500 [01:28<03:58,  1.53it/s, Train Loss=2.01, validation loss=2.37] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:28<03:53,  1.56it/s, Train Loss=2.01, validation loss=2.37] 27%|â–ˆâ–ˆâ–‹       | 137/500 [01:29<03:53,  1.56it/s, Train Loss=1.32, validation loss=2.38] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:29<04:00,  1.50it/s, Train Loss=1.32, validation loss=2.38] 28%|â–ˆâ–ˆâ–Š       | 138/500 [01:29<04:00,  1.50it/s, Train Loss=1.75, validation loss=2.35] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:29<03:56,  1.53it/s, Train Loss=1.75, validation loss=2.35] 28%|â–ˆâ–ˆâ–Š       | 139/500 [01:30<03:56,  1.53it/s, Train Loss=4.2, validation loss=2.34]  28%|â–ˆâ–ˆâ–Š       | 140/500 [01:30<03:52,  1.55it/s, Train Loss=4.2, validation loss=2.34] 28%|â–ˆâ–ˆâ–Š       | 140/500 [01:31<03:52,  1.55it/s, Train Loss=1.62, validation loss=2.36] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:31<03:49,  1.57it/s, Train Loss=1.62, validation loss=2.36] 28%|â–ˆâ–ˆâ–Š       | 141/500 [01:31<03:49,  1.57it/s, Train Loss=2.09, validation loss=2.36] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:31<03:45,  1.59it/s, Train Loss=2.09, validation loss=2.36] 28%|â–ˆâ–ˆâ–Š       | 142/500 [01:32<03:45,  1.59it/s, Train Loss=2.06, validation loss=2.35] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:32<03:49,  1.55it/s, Train Loss=2.06, validation loss=2.35] 29%|â–ˆâ–ˆâ–Š       | 143/500 [01:33<03:49,  1.55it/s, Train Loss=2.38, validation loss=2.36] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:33<03:48,  1.56it/s, Train Loss=2.38, validation loss=2.36] 29%|â–ˆâ–ˆâ–‰       | 144/500 [01:33<03:48,  1.56it/s, Train Loss=1.98, validation loss=2.34] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:33<03:46,  1.57it/s, Train Loss=1.98, validation loss=2.34] 29%|â–ˆâ–ˆâ–‰       | 145/500 [01:34<03:46,  1.57it/s, Train Loss=2, validation loss=2.36]    29%|â–ˆâ–ˆâ–‰       | 146/500 [01:34<03:45,  1.57it/s, Train Loss=2, validation loss=2.36] 29%|â–ˆâ–ˆâ–‰       | 146/500 [01:35<03:45,  1.57it/s, Train Loss=2.36, validation loss=2.36] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:35<03:53,  1.51it/s, Train Loss=2.36, validation loss=2.36] 29%|â–ˆâ–ˆâ–‰       | 147/500 [01:35<03:53,  1.51it/s, Train Loss=4.81, validation loss=2.34] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:35<03:49,  1.53it/s, Train Loss=4.81, validation loss=2.34] 30%|â–ˆâ–ˆâ–‰       | 148/500 [01:36<03:49,  1.53it/s, Train Loss=2.38, validation loss=2.37] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:36<03:43,  1.57it/s, Train Loss=2.38, validation loss=2.37] 30%|â–ˆâ–ˆâ–‰       | 149/500 [01:36<03:43,  1.57it/s, Train Loss=2.85, validation loss=2.33] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:36<03:43,  1.56it/s, Train Loss=2.85, validation loss=2.33] 30%|â–ˆâ–ˆâ–ˆ       | 150/500 [01:37<03:43,  1.56it/s, Train Loss=1.93, validation loss=2.35] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:37<03:41,  1.58it/s, Train Loss=1.93, validation loss=2.35] 30%|â–ˆâ–ˆâ–ˆ       | 151/500 [01:38<03:41,  1.58it/s, Train Loss=2.19, validation loss=2.36] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:38<03:48,  1.52it/s, Train Loss=2.19, validation loss=2.36] 30%|â–ˆâ–ˆâ–ˆ       | 152/500 [01:38<03:48,  1.52it/s, Train Loss=2.46, validation loss=2.35] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:38<03:49,  1.51it/s, Train Loss=2.46, validation loss=2.35] 31%|â–ˆâ–ˆâ–ˆ       | 153/500 [01:39<03:49,  1.51it/s, Train Loss=2.8, validation loss=2.33]  31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:39<03:46,  1.53it/s, Train Loss=2.8, validation loss=2.33] 31%|â–ˆâ–ˆâ–ˆ       | 154/500 [01:40<03:46,  1.53it/s, Train Loss=2.12, validation loss=2.33] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:40<03:42,  1.55it/s, Train Loss=2.12, validation loss=2.33] 31%|â–ˆâ–ˆâ–ˆ       | 155/500 [01:40<03:42,  1.55it/s, Train Loss=2.22, validation loss=2.34] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:40<03:43,  1.54it/s, Train Loss=2.22, validation loss=2.34] 31%|â–ˆâ–ˆâ–ˆ       | 156/500 [01:41<03:43,  1.54it/s, Train Loss=1.84, validation loss=2.37] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:41<03:49,  1.50it/s, Train Loss=1.84, validation loss=2.37] 31%|â–ˆâ–ˆâ–ˆâ–      | 157/500 [01:42<03:49,  1.50it/s, Train Loss=3.91, validation loss=2.35] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:42<03:41,  1.54it/s, Train Loss=3.91, validation loss=2.35] 32%|â–ˆâ–ˆâ–ˆâ–      | 158/500 [01:42<03:41,  1.54it/s, Train Loss=2.71, validation loss=2.34] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:42<03:41,  1.54it/s, Train Loss=2.71, validation loss=2.34] 32%|â–ˆâ–ˆâ–ˆâ–      | 159/500 [01:43<03:41,  1.54it/s, Train Loss=2.58, validation loss=2.34] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:43<03:44,  1.51it/s, Train Loss=2.58, validation loss=2.34] 32%|â–ˆâ–ˆâ–ˆâ–      | 160/500 [01:44<03:44,  1.51it/s, Train Loss=2.61, validation loss=2.35] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:44<03:43,  1.51it/s, Train Loss=2.61, validation loss=2.35] 32%|â–ˆâ–ˆâ–ˆâ–      | 161/500 [01:44<03:43,  1.51it/s, Train Loss=1.83, validation loss=2.36] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:44<03:42,  1.52it/s, Train Loss=1.83, validation loss=2.36] 32%|â–ˆâ–ˆâ–ˆâ–      | 162/500 [01:45<03:42,  1.52it/s, Train Loss=2.23, validation loss=2.33] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:45<03:35,  1.57it/s, Train Loss=2.23, validation loss=2.33] 33%|â–ˆâ–ˆâ–ˆâ–      | 163/500 [01:46<03:35,  1.57it/s, Train Loss=2.14, validation loss=2.33] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:46<03:34,  1.57it/s, Train Loss=2.14, validation loss=2.33] 33%|â–ˆâ–ˆâ–ˆâ–      | 164/500 [01:46<03:34,  1.57it/s, Train Loss=2.55, validation loss=2.34] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:46<03:35,  1.55it/s, Train Loss=2.55, validation loss=2.34] 33%|â–ˆâ–ˆâ–ˆâ–      | 165/500 [01:47<03:35,  1.55it/s, Train Loss=1.52, validation loss=2.37] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:47<03:47,  1.47it/s, Train Loss=1.52, validation loss=2.37] 33%|â–ˆâ–ˆâ–ˆâ–      | 166/500 [01:48<03:47,  1.47it/s, Train Loss=1.93, validation loss=2.35] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:48<03:39,  1.52it/s, Train Loss=1.93, validation loss=2.35] 33%|â–ˆâ–ˆâ–ˆâ–      | 167/500 [01:48<03:39,  1.52it/s, Train Loss=2.02, validation loss=2.33] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:48<03:33,  1.56it/s, Train Loss=2.02, validation loss=2.33] 34%|â–ˆâ–ˆâ–ˆâ–      | 168/500 [01:49<03:33,  1.56it/s, Train Loss=3.38, validation loss=2.34] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:49<03:39,  1.51it/s, Train Loss=3.38, validation loss=2.34] 34%|â–ˆâ–ˆâ–ˆâ–      | 169/500 [01:50<03:39,  1.51it/s, Train Loss=2.5, validation loss=2.31]  34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:50<03:33,  1.54it/s, Train Loss=2.5, validation loss=2.31] 34%|â–ˆâ–ˆâ–ˆâ–      | 170/500 [01:50<03:33,  1.54it/s, Train Loss=3.34, validation loss=2.34] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:50<03:28,  1.58it/s, Train Loss=3.34, validation loss=2.34] 34%|â–ˆâ–ˆâ–ˆâ–      | 171/500 [01:51<03:28,  1.58it/s, Train Loss=4.38, validation loss=2.32] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:51<03:28,  1.57it/s, Train Loss=4.38, validation loss=2.32] 34%|â–ˆâ–ˆâ–ˆâ–      | 172/500 [01:51<03:28,  1.57it/s, Train Loss=4.18, validation loss=2.32] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:51<03:26,  1.59it/s, Train Loss=4.18, validation loss=2.32] 35%|â–ˆâ–ˆâ–ˆâ–      | 173/500 [01:52<03:26,  1.59it/s, Train Loss=1.95, validation loss=2.35] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:52<03:33,  1.53it/s, Train Loss=1.95, validation loss=2.35] 35%|â–ˆâ–ˆâ–ˆâ–      | 174/500 [01:53<03:33,  1.53it/s, Train Loss=2.33, validation loss=2.36] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:53<03:27,  1.56it/s, Train Loss=2.33, validation loss=2.36] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175/500 [01:53<03:27,  1.56it/s, Train Loss=2.6, validation loss=2.34]  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:53<03:25,  1.58it/s, Train Loss=2.6, validation loss=2.34] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176/500 [01:54<03:25,  1.58it/s, Train Loss=1.86, validation loss=2.33] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:54<03:29,  1.54it/s, Train Loss=1.86, validation loss=2.33] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177/500 [01:55<03:29,  1.54it/s, Train Loss=3.47, validation loss=2.33] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:55<03:28,  1.54it/s, Train Loss=3.47, validation loss=2.33] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178/500 [01:55<03:28,  1.54it/s, Train Loss=3.03, validation loss=2.34] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:55<03:26,  1.56it/s, Train Loss=3.03, validation loss=2.34] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179/500 [01:56<03:26,  1.56it/s, Train Loss=2.55, validation loss=2.35] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:56<03:24,  1.56it/s, Train Loss=2.55, validation loss=2.35] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180/500 [01:57<03:24,  1.56it/s, Train Loss=1.91, validation loss=2.34] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:57<03:22,  1.57it/s, Train Loss=1.91, validation loss=2.34] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181/500 [01:57<03:22,  1.57it/s, Train Loss=1.59, validation loss=2.33] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:57<03:22,  1.57it/s, Train Loss=1.59, validation loss=2.33] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 182/500 [01:58<03:22,  1.57it/s, Train Loss=3.31, validation loss=2.32] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:58<03:31,  1.50it/s, Train Loss=3.31, validation loss=2.32] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/500 [01:59<03:31,  1.50it/s, Train Loss=2.09, validation loss=2.32] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:59<03:26,  1.53it/s, Train Loss=2.09, validation loss=2.32] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 184/500 [01:59<03:26,  1.53it/s, Train Loss=2.85, validation loss=2.33] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [01:59<03:23,  1.55it/s, Train Loss=2.85, validation loss=2.33] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 185/500 [02:00<03:23,  1.55it/s, Train Loss=1.72, validation loss=2.33] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:00<03:30,  1.49it/s, Train Loss=1.72, validation loss=2.33] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 186/500 [02:01<03:30,  1.49it/s, Train Loss=2.58, validation loss=2.32] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:01<03:23,  1.54it/s, Train Loss=2.58, validation loss=2.32] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 187/500 [02:01<03:23,  1.54it/s, Train Loss=2.49, validation loss=2.31] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:01<03:19,  1.56it/s, Train Loss=2.49, validation loss=2.31] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 188/500 [02:02<03:19,  1.56it/s, Train Loss=1.94, validation loss=2.33] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:02<03:15,  1.59it/s, Train Loss=1.94, validation loss=2.33] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 189/500 [02:02<03:15,  1.59it/s, Train Loss=2, validation loss=2.32]    38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:02<03:13,  1.60it/s, Train Loss=2, validation loss=2.32] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 190/500 [02:03<03:13,  1.60it/s, Train Loss=2.34, validation loss=2.34] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:03<03:22,  1.52it/s, Train Loss=2.34, validation loss=2.34] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 191/500 [02:04<03:22,  1.52it/s, Train Loss=1.96, validation loss=2.35] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:04<03:16,  1.56it/s, Train Loss=1.96, validation loss=2.35] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 192/500 [02:04<03:16,  1.56it/s, Train Loss=3.69, validation loss=2.34] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:04<03:16,  1.56it/s, Train Loss=3.69, validation loss=2.34] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 193/500 [02:05<03:16,  1.56it/s, Train Loss=1.82, validation loss=2.32] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:05<03:13,  1.58it/s, Train Loss=1.82, validation loss=2.32] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 194/500 [02:06<03:13,  1.58it/s, Train Loss=2.03, validation loss=2.32] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:06<03:22,  1.51it/s, Train Loss=2.03, validation loss=2.32] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 195/500 [02:06<03:22,  1.51it/s, Train Loss=1.96, validation loss=2.35] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:06<03:26,  1.47it/s, Train Loss=1.96, validation loss=2.35] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 196/500 [02:07<03:26,  1.47it/s, Train Loss=1.74, validation loss=2.33] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:07<03:29,  1.45it/s, Train Loss=1.74, validation loss=2.33] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 197/500 [02:08<03:29,  1.45it/s, Train Loss=2.09, validation loss=2.31] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:08<03:20,  1.51it/s, Train Loss=2.09, validation loss=2.31] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 198/500 [02:08<03:20,  1.51it/s, Train Loss=1.55, validation loss=2.32] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:08<03:14,  1.55it/s, Train Loss=1.55, validation loss=2.32]####################################################################################################
--------------------------------------------- Epoch:200 ---------------------------------------------
-- Training set:
Loss: 3.0067992210388184, Lr: 0.00025
Average AUC ROC: 0.52                Average AUC PR: 0.3
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 199/500 [02:09<03:14,  1.55it/s, Train Loss=3.01, validation loss=2.3]  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:09<03:20,  1.50it/s, Train Loss=3.01, validation loss=2.3]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.304604895412922
Average AUC ROC: 0.56                    Average AUC PR: 0.31
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200/500 [02:10<03:20,  1.50it/s, Train Loss=2.13, validation loss=2.34] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:10<03:13,  1.54it/s, Train Loss=2.13, validation loss=2.34] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 201/500 [02:10<03:13,  1.54it/s, Train Loss=2.56, validation loss=2.33] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:10<03:09,  1.57it/s, Train Loss=2.56, validation loss=2.33] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202/500 [02:11<03:09,  1.57it/s, Train Loss=2.56, validation loss=2.31] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:11<03:07,  1.59it/s, Train Loss=2.56, validation loss=2.31] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203/500 [02:12<03:07,  1.59it/s, Train Loss=2.41, validation loss=2.3]  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:12<03:13,  1.53it/s, Train Loss=2.41, validation loss=2.3] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204/500 [02:12<03:13,  1.53it/s, Train Loss=1.46, validation loss=2.31] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:12<03:09,  1.56it/s, Train Loss=1.46, validation loss=2.31] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205/500 [02:13<03:09,  1.56it/s, Train Loss=1.71, validation loss=2.3]  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:13<03:07,  1.57it/s, Train Loss=1.71, validation loss=2.3] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206/500 [02:13<03:07,  1.57it/s, Train Loss=2.84, validation loss=2.3] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:13<03:05,  1.58it/s, Train Loss=2.84, validation loss=2.3] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207/500 [02:14<03:05,  1.58it/s, Train Loss=1.23, validation loss=2.31] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:14<03:10,  1.53it/s, Train Loss=1.23, validation loss=2.31] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208/500 [02:15<03:10,  1.53it/s, Train Loss=2.55, validation loss=2.3]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:15<03:06,  1.56it/s, Train Loss=2.55, validation loss=2.3] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209/500 [02:15<03:06,  1.56it/s, Train Loss=2.63, validation loss=2.3] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:15<03:01,  1.60it/s, Train Loss=2.63, validation loss=2.3] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/500 [02:16<03:01,  1.60it/s, Train Loss=1.79, validation loss=2.31] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:16<03:01,  1.60it/s, Train Loss=1.79, validation loss=2.31] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211/500 [02:17<03:01,  1.60it/s, Train Loss=1.85, validation loss=2.31] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:17<03:00,  1.59it/s, Train Loss=1.85, validation loss=2.31] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212/500 [02:17<03:00,  1.59it/s, Train Loss=1.99, validation loss=2.32] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:17<03:05,  1.55it/s, Train Loss=1.99, validation loss=2.32] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 213/500 [02:18<03:05,  1.55it/s, Train Loss=2.45, validation loss=2.3]  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:18<03:03,  1.56it/s, Train Loss=2.45, validation loss=2.3] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 214/500 [02:19<03:03,  1.56it/s, Train Loss=1.96, validation loss=2.3] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:19<03:00,  1.58it/s, Train Loss=1.96, validation loss=2.3] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 215/500 [02:19<03:00,  1.58it/s, Train Loss=1.37, validation loss=2.32] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:19<03:00,  1.58it/s, Train Loss=1.37, validation loss=2.32] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216/500 [02:20<03:00,  1.58it/s, Train Loss=2.71, validation loss=2.3]  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:20<03:04,  1.53it/s, Train Loss=2.71, validation loss=2.3] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 217/500 [02:20<03:04,  1.53it/s, Train Loss=1.9, validation loss=2.3]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:20<03:01,  1.55it/s, Train Loss=1.9, validation loss=2.3] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 218/500 [02:21<03:01,  1.55it/s, Train Loss=1.96, validation loss=2.33] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:21<02:59,  1.57it/s, Train Loss=1.96, validation loss=2.33] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219/500 [02:22<02:59,  1.57it/s, Train Loss=1.8, validation loss=2.31]  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:22<03:01,  1.54it/s, Train Loss=1.8, validation loss=2.31] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/500 [02:23<03:01,  1.54it/s, Train Loss=1.79, validation loss=2.32] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:23<03:06,  1.50it/s, Train Loss=1.79, validation loss=2.32] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221/500 [02:23<03:06,  1.50it/s, Train Loss=4.31, validation loss=2.32] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:23<03:02,  1.53it/s, Train Loss=4.31, validation loss=2.32] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222/500 [02:24<03:02,  1.53it/s, Train Loss=2.29, validation loss=2.33] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:24<02:58,  1.55it/s, Train Loss=2.29, validation loss=2.33] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 223/500 [02:24<02:58,  1.55it/s, Train Loss=1.98, validation loss=2.32] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:24<03:03,  1.50it/s, Train Loss=1.98, validation loss=2.32] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/500 [02:25<03:03,  1.50it/s, Train Loss=1.94, validation loss=2.32] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:25<03:02,  1.51it/s, Train Loss=1.94, validation loss=2.32] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225/500 [02:26<03:02,  1.51it/s, Train Loss=1.58, validation loss=2.33] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:26<02:59,  1.53it/s, Train Loss=1.58, validation loss=2.33] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226/500 [02:26<02:59,  1.53it/s, Train Loss=3.37, validation loss=2.29] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:26<02:59,  1.52it/s, Train Loss=3.37, validation loss=2.29] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227/500 [02:27<02:59,  1.52it/s, Train Loss=1.71, validation loss=2.33] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:27<02:59,  1.51it/s, Train Loss=1.71, validation loss=2.33] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228/500 [02:28<02:59,  1.51it/s, Train Loss=2.09, validation loss=2.33] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:28<02:57,  1.53it/s, Train Loss=2.09, validation loss=2.33] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229/500 [02:28<02:57,  1.53it/s, Train Loss=2.36, validation loss=2.31] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:28<03:04,  1.46it/s, Train Loss=2.36, validation loss=2.31] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230/500 [02:29<03:04,  1.46it/s, Train Loss=2.1, validation loss=2.29]  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:29<02:57,  1.51it/s, Train Loss=2.1, validation loss=2.29] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231/500 [02:30<02:57,  1.51it/s, Train Loss=1.95, validation loss=2.33] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:30<02:52,  1.55it/s, Train Loss=1.95, validation loss=2.33] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232/500 [02:30<02:52,  1.55it/s, Train Loss=2.14, validation loss=2.31] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:30<02:55,  1.52it/s, Train Loss=2.14, validation loss=2.31] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233/500 [02:31<02:55,  1.52it/s, Train Loss=1.7, validation loss=2.32]  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:31<02:51,  1.55it/s, Train Loss=1.7, validation loss=2.32] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234/500 [02:32<02:51,  1.55it/s, Train Loss=1.87, validation loss=2.34] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:32<02:50,  1.56it/s, Train Loss=1.87, validation loss=2.34] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235/500 [02:32<02:50,  1.56it/s, Train Loss=2.45, validation loss=2.31] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:32<02:50,  1.55it/s, Train Loss=2.45, validation loss=2.31] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236/500 [02:33<02:50,  1.55it/s, Train Loss=2.62, validation loss=2.33] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:33<02:46,  1.58it/s, Train Loss=2.62, validation loss=2.33] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/500 [02:34<02:46,  1.58it/s, Train Loss=2.32, validation loss=2.33] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:34<02:55,  1.49it/s, Train Loss=2.32, validation loss=2.33] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238/500 [02:34<02:55,  1.49it/s, Train Loss=1.76, validation loss=2.31] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:34<02:49,  1.54it/s, Train Loss=1.76, validation loss=2.31] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239/500 [02:35<02:49,  1.54it/s, Train Loss=2.58, validation loss=2.35] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:35<02:46,  1.56it/s, Train Loss=2.58, validation loss=2.35] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240/500 [02:36<02:46,  1.56it/s, Train Loss=1.92, validation loss=2.33] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:36<02:52,  1.50it/s, Train Loss=1.92, validation loss=2.33] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/500 [02:36<02:52,  1.50it/s, Train Loss=1.79, validation loss=2.32] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:36<02:47,  1.54it/s, Train Loss=1.79, validation loss=2.32] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242/500 [02:37<02:47,  1.54it/s, Train Loss=2.56, validation loss=2.3]  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:37<02:43,  1.57it/s, Train Loss=2.56, validation loss=2.3] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243/500 [02:37<02:43,  1.57it/s, Train Loss=1.77, validation loss=2.3] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:37<02:41,  1.59it/s, Train Loss=1.77, validation loss=2.3] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244/500 [02:38<02:41,  1.59it/s, Train Loss=2.53, validation loss=2.29] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:38<02:38,  1.61it/s, Train Loss=2.53, validation loss=2.29] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245/500 [02:39<02:38,  1.61it/s, Train Loss=2.07, validation loss=2.32] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:39<02:42,  1.56it/s, Train Loss=2.07, validation loss=2.32] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246/500 [02:39<02:42,  1.56it/s, Train Loss=1.43, validation loss=2.31] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:39<02:40,  1.57it/s, Train Loss=1.43, validation loss=2.31] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247/500 [02:40<02:40,  1.57it/s, Train Loss=3.75, validation loss=2.3]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:40<02:38,  1.59it/s, Train Loss=3.75, validation loss=2.3] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248/500 [02:41<02:38,  1.59it/s, Train Loss=2.25, validation loss=2.31] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:41<02:40,  1.56it/s, Train Loss=2.25, validation loss=2.31] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249/500 [02:41<02:40,  1.56it/s, Train Loss=3.18, validation loss=2.3]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:41<02:37,  1.59it/s, Train Loss=3.18, validation loss=2.3] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/500 [02:42<02:37,  1.59it/s, Train Loss=1.86, validation loss=2.32] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:42<02:34,  1.61it/s, Train Loss=1.86, validation loss=2.32] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251/500 [02:42<02:34,  1.61it/s, Train Loss=2.26, validation loss=2.33] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:42<02:33,  1.62it/s, Train Loss=2.26, validation loss=2.33] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252/500 [02:43<02:33,  1.62it/s, Train Loss=3.44, validation loss=2.31] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:43<02:33,  1.61it/s, Train Loss=3.44, validation loss=2.31] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253/500 [02:44<02:33,  1.61it/s, Train Loss=2.74, validation loss=2.32] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:44<02:39,  1.54it/s, Train Loss=2.74, validation loss=2.32] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254/500 [02:44<02:39,  1.54it/s, Train Loss=1.76, validation loss=2.3]  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:44<02:37,  1.55it/s, Train Loss=1.76, validation loss=2.3] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255/500 [02:45<02:37,  1.55it/s, Train Loss=1.63, validation loss=2.3] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:45<02:36,  1.56it/s, Train Loss=1.63, validation loss=2.3] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 256/500 [02:46<02:36,  1.56it/s, Train Loss=2.37, validation loss=2.3] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:46<02:32,  1.59it/s, Train Loss=2.37, validation loss=2.3] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257/500 [02:46<02:32,  1.59it/s, Train Loss=1.95, validation loss=2.29] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:46<02:37,  1.54it/s, Train Loss=1.95, validation loss=2.29] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258/500 [02:47<02:37,  1.54it/s, Train Loss=1.64, validation loss=2.3]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:47<02:33,  1.57it/s, Train Loss=1.64, validation loss=2.3] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 259/500 [02:48<02:33,  1.57it/s, Train Loss=3.54, validation loss=2.29] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:48<02:31,  1.59it/s, Train Loss=3.54, validation loss=2.29] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260/500 [02:48<02:31,  1.59it/s, Train Loss=3.13, validation loss=2.3]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:48<02:30,  1.59it/s, Train Loss=3.13, validation loss=2.3] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261/500 [02:49<02:30,  1.59it/s, Train Loss=1.62, validation loss=2.3] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:49<02:32,  1.56it/s, Train Loss=1.62, validation loss=2.3] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262/500 [02:49<02:32,  1.56it/s, Train Loss=2.74, validation loss=2.31] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:49<02:30,  1.58it/s, Train Loss=2.74, validation loss=2.31] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 263/500 [02:50<02:30,  1.58it/s, Train Loss=2.14, validation loss=2.33] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:50<02:28,  1.59it/s, Train Loss=2.14, validation loss=2.33] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264/500 [02:51<02:28,  1.59it/s, Train Loss=2.04, validation loss=2.31] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:51<02:28,  1.58it/s, Train Loss=2.04, validation loss=2.31] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 265/500 [02:51<02:28,  1.58it/s, Train Loss=2.64, validation loss=2.31] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:51<02:33,  1.52it/s, Train Loss=2.64, validation loss=2.31] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 266/500 [02:52<02:33,  1.52it/s, Train Loss=1.75, validation loss=2.3]  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:52<02:33,  1.52it/s, Train Loss=1.75, validation loss=2.3] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 267/500 [02:53<02:33,  1.52it/s, Train Loss=1.9, validation loss=2.31] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:53<02:30,  1.54it/s, Train Loss=1.9, validation loss=2.31] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 268/500 [02:53<02:30,  1.54it/s, Train Loss=2.02, validation loss=2.31] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:53<02:27,  1.57it/s, Train Loss=2.02, validation loss=2.31] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269/500 [02:54<02:27,  1.57it/s, Train Loss=3.42, validation loss=2.3]  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:54<02:29,  1.54it/s, Train Loss=3.42, validation loss=2.3] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270/500 [02:55<02:29,  1.54it/s, Train Loss=1.83, validation loss=2.32] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:55<02:26,  1.56it/s, Train Loss=1.83, validation loss=2.32] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271/500 [02:55<02:26,  1.56it/s, Train Loss=3.08, validation loss=2.32] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:55<02:23,  1.58it/s, Train Loss=3.08, validation loss=2.32] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272/500 [02:56<02:23,  1.58it/s, Train Loss=2.77, validation loss=2.3]  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:56<02:22,  1.60it/s, Train Loss=2.77, validation loss=2.3] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273/500 [02:57<02:22,  1.60it/s, Train Loss=2.3, validation loss=2.32] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:57<02:27,  1.53it/s, Train Loss=2.3, validation loss=2.32] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274/500 [02:57<02:27,  1.53it/s, Train Loss=1.62, validation loss=2.32] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:57<02:24,  1.56it/s, Train Loss=1.62, validation loss=2.32] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275/500 [02:58<02:24,  1.56it/s, Train Loss=2.37, validation loss=2.29] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:58<02:21,  1.58it/s, Train Loss=2.37, validation loss=2.29] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276/500 [02:58<02:21,  1.58it/s, Train Loss=1.91, validation loss=2.32] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:58<02:24,  1.55it/s, Train Loss=1.91, validation loss=2.32] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277/500 [02:59<02:24,  1.55it/s, Train Loss=1.8, validation loss=2.32]  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [02:59<02:22,  1.56it/s, Train Loss=1.8, validation loss=2.32] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278/500 [03:00<02:22,  1.56it/s, Train Loss=2.57, validation loss=2.31] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:00<02:21,  1.56it/s, Train Loss=2.57, validation loss=2.31] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279/500 [03:00<02:21,  1.56it/s, Train Loss=4.12, validation loss=2.31] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:00<02:17,  1.60it/s, Train Loss=4.12, validation loss=2.31] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280/500 [03:01<02:17,  1.60it/s, Train Loss=2.79, validation loss=2.31] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:01<02:16,  1.61it/s, Train Loss=2.79, validation loss=2.31] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 281/500 [03:02<02:16,  1.61it/s, Train Loss=2.88, validation loss=2.31] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:02<02:17,  1.58it/s, Train Loss=2.88, validation loss=2.31] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282/500 [03:02<02:17,  1.58it/s, Train Loss=2.51, validation loss=2.3]  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:02<02:17,  1.58it/s, Train Loss=2.51, validation loss=2.3] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283/500 [03:03<02:17,  1.58it/s, Train Loss=1.69, validation loss=2.32] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:03<02:17,  1.57it/s, Train Loss=1.69, validation loss=2.32] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284/500 [03:04<02:17,  1.57it/s, Train Loss=1.7, validation loss=2.31]  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:04<02:21,  1.52it/s, Train Loss=1.7, validation loss=2.31] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285/500 [03:04<02:21,  1.52it/s, Train Loss=3.92, validation loss=2.29] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:04<02:17,  1.56it/s, Train Loss=3.92, validation loss=2.29] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286/500 [03:05<02:17,  1.56it/s, Train Loss=1.76, validation loss=2.32] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:05<02:15,  1.57it/s, Train Loss=1.76, validation loss=2.32] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287/500 [03:05<02:15,  1.57it/s, Train Loss=1.9, validation loss=2.31]  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:05<02:14,  1.57it/s, Train Loss=1.9, validation loss=2.31] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 288/500 [03:06<02:14,  1.57it/s, Train Loss=1.07, validation loss=2.31] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:06<02:14,  1.57it/s, Train Loss=1.07, validation loss=2.31] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289/500 [03:07<02:14,  1.57it/s, Train Loss=1.79, validation loss=2.3]  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:07<02:18,  1.52it/s, Train Loss=1.79, validation loss=2.3] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/500 [03:07<02:18,  1.52it/s, Train Loss=3.56, validation loss=2.31] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:07<02:15,  1.55it/s, Train Loss=3.56, validation loss=2.31] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291/500 [03:08<02:15,  1.55it/s, Train Loss=2.09, validation loss=2.31] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:08<02:14,  1.55it/s, Train Loss=2.09, validation loss=2.31] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/500 [03:09<02:14,  1.55it/s, Train Loss=2.65, validation loss=2.31] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:09<02:15,  1.53it/s, Train Loss=2.65, validation loss=2.31] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293/500 [03:09<02:15,  1.53it/s, Train Loss=1.97, validation loss=2.32] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:09<02:14,  1.53it/s, Train Loss=1.97, validation loss=2.32] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294/500 [03:10<02:14,  1.53it/s, Train Loss=2.11, validation loss=2.3]  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:10<02:13,  1.53it/s, Train Loss=2.11, validation loss=2.3] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295/500 [03:11<02:13,  1.53it/s, Train Loss=2.97, validation loss=2.33] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:11<02:12,  1.55it/s, Train Loss=2.97, validation loss=2.33] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296/500 [03:11<02:12,  1.55it/s, Train Loss=3.05, validation loss=2.29] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:11<02:08,  1.57it/s, Train Loss=3.05, validation loss=2.29] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297/500 [03:12<02:08,  1.57it/s, Train Loss=2.44, validation loss=2.32] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:12<02:13,  1.52it/s, Train Loss=2.44, validation loss=2.32] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298/500 [03:13<02:13,  1.52it/s, Train Loss=2.32, validation loss=2.31] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:13<02:13,  1.50it/s, Train Loss=2.32, validation loss=2.31]####################################################################################################
--------------------------------------------- Epoch:300 ---------------------------------------------
-- Training set:
Loss: 1.67879319190979, Lr: 0.000125
Average AUC ROC: 0.53                Average AUC PR: 0.29
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299/500 [03:13<02:13,  1.50it/s, Train Loss=1.68, validation loss=2.31] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:13<02:14,  1.49it/s, Train Loss=1.68, validation loss=2.31]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.307154342532158
Average AUC ROC: 0.55                    Average AUC PR: 0.31
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300/500 [03:14<02:14,  1.49it/s, Train Loss=3.14, validation loss=2.29] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:14<02:16,  1.46it/s, Train Loss=3.14, validation loss=2.29] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301/500 [03:15<02:16,  1.46it/s, Train Loss=1.94, validation loss=2.3]  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:15<02:12,  1.50it/s, Train Loss=1.94, validation loss=2.3] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302/500 [03:15<02:12,  1.50it/s, Train Loss=1.62, validation loss=2.32] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:15<02:09,  1.52it/s, Train Loss=1.62, validation loss=2.32] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303/500 [03:16<02:09,  1.52it/s, Train Loss=1.37, validation loss=2.31] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:16<02:05,  1.56it/s, Train Loss=1.37, validation loss=2.31] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304/500 [03:17<02:05,  1.56it/s, Train Loss=2.74, validation loss=2.31] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:17<02:02,  1.60it/s, Train Loss=2.74, validation loss=2.31] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305/500 [03:17<02:02,  1.60it/s, Train Loss=2.35, validation loss=2.3]  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:17<02:05,  1.54it/s, Train Loss=2.35, validation loss=2.3] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306/500 [03:18<02:05,  1.54it/s, Train Loss=3.45, validation loss=2.3] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:18<02:02,  1.57it/s, Train Loss=3.45, validation loss=2.3] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307/500 [03:19<02:02,  1.57it/s, Train Loss=2.35, validation loss=2.3] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:19<02:06,  1.52it/s, Train Loss=2.35, validation loss=2.3] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308/500 [03:19<02:06,  1.52it/s, Train Loss=2.09, validation loss=2.3] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:19<02:08,  1.48it/s, Train Loss=2.09, validation loss=2.3] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309/500 [03:20<02:08,  1.48it/s, Train Loss=2.6, validation loss=2.28] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:20<02:08,  1.47it/s, Train Loss=2.6, validation loss=2.28] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310/500 [03:21<02:08,  1.47it/s, Train Loss=1.91, validation loss=2.3] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:21<02:08,  1.48it/s, Train Loss=1.91, validation loss=2.3] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311/500 [03:21<02:08,  1.48it/s, Train Loss=1.78, validation loss=2.29] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:21<02:17,  1.37it/s, Train Loss=1.78, validation loss=2.29] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312/500 [03:22<02:17,  1.37it/s, Train Loss=2.32, validation loss=2.3]  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:22<02:15,  1.38it/s, Train Loss=2.32, validation loss=2.3] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 313/500 [03:23<02:15,  1.38it/s, Train Loss=1.75, validation loss=2.32] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:23<02:08,  1.44it/s, Train Loss=1.75, validation loss=2.32] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 314/500 [03:23<02:08,  1.44it/s, Train Loss=1.53, validation loss=2.3]  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:23<02:03,  1.50it/s, Train Loss=1.53, validation loss=2.3] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315/500 [03:24<02:03,  1.50it/s, Train Loss=2.78, validation loss=2.31] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:24<02:03,  1.49it/s, Train Loss=2.78, validation loss=2.31] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 316/500 [03:25<02:03,  1.49it/s, Train Loss=1.62, validation loss=2.29] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:25<01:59,  1.53it/s, Train Loss=1.62, validation loss=2.29] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/500 [03:25<01:59,  1.53it/s, Train Loss=1.86, validation loss=2.31] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:25<01:57,  1.55it/s, Train Loss=1.86, validation loss=2.31] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 318/500 [03:26<01:57,  1.55it/s, Train Loss=2.02, validation loss=2.3]  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:26<02:03,  1.47it/s, Train Loss=2.02, validation loss=2.3] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319/500 [03:27<02:03,  1.47it/s, Train Loss=2.26, validation loss=2.29] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:27<02:03,  1.46it/s, Train Loss=2.26, validation loss=2.29] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320/500 [03:28<02:03,  1.46it/s, Train Loss=2.66, validation loss=2.33] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:28<02:03,  1.45it/s, Train Loss=2.66, validation loss=2.33] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321/500 [03:28<02:03,  1.45it/s, Train Loss=2.85, validation loss=2.3]  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:28<02:08,  1.38it/s, Train Loss=2.85, validation loss=2.3] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322/500 [03:29<02:08,  1.38it/s, Train Loss=3.64, validation loss=2.3] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:29<02:17,  1.29it/s, Train Loss=3.64, validation loss=2.3] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323/500 [03:30<02:17,  1.29it/s, Train Loss=2.68, validation loss=2.3] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:30<02:15,  1.29it/s, Train Loss=2.68, validation loss=2.3] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324/500 [03:31<02:15,  1.29it/s, Train Loss=5.04, validation loss=2.28] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:31<02:19,  1.25it/s, Train Loss=5.04, validation loss=2.28] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325/500 [03:32<02:19,  1.25it/s, Train Loss=2.8, validation loss=2.31]  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:32<02:17,  1.26it/s, Train Loss=2.8, validation loss=2.31] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326/500 [03:32<02:17,  1.26it/s, Train Loss=3.73, validation loss=2.31] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:32<02:08,  1.35it/s, Train Loss=3.73, validation loss=2.31] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327/500 [03:33<02:08,  1.35it/s, Train Loss=2.59, validation loss=2.29] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:33<02:00,  1.43it/s, Train Loss=2.59, validation loss=2.29] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328/500 [03:33<02:00,  1.43it/s, Train Loss=1.98, validation loss=2.31] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:33<01:56,  1.46it/s, Train Loss=1.98, validation loss=2.31] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329/500 [03:34<01:56,  1.46it/s, Train Loss=2.58, validation loss=2.3]  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:34<01:58,  1.44it/s, Train Loss=2.58, validation loss=2.3] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330/500 [03:35<01:58,  1.44it/s, Train Loss=1.78, validation loss=2.32] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:35<01:54,  1.48it/s, Train Loss=1.78, validation loss=2.32] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331/500 [03:36<01:54,  1.48it/s, Train Loss=2.41, validation loss=2.29] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:36<01:53,  1.48it/s, Train Loss=2.41, validation loss=2.29] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332/500 [03:36<01:53,  1.48it/s, Train Loss=1.52, validation loss=2.33] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:36<01:49,  1.52it/s, Train Loss=1.52, validation loss=2.33] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/500 [03:37<01:49,  1.52it/s, Train Loss=2.16, validation loss=2.32] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:37<01:47,  1.55it/s, Train Loss=2.16, validation loss=2.32] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334/500 [03:37<01:47,  1.55it/s, Train Loss=2.09, validation loss=2.3]  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:37<01:44,  1.57it/s, Train Loss=2.09, validation loss=2.3] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335/500 [03:38<01:44,  1.57it/s, Train Loss=1.4, validation loss=2.31] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:38<01:48,  1.51it/s, Train Loss=1.4, validation loss=2.31] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336/500 [03:39<01:48,  1.51it/s, Train Loss=2.82, validation loss=2.3] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:39<01:45,  1.54it/s, Train Loss=2.82, validation loss=2.3] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337/500 [03:39<01:45,  1.54it/s, Train Loss=1.64, validation loss=2.3] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:39<01:44,  1.55it/s, Train Loss=1.64, validation loss=2.3] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338/500 [03:40<01:44,  1.55it/s, Train Loss=1.76, validation loss=2.32] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:40<01:42,  1.58it/s, Train Loss=1.76, validation loss=2.32] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339/500 [03:41<01:42,  1.58it/s, Train Loss=1.52, validation loss=2.3]  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:41<01:44,  1.54it/s, Train Loss=1.52, validation loss=2.3] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340/500 [03:41<01:44,  1.54it/s, Train Loss=3.18, validation loss=2.31] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:41<01:41,  1.56it/s, Train Loss=3.18, validation loss=2.31] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341/500 [03:42<01:41,  1.56it/s, Train Loss=1.9, validation loss=2.32]  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:42<01:41,  1.56it/s, Train Loss=1.9, validation loss=2.32] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342/500 [03:43<01:41,  1.56it/s, Train Loss=2.88, validation loss=2.31] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:43<01:42,  1.53it/s, Train Loss=2.88, validation loss=2.31] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343/500 [03:43<01:42,  1.53it/s, Train Loss=1.82, validation loss=2.29] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:43<01:43,  1.51it/s, Train Loss=1.82, validation loss=2.29] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344/500 [03:44<01:43,  1.51it/s, Train Loss=1.57, validation loss=2.3]  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:44<01:41,  1.53it/s, Train Loss=1.57, validation loss=2.3] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345/500 [03:44<01:41,  1.53it/s, Train Loss=2.88, validation loss=2.31] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:44<01:38,  1.57it/s, Train Loss=2.88, validation loss=2.31] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346/500 [03:45<01:38,  1.57it/s, Train Loss=3.89, validation loss=2.3]  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:45<01:39,  1.54it/s, Train Loss=3.89, validation loss=2.3] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347/500 [03:46<01:39,  1.54it/s, Train Loss=3.03, validation loss=2.32] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:46<01:41,  1.50it/s, Train Loss=3.03, validation loss=2.32] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348/500 [03:46<01:41,  1.50it/s, Train Loss=2.26, validation loss=2.32] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:46<01:38,  1.54it/s, Train Loss=2.26, validation loss=2.32] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349/500 [03:47<01:38,  1.54it/s, Train Loss=1.82, validation loss=2.31] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:47<01:39,  1.50it/s, Train Loss=1.82, validation loss=2.31] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350/500 [03:48<01:39,  1.50it/s, Train Loss=2.74, validation loss=2.31] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:48<01:37,  1.53it/s, Train Loss=2.74, validation loss=2.31] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351/500 [03:48<01:37,  1.53it/s, Train Loss=2.74, validation loss=2.33] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:48<01:33,  1.58it/s, Train Loss=2.74, validation loss=2.33] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352/500 [03:49<01:33,  1.58it/s, Train Loss=2.05, validation loss=2.31] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:49<01:32,  1.58it/s, Train Loss=2.05, validation loss=2.31] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353/500 [03:50<01:32,  1.58it/s, Train Loss=1.25, validation loss=2.33] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:50<01:30,  1.61it/s, Train Loss=1.25, validation loss=2.33] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354/500 [03:50<01:30,  1.61it/s, Train Loss=2.42, validation loss=2.31] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:50<01:33,  1.56it/s, Train Loss=2.42, validation loss=2.31] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355/500 [03:51<01:33,  1.56it/s, Train Loss=2.6, validation loss=2.32]  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:51<01:31,  1.57it/s, Train Loss=2.6, validation loss=2.32] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356/500 [03:52<01:31,  1.57it/s, Train Loss=2.08, validation loss=2.32] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:52<01:30,  1.58it/s, Train Loss=2.08, validation loss=2.32] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357/500 [03:52<01:30,  1.58it/s, Train Loss=2.61, validation loss=2.31] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:52<01:32,  1.53it/s, Train Loss=2.61, validation loss=2.31] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358/500 [03:53<01:32,  1.53it/s, Train Loss=1.14, validation loss=2.33] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:53<01:31,  1.54it/s, Train Loss=1.14, validation loss=2.33] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359/500 [03:54<01:31,  1.54it/s, Train Loss=2.76, validation loss=2.29] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:54<01:29,  1.57it/s, Train Loss=2.76, validation loss=2.29] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360/500 [03:54<01:29,  1.57it/s, Train Loss=1.68, validation loss=2.31] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:54<01:31,  1.53it/s, Train Loss=1.68, validation loss=2.31] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361/500 [03:55<01:31,  1.53it/s, Train Loss=2.76, validation loss=2.31] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:55<01:28,  1.55it/s, Train Loss=2.76, validation loss=2.31] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362/500 [03:55<01:28,  1.55it/s, Train Loss=2.78, validation loss=2.33] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:55<01:27,  1.56it/s, Train Loss=2.78, validation loss=2.33] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/500 [03:56<01:27,  1.56it/s, Train Loss=1.92, validation loss=2.31] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:56<01:25,  1.59it/s, Train Loss=1.92, validation loss=2.31] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/500 [03:57<01:25,  1.59it/s, Train Loss=1.54, validation loss=2.3]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:57<01:24,  1.60it/s, Train Loss=1.54, validation loss=2.3] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/500 [03:57<01:24,  1.60it/s, Train Loss=1.92, validation loss=2.3] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:57<01:26,  1.54it/s, Train Loss=1.92, validation loss=2.3] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/500 [03:58<01:26,  1.54it/s, Train Loss=2.26, validation loss=2.3] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:58<01:25,  1.56it/s, Train Loss=2.26, validation loss=2.3] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/500 [03:59<01:25,  1.56it/s, Train Loss=2.02, validation loss=2.31] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:59<01:26,  1.53it/s, Train Loss=2.02, validation loss=2.31] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/500 [03:59<01:26,  1.53it/s, Train Loss=1.43, validation loss=2.31] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [03:59<01:23,  1.57it/s, Train Loss=1.43, validation loss=2.31] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369/500 [04:00<01:23,  1.57it/s, Train Loss=2.07, validation loss=2.29] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [04:00<01:21,  1.59it/s, Train Loss=2.07, validation loss=2.29] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370/500 [04:01<01:21,  1.59it/s, Train Loss=1.96, validation loss=2.32] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [04:01<01:20,  1.60it/s, Train Loss=1.96, validation loss=2.32] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [04:01<01:20,  1.60it/s, Train Loss=2.48, validation loss=2.32] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [04:01<01:20,  1.60it/s, Train Loss=2.48, validation loss=2.32] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372/500 [04:02<01:20,  1.60it/s, Train Loss=1.24, validation loss=2.32] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:02<01:22,  1.53it/s, Train Loss=1.24, validation loss=2.32] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373/500 [04:03<01:22,  1.53it/s, Train Loss=1.84, validation loss=2.33] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:03<01:22,  1.53it/s, Train Loss=1.84, validation loss=2.33] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374/500 [04:03<01:22,  1.53it/s, Train Loss=2.12, validation loss=2.31] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:03<01:20,  1.56it/s, Train Loss=2.12, validation loss=2.31] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/500 [04:04<01:20,  1.56it/s, Train Loss=1.71, validation loss=2.3]  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:04<01:20,  1.53it/s, Train Loss=1.71, validation loss=2.3] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376/500 [04:04<01:20,  1.53it/s, Train Loss=2.71, validation loss=2.3] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:04<01:19,  1.55it/s, Train Loss=2.71, validation loss=2.3] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377/500 [04:05<01:19,  1.55it/s, Train Loss=3.03, validation loss=2.3] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:05<01:18,  1.56it/s, Train Loss=3.03, validation loss=2.3] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378/500 [04:06<01:18,  1.56it/s, Train Loss=1.91, validation loss=2.33] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:06<01:19,  1.53it/s, Train Loss=1.91, validation loss=2.33] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379/500 [04:06<01:19,  1.53it/s, Train Loss=1.57, validation loss=2.31] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:06<01:17,  1.55it/s, Train Loss=1.57, validation loss=2.31] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380/500 [04:07<01:17,  1.55it/s, Train Loss=2.06, validation loss=2.32] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:07<01:15,  1.58it/s, Train Loss=2.06, validation loss=2.32] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381/500 [04:08<01:15,  1.58it/s, Train Loss=2.13, validation loss=2.32] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:08<01:15,  1.57it/s, Train Loss=2.13, validation loss=2.32] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382/500 [04:08<01:15,  1.57it/s, Train Loss=2.33, validation loss=2.31] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:08<01:14,  1.57it/s, Train Loss=2.33, validation loss=2.31] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383/500 [04:09<01:14,  1.57it/s, Train Loss=2.34, validation loss=2.29] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:09<01:15,  1.53it/s, Train Loss=2.34, validation loss=2.29] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 384/500 [04:10<01:15,  1.53it/s, Train Loss=1.81, validation loss=2.3]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:10<01:16,  1.49it/s, Train Loss=1.81, validation loss=2.3] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385/500 [04:10<01:16,  1.49it/s, Train Loss=2.05, validation loss=2.34] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:10<01:16,  1.50it/s, Train Loss=2.05, validation loss=2.34] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386/500 [04:11<01:16,  1.50it/s, Train Loss=2.71, validation loss=2.3]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:11<01:15,  1.49it/s, Train Loss=2.71, validation loss=2.3] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387/500 [04:12<01:15,  1.49it/s, Train Loss=1.71, validation loss=2.32] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:12<01:12,  1.54it/s, Train Loss=1.71, validation loss=2.32] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388/500 [04:12<01:12,  1.54it/s, Train Loss=1.95, validation loss=2.3]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:12<01:11,  1.54it/s, Train Loss=1.95, validation loss=2.3] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389/500 [04:13<01:11,  1.54it/s, Train Loss=2.61, validation loss=2.32] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:13<01:12,  1.51it/s, Train Loss=2.61, validation loss=2.32] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390/500 [04:14<01:12,  1.51it/s, Train Loss=2.14, validation loss=2.29] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:14<01:10,  1.54it/s, Train Loss=2.14, validation loss=2.29] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391/500 [04:14<01:10,  1.54it/s, Train Loss=1.87, validation loss=2.3]  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:14<01:08,  1.57it/s, Train Loss=1.87, validation loss=2.3] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392/500 [04:15<01:08,  1.57it/s, Train Loss=2.11, validation loss=2.3] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:15<01:07,  1.59it/s, Train Loss=2.11, validation loss=2.3] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393/500 [04:15<01:07,  1.59it/s, Train Loss=2.2, validation loss=2.32] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:15<01:08,  1.55it/s, Train Loss=2.2, validation loss=2.32] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 394/500 [04:16<01:08,  1.55it/s, Train Loss=1.43, validation loss=2.3] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:16<01:06,  1.57it/s, Train Loss=1.43, validation loss=2.3] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395/500 [04:17<01:06,  1.57it/s, Train Loss=1.61, validation loss=2.29] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:17<01:07,  1.54it/s, Train Loss=1.61, validation loss=2.29] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396/500 [04:17<01:07,  1.54it/s, Train Loss=1.47, validation loss=2.29] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:17<01:06,  1.54it/s, Train Loss=1.47, validation loss=2.29] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397/500 [04:18<01:06,  1.54it/s, Train Loss=1.74, validation loss=2.31] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:18<01:04,  1.58it/s, Train Loss=1.74, validation loss=2.31] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398/500 [04:19<01:04,  1.58it/s, Train Loss=2.32, validation loss=2.33] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:19<01:03,  1.60it/s, Train Loss=2.32, validation loss=2.33]####################################################################################################
--------------------------------------------- Epoch:400 ---------------------------------------------
-- Training set:
Loss: 2.5540928840637207, Lr: 6.25e-05
Average AUC ROC: 0.51                Average AUC PR: 0.28
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399/500 [04:19<01:03,  1.60it/s, Train Loss=2.55, validation loss=2.29] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:19<01:02,  1.60it/s, Train Loss=2.55, validation loss=2.29]----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.2882672920823097
Average AUC ROC: 0.55                    Average AUC PR: 0.31
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400/500 [04:20<01:02,  1.60it/s, Train Loss=2.31, validation loss=2.3]  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:20<01:04,  1.53it/s, Train Loss=2.31, validation loss=2.3] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401/500 [04:21<01:04,  1.53it/s, Train Loss=1.58, validation loss=2.29] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:21<01:03,  1.55it/s, Train Loss=1.58, validation loss=2.29] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402/500 [04:21<01:03,  1.55it/s, Train Loss=1.74, validation loss=2.31] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:21<01:03,  1.54it/s, Train Loss=1.74, validation loss=2.31] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403/500 [04:22<01:03,  1.54it/s, Train Loss=2.25, validation loss=2.29] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:22<01:02,  1.53it/s, Train Loss=2.25, validation loss=2.29] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404/500 [04:23<01:02,  1.53it/s, Train Loss=3.16, validation loss=2.31] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:23<01:01,  1.55it/s, Train Loss=3.16, validation loss=2.31] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405/500 [04:23<01:01,  1.55it/s, Train Loss=1.83, validation loss=2.3]  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:23<01:02,  1.51it/s, Train Loss=1.83, validation loss=2.3] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406/500 [04:24<01:02,  1.51it/s, Train Loss=1.75, validation loss=2.32] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:24<01:00,  1.53it/s, Train Loss=1.75, validation loss=2.32] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407/500 [04:24<01:00,  1.53it/s, Train Loss=2.52, validation loss=2.3]  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:24<00:59,  1.56it/s, Train Loss=2.52, validation loss=2.3] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408/500 [04:25<00:59,  1.56it/s, Train Loss=1.88, validation loss=2.29] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:25<00:58,  1.56it/s, Train Loss=1.88, validation loss=2.29] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409/500 [04:26<00:58,  1.56it/s, Train Loss=2.26, validation loss=2.31] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:26<00:57,  1.57it/s, Train Loss=2.26, validation loss=2.31] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410/500 [04:26<00:57,  1.57it/s, Train Loss=2.57, validation loss=2.29] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:26<00:57,  1.54it/s, Train Loss=2.57, validation loss=2.29] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411/500 [04:27<00:57,  1.54it/s, Train Loss=3.43, validation loss=2.3]  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:27<00:56,  1.56it/s, Train Loss=3.43, validation loss=2.3] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 412/500 [04:28<00:56,  1.56it/s, Train Loss=1.39, validation loss=2.29] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:28<00:54,  1.60it/s, Train Loss=1.39, validation loss=2.29] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/500 [04:28<00:54,  1.60it/s, Train Loss=2.12, validation loss=2.33] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:28<00:55,  1.54it/s, Train Loss=2.12, validation loss=2.33] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/500 [04:29<00:55,  1.54it/s, Train Loss=1.75, validation loss=2.32] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:29<00:54,  1.57it/s, Train Loss=1.75, validation loss=2.32] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/500 [04:30<00:54,  1.57it/s, Train Loss=3.32, validation loss=2.3]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:30<00:53,  1.58it/s, Train Loss=3.32, validation loss=2.3] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/500 [04:30<00:53,  1.58it/s, Train Loss=1.67, validation loss=2.31] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:30<00:57,  1.46it/s, Train Loss=1.67, validation loss=2.31] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/500 [04:31<00:57,  1.46it/s, Train Loss=1.77, validation loss=2.32] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:31<00:54,  1.50it/s, Train Loss=1.77, validation loss=2.32] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/500 [04:32<00:54,  1.50it/s, Train Loss=2.41, validation loss=2.31] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:32<00:53,  1.52it/s, Train Loss=2.41, validation loss=2.31] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419/500 [04:32<00:53,  1.52it/s, Train Loss=1.83, validation loss=2.31] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:32<00:51,  1.56it/s, Train Loss=1.83, validation loss=2.31] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420/500 [04:33<00:51,  1.56it/s, Train Loss=2.82, validation loss=2.29] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:33<00:52,  1.51it/s, Train Loss=2.82, validation loss=2.29] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421/500 [04:34<00:52,  1.51it/s, Train Loss=3.48, validation loss=2.29] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:34<00:50,  1.54it/s, Train Loss=3.48, validation loss=2.29] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422/500 [04:34<00:50,  1.54it/s, Train Loss=2.88, validation loss=2.31] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:34<00:50,  1.52it/s, Train Loss=2.88, validation loss=2.31] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423/500 [04:35<00:50,  1.52it/s, Train Loss=1.38, validation loss=2.3]  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:35<00:48,  1.55it/s, Train Loss=1.38, validation loss=2.3] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424/500 [04:35<00:48,  1.55it/s, Train Loss=2.08, validation loss=2.29] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:35<00:48,  1.55it/s, Train Loss=2.08, validation loss=2.29] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425/500 [04:36<00:48,  1.55it/s, Train Loss=1.3, validation loss=2.3]   85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:36<00:47,  1.56it/s, Train Loss=1.3, validation loss=2.3] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426/500 [04:37<00:47,  1.56it/s, Train Loss=1.73, validation loss=2.3] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:37<00:46,  1.57it/s, Train Loss=1.73, validation loss=2.3] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427/500 [04:37<00:46,  1.57it/s, Train Loss=4.1, validation loss=2.29] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:37<00:46,  1.54it/s, Train Loss=4.1, validation loss=2.29] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428/500 [04:38<00:46,  1.54it/s, Train Loss=1.97, validation loss=2.3] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:38<00:45,  1.55it/s, Train Loss=1.97, validation loss=2.3] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429/500 [04:39<00:45,  1.55it/s, Train Loss=2.82, validation loss=2.29] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:39<00:44,  1.58it/s, Train Loss=2.82, validation loss=2.29] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430/500 [04:39<00:44,  1.58it/s, Train Loss=1.57, validation loss=2.29] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:39<00:44,  1.55it/s, Train Loss=1.57, validation loss=2.29] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 431/500 [04:40<00:44,  1.55it/s, Train Loss=1.75, validation loss=2.29] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:40<00:43,  1.56it/s, Train Loss=1.75, validation loss=2.29] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432/500 [04:41<00:43,  1.56it/s, Train Loss=2.14, validation loss=2.31] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:41<00:43,  1.53it/s, Train Loss=2.14, validation loss=2.31] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433/500 [04:41<00:43,  1.53it/s, Train Loss=2.47, validation loss=2.31] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:41<00:41,  1.58it/s, Train Loss=2.47, validation loss=2.31] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434/500 [04:42<00:41,  1.58it/s, Train Loss=1.7, validation loss=2.3]   87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:42<00:40,  1.59it/s, Train Loss=1.7, validation loss=2.3] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 435/500 [04:42<00:40,  1.59it/s, Train Loss=1.89, validation loss=2.31] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:42<00:39,  1.61it/s, Train Loss=1.89, validation loss=2.31] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436/500 [04:43<00:39,  1.61it/s, Train Loss=3.35, validation loss=2.3]  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:43<00:38,  1.63it/s, Train Loss=3.35, validation loss=2.3] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 437/500 [04:44<00:38,  1.63it/s, Train Loss=1.97, validation loss=2.29] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:44<00:39,  1.56it/s, Train Loss=1.97, validation loss=2.29] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438/500 [04:44<00:39,  1.56it/s, Train Loss=1.72, validation loss=2.29] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:44<00:38,  1.57it/s, Train Loss=1.72, validation loss=2.29] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439/500 [04:45<00:38,  1.57it/s, Train Loss=1.87, validation loss=2.31] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:45<00:37,  1.59it/s, Train Loss=1.87, validation loss=2.31] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440/500 [04:46<00:37,  1.59it/s, Train Loss=1.84, validation loss=2.29] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:46<00:38,  1.55it/s, Train Loss=1.84, validation loss=2.29] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441/500 [04:46<00:38,  1.55it/s, Train Loss=2.24, validation loss=2.3]  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:46<00:37,  1.56it/s, Train Loss=2.24, validation loss=2.3] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442/500 [04:47<00:37,  1.56it/s, Train Loss=1.93, validation loss=2.3] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:47<00:37,  1.54it/s, Train Loss=1.93, validation loss=2.3] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443/500 [04:48<00:37,  1.54it/s, Train Loss=1.61, validation loss=2.31] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:48<00:35,  1.56it/s, Train Loss=1.61, validation loss=2.31] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444/500 [04:48<00:35,  1.56it/s, Train Loss=2.95, validation loss=2.29] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:48<00:34,  1.58it/s, Train Loss=2.95, validation loss=2.29] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445/500 [04:49<00:34,  1.58it/s, Train Loss=1.82, validation loss=2.32] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:49<00:34,  1.58it/s, Train Loss=1.82, validation loss=2.32] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446/500 [04:49<00:34,  1.58it/s, Train Loss=2.94, validation loss=2.29] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:49<00:33,  1.59it/s, Train Loss=2.94, validation loss=2.29] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447/500 [04:50<00:33,  1.59it/s, Train Loss=2.44, validation loss=2.29] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:50<00:34,  1.50it/s, Train Loss=2.44, validation loss=2.29] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448/500 [04:51<00:34,  1.50it/s, Train Loss=2.55, validation loss=2.3]  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:51<00:33,  1.52it/s, Train Loss=2.55, validation loss=2.3] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 449/500 [04:52<00:33,  1.52it/s, Train Loss=1.48, validation loss=2.32] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:52<00:32,  1.52it/s, Train Loss=1.48, validation loss=2.32] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450/500 [04:52<00:32,  1.52it/s, Train Loss=2.18, validation loss=2.29] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:52<00:32,  1.50it/s, Train Loss=2.18, validation loss=2.29] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451/500 [04:53<00:32,  1.50it/s, Train Loss=2.64, validation loss=2.3]  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:53<00:31,  1.52it/s, Train Loss=2.64, validation loss=2.3] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452/500 [04:54<00:31,  1.52it/s, Train Loss=1.78, validation loss=2.3] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:54<00:31,  1.51it/s, Train Loss=1.78, validation loss=2.3] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453/500 [04:54<00:31,  1.51it/s, Train Loss=2.48, validation loss=2.3] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:54<00:29,  1.54it/s, Train Loss=2.48, validation loss=2.3] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 454/500 [04:55<00:29,  1.54it/s, Train Loss=3.05, validation loss=2.31] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:55<00:29,  1.55it/s, Train Loss=3.05, validation loss=2.31] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455/500 [04:55<00:29,  1.55it/s, Train Loss=1.73, validation loss=2.29] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:55<00:27,  1.58it/s, Train Loss=1.73, validation loss=2.29] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 456/500 [04:56<00:27,  1.58it/s, Train Loss=1.64, validation loss=2.29] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:56<00:26,  1.62it/s, Train Loss=1.64, validation loss=2.29] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457/500 [04:57<00:26,  1.62it/s, Train Loss=2.74, validation loss=2.31] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:57<00:27,  1.55it/s, Train Loss=2.74, validation loss=2.31] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458/500 [04:57<00:27,  1.55it/s, Train Loss=3.09, validation loss=2.28] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:57<00:26,  1.58it/s, Train Loss=3.09, validation loss=2.28] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459/500 [04:58<00:26,  1.58it/s, Train Loss=1.91, validation loss=2.29] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:58<00:25,  1.54it/s, Train Loss=1.91, validation loss=2.29] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 460/500 [04:59<00:25,  1.54it/s, Train Loss=1.39, validation loss=2.31] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:59<00:24,  1.56it/s, Train Loss=1.39, validation loss=2.31] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461/500 [04:59<00:24,  1.56it/s, Train Loss=1.82, validation loss=2.3]  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [04:59<00:24,  1.58it/s, Train Loss=1.82, validation loss=2.3] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/500 [05:00<00:24,  1.58it/s, Train Loss=1.6, validation loss=2.3]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [05:00<00:23,  1.58it/s, Train Loss=1.6, validation loss=2.3] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/500 [05:01<00:23,  1.58it/s, Train Loss=1.83, validation loss=2.3] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [05:01<00:23,  1.54it/s, Train Loss=1.83, validation loss=2.3] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/500 [05:01<00:23,  1.54it/s, Train Loss=2.18, validation loss=2.31] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [05:01<00:22,  1.55it/s, Train Loss=2.18, validation loss=2.31] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/500 [05:02<00:22,  1.55it/s, Train Loss=2.77, validation loss=2.3]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [05:02<00:21,  1.57it/s, Train Loss=2.77, validation loss=2.3] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/500 [05:02<00:21,  1.57it/s, Train Loss=2.13, validation loss=2.28] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:02<00:20,  1.59it/s, Train Loss=2.13, validation loss=2.28] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/500 [05:03<00:20,  1.59it/s, Train Loss=2.2, validation loss=2.3]   94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:03<00:21,  1.51it/s, Train Loss=2.2, validation loss=2.3] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468/500 [05:04<00:21,  1.51it/s, Train Loss=1.83, validation loss=2.29] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:04<00:20,  1.53it/s, Train Loss=1.83, validation loss=2.29] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469/500 [05:04<00:20,  1.53it/s, Train Loss=2, validation loss=2.3]     94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:04<00:19,  1.53it/s, Train Loss=2, validation loss=2.3] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 470/500 [05:05<00:19,  1.53it/s, Train Loss=2.18, validation loss=2.3] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:05<00:18,  1.54it/s, Train Loss=2.18, validation loss=2.3] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471/500 [05:06<00:18,  1.54it/s, Train Loss=2.15, validation loss=2.3] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:06<00:17,  1.59it/s, Train Loss=2.15, validation loss=2.3] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472/500 [05:06<00:17,  1.59it/s, Train Loss=2.16, validation loss=2.31] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:06<00:17,  1.57it/s, Train Loss=2.16, validation loss=2.31] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 473/500 [05:07<00:17,  1.57it/s, Train Loss=1.64, validation loss=2.3]  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:07<00:16,  1.54it/s, Train Loss=1.64, validation loss=2.3] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474/500 [05:08<00:16,  1.54it/s, Train Loss=2.28, validation loss=2.3] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:08<00:16,  1.56it/s, Train Loss=2.28, validation loss=2.3] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475/500 [05:08<00:16,  1.56it/s, Train Loss=1.93, validation loss=2.3] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:08<00:15,  1.56it/s, Train Loss=1.93, validation loss=2.3] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476/500 [05:09<00:15,  1.56it/s, Train Loss=2.26, validation loss=2.32] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:09<00:14,  1.56it/s, Train Loss=2.26, validation loss=2.32] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477/500 [05:09<00:14,  1.56it/s, Train Loss=2.17, validation loss=2.3]  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:09<00:13,  1.58it/s, Train Loss=2.17, validation loss=2.3] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478/500 [05:10<00:13,  1.58it/s, Train Loss=1.78, validation loss=2.3] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:10<00:13,  1.59it/s, Train Loss=1.78, validation loss=2.3] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479/500 [05:11<00:13,  1.59it/s, Train Loss=2.39, validation loss=2.29] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:11<00:13,  1.50it/s, Train Loss=2.39, validation loss=2.29] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480/500 [05:11<00:13,  1.50it/s, Train Loss=2.04, validation loss=2.31] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:11<00:12,  1.54it/s, Train Loss=2.04, validation loss=2.31] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [05:12<00:12,  1.54it/s, Train Loss=1.43, validation loss=2.31] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:12<00:11,  1.55it/s, Train Loss=1.43, validation loss=2.31] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482/500 [05:13<00:11,  1.55it/s, Train Loss=2.23, validation loss=2.3]  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:13<00:11,  1.52it/s, Train Loss=2.23, validation loss=2.3] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483/500 [05:13<00:11,  1.52it/s, Train Loss=2.06, validation loss=2.3] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:13<00:10,  1.57it/s, Train Loss=2.06, validation loss=2.3] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484/500 [05:14<00:10,  1.57it/s, Train Loss=1.98, validation loss=2.3] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:14<00:09,  1.58it/s, Train Loss=1.98, validation loss=2.3] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485/500 [05:15<00:09,  1.58it/s, Train Loss=2.36, validation loss=2.3] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:15<00:08,  1.58it/s, Train Loss=2.36, validation loss=2.3] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486/500 [05:15<00:08,  1.58it/s, Train Loss=1.99, validation loss=2.3] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:15<00:08,  1.53it/s, Train Loss=1.99, validation loss=2.3] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 487/500 [05:16<00:08,  1.53it/s, Train Loss=2.3, validation loss=2.3]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:16<00:07,  1.55it/s, Train Loss=2.3, validation loss=2.3] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488/500 [05:17<00:07,  1.55it/s, Train Loss=2.08, validation loss=2.29] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:17<00:07,  1.53it/s, Train Loss=2.08, validation loss=2.29] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489/500 [05:17<00:07,  1.53it/s, Train Loss=3.12, validation loss=2.3]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:17<00:06,  1.55it/s, Train Loss=3.12, validation loss=2.3] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490/500 [05:18<00:06,  1.55it/s, Train Loss=2.43, validation loss=2.29] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:18<00:05,  1.58it/s, Train Loss=2.43, validation loss=2.29] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491/500 [05:18<00:05,  1.58it/s, Train Loss=3.1, validation loss=2.29]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:18<00:05,  1.59it/s, Train Loss=3.1, validation loss=2.29] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492/500 [05:19<00:05,  1.59it/s, Train Loss=2.37, validation loss=2.29] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:19<00:04,  1.55it/s, Train Loss=2.37, validation loss=2.29] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493/500 [05:20<00:04,  1.55it/s, Train Loss=1.52, validation loss=2.31] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:20<00:03,  1.57it/s, Train Loss=1.52, validation loss=2.31] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494/500 [05:20<00:03,  1.57it/s, Train Loss=2.99, validation loss=2.33] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:20<00:03,  1.57it/s, Train Loss=2.99, validation loss=2.33] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495/500 [05:21<00:03,  1.57it/s, Train Loss=2.46, validation loss=2.31] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:21<00:02,  1.51it/s, Train Loss=2.46, validation loss=2.31] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496/500 [05:22<00:02,  1.51it/s, Train Loss=1.68, validation loss=2.29] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:22<00:01,  1.55it/s, Train Loss=1.68, validation loss=2.29] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497/500 [05:22<00:01,  1.55it/s, Train Loss=1.55, validation loss=2.29]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:22<00:01,  1.52it/s, Train Loss=1.55, validation loss=2.29]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498/500 [05:23<00:01,  1.52it/s, Train Loss=2.25, validation loss=2.29]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:23<00:00,  1.56it/s, Train Loss=2.25, validation loss=2.29]####################################################################################################
--------------------------------------------- Epoch:500 ---------------------------------------------
-- Training set:
Loss: 1.514199137687683, Lr: 3.125e-05
Average AUC ROC: 0.51                Average AUC PR: 0.28
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499/500 [05:24<00:00,  1.56it/s, Train Loss=1.51, validation loss=2.32]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:24<00:00,  1.57it/s, Train Loss=1.51, validation loss=2.32]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:24<00:00,  1.54it/s, Train Loss=1.51, validation loss=2.32]
----------------------------------------------------------------------------------------------------
-- Validation ste:
Loss: 2.315172851085663
Average AUC ROC: 0.55                    Average AUC PR: 0.31
